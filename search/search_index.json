{"config": {"lang": ["en"], "separator": "[\\s\\-]+", "pipeline": ["stopWordFilter"]}, "docs": [{"location": "", "title": "Home", "text": ""}, {"location": "#welcome-to-thehive-5-documentation-website", "title": "Welcome to TheHive 5 documentation website", "text": "<p>For full documentation visit mkdocs.org.</p>"}, {"location": "cortex/", "title": "Home", "text": "Cortex : Installation, operation and user guides    <p>Source Code: https://github.com/thehive-project/Cortex/</p> <p>Website: https://www.strangebee.com</p>"}, {"location": "cortex/#cortex", "title": "Cortex", "text": "<p>Cortex solves two common problems frequently encountered by SOCs, CSIRTs and security researchers in the course of threat intelligence, digital forensics and incident response:</p> <ul> <li>How to analyze observables they have collected, at scale, by querying a single tool instead of several?</li> <li>How to actively respond to threats and interact with the constituency and other teams?</li> </ul> <p>Thanks to its many analyzers and to its RESTful API, Cortex makes observable analysis a breeze, particularly if called from TheHive, the highly popular, Security Incident Response Platform (SIRP). </p> <p>TheHive can also leverage Cortex responders to perform specific actions on alerts, cases, tasks and observables collected in the course of the investigation: send an email to the constituents, block an IP address at the proxy level, notify team members that an alert needs to be taken care of urgently and much more.</p> <p>Many features are included with Cortex: </p> <ul> <li>Manage multiple organizations (i.e multi-tenancy)</li> <li>Manage users per organizations and roles</li> <li>Specify per-org analyzer &amp; responder configuration</li> <li>Define rate limits: avoid consuming all your quotas at once</li> <li>Cache: an analysis is not re-executed for the same observable if a given analyzer is called on that observable several times within a specific timespan (10 minutes by default, can be adjusted for each analyzer).</li> </ul>"}, {"location": "cortex/#installation-and-configuration-guides", "title": "Installation and configuration guides", "text": "<p>This documentation contains step-by-step installation instructions for Cortex for different operating systems as well as corresponding binary archives. </p> <p>All aspects of the configuration are aslo detailled in a dedicated section. s</p>"}, {"location": "cortex/#user-guides", "title": "User guides", "text": "<p>The first connection to the application requires several actions. </p> <p>Cortex supports differents roles for users. Refer to User roles for more details.</p>"}, {"location": "cortex/#license", "title": "License", "text": "<p>Cortex is an open source and free software released under the AGPL (Affero General Public License). We, StrangeBee, are committed to ensure that Cortex will remain a free and open source project on the long-run.</p>"}, {"location": "cortex/#updates-and-community-discussions", "title": "Updates and community discussions", "text": "<p>Information, news and updates are regularly posted on several communication channels:</p> <p> StrangeBee Twitter account / TheHive Project Twitter account</p> <p> TheHive Project Mastodon account / StrangeBee Mastodon account</p> <p> blog at StrangeBee</p> <p> Join users community on Discord</p>"}, {"location": "cortex/#professional-support", "title": "Professional support", "text": "<p> Since 2018, Cortex is fully developped and maintained by StrangeBee. Should you need specific assistance, be aware that StrangeBee also provides professional services and support.</p>"}, {"location": "cortex/code-of-conduct/", "title": "Contributor Covenant Code of Conduct", "text": ""}, {"location": "cortex/code-of-conduct/#contributor-covenant-code-of-conduct", "title": "Contributor Covenant Code of Conduct", "text": ""}, {"location": "cortex/code-of-conduct/#our-pledge", "title": "Our Pledge", "text": "<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"}, {"location": "cortex/code-of-conduct/#our-standards", "title": "Our Standards", "text": "<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or   advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic   address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"}, {"location": "cortex/code-of-conduct/#our-responsibilities", "title": "Our Responsibilities", "text": "<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior, in compliance with the licensing terms applying to the Project developments.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. However, these actions shall respect the licensing terms of the Project Developments that will always supersede such Code of Conduct.</p>"}, {"location": "cortex/code-of-conduct/#scope", "title": "Scope", "text": "<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"}, {"location": "cortex/code-of-conduct/#enforcement", "title": "Enforcement", "text": "<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at support@thehive-project.org. The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"}, {"location": "cortex/code-of-conduct/#attribution", "title": "Attribution", "text": "<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at http://contributor-covenant.org/version/1/4</p> <p>This version includes a clarification to ensure that the code of conduct is in compliance with the free software licensing terms of the project.</p>"}, {"location": "cortex/api/api-guide/", "title": "API Guide", "text": ""}, {"location": "cortex/api/api-guide/#api-guide", "title": "API Guide", "text": "<p>This guide applies only to Cortex 2 and newer. It is not applicable to Cortex 1.</p>"}, {"location": "cortex/api/api-guide/#table-of-contents", "title": "Table of Contents", "text": "<ul> <li>Introduction<ul> <li>Request &amp; Response Formats</li> <li>Authentication</li> </ul> </li> <li>Organization APIs<ul> <li>Organization Model</li> <li>List</li> <li>Create an Organization</li> <li>Update an Organization</li> <li>Delete an Organization</li> <li>Obtain Details</li> <li>List Users</li> <li>List Enabled Analyzers</li> </ul> </li> <li>User APIs<ul> <li>User Model</li> <li>List All</li> <li>List Users within an Organization</li> <li>Search</li> <li>Create a User</li> <li>Update a User</li> <li>Get Details About a User</li> <li>Set a Password</li> <li>Change a password</li> <li>Set and Renew an API Key</li> <li>Get an API Key</li> <li>Revoke an API Key</li> </ul> </li> <li>Job APIs<ul> <li>Job Model</li> <li>List and Search Jobs</li> <li>Get Details About a Job</li> <li>Get Details and Report</li> <li>Wait and Get Job Report</li> <li>Get Artifacts</li> <li>Delete a Job</li> </ul> </li> <li>Analyzer APIs<ul> <li>Analyzer Model</li> <li>Enable</li> <li>List and Search</li> <li>Get Details</li> <li>Get By Type</li> <li>Update</li> <li>Run</li> <li>Disable</li> </ul> </li> <li>Miscellaneous APIs<ul> <li>Paging and Sorting</li> </ul> </li> </ul>"}, {"location": "cortex/api/api-guide/#introduction", "title": "Introduction", "text": "<p>Cortex 2 offers a REST API that can be leveraged by various applications and programs to interact with it. The following guide describe the Cortex 2 API to allow developers to interface the powerful observable analysis engine with other SIRPs (Security Incident Response Platforms) besides TheHive, TIPs (Threat Intelligence Platforms), SIEMs or scripts. Please note that the Web UI of Cortex 2 exclusively leverage the REST API to interact with the back-end.</p> <p>Note: You can use Cortex4py, the Python library we provide, to facilitate interaction with the REST API of Cortex. You need Cortex4py 2.0.0 or later as earlier versions are not compatible with Cortex 2.</p> <p>All the exposed APIs share the same request &amp; response formats and authentication strategies as described below.</p> <p>There are also some transverse parameters supported by several calls, in addition to utility APIs.</p> <p>If you want to create an analyzer, please read the How to Write and Submit an Analyzer  guide.</p>"}, {"location": "cortex/api/api-guide/#request-and-response-formats", "title": "Request and Response Formats", "text": "<p>Cortex accepts several parameter formats within a HTTP request. They can be used indifferently. Input data can be:</p> <ul> <li>A query string</li> <li>A URL-encoded form</li> <li>A multi-part</li> <li>JSON</li> </ul> <p>Hence, the requests shown below are equivalent.</p>"}, {"location": "cortex/api/api-guide/#query-string", "title": "Query String", "text": "<pre><code>curl -XPOST 'https://CORTEX_APP_URL:9001/api/login?user=me&amp;password=secret'\n</code></pre>"}, {"location": "cortex/api/api-guide/#url-encoded-form", "title": "URL-encoded Form", "text": "<pre><code>curl -XPOST 'https://CORTEX_APP_URL:9001/api/login' -d user=me -d password=secret\n</code></pre>"}, {"location": "cortex/api/api-guide/#json", "title": "JSON", "text": "<pre><code>curl -XPOST https://CORTEX_APP_URL:9001/api/login -H 'Content-Type: application/json' -d '{\n  \"user\": \"me\",\n  \"password\": \"secret\"\n}'\n</code></pre>"}, {"location": "cortex/api/api-guide/#multi-part", "title": "Multi-part", "text": "<pre><code>curl -XPOST https://CORTEX_APP_URL:9001/api/login -F '_json=&lt;-;type=application/json' &lt;&lt; _EOF_\n{\n  \"user\": \"me\",\n  \"password\": \"secret\"\n}\n_EOF_\n</code></pre>"}, {"location": "cortex/api/api-guide/#response-format", "title": "Response Format", "text": "<p>For each request submitted, Cortex will respond back with JSON data. For example, if the authentication request is successful, Cortex should return the following output:</p> <pre><code>{\"id\":\"me\",\"name\":\"me\",\"roles\":[\"read\",\"analyze\",\"orgadmin\"]}\n</code></pre> <p>If not, Cortex should return an authentication error:</p> <pre><code>{\"type\":\"AuthenticationError\",\"message\":\"Authentication failure\"}\n</code></pre>"}, {"location": "cortex/api/api-guide/#authentication", "title": "Authentication", "text": "<p>Most API calls require authentication. Credentials can be provided using a session cookie, an API key or directly using HTTP basic authentication (if this method is specifically enabled).</p> <p>Session cookies are better suited for browser authentication. Hence, we recommend authenticating with API keys when calling the Cortex APIs.</p>"}, {"location": "cortex/api/api-guide/#generating-api-keys-with-an-orgadmin-account", "title": "Generating API Keys with an orgAdmin Account", "text": "<p>API keys can be generated using the Web UI. To do so, connect using an <code>orgAdmin</code> account then click on Organization and then on the <code>Create API Key</code> button in the row corresponding to the user you intend to use for API authentication. Once the API key has been created, click on <code>Reveal</code> to display the API key then click on the copy to clipboard button if you wish to copy the key to your system's clipboard.</p> <p>If the user is not yet created, start by clicking on <code>Add user</code> to create it then follow the steps mentioned above.</p>"}, {"location": "cortex/api/api-guide/#generating-api-keys-with-a-superadmin-account", "title": "Generating API Keys with a superAdmin Account", "text": "<p>You can use a <code>superAdmin</code> account to achieve the same result as described above. Once authenticated, click on Users then on the <code>Create API Key</code> button in the row corresponding to the user you intend to use for API authentication. Please make sure the user is in the right organization by thoroughly reading its name, which is shown below the user name. Once the API key has been created, click on <code>Reveal</code> to display the API key then click on the copy to clipboard button if you wish to copy the key to your system's clipboard.</p>"}, {"location": "cortex/api/api-guide/#authenticating-with-an-api-key", "title": "Authenticating with an API Key", "text": "<p>Once you have generated an API key you can use it, for example, to list the Cortex jobs thanks to the following <code>curl</code> command:</p> <p></p><pre><code># Using API key\ncurl -H 'Authorization: Bearer **API_KEY**' https://CORTEX_APP_URL:9001/api/job\n</code></pre> As you can see in the example above, we instructed <code>curl</code> to add the Authorization header to the request. The value of the header is <code>Bearer: **API_KEY**</code>. So if your API key is <code>GPX20GUAQWwpqnhA6JpOwNGPMfWuxsX3</code>, the <code>curl</code> command above would look like the following: <pre><code># Using API key\ncurl -H 'Authorization: Bearer GPX20GUAQWwpqnhA6JpOwNGPMfWuxsX3' https://CORTEX_APP_URL:9001/api/job\n</code></pre>"}, {"location": "cortex/api/api-guide/#using-basic-authentication", "title": "Using Basic Authentication", "text": "<p>Cortex also supports basic authentication but it is disabled by default for security reasons. If you absolutely need to use it, you can enable it by adding <code>auth.method.basic=true</code> to the configuration file (<code>/etc/cortex/application.conf</code> by default). Once you do, restart the Cortex service. You can then, for example, list the Cortex jobs using the following <code>curl</code> command:</p> <pre><code># Using basic authentication\ncurl -u mylogin:mypassword https://CORTEX_APP_URL:9001/api/job\n</code></pre>"}, {"location": "cortex/api/api-guide/#organization-apis", "title": "Organization APIs", "text": "<p>Cortex offers a set of APIs to create, update and list organizations.</p>"}, {"location": "cortex/api/api-guide/#organization-model", "title": "Organization Model", "text": "<p>An organization (org) is defined by the following attributes:</p> Attribute Description Type <code>id</code> Copy of the org's name (see next row) readonly <code>name</code> Name readonly <code>status</code> Status (<code>Active</code> or <code>Locked</code>) writable <code>description</code> Description writable <code>createdAt</code> Creation date computed <code>createdBy</code> User who created the org computed <code>updatedAt</code> Last update computed <code>updatedBy</code> User who last updated the org computed <p>Please note that <code>id</code> and <code>name</code> are essentially the same. Also, <code>createdAt</code> and <code>updatedAt</code> are in epoch.</p>"}, {"location": "cortex/api/api-guide/#list", "title": "List", "text": "<p>It is possible to list all the organizations using the following API call, which requires the API key associated with a <code>superAdmin</code> account:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization'\n</code></pre> <p>You can also search/filter organizations using the following query:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/organization/_search' -d '{\n  \"query\": {\"status\": \"Active\"}\n}'\n</code></pre> <p>Both APIs supports the <code>range</code> and <code>sort</code> query parameters described in paging and sorting details.</p>"}, {"location": "cortex/api/api-guide/#create-an-organization", "title": "Create an Organization", "text": "<p>It is possible to create an organization using the following API call, which requires the API key associated with a <code>superAdmin</code> account:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/organization' -d '{\n  \"name\": \"demo\",\n  \"description\": \"Demo organization\",\n  \"status\": \"Active\"\n}'\n</code></pre>"}, {"location": "cortex/api/api-guide/#update-an-organization", "title": "Update an Organization", "text": "<p>You can update an organization's description and status (<code>Active</code> or <code>Locked</code>) using the following API call. This requires the API key associated with a <code>superAdmin</code> account:</p> <pre><code>curl -XPATCH -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID' -d '{\n  \"description\": \"New Demo organization\",\n}'\n</code></pre> <p>or</p> <pre><code>curl -XPATCH -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID' -d '{\n  \"status\": \"Active\",\n}'\n</code></pre>"}, {"location": "cortex/api/api-guide/#delete-an-organization", "title": "Delete an Organization", "text": "<p>Deleting an organization just marks it as <code>Locked</code> and doesn't remove the associated data from the DB. To \"delete\" an organization, you can use the API call shown below. It requires the API key associated with a <code>superAdmin</code> account.</p> <pre><code>curl -XDELETE -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID'\n</code></pre>"}, {"location": "cortex/api/api-guide/#obtain-details", "title": "Obtain Details", "text": "<p>This API call returns the details of an organization as described in the Organization model section.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID'\n</code></pre> <p>Let's assume that the organization we are seeking to obtain details about is called demo. The <code>curl</code> command would be:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization/demo'\n</code></pre> <p>and it should return:</p> <pre><code>{\n  \"id\": \"demo\",\n  \"name\": \"demo\",\n  \"status\": \"Active\",\n  \"description\": \"Demo organization\",\n  \"createdAt\": 1520258040437,\n  \"createdBy\": \"superadmin\",\n  \"updatedBy\": \"superadmin\",\n  \"updatedAt\": 1522077420693\n}\n</code></pre>"}, {"location": "cortex/api/api-guide/#list-users", "title": "List Users", "text": "<p>As mentioned above, you can use the API to return the list of all the users declared withing an organization. For that purpose, use the API call shown below with the API key of an <code>orgAdmin</code> or <code>superAdmin</code> account. It supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID/user'\n</code></pre> <p>and should return a list of users.</p> <p>If one wants to filter/search for some users (active ones for example), there is a search API to use as below:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID/user/_search' -d '{\n  \"query\": {}\n}'\n</code></pre> <p>It also supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details.</p>"}, {"location": "cortex/api/api-guide/#list-enabled-analyzers", "title": "List Enabled Analyzers", "text": "<p>To list the analyzers that have been enabled within an organization, use the following API call with the API key of an <code>orgAdmin</code> user:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/analyzer'\n</code></pre> <p>It should return a list of Analyzers.</p> <p>Please note that this API call does not display analyzers that are disabled. It supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details.</p>"}, {"location": "cortex/api/api-guide/#user-apis", "title": "User APIs", "text": "<p>The following section describes the APIs that allow creating, updating and listing users within an organization.</p>"}, {"location": "cortex/api/api-guide/#user-model", "title": "User Model", "text": "<p>A user is defined by the following attributes:</p> Attribute Description Type <code>id</code> ID/login readonly <code>name</code> Name writable <code>roles</code> Roles. Possible values are: <code>read</code>, <code>read,analyze</code>, <code>read,analyze,orgadmin</code> and <code>superadmin</code> writable <code>status</code> Status (<code>Active</code> or <code>Locked</code>) writable <code>organization</code> organization to which the user belongs (set upon account creation) readonly <code>createdAt</code> Creation date computed <code>createdBy</code> User who created the account computed <code>updatedAt</code> Last update date computed <code>updatedBy</code> User who last updated the account computed <code>hasKey</code> true when the user has an API key computed <code>hasPassword</code> true if the user has a password computed"}, {"location": "cortex/api/api-guide/#list-all", "title": "List All", "text": "<p>This API call allows a <code>superAdmin</code> to list and search all the users of all defined organizations:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/user'\n</code></pre> <p>This call supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details.</p>"}, {"location": "cortex/api/api-guide/#list-users-within-an-organization", "title": "List Users within an Organization", "text": "<p>This call is described in organization APIs.</p>"}, {"location": "cortex/api/api-guide/#search", "title": "Search", "text": "<p>This API call allows a <code>superAdmin</code> to perform search on the user accounts created in a Cortex instance:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/user/_search' -d '{\n  \"query\": {}\n}'\n</code></pre> <p>This call supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details</p>"}, {"location": "cortex/api/api-guide/#create-a-user", "title": "Create a User", "text": "<p>This API calls allows you to programmatically create user creation. If the call is made by a <code>superAdmin</code> user, the request must specify the organization to which the user belong in the <code>organization</code> field.</p> <p>If the call is made by an <code>orgAdmin</code> user, the value of <code>organization</code> field must be the same as the user who makes the call: <code>orgAdmin</code> users are allowed to create users only in their organization.</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/user' -d '{\n  \"name\": \"Demo org Admin\",\n  \"roles\": [\n    \"read\",\n    \"analyze\",\n    \"orgadmin\"\n  ],\n  \"organization\": \"demo\",\n  \"login\": \"demo\"\n}'\n</code></pre> <p>If successful, the call returns a JSON object representing the created user as described above.</p> <pre><code>{\n  \"id\": \"demo\",\n  \"organization\": \"demo\",\n  \"name\": \"Demo org Admin\",\n  \"roles\": [\n    \"read\",\n    \"analyze\",\n    \"orgadmin\"\n  ],\n  \"status\": \"Ok\",\n  \"createdAt\": 1526050123286,\n  \"createdBy\": \"superadmin\",\n  \"hasKey\": false,\n  \"hasPassword\": false\n}\n</code></pre>"}, {"location": "cortex/api/api-guide/#update-a-user", "title": "Update a User", "text": "<p>This API call allows updating the writable attributed of a user account. It's available to users with <code>superAdmin</code> or <code>orgAdmin</code> roles. Any user can also use it to update their own information (but obviously not their roles).</p> <pre><code>curl -XPATCH -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN' -d '{\n  \"name\": \"John Doe\",\n  \"roles\": [\n    \"read\",\n    \"analyze\"\n  ],\n  \"status\": \"Locked\"\n}'\n</code></pre> <p>It returns a JSON object representing the updated user as described above.</p>"}, {"location": "cortex/api/api-guide/#get-details-about-a-user", "title": "Get Details About a User", "text": "<p>This call returns the user details. It's available to users with <code>superAdmin</code> roles and to users in the same organization. Every user can also use it to read their own details.</p> <p></p><pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN'\n</code></pre> It returns a JSON object representing the user as described previously."}, {"location": "cortex/api/api-guide/#set-a-password", "title": "Set a Password", "text": "<p>This call sets the user's password. It's available to users with <code>superAdmin</code> or <code>orgAdmin</code> roles. Please note that the request needs to be made using HTTPS with a valid certificate on the server's end to prevent credential sniffing or other PITM (Person-In-The-Middle) attacks.</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN/password/set' -d '{\n  \"password\": \"SOMEPASSWORD\"\n}'\n</code></pre> <p>If successful, the call returns 204 (success / no content).</p>"}, {"location": "cortex/api/api-guide/#change-a-password", "title": "Change a password", "text": "<p>This call allows a given user to change only their own existing password. It is available to all users including <code>superAdmin</code> and <code>orgAdmin</code> ones. Please note that if a <code>superAdmin</code> or an <code>orgAdmin</code> needs to update the password of another user, they must use the <code>/password/set</code> call described in the previous subsection.</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN/password/change' -d '{\n  \"currentPassword\": \"password\",\n  \"password\": \"new-password\"\n}'\n</code></pre> <p>If successful, the call returns 204 (success / no content).</p>"}, {"location": "cortex/api/api-guide/#set-and-renew-an-api-key", "title": "Set and Renew an API Key", "text": "<p>This calls allows setting and renewing the API key of a user. It's available to users with <code>superAdmin</code> or <code>orgAdmin</code> roles. Any user can also use it to renew their own API key. Again, the request needs to be made using HTTPS with a valid certificate on the server's end to prevent credential sniffing or other PITM (Person-In-The-Middle) attacks. You know the drill ;-)</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN/key/renew'\n</code></pre> <p>If successful, it returns the generated API key in a <code>text/plain</code>response.</p>"}, {"location": "cortex/api/api-guide/#get-an-api-key", "title": "Get an API Key", "text": "<p>This calls allows getting a user's API key. It's available to users with <code>superAdmin</code> or <code>orgAdmin</code> roles. Any user can also use it to obtain their own API key.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN/key'\n</code></pre> <p>If successful, the generated API key is returned in <code>text/plain</code>response</p>"}, {"location": "cortex/api/api-guide/#revoke-an-api-key", "title": "Revoke an API Key", "text": "<p>This calls allow revoking a user's API key. This calls allow revoking a user's API key.</p> <pre><code>curl -XDELETE -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN/key'\n</code></pre> <p>A successful request returns nothing (HTTP 200 OK).</p>"}, {"location": "cortex/api/api-guide/#job-apis", "title": "Job APIs", "text": "<p>The following section describes the APIs that allow manipulating jobs. Jobs are basically submissions made to analyzers and the resulting reports.</p>"}, {"location": "cortex/api/api-guide/#job-model", "title": "Job Model", "text": "<p>A job is defined by the following attributes:</p> Attribute Description Type <code>id</code> Job ID computed <code>organization</code> The organization to which the job belongs readonly <code>analyzerDefinitionId</code> Analyzer definition name readonly <code>analyzerId</code> Instance ID of the analyzer to which the job is associated readonly <code>organization</code> Organization to which the user belongs (set upon account creation) readonly <code>analyzerName</code> Name of the analyzer to which the job is associated readonly <code>dataType</code> the datatype of the analyzed observable readonly <code>status</code> Status of the job (<code>Waiting</code>, <code>InProgress</code>, <code>Success</code>, <code>Failure</code>, <code>Deleted</code>) computed <code>data</code> Value of the analyzed observable (does not apply to <code>file</code> observables) readonly <code>attachment</code> JSON object representing <code>file</code> observables (does not apply to non-<code>file</code> observables). It  defines the<code>name</code>, <code>hashes</code>, <code>size</code>, <code>contentType</code> and <code>id</code> of the <code>file</code> observable readonly <code>parameters</code> JSON object of key/value pairs set during job creation readonly <code>message</code> A free text field to set additional text/context for a job readonly <code>tlp</code> The TLP of the analyzed observable readonly <code>startDate</code> Start date computed <code>endDate</code> End date computed <code>createdAt</code> Creation date. Please note that a job can be requested but not immediately honored. The actual time at which it is started is the value of <code>startDate</code> computed <code>createdBy</code> User who created the job computed <code>updatedAt</code> Last update date (only Cortex updates a job when it finishes) computed <code>updatedBy</code> User who submitted the job and which identity is used by Cortex to update the job once it is finished computed"}, {"location": "cortex/api/api-guide/#list-and-search-jobs", "title": "List and Search Jobs", "text": "<p>This call allows a user with <code>read</code>,<code>analyze</code> or <code>orgAdmin</code> role to list and search all the analysis jobs made by their organization.</p> <p>If you want to list all the jobs: </p><pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/_search?range=all'\n</code></pre> <p>If you want to list 10 jobs: </p><pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/_search'\n</code></pre> <p>If you want to list 100 jobs: </p><pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/_search?range=0-100'\n</code></pre> <p>If you want to search jobs according to various criteria: </p><pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/job/_search' -d '{\n  \"query\": {\n    \"_and\": [\n      {\"status\": \"Success\"},\n      {\"dataType\": \"ip\"}\n    ]\n  }\n}'\n</code></pre> <p>This call supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details</p>"}, {"location": "cortex/api/api-guide/#get-details", "title": "Get Details", "text": "<p>This call allows a user with <code>read</code>,<code>analyze</code> or <code>orgAdmin</code> role to get the details of a job. It does not fetch the job report.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/JOB_ID'\n</code></pre> <p>It returns a JSON response with the following structure:</p> <pre><code>{\n  \"id\": \"AWNei4vH3rJ8unegCPB9\",\n  \"analyzerDefinitionId\": \"Abuse_Finder_2_0\",\n  \"analyzerId\": \"220483fde9608c580fb6a2508ff3d2d3\",\n  \"analyzerName\": \"Abuse_Finder_2_0\",\n  \"status\": \"Success\",\n  \"data\": \"8.8.8.8\",\n  \"parameters\": \"{}\",\n  \"tlp\": 0,\n  \"message\": \"\",\n  \"dataType\": \"ip\",\n  \"organization\": \"demo\",\n  \"startDate\": 1526299593923,\n  \"endDate\": 1526299597064,\n  \"date\": 1526299593633,\n  \"createdAt\": 1526299593633,\n  \"createdBy\": \"demo\",\n  \"updatedAt\": 1526299597066,\n  \"updatedBy\": \"demo\"\n}\n</code></pre>"}, {"location": "cortex/api/api-guide/#get-details-and-report", "title": "Get Details and Report", "text": "<p>This call allows a user with <code>read</code>,<code>analyze</code> or <code>orgAdmin</code> role to get the details of a job including its report.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/JOB_ID/report'\n</code></pre> <p>It returns a JSON response with the structure below. If the job is not yet completed, the <code>report</code> field contains a string representing the job status:</p> <pre><code>{\n  \"id\": \"AWNei4vH3rJ8unegCPB9\",\n  \"analyzerDefinitionId\": \"Abuse_Finder_2_0\",\n  \"analyzerId\": \"220483fde9608c580fb6a2508ff3d2d3\",\n  \"analyzerName\": \"Abuse_Finder_2_0\",\n  \"status\": \"Success\",\n  \"data\": \"8.8.8.8\",\n  \"parameters\": \"{}\",\n  \"tlp\": 0,\n  \"message\": \"\",\n  \"dataType\": \"ip\",\n  \"organization\": \"demo\",\n  \"startDate\": 1526299593923,\n  \"endDate\": 1526299597064,\n  \"date\": 1526299593633,\n  \"createdAt\": 1526299593633,\n  \"createdBy\": \"demo\",\n  \"updatedAt\": 1526299597066,\n  \"updatedBy\": \"demo\",\n  \"report\": {\n    \"summary\": {\n      \"taxonomies\": [\n        {\n          \"predicate\": \"Address\",\n          \"namespace\": \"Abuse_Finder\",\n          \"value\": \"network-abuse@google.com\",\n          \"level\": \"info\"\n        }\n      ]\n    },\n    \"full\": {\n      \"abuse_finder\": {\n        \"raw\": \"...\",\n        \"abuse\": [\n          \"network-abuse@google.com\"\n        ],\n        \"names\": [\n          \"Google LLC\",\n          \"Level 3 Parent, LLC\"\n        ],\n        \"value\": \"8.8.8.8\"\n      }\n    },\n    \"success\": true,\n    \"artifacts\": []\n  }\n}\n</code></pre>"}, {"location": "cortex/api/api-guide/#wait-and-get-job-report", "title": "Wait and Get Job Report", "text": "<p>This call is similar the one described above but allows the user to provide a timeout to wait for the report in case it is not available at the time the query was made:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/JOB_ID/waitreport?atMost=1minute'\n</code></pre> <p>The <code>atMost</code> is a duration using the format <code>Xhour</code>, <code>Xminute</code> or <code>Xsecond</code>.</p>"}, {"location": "cortex/api/api-guide/#get-artifacts", "title": "Get Artifacts", "text": "<p>This call allows a user with <code>read</code>,<code>analyze</code> or <code>orgAdmin</code> role to get the extracted artifacts from a job if such extraction has been enabled in the corresponding analyzer configuration. Please note that extraction is imperfect and you might have inconsistent or incorrect data.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/JOB_ID/artifacts'\n</code></pre> <p>It returns a JSON array with the following structure:</p> <pre><code>[\n  {\n    \"dataType\": \"ip\",\n    \"createdBy\": \"demo\",\n    \"data\": \"8.8.8.8\",\n    \"tlp\": 0,\n    \"createdAt\": 1525432900553,\n    \"id\": \"AWMq4tvLjidKq_asiwcl\"\n  }\n]\n</code></pre>"}, {"location": "cortex/api/api-guide/#delete-a-job", "title": "Delete a Job", "text": "<p>This API allows a user with <code>analyze</code> or <code>orgAdmin</code> role to delete a job:</p> <pre><code>curl -XDELETE -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/JOB_ID'\n</code></pre> <p>This marks the job as <code>Deleted</code>. However the job's data is not removed from the  database.</p>"}, {"location": "cortex/api/api-guide/#analyzer-apis", "title": "Analyzer APIs", "text": "<p>The following section describes the APIs that allow manipulating analyzers.</p>"}, {"location": "cortex/api/api-guide/#analyzer-model", "title": "Analyzer Model", "text": "<p>An analyzer is defined by the following attributes:</p> Attribute Description Type <code>id</code> Analyzer ID once enabled within an organization readonly <code>analyzerDefinitionId</code> Analyzer definition name readonly <code>name</code> Name of the analyzer readonly <code>version</code> Version of the analyzer readonly <code>description</code> Description of the analyzer readonly <code>author</code> Author of the analyzer readonly <code>url</code> URL where the analyzer has been published readonly <code>license</code> License of the analyzer readonly <code>dataTypeList</code> Allowed datatypes readonly <code>baseConfig</code> Base configuration name. This identifies the shared set of configuration with all the analyzer's flavors readonly <code>jobCache</code> Report cache timeout in minutes, visible for <code>orgAdmin</code> users only writable <code>rate</code> Numeric amount of analyzer calls authorized for the specified <code>rateUnit</code>, visible for <code>orgAdmin</code> users only writable <code>rateUnit</code> Period of availability of the rate limite: <code>Day</code> or <code>Month</code>, visible for <code>orgAdmin</code> users only writable <code>configuration</code> A JSON object where key/value pairs represent the config names, and their values. It includes the default properties <code>proxy_http</code>, <code>proxy_https</code>, <code>auto_extract_artifacts</code>, <code>check_tlp</code>, and <code>max_tlp</code>, visible for <code>orgAdmin</code> users only writable <code>createdBy</code> User who enabled the analyzer computed <code>updatedAt</code> Last update date computed <code>updatedBy</code> User who last updated the analyzer computed"}, {"location": "cortex/api/api-guide/#enable", "title": "Enable", "text": "<p>This call allows a user with an <code>orgAdmin</code> role to enable an analyzer.</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization/analyzer/:analyzerId' -d '{\n  \"name\": \"Censys_1_0\",\n  \"configuration\": {\n    \"uid\": \"XXXX\",\n    \"key\": \"XXXXXXXXXXXXXXXXXXXX\",\n    \"proxy_http\": \"http://proxy:9999\",\n    \"proxy_https\": \"http://proxy:9999\",\n    \"auto_extract_artifacts\": false,\n    \"check_tlp\": true,\n    \"max_tlp\": 2\n  },\n  \"rate\": 1000,\n  \"rateUnit\": \"Day\",\n  \"jobCache\": 5\n}'\n</code></pre>"}, {"location": "cortex/api/api-guide/#list-and-search", "title": "List and Search", "text": "<p>These calls allow a user with a <code>analyze</code> or <code>orgAdmin</code> role to list and search all the enabled analyzers within the organization.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/analyzer'\n</code></pre> <p>or</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/analyzer/_search' -d '{\n  \"query\": {}\n}'\n</code></pre> <p>Both calls supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details, and both return a JSON array of analyzer objects as described in Analyzer Model section.</p> <p>If called by a user with only an <code>nalyzer</code> role, the <code>configuration</code> attribute is not included on the JSON objects.</p>"}, {"location": "cortex/api/api-guide/#get-details-about-a-job", "title": "Get Details About a Job", "text": "<p>This call allows a user with a <code>analyze</code> or <code>orgAdmin</code> role to get an analyzer's details.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID'\n</code></pre> <p>It returns a analyzer JSON object as described in Analyzer Model section.</p> <p>If called by a user with only an <code>nalyzer</code> role, the <code>configuration</code> attribute is not included on the JSON objects.</p>"}, {"location": "cortex/api/api-guide/#get-by-type", "title": "Get By Type", "text": "<p>This call is mostly used by TheHive and allows to quickly get the list of analyzers that can run on the given datatype. It requires an <code>analyze</code> or <code>orgAdmin</code> role.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/analyzer/type/DATA_TYPE'\n</code></pre> <p>It returns a JSON array of analyzer objects as described in Analyzer Model section without the <code>configuration</code> attribute, which could contain sensitive data.</p>"}, {"location": "cortex/api/api-guide/#update", "title": "Update", "text": "<p>This call allows an <code>orgAdmin</code> user to update the <code>name</code>, <code>configuration</code> and <code>jobCache</code> of an enabled analyzer.</p> <pre><code>curl -XPATCH -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID' -d '{\n  \"configuration\": {\n    \"key\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n    \"polling_interval\": 60,\n    \"proxy_http\": \"http://localhost:8080\",\n    \"proxy_https\": \"http://localhost:8080\",\n    \"auto_extract_artifacts\": true,\n    \"check_tlp\": true,\n    \"max_tlp\": 1\n  },\n  \"name\": \"Shodan_Host_1_0\",\n  \"rate\": 1000,\n  \"rateUnit\": \"Day\",\n  \"jobCache\": null\n}'\n</code></pre> <p>It returns a JSON object describing the analyzer as defined in Analyzer Model section.</p>"}, {"location": "cortex/api/api-guide/#run", "title": "Run", "text": "<p>This API allows a user with a <code>analyze</code> or <code>orgAdmin</code> role to run analyzers on observables of different datatypes.</p> <p>For <code>file</code> observables, the API call must be made as described below:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID/run' \\\n  -F 'attachment=@/path/to/observable-file' \\\n  -F '_json=&lt;-;type=application/json' &lt;&lt; _EOF_\n  {\n    \"dataType\":\"file\",\n    \"tlp\":0\n  }\n_EOF_\n</code></pre> <p>for all the other types of observerables, the request is:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID/run' -d '{\n  \"data\":\"8.8.8.8\",\n  \"dataType\":\"ip\",\n  \"tlp\":0,\n  \"message\": \"A message that can be accessed from the analyzer\",\n  \"parameters\": {\n    \"key1\": \"value1\",\n    \"key2\": \"value2\"\n  }\n}'\n</code></pre> <p>This call will fetch a similar job from the cache, and if it finds one, it returns it from the cache, based on the duration defined in <code>jobCache</code> attribute of the analyzer.</p> <p>To force bypassing the cache, one can add the following query parameter: <code>force=1</code></p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID/run?force=1' -d '{\n  \"data\":\"8.8.8.8\",\n  \"dataType\":\"ip\",\n  \"tlp\":0,\n  \"message\": \"A message that can be accessed from the analyzer\",\n  \"parameters\": {\n    \"key1\": \"value1\",\n    \"key2\": \"value2\"\n  }\n}'\n</code></pre>"}, {"location": "cortex/api/api-guide/#disable", "title": "Disable", "text": "<p>This API allows an <code>orgAdmin</code> to disable an existing analyzer in their organization and delete the corresponding configuration.</p> <pre><code>curl -XDELETE -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID'\n</code></pre>"}, {"location": "cortex/api/api-guide/#miscellaneous-apis", "title": "Miscellaneous APIs", "text": ""}, {"location": "cortex/api/api-guide/#paging-and-sorting", "title": "Paging and Sorting", "text": "<p>All the <code>search</code> API calls allow sorting and paging parameters, in addition to a query in the request's body. These calls usually have URLs ending with the <code>_search</code> keyword but that's not always the case.</p> <p>The followings are query parameters:</p> <ul> <li><code>range</code>: <code>all</code> or <code>x-y</code> where <code>x</code> and <code>y</code> are numbers (ex: 0-10).</li> <li><code>sort</code>: you can provide multiple sort criteria such as: <code>-createdAt</code> or <code>+status</code>.</li> </ul> <p>Example:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'http://CORTEX_APP_URL:9001/api/organization/ORG_ID/user?range=0-10&amp;sort=-createdAt&amp;sort=+status' -d '{\n  \"query\": {}\n}'\n</code></pre>"}, {"location": "cortex/api/how-to-create-a-responder/", "title": "How to create a Responder", "text": ""}, {"location": "cortex/api/how-to-create-a-responder/#how-to-write-and-submit-a-responder", "title": "How to Write and Submit a Responder", "text": ""}, {"location": "cortex/api/how-to-create-a-responder/#table-of-contents", "title": "Table of Contents", "text": "<ul> <li>Writing a Responder<ul> <li>The Program</li> <li>Service Interaction Files (Flavors)</li> <li>Python Requirements</li> <li>Example: Mailer Responder Files</li> <li>Input</li> <li>Service Interaction Configuration Items</li> <li>Output</li> <li>The Cortexutils Python Library</li> </ul> </li> <li>Submitting a Responder<ul> <li>Check Existing Issues</li> <li>Open an Issue</li> <li>Review your Service Interaction File(s)</li> <li>Provide the List of Requirements</li> <li>Verify Execution</li> <li>Create a Pull Request</li> </ul> </li> <li>Need Help?</li> </ul>"}, {"location": "cortex/api/how-to-create-a-responder/#writing-a-responder", "title": "Writing a Responder", "text": "<p>A responder is a program that takes JSON input and do an action and produces a basic result of that action. Responders are very similar to analyzers though they have different purposes. Responders are made of at least 2 types of files:</p> <ul> <li>The program itself</li> <li>One or several service interaction files or flavors</li> <li>A Python requirements file, which is only necessary if the responder is written in Python.</li> </ul>"}, {"location": "cortex/api/how-to-create-a-responder/#the-program", "title": "The Program", "text": "<p>The first type of files a responder is made of is the core program that performs actions. It can be written in any programming language that is supported by Linux.</p> <p>you can write your responders in Python, Ruby, Perl or even Scala. However, the very handy <code>Cortexutils</code> library described below is in Python. It greatly facilitates responder development and it also provides some methods to quickly format the output to make it compliant with the JSON schema expected by TheHive.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#service-interaction-files-flavors", "title": "Service Interaction Files (Flavors)", "text": "<p>A responder must have at least one service interaction file. Such files contain key configuration information such as the responder's author information, the datatypes (<code>thehive:case</code>, <code>thehive:alert</code>, ...) the responder accepts as input and to which it applies to if used from TheHive, the TLP and PAP (or Permissible Actions Protocol) above which it will refuse to execute to protect against data leakage and to enforce sane OPSEC practices and so on.</p> <p>A responder can have two or more service interaction files to allow it to perform different actions.  We speak then of flavors. For example, a Mailer responder can send message using several body templates.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#python-requirements", "title": "Python Requirements", "text": "<p>If the responder is written in Python, a <code>requirements.txt</code> must be provided with the list of all the dependencies.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#example-mailer-responder-files", "title": "Example: Mailer Responder Files", "text": "<p>Below is a directory listing of the files corresponding to a Mailer responder.</p> <pre><code>responders/Mailer\n|-- Mailer.json\n|-- requirements.txt\n`-- mailer.py\n</code></pre>"}, {"location": "cortex/api/how-to-create-a-responder/#input", "title": "Input", "text": "<p>The input of a responder can be any JSON data, even a simple string. The submitter must send data with the structure expected by the program. The acceptable datatypes described in the Service Interaction files indicate what kind of data is expected. For example, if the program requires a <code>thehive:case</code> (i.e. it applies at the case level in TheHive), input must comply with TheHive case. Below an example of <code>thehive:case</code> input.</p> <pre><code>    {\n        \"data\": {\n        \"updatedAt\": 1606230814019,\n        \"tlp\": 2,\n        \"endDate\": 1606230814019,\n        \"description\": \"Case Description\",\n        \"tags\": [\n            \"tag\"\n        ],\n        \"caseId\": 157,\n        \"customFields\": {},\n        \"pap\": 2,\n        \"status\": \"Open\",\n        \"resolutionStatus\": \"Indeterminate\",\n        \"createdAt\": 1606183201646,\n        \"createdBy\": \"user\",\n        \"flag\": false,\n        \"severity\": 2,\n        \"metrics\": {},\n        \"owner\": \"user\",\n        \"title\": \"Title\",\n        \"updatedBy\": \"user\",\n        \"startDate\": 1606183201000,\n        \"impactStatus\": \"NotApplicable\",\n        \"_type\": \"case\",\n        \"_routing\": \"iwD693UBlJefU8pMrqOq\",\n        \"_parent\": null,\n        \"_id\": \"iwD693UBlJefU8pMrqOq\",\n        \"_seqNo\": 4572,\n        \"_primaryTerm\": 48,\n        \"id\": \"iwD693UBlJefU8pMrqOq\"\n        },\n        \"dataType\": \"thehive:case\",\n        \"tlp\": 2,\n        \"pap\": 2,\n        \"message\": \"\",\n        \"parameters\": {\n        \"user\": \"user\"\n        },\n        \"config\": {\n        \"proxy_https\": null,\n        \"cacerts\": null,\n        \"max_pap\": 2,\n        \"jobTimeout\": 30,\n        \"api_key\": \"3bDBUb7EL409MHOmXBkqsysZ1vpTab1Q\",\n        \"check_tlp\": true,\n        \"proxy_http\": null,\n        \"max_tlp\": 2,\n        \"url\": \"configured_url\",\n        \"check_pap\": true\n        }\n    }\n</code></pre> <p>In the addition to the input (<code>data</code> section) sent by the submitter, Cortex adds the <code>config</code> section which is the responder's specific configuration provided by an <code>orgAdmin</code> user when the responder is enabled in the Cortex UI. </p>"}, {"location": "cortex/api/how-to-create-a-responder/#example-service-interaction-file-for-the-mailer-responder", "title": "Example: Service Interaction File for the Mailer Responder", "text": "<p>The <code>&lt;==</code> sign and anything after it are comments that do no appear in the original file. </p><pre><code>{\n  \"name\": \"Mailer\",\n  \"version\": \"1.0\",\n  \"author\": \"CERT-BDF\",\n  \"url\": \"https://github.com/TheHive-Project/Cortex-Analyzers\",\n  \"license\": \"AGPL-V3\",\n  \"description\": \"Send an email with information from a TheHive case or alert\",\n  \"dataTypeList\": [\"thehive:case\", \"thehive:alert\", \"thehive:case_task\"],\n  \"command\": \"Mailer/mailer.py\",\n  \"baseConfig\": \"Mailer\",\n  \"configurationItems\": [\n    {\n      \"name\": \"from\",\n      \"description\": \"email address from which the mail is send\",\n      \"type\": \"string\", &lt;== defines what kind of data type the configuration item is (string, number)\n      \"multi\": false, &lt;== setting multi to true allows to pass a list of items\n      \"required\": true\n    },\n    {\n      \"name\": \"smtp_host\",\n      \"description\": \"SMTP server used to send mail\",\n      \"type\": \"string\",\n      \"multi\": false,\n      \"required\": true,\n      \"defaultValue\": \"localhost\"\n    },\n    {\n      \"name\": \"smtp_port\",\n      \"description\": \"SMTP server port\",\n      \"type\": \"number\",\n      \"multi\": false,\n      \"required\": true,\n      \"defaultValue\": 25\n    },\n    {\n      \"name\": \"smtp_user\",\n      \"description\": \"SMTP server user\",\n      \"type\": \"string\",\n      \"multi\": false,\n      \"required\": false,\n      \"defaultValue\": \"user\"\n    },\n    {\n      \"name\": \"smtp_pwd\",\n      \"description\": \"SMTP server password\",\n      \"type\": \"string\",\n      \"multi\": false,\n      \"required\": false,\n      \"defaultValue\": \"pwd\"\n    }\n  ]\n}\n</code></pre>"}, {"location": "cortex/api/how-to-create-a-responder/#service-interaction-configuration-items", "title": "Service Interaction Configuration Items", "text": ""}, {"location": "cortex/api/how-to-create-a-responder/#name", "title": "name", "text": "<p>Name of the specific service (or flavor) of the responder.</p> <p>If your responder has only one service interaction (i.e. performs only one action), it is the name of the responder's directory.</p> <p>If your responder performs several actions (i.e. comes in several flavors), you have to give a specific and meaningful name to each flavor.</p> <p>Each flavor's name appear in TheHive's responder list and in MISP when you use Cortex for attribute enrichment.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#version", "title": "version", "text": "<p>The version of the responder.</p> <p>You must increase major version numbers when new features are added, modifications are made to take into account API changes, report output is modified or when report templates (more on this later) are updated.</p> <p>You must increase minor version numbers when bugs are fixed.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#author", "title": "author", "text": "<p>You must provide your full name and/or your organization/team name when submitting a responder. Pseudos are not accepted. If you'd rather remain anonymous, please contact us at support@thehive-project.org prior to submitting your responder.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#url", "title": "url", "text": "<p>The URL where the responder is stored. This should ideally be <code>https://github.com/TheHive-Project/Cortex-Analyzers</code></p>"}, {"location": "cortex/api/how-to-create-a-responder/#license", "title": "license", "text": "<p>The license of the code. Ideally, we recommend using the AGPL-v3 license.</p> <p>Make sure your code's license is compatible with the license(s) of the various components and libraries you use if applicable.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#description", "title": "description", "text": "<p>Description of the responder. Please be concise and clear. The description is  shown in the Cortex UI and TheHive.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#datatypelist", "title": "dataTypeList", "text": "<p>The list of TheHive datatypes supported by the responder. Currently TheHive accepts the following datatypes:</p> <ul> <li><code>thehive:case</code></li> <li><code>thehive:case_artifact</code> (i.e. observable)</li> <li><code>thehive:alert</code></li> <li><code>thehive:case_task</code></li> <li><code>thehive:case_task_log</code> (i.e. task log)</li> </ul>"}, {"location": "cortex/api/how-to-create-a-responder/#baseconfig", "title": "baseConfig", "text": "<p>Name used to group configuration items common to several responders. This prevent the user to enter the same API key for all responder flavors. The Cortex responder config page group configuration items by their <code>baseConfig</code>.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#config", "title": "config", "text": "<p>Configuration dedicated to the responder's flavor. This is where we  typically specify the TLP level of observables allowed to be analyzed with the  <code>check_tlp</code> and <code>max_tlp</code> parameters. For example, if <code>max_tlp</code> is set to <code>2</code> (TLP:AMBER), TLP:RED observables cannot be analyzed.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#max_tlp", "title": "max_tlp", "text": "<p>The TLP level above which the responder must not be executed.</p> TLP max_tlp value Unknown -1 WHITE 0 GREEN 1 AMBER 2 RED 3"}, {"location": "cortex/api/how-to-create-a-responder/#check_tlp", "title": "check_tlp", "text": "<p>This is a boolean parameter. When <code>true</code>, <code>max_tlp</code> is checked. And if the input's TLP is above <code>max_tlp</code>, the responder is not executed.</p> <p>For consistency reasons, we do recommend setting both <code>check_tlp</code> and <code>max_tlp</code> even if <code>check_tlp</code> is set to <code>false</code>.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#max_pap", "title": "max_pap", "text": "<p>The PAP level above which the responder must not be executed.</p> TLP max_tlp value Unknown -1 WHITE 0 GREEN 1 AMBER 2 RED 3"}, {"location": "cortex/api/how-to-create-a-responder/#check_pap", "title": "check_pap", "text": "<p>This is a boolean parameter. When <code>true</code>, <code>max_pap</code> is checked. And if the input's PAP is above <code>max_pap</code>, the responder is not executed.</p> <p>For consistency reasons, we do recommend setting both <code>check_pap</code> and <code>max_pap</code> even if <code>check_pap</code> is set to <code>false</code>.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#command", "title": "command", "text": "<p>The command used to run the responder. That's typically the full, absolute path to the main program file.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#configurationitems", "title": "configurationItems", "text": "<p>The list of configurationItems is necessary in order to be able to set all configuration variables for responders directly in the Cortex 2 user interface. As in the VirusTotal example above can be seen, every item is a json object that defines: - name (string) - description (string) - type (string) - multi (boolean) - required (boolean) - defaultValue (according to type, optional)</p> <p>The <code>multi</code> parameter allows to pass a list as configuration variable instead of a single string or number. This is used e.g. in the MISP responder that queries multiple servers in one run and needs different parameters for that.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#output", "title": "Output", "text": "<p>The output of a responder depends on the success or failure of its execution.</p> <p>If the responder fails to execute:</p> <pre><code>{\n    \"success\": false,\n    \"errorMessage\":\"..\"\n}\n</code></pre> <ul> <li>When <code>success</code> is set to <code>false</code>, it indicates that something went wrong     during the execution.</li> <li><code>errorMessage</code> is free text - typically the error output message.</li> </ul> <p>If the responder succeeds (i.e. it runs without any error):</p> <pre><code>{\n    \"success\":true,\n    \"full\":{ \"message\": \"..\" },\n    \"operations\":[]\n}\n</code></pre> <ul> <li>When <code>success</code> is set to <code>true</code>, it indicates that the responder ran     successfully.</li> <li><code>full</code> is the full report of the responder. It must contain at least     a message.</li> <li><code>operations</code> is a list what the submitter system should execute.     As of version 3.1.0, TheHive accepts the following operations:<ul> <li><code>AddTagToArtifact</code> (<code>{ \"type\": \"AddTagToArtifact\", \"tag\": \"tag to add\" }</code>): add      a tag to the artifact related to the object</li> <li><code>AddTagToCase</code> (<code>{ \"type\": \"AddTagToCase\", \"tag\": \"tag to add\" }</code>): add      a tag to the case related to the object</li> <li><code>MarkAlertAsRead</code>: mark the alert related to the object as read</li> <li><code>AddCustomFields</code> (<code>{\"name\": \"key\", \"value\": \"value\", \"tpe\": \"type\"</code>): add a custom field to the case related to the object</li> </ul> </li> </ul> <p>The list of acceptable operations will increase in future releases of TheHive.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#the-cortexutils-python-library", "title": "The Cortexutils Python Library", "text": "<p>So far, all the published responders have been written in Python. We provide a Python library called <code>cortexutils</code> to help developers easily write their programs. Note though that Python is not mandatory for responder coding and any language that runs on Linux can be used, though you won't have the benefits of the CortexUtils library.</p> <p>Cortexutils can be used with Python 2 and 3. Due to the end of life from Python2 it is strongly advised to work as much with Python3 as possible. To install it :</p> <pre><code>pip install cortexutils\n</code></pre> <p>or</p> <pre><code>pip3 install cortexutils\n</code></pre> <p>This library is already used by all the responders published in our Github repository. Feel free to start reading the code of some of them before writing your own.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#submitting-a-responder", "title": "Submitting a Responder", "text": "<p>We highly encourage you to share your responders with the community through our Github repository. To do so, we invite you to follow a few steps before submitting a pull request.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#check-existing-issues", "title": "Check Existing Issues", "text": "<p>Start by checking if an issue already exists for the responder you'd like to write and contribute. Verify that nobody is working on it. If an issue exists and has the in progress, under review or pr-submitted label, it means somebody is already working on the code or has finished it.</p> <p>If you are short on ideas, check issues with a help wanted label. If one of those issues interest you, indicate that you are working on it.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#open-an-issue", "title": "Open an Issue", "text": "<p>If there's no issue open for the responder you'd like to contribute, open one. Indicate that you are working on it to avoid having someone start coding it.</p> <p>You have to create an issue for each responder you'd like to submit.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#review-your-service-interaction-files", "title": "Review your Service Interaction File(s)", "text": "<p>Review your service interaction files. For example, let's check the Mailer JSON responder configuration file(s):</p> <p></p><pre><code>{\n  \"name\": \"Mailer\",\n  \"version\": \"1.0\",\n  \"author\": \"CERT-BDF\",\n  \"url\": \"https://github.com/TheHive-Project/Cortex-Analyzers\",\n  \"license\": \"AGPL-V3\",\n  \"description\": \"Send an email with information from a TheHive case or alert\",\n  \"dataTypeList\": [\"thehive:case\", \"thehive:alert\", \"thehive:case_task\"],\n  \"command\": \"Mailer/mailer.py\",\n  \"baseConfig\": \"Mailer\",\n  \"configurationItems\": [\n    {\n      \"name\": \"from\",\n      \"description\": \"email address from which the mail is send\",\n      \"type\": \"string\", &lt;== defines what kind of data type the configuration item is (string, number)\n      \"multi\": false, &lt;== setting multi to true allows to pass a list of items\n      \"required\": true\n    },\n    {\n      \"name\": \"smtp_host\",\n      \"description\": \"SMTP server used to send mail\",\n      \"type\": \"string\",\n      \"multi\": false,\n      \"required\": true,\n      \"defaultValue\": \"localhost\"\n    },\n    {\n      \"name\": \"smtp_port\",\n      \"description\": \"SMTP server port\",\n      \"type\": \"number\",\n      \"multi\": false,\n      \"required\": true,\n      \"defaultValue\": 25\n    },\n    {\n      \"name\": \"smtp_user\",\n      \"description\": \"SMTP server user\",\n      \"type\": \"string\",\n      \"multi\": false,\n      \"required\": false,\n      \"defaultValue\": \"user\"\n    },\n    {\n      \"name\": \"smtp_pwd\",\n      \"description\": \"SMTP server password\",\n      \"type\": \"string\",\n      \"multi\": false,\n      \"required\": false,\n      \"defaultValue\": \"pwd\"\n    }\n  ]\n}\n</code></pre> Ensure that all information is correct and particularly the <code>author</code> and <code>license</code> parameters."}, {"location": "cortex/api/how-to-create-a-responder/#provide-the-list-of-requirements", "title": "Provide the List of Requirements", "text": "<p>If your responder is written in Python, make sure to complete the <code>requirements.txt</code> file with the list of all the external libraries that are needed to run the responder correctly.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#verify-execution", "title": "Verify Execution", "text": "<p>Use these three simple checks before submitting your responder:</p> <ul> <li>Ensure it works with the expected configuration, TLP, PAP or datatype.</li> <li>Ensure it works with missing configuration, PAP, datatype or TLP: your responder must generate an explicit error message.</li> </ul>"}, {"location": "cortex/api/how-to-create-a-responder/#create-a-pull-request", "title": "Create a Pull Request", "text": "<p>Create one Pull Request per responder against the develop branch of the Cortex-Analyzers repository. Reference the issue you've created in your PR.</p> <p>We have to review your responders. Distinct PRs will allow us to review them more quickly and release them to the benefit of the whole community.</p>"}, {"location": "cortex/api/how-to-create-a-responder/#need-help", "title": "Need Help?", "text": "<p>Something does not work as expected? No worries, we got you covered. Please join our user forum,  contact us on Gitter, or send us  an email at support@thehive-project.org. We are here to help.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/", "title": "How to create an Analyzer", "text": ""}, {"location": "cortex/api/how-to-create-an-analyzer/#how-to-write-and-submit-an-analyzer", "title": "How to Write and Submit an Analyzer", "text": ""}, {"location": "cortex/api/how-to-create-an-analyzer/#table-of-contents", "title": "Table of Contents", "text": "<ul> <li>Writing an Analyzer<ul> <li>The Program</li> <li>Service Interaction Files (Flavors)</li> <li>Python Requirements</li> <li>Example: VirusTotal Analyzer Files</li> <li>Input</li> <li>Service Interaction Configuration Items</li> <li>Output</li> <li>The Cortexutils Python Library</li> <li>Report Templates</li> </ul> </li> <li>Submitting an Analyzer<ul> <li>Check Existing Issues</li> <li>Open an Issue</li> <li>Review your Service Interaction File(s)</li> <li>Provide the List of Requirements</li> <li>Check the Taxonomy</li> <li>Provide Global Configuration Parameters</li> <li>Verify Execution</li> <li>Create a Pull Request</li> </ul> </li> <li>Need Help?</li> </ul>"}, {"location": "cortex/api/how-to-create-an-analyzer/#writing-an-analyzer", "title": "Writing an Analyzer", "text": "<p>An analyzer is a program that takes an observable and configuration information as raw input, analyze the observable and produces a result as raw output. It is made of at least 2 types of files:</p> <ul> <li>The program itself</li> <li>One or several service interaction files or flavors</li> <li>A Python requirements file, which is only necessary if the analyzer is written in Python.</li> </ul>"}, {"location": "cortex/api/how-to-create-an-analyzer/#the-program", "title": "The Program", "text": "<p>The first type of files an analyzer is made of is the core program that performs actions. It can be written in any programming language that is supported by Linux.</p> <p>While many analyzers are written in Python (<code>*.py</code> files), you can write yours in Ruby, Perl or even Scala. However, the very handy <code>Cortexutils</code> library described below is in Python. It greatly facilitates analyzer development and it also provides some methods to quickly format the output to make it compliant with the JSON schema expected by TheHive.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#service-interaction-files-flavors", "title": "Service Interaction Files (Flavors)", "text": "<p>An analyzer must have at least one service interaction file. Such files contain key configuration information such as the analyzer's author information, the datatypes (IP, URL, hash, domain...) the analyzer accepts as input, the TLP and PAP (Permissible Actions Protocol) above which it will refuse to execute to protect against data leakage and to enforce sane OPSEC practices and so on.</p> <p>An analyzer can have two or more service interaction files to allow it to perform different actions.  We speak then of flavors. For example, a sandbox analyzer can analyze a file with or without an Internet connection. Another example could be an analyzer that can either send a file to VirusTotal for analysis or get the last report using its hash.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#python-requirements", "title": "Python Requirements", "text": "<p>If the analyzer is written in Python, a <code>requirements.txt</code> must be provided with the list of all the dependencies.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#example-virustotal-analyzer-files", "title": "Example: VirusTotal Analyzer Files", "text": "<p>Below is a directory listing of the files corresponding to the VirusTotal analyzer. You can see that the analyzer has two flavors: GetReport and Scan.</p> <pre><code>analyzers/VirusTotal\n|-- VirusTotal_GetReport.json\n|-- VirusTotal_Scan.json\n|-- requirements.txt\n|-- virustotal.py\n`-- virustotal_api.py\n</code></pre>"}, {"location": "cortex/api/how-to-create-an-analyzer/#input", "title": "Input", "text": "<p>The input of an analyzer is a JSON structure with different pieces of information. For example, to use the VirusTotal analyzer's GetReport flavor in order to obtain the latest available report for hash <code>d41d8cd98f00b204e9800998ecf8427e</code>, you must submit input such as:</p> <pre><code>{\n    \"data\":\"d41d8cd98f00b204e9800998ecf8427e\",\n    \"dataType\":\"hash\",\n    \"tlp\":0,\n    \"config\":{\n        \"key\":\"1234567890abcdef\",\n        \"max_tlp\":3,\n        \"check_tlp\":true,\n        \"service\":\"GetReport\"\n        [..]\n    },\n    \"proxy\":{\n        \"http\":\"http://myproxy:8080\",\n        \"https\":\"https://myproxy:8080\"\n      }\n  }\n</code></pre> <p><code>data</code>, <code>dataType</code> and <code>tlp</code> are the observable-related information generated by TheHive or any other program that is calling Cortex. <code>config</code> is the analyzer's specific configuration provided by an <code>orgAdmin</code> users when the analyzer is enabled in the Cortex UI.</p> <p>Let's take the GetReport flavor of the VirusTotal analyzer as an example again.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#example-virustotal-get-reports-input", "title": "Example: VirusTotal Get Report's Input", "text": "<pre><code>{\n    \"data\":\"d41d8cd98f00b204e9800998ecf8427e\",\n    \"dataType\":\"hash\",\n    \"tlp\":0,\n    [..]\n  }\n</code></pre>"}, {"location": "cortex/api/how-to-create-an-analyzer/#example-service-interaction-file-for-virustotal-getreport", "title": "Example: Service Interaction File for VirusTotal GetReport", "text": "<p>The <code>&lt;==</code> sign and anything after it are comments that do no appear in the original file. </p><pre><code>{\n  \"name\": \"VirusTotal_GetReport\",\n  \"version\": \"3.0\",\n  \"author\": \"CERT-BDF\",\n  \"url\": \"https://github.com/TheHive-Project/Cortex-Analyzers\",\n  \"license\": \"AGPL-V3\",\n  \"description\": \"Get the latest VirusTotal report for a file, hash, domain or an IP address.\",\n  \"dataTypeList\": [\"file\", \"hash\", \"domain\", \"ip\"],\n  \"command\": \"VirusTotal/virustotal.py\", &lt;== Program to run when invoking the analyzer\n  \"baseConfig\": \"VirusTotal\", &lt;== name of base config in Cortex analyzer config page\n  \"config\": {\n    \"service\": \"get\"\n  },\n  \"configurationItems\": [ &lt;== list of configuration items the analyzer needs to operate (api key etc.)\n    {\n      \"name\": \"key\",\n      \"description\": \"API key for Virustotal\",\n      \"type\": \"string\", &lt;== defines what kind of data type the configuration item is (string, number)\n      \"multi\": false, &lt;== setting multi to true allows to pass a list of items (e.g. MISP analyzer)\n      \"required\": true \n    },\n    {\n      \"name\": \"polling_interval\",\n      \"description\": \"Define time interval between two requests attempts for the report\",\n      \"type\": \"number\",\n      \"multi\": false,\n      \"required\": false,\n      \"defaultValue\": 60\n    }\n  ]\n}\n</code></pre>"}, {"location": "cortex/api/how-to-create-an-analyzer/#service-interaction-configuration-items", "title": "Service Interaction Configuration Items", "text": ""}, {"location": "cortex/api/how-to-create-an-analyzer/#name", "title": "name", "text": "<p>Name of the specific service (or flavor) of the analyzer.</p> <p>If your analyzer has only one service interaction (i.e. performs only one action), it is the name of the analyzer's directory.</p> <p>If your analyzer performs several actions (i.e. comes in several flavors), you have to give a specific and meaningful name to each flavor.</p> <p>Each flavor's name appear in TheHive's analyzer list and in MISP when you use Cortex for attribute enrichment.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#version", "title": "version", "text": "<p>The version of the analyzer.</p> <p>You must increase major version numbers when new features are added, modifications are made to take into account API changes, report output is modified or when report templates (more on this later) are updated.</p> <p>You must increase minor version numbers when bugs are fixed.</p> <p>The version number is also used in the folder name of the associated report templates ; e.g. VirusTotal_GetReport and 3.0 on the JSON file should correspond a folder named VirusTotal_GetReport_3_0 for report templates.  Report templates are used by TheHive to display the analyzer's JSON output  in an analyst-friendly fashion.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#author", "title": "author", "text": "<p>You must provide your full name and/or your organization/team name when submitting an analyzer. Pseudos are not accepted. If you'd rather remain anonymous, please contact us at support@thehive-project.org prior to submitting your analyzer.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#url", "title": "url", "text": "<p>The URL where the analyzer is stored. This should ideally be <code>https://github.com/TheHive-Project/Cortex-Analyzers</code></p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#license", "title": "license", "text": "<p>The license of the code. Ideally, we recommend using the AGPL-v3 license.</p> <p>Make sure your code's license is compatible with the license(s) of the various components and libraries you use if applicable.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#description", "title": "description", "text": "<p>Description of the analyzer. Please be concise and clear. The description is  shown in the Cortex UI, TheHive and MISP.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#datatypelist", "title": "dataTypeList", "text": "<p>The list of TheHive datatypes supported by the analyzer. Currently TheHive accepts the following datatypes:</p> <ul> <li>domain</li> <li>file</li> <li>filename</li> <li>fqdn</li> <li>hash</li> <li>hostname</li> <li>ip</li> <li>mail</li> <li>mail_subject</li> <li>other</li> <li>regexp</li> <li>registry</li> <li>uri_path</li> <li>url</li> <li>user-agent</li> </ul> <p>If you need additional datatypes for your analyzer, please let us know at support@thehive-project.org.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#baseconfig", "title": "baseConfig", "text": "<p>Name used to group configuration items common to several analyzer. This prevent the user to enter the same API key for all analyzer flavors. The Cortex analyzer config page group configuration items by their <code>baseConfig</code>.  </p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#config", "title": "config", "text": "<p>Configuration dedicated to the analyzer's flavor. This is where we  typically specify the TLP level of observables allowed to be analyzed with the  <code>check_tlp</code> and <code>max_tlp</code> parameters. For example, if <code>max_tlp</code> is set to <code>2</code> (TLP:AMBER),  TLP:RED observables cannot be analyzed.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#max_tlp", "title": "max_tlp", "text": "<p>The TLP level above which the analyzer must not be executed.</p> TLP max_tlp value Unknown -1 WHITE 0 GREEN 1 AMBER 2 RED 3"}, {"location": "cortex/api/how-to-create-an-analyzer/#check_tlp", "title": "check_tlp", "text": "<p>This is a boolean parameter. When <code>true</code>, <code>max_tlp</code> is checked. And if the input's TLP is above <code>max_tlp</code>, the analyzer is not executed.</p> <p>For consistency reasons, we do recommend setting both <code>check_tlp</code> and <code>max_tlp</code> even if <code>check_tlp</code> is set to <code>false</code>.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#max_pap", "title": "max_pap", "text": "<p>The PAP level above which the analyzer must not be executed.</p> TLP max_tlp value Unknown -1 WHITE 0 GREEN 1 AMBER 2 RED 3"}, {"location": "cortex/api/how-to-create-an-analyzer/#check_pap", "title": "check_pap", "text": "<p>This is a boolean parameter. When <code>true</code>, <code>max_pap</code> is checked. And if the input's PAP is above <code>max_pap</code>, the analyzer is not executed.</p> <p>For consistency reasons, we do recommend setting both <code>check_pap</code> and <code>max_pap</code> even if <code>check_pap</code> is set to <code>false</code>.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#command", "title": "command", "text": "<p>The command used to run the analyzer. That's typically the full, absolute path to the main program file.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#configurationitems", "title": "configurationItems", "text": "<p>The list of configurationItems is necessary in order to be able to set all configuration variables for analyzers directly in the Cortex 2 user interface. As in the VirusTotal example above can be seen, every item is a json object that defines: - name (string) - description (string) - type (string) - multi (boolean) - required (boolean) - defaultValue (according to type, optional)</p> <p>The <code>multi</code> parameter allows to pass a list as configuration variable instead of a single string or number. This is used e.g. in the MISP analyzer that queries multiple servers in one run and needs different parameters for that.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#output", "title": "Output", "text": "<p>The output of an analyzer depends on the success or failure of its execution.</p> <p>If the analyzer fails to execute:</p> <pre><code>{\n    \"success\": false,\n    \"errorMessage\":\"..\"\n}\n</code></pre> <ul> <li>When <code>success</code> is set to <code>false</code>, it indicates that something went wrong     during the execution.</li> <li><code>errorMessage</code> is free text - typically the error output message.</li> </ul> <p>If the analyzer succeeds (i.e. it runs without any error):</p> <pre><code>{\n    \"success\":true,\n    \"artifacts\":[..],\n    \"summary\":{\n        \"taxonomies\":[..]\n    },\n    \"full\":{..}\n}\n</code></pre> <ul> <li>When <code>success</code> is set to <code>true</code>, it indicates that the analyzer ran     successfully.</li> <li><code>artifacts</code> is a list of indicators extracted from the produced report.</li> <li><code>full</code> is the full report of the analyzer. It is free form, as long as it is JSON formatted.</li> <li> <p><code>summary</code> is used in TheHive for short reports displayed in the     observable list and in the detailed page of each observable. It     contains a list of taxonomies.</p> <ul> <li><code>taxonomies</code>:</li> </ul> <pre><code>\"taxonomies\":[\n  {\n      \"namespace\": \"NAME\",\n      \"predicate\": \"PREDICATE\",\n      \"value\": \"\\\"VALUE\\\"\",\n      \"level\":\"info\"\n  }\n]\n</code></pre> <ul> <li><code>namespace</code> and <code>predicate</code> are free values but they should be as  concise as possible. For example, the VirusTotal analyzer uses VT  as a namespace and Score as a predicate.</li> <li><code>level</code> intends to convey the maliciousness of the result:     :<ul> <li><code>info</code> : the analyzer produced an information, and the     short report is shown in blue color in TheHive.</li> <li><code>safe</code> : the analyzer did not find anything suspicious     or the analyzed observable is safe according to     the analyzer. TheHive displays the short report in green     color.</li> <li><code>suspicious</code> : the analyzer found that the observable is     either suspicious or warrants further investigation. The     short report has an orange color in TheHive.</li> <li><code>malicious</code> : the analyzer found that the observable     is malicious. The short report is red colored in TheHive.</li> </ul> </li> </ul> </li> </ul> <p>For more information refer to our blog.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#the-cortexutils-python-library", "title": "The Cortexutils Python Library", "text": "<p>So far, all the published analyzers have been written in Python. We released a special Python library called <code>cortexutils</code> to help developers easily write their programs. Note though that Python is not mandatory for analyzer coding and any language that runs on Linux can be used, though you won't have the benefits of the CortexUtils library.</p> <p>Cortexutils can be used with Python 2 and 3. To install it :</p> <pre><code>pip install cortexutils\n</code></pre> <p>or</p> <pre><code>pip3 install cortexutils\n</code></pre> <p>This library is already used by all the analyzers published in our Github repository. Feel free to start reading the code of some of them before writing your own.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#report-templates", "title": "Report Templates", "text": "<p>When using TheHive, analysts can submit an observable for analysis to one or several Cortex instances by a click of a button. Once finished, Cortex returns the result to TheHive. The TheHive displays that result using HTML templates for short and long reports.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#cortex-result-in-thehive", "title": "Cortex Result in TheHive", "text": "<p>TheHive receives the Cortex result which is simply the JSON formatted analyzer output described above:</p> <ul> <li>The <code>summary</code> section is read to display short reports in the observables list and in the detailed observable page. This is stored in a dict object named <code>content</code> within TheHive.</li> <li>The <code>full</code> section is read to display long reports when clicking the short     report in the observable list or when accessing a detailed observable     page. In TheHive application, it is stored in a dict object named     <code>content</code>.</li> </ul>"}, {"location": "cortex/api/how-to-create-an-analyzer/#displayed-information", "title": "Displayed Information", "text": ""}, {"location": "cortex/api/how-to-create-an-analyzer/#when-no-template-is-imported", "title": "When No Template is Imported", "text": "<p>In the event that the analyzer report templates are not imported in TheHive (only administrators can do such an operation via the Admin &gt; Report Templates menu):</p> <ul> <li>In the observable list, TheHive is able to display the analyzer <code>summary</code>     results using a builtin style sheet associated with the previously     described taxonomy.</li> <li>In the detailed observable page:<ul> <li>the <code>full</code> result is displayed in raw format (the JSON output from   Cortex)</li> <li>the <code>summary</code> result is not displayed.</li> </ul> </li> </ul>"}, {"location": "cortex/api/how-to-create-an-analyzer/#when-templates-are-imported", "title": "When Templates are Imported", "text": "<p>If templates are imported into TheHive:</p> <ul> <li>Short reports are displayed in the observable list and in the detailed observable page.</li> </ul> <p></p> <ul> <li>Long reports are displayed when clicking on the short reports or in the detailed observable page.</li> </ul> <p></p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#writing-templates", "title": "Writing Templates", "text": "<p>To display results nicely in TheHive, write two HTML templates:</p> <ul> <li>One for short reports</li> <li>One for long reports</li> </ul> <p>When TheHive users import them in the application, they will be definitely more efficient at reading the analyzer reports and do their job accordingly.</p> <p>If the analyzer is made of different flavors (i.e. has different service interaction files with a <code>json</code> extension), you should provide two HTML templates (short and long reports) for each flavor.</p> <p>For example, the VirusTotal analyzer comes in two flavors hence it has 4 HTML  templates:</p> <pre><code>thehive-templates/VirusTotal_GetReport_3_0\n|-- long.html\n`-- short.html\nthehive-templates/VirusTotal_Scan_3_0\n|-- long.html\n`-- short.html\n</code></pre> <p>The folder's name is the concatenation of the <code>name</code> and the <code>version</code> values found in the service interaction files.</p> <p>TheHive uses Bootstrap and AngularJS so you can leverage them in your templates.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#short-report-templates-shorthtml", "title": "Short Report Templates (short.html)", "text": "<p>The short report uses taxonomies and is built into the analyzers by the <code>summary()</code> function. Report templates read it as shown in the example below:</p> <pre><code>&lt;span class=\"label\" ng-repeat=\"t in content.taxonomies\"\n  ng-class=\"{'info': 'label-info', 'safe': 'label-success',\n  'suspicious': 'label-warning',\n  'malicious':'label-danger'}[t.level]\"&gt;\n    {{t.namespace}}:{{t.predicate}}={{t.value}}\n&lt;/span&gt;\n</code></pre> <p>If you want to change or add the information displayed in the short report in the detailed observable page, you have to update the <code>summary()</code> function in the analyzer's program and edit short.html as well. Basically, copy the code in your short.html template and it will do the job.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#long-report-templates-longhtml", "title": "Long Report Templates (long.html)", "text": "<p>Long report templates are more or less free form as long as it reads the content of the relevant section in the Cortex result (<code>full</code>). Feel free to check what has already been written for existing analyzers to write yours.</p> <p>A good start can be:</p> <pre><code>&lt;!-- Success --&gt;\n&lt;div class=\"panel panel-danger\" ng-if=\"success\"&gt;\n    &lt;div class=\"panel-heading\"&gt;\n        ANALYZERNAME Report\n    &lt;/div&gt;\n    &lt;div class=\"panel-body\"&gt;\n        [...]                      &lt;= code here\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;!-- General error  --&gt;\n&lt;div class=\"panel panel-danger\" ng-if=\"!success\"&gt;\n    &lt;div class=\"panel-heading\"&gt;\n        &lt;strong&gt;{{(artifact.data || artifact.attachment.name) | fang}}&lt;/strong&gt;\n    &lt;/div&gt;\n    &lt;div class=\"panel-body\"&gt;\n        &lt;dl class=\"dl-horizontal\" ng-if=\"content.errorMessage\"&gt;\n            &lt;dt&gt;&lt;i class=\"fa fa-warning\"&gt;&lt;/i&gt; ANALYZERNAME: &lt;/dt&gt;\n            &lt;dd class=\"wrap\"&gt;{{content.errorMessage}}&lt;/dd&gt;\n        &lt;/dl&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>"}, {"location": "cortex/api/how-to-create-an-analyzer/#submitting-an-analyzer", "title": "Submitting an Analyzer", "text": "<p>We highly encourage you to share your analyzers with the community through our Github repository. To do so, we invite you to follow a few steps before submitting a pull request.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#check-existing-issues", "title": "Check Existing Issues", "text": "<p>Start by checking if an issue already exists for the analyzer you'd like to write and contribute. Verify that nobody is working on it. If an issue exists and has the in progress, under review or pr-submitted label, it means somebody is already working on the code or has finished it.</p> <p>If you are short on ideas, check issues with a help wanted label. If one of those issues interest you, indicate that you are working on it.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#open-an-issue", "title": "Open an Issue", "text": "<p>If there's no issue open for the analyzer you'd like to contribute, open one. Indicate that you are working on it to avoid having someone start coding it.</p> <p>You have to create an issue for each analyzer you'd like to submit.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#review-your-service-interaction-files", "title": "Review your Service Interaction File(s)", "text": "<p>Review your service interaction files. For example, let's check the VirusTotal JSON analyzer configuration file(s):</p> <p></p><pre><code>{\n    \"name\": \"VirusTotal_GetReport\",\n    \"version\": \"3.0\",\n    \"author\": \"CERT-BDF\",\n    \"url\": \"https://github.com/TheHive-Project/Cortex-Analyzers\",\n    \"license\": \"AGPL-V3\",\n    \"description\": \"Get the latest VirusTotal report for a file, hash, domain or an IP address\",\n    \"dataTypeList\": [\"file\", \"hash\", \"domain\", \"ip\"],\n    \"baseConfig\": \"VirusTotal\",\n    \"config\": {\n        \"check_tlp\": true,\n        \"max_tlp\": 3,\n        \"service\": \"get\"\n    },\n    \"command\": \"VirusTotal/virustotal.py\"\n}\n</code></pre> Ensure that all information is correct and particularly the <code>author</code> and <code>license</code> parameters."}, {"location": "cortex/api/how-to-create-an-analyzer/#provide-the-list-of-requirements", "title": "Provide the List of Requirements", "text": "<p>If your analyzer is written in Python, make sure to complete the <code>requirements.txt</code> file with the list of all the external libraries that are needed to run the analyzer correctly.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#check-the-taxonomy", "title": "Check the Taxonomy", "text": "<p>We chose to use a formatted summary report to match a taxonomy as described above. If you want your analyzer reports in the observable lists, ensure that your summary matches this format. If your analyzer is written in Python and you are using our <code>cortexutils</code> library, you can use the <code>summary()</code>and <code>build_taxonomy()</code> functions.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#provide-global-configuration-parameters", "title": "Provide Global Configuration Parameters", "text": "<p>When submitting your analyzer, please provide the necessary global configuration in <code>/etc/cortex/application.conf</code> if needed. You can provide this information in a <code>README</code> file.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#verify-execution", "title": "Verify Execution", "text": "<p>Use these three simple checks before submtting your analyzer:</p> <ul> <li>Ensure it works with the expected configuration, TLP or dataType.</li> <li>Ensure it works with missing configuration, dataType or TLP: your analyzer must generate an explicit error message.</li> <li>Ensure the long report template handles error messages correctly.</li> </ul>"}, {"location": "cortex/api/how-to-create-an-analyzer/#create-a-pull-request", "title": "Create a Pull Request", "text": "<p>Create one Pull Request per analyzer against the develop branch of the Cortex-Analyzers repository. Reference the issue you've created in your PR.</p> <p>We have to review your analyzers. Distinct PRs will allow us to review them more quickly and release them to the benefit of the whole community.</p>"}, {"location": "cortex/api/how-to-create-an-analyzer/#need-help", "title": "Need Help?", "text": "<p>Something does not work as expected? No worries, we got you covered. Please join our user forum,  contact us on Gitter, or send us  an email at support@thehive-project.org. We are here to help.</p>"}, {"location": "cortex/download/", "title": "Downloading Cortex", "text": ""}, {"location": "cortex/download/#downloading-cortex", "title": "Downloading Cortex", "text": "<p>Cortex is available in multiple binary package formats, making installation flexible across various operating systems. Choose the method that best suits your environment.</p>"}, {"location": "cortex/download/#debian-ubuntu-installation", "title": "Debian /  Ubuntu Installation", "text": ""}, {"location": "cortex/download/#step-1-import-the-gpg-key", "title": "Step 1: Import the GPG Key", "text": "<p>Before adding the repository, import TheHive project's GPG key for package verification:</p> <pre><code>wget -qO- https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY | sudo gpg --dearmor -o /usr/share/keyrings/thehive-project-archive-keyring.gpg\n</code></pre>"}, {"location": "cortex/download/#step-2-add-thehive-project-repository", "title": "Step 2: Add TheHive Project Repository", "text": "<p>Create a new repository configuration file:</p> <pre><code># /etc/apt/sources.list.d/thehive-project.list\ndeb [signed-by=/usr/share/keyrings/thehive-project-archive-keyring.gpg] https://deb.thehive-project.org release main\n</code></pre>"}, {"location": "cortex/download/#step-3-update-package-lists-and-install-cortex", "title": "Step 3: Update Package Lists and Install Cortex", "text": "<pre><code>sudo apt update\nsudo apt install cortex\n</code></pre>"}, {"location": "cortex/download/#red-hat-enterprise-linux-fedora-installation", "title": "Red Hat Enterprise Linux /  Fedora Installation", "text": ""}, {"location": "cortex/download/#step-1-import-the-gpg-key_1", "title": "Step 1: Import the GPG Key", "text": "<p>Run the following command to import TheHive project\u2019s GPG key:</p> <pre><code>sudo rpm --import https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY\n</code></pre>"}, {"location": "cortex/download/#step-2-add-thehive-project-repository_1", "title": "Step 2: Add TheHive Project Repository", "text": "<p>Create a repository configuration file:</p> <pre><code># /etc/yum.repos.d/thehive-project.repo\n[thehive-project]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=https://rpm.thehive-project.org/release/noarch\ngpgcheck=1\n</code></pre>"}, {"location": "cortex/download/#step-3-install-cortex", "title": "Step 3: Install Cortex", "text": "<pre><code>sudo dnf install cortex  # Fedora\nsudo yum install cortex  # RHEL-based systems\n</code></pre>"}, {"location": "cortex/download/#download-as-a-zip-archive", "title": "Download as a ZIP Archive", "text": "<p>For manual installation, download the latest Cortex release as a ZIP archive:</p> <p>\ud83d\udd17 Download Cortex ZIP </p> <p>After downloading, extract the archive:  </p> <pre><code>unzip cortex-latest.zip -d cortex\ncd cortex\n</code></pre>"}, {"location": "cortex/download/#docker-installation", "title": "Docker Installation", "text": "<p>Cortex is also available as a Docker image, simplifying deployment.</p>"}, {"location": "cortex/download/#step-1-pull-the-latest-cortex-image", "title": "Step 1: Pull the Latest Cortex Image", "text": "<pre><code>docker pull thehiveproject/cortex\n</code></pre>"}, {"location": "cortex/download/#step-2-run-cortex", "title": "Step 2: Run Cortex", "text": "<pre><code>docker run -d --name cortex -p 9001:9001 thehiveproject/cortex\n</code></pre> <p>\ud83d\udd17 View Cortex on Docker Hub </p>"}, {"location": "cortex/download/#archives", "title": "Archives", "text": "<p>There are currently no archived versions of Cortex available.</p>"}, {"location": "cortex/installation-and-configuration/", "title": "Installation &amp; configuration guides", "text": ""}, {"location": "cortex/installation-and-configuration/#installation-configuration-guides", "title": "Installation &amp; configuration guides", "text": ""}, {"location": "cortex/installation-and-configuration/#overview", "title": "Overview", "text": "<p>Cortex relies on Elasticsearch to store its data. A basic setup to install Elasticsearch, then Cortex on a standalone and dedicated server (physical or virtual).</p>"}, {"location": "cortex/installation-and-configuration/#hardware-requirements", "title": "Hardware requirements", "text": "<p>Hardware requirements depends on the usage of the system. We recommend starting with dedicated resources: </p> <ul> <li> 8 vCPU</li> <li> 16 GB of RAM</li> </ul>"}, {"location": "cortex/installation-and-configuration/#operating-systems", "title": "Operating systems", "text": "<p>Cortex has been tested and is supported on the following operating systems: </p> <ul> <li> Ubuntu 20.04 LTS</li> <li> Debian 11 </li> <li> RHEL 8</li> <li> Fedora 35</li> </ul>"}, {"location": "cortex/installation-and-configuration/#installation-guide", "title": "Installation Guide", "text": "<p>Too much in a hurry to read ? </p> <p>If you are using one of the supported operating systems, use our all-in-one installation script: </p> <pre><code>wget -q -O /tmp/install.sh https://archives.strangebee.com/scripts/install.sh ; sudo -v ; bash /tmp/install.sh\n</code></pre> <p>This script helps with the installation process on a fresh and supported OS ; the program also run successfully if the conditions in terms of hardware requirements are met.</p> <p></p> <p>Once executed, several options are available: </p> <ol> <li>Setup proxy settings ; will configure everything on the host to work with a HTTP proxy, and custom CA certificate.</li> <li>Install TheHive ; use this option to install TheHive 5 and its dependancies</li> <li>Install Cortex and all its dependencies to run Analyzers &amp; Responders as Docker Iiages</li> <li>Install Cortex and all its dependencies to run Analyzers &amp; Responders on the host (Debian and Ubuntu ONLY)</li> </ol> <p>For each release, DEB, RPM and ZIP binary packages are built and provided.</p> <p>The following Guide let you prepare, install and configure Cortex and its prerequisites for Debian and RPM packages based Operating Systems, as well as for other systems and using our binary packages. </p>"}, {"location": "cortex/installation-and-configuration/#configuration-guides", "title": "Configuration Guides", "text": "<p>The configuration of Cortex is in files stored in the <code>/etc/cortex</code> folder:</p> <ul> <li><code>application.conf</code> contains all parameters and options</li> <li><code>logback.xml</code> is dedicated to log management</li> </ul> <pre><code>/etc/cortex\n\u251c\u2500\u2500 application.conf\n\u251c\u2500\u2500 logback.xml\n\u2514\u2500\u2500 secret.conf\n</code></pre> <p>A separate secret.conf file is automatically created by Debian or RPM packages. This file should contain a secret that should be used by one instance.</p> <p>Various aspects can configured in the <code>application.conf</code> file:</p> <ul> <li>database</li> <li>Authentication</li> <li>Analyzers &amp; Responders</li> </ul>"}, {"location": "cortex/installation-and-configuration/#analyzers-responders", "title": "Analyzers &amp; Responders", "text": "<p>Before starting the installation of Cortex, this is important to know how Analyzers and Responders will be managed and run. 2 solutions are available to run them:</p>"}, {"location": "cortex/installation-and-configuration/#run-locally", "title": "Run locally", "text": "<p>The programs are downloaded and installed on the system running Cortex. </p> <p>There are many disadvantages with this option:</p> <ul> <li>Some public Analyzers or Responders, or you own custom program might required specific applications installed on the system, </li> <li>All of the programs published are written in Python and come with dependancies. To run successfully, the dependancies of all programs should be installed on the same operating system ; so there is a high risk of incompatibilities (some program might require a specific version of a librarie with the latest is also required by another one)</li> <li>The goal of Analyzers is to extract or gather information or intelligence about observables ; and some of them might be malicious. Depending on the analysis, like a code analysis, you might want to ensure the Analyzer has not been compromised - and the host - by the observable itself</li> <li>You might want to ensure that when you run an Analyzer, there is no question about the integrity of its programs</li> <li>Updating them might be a pain regarding Operating System used and dependancies</li> </ul>"}, {"location": "cortex/installation-and-configuration/#run-with-docker", "title": "Run with Docker", "text": "<p>Analyzers &amp; Responders we publish also have their own Docker images. </p> <p>There are several benefits to use Docker images of Analyzers &amp; Responders.</p> <ul> <li>No need to worry about applications required or libraries, it just work</li> <li>When requested, Cortex downloads the docker image of a program and instanciate a container running the program. When finished, the container is trashed and a new one is created the next time. No need to worry about the integrity of the program</li> <li>This is simple to use and maintain</li> </ul> <p>This is the recommended option. It requires installing Docker engine as well.</p> <p>This is not an exclusive choice, both solutions can be used by the same instance of Cortex.</p>"}, {"location": "cortex/installation-and-configuration/advanced-configuration/", "title": "Advanced configuration", "text": ""}, {"location": "cortex/installation-and-configuration/advanced-configuration/#advanced-configuration", "title": "Advanced configuration", "text": ""}, {"location": "cortex/installation-and-configuration/advanced-configuration/#cache", "title": "Cache", "text": ""}, {"location": "cortex/installation-and-configuration/advanced-configuration/#performance", "title": "Performance", "text": "<p>In order to increase Cortex performance, a cache is configured to prevent repetitive database solicitation. Cache retention time can be configured for users and organizations (default is 5 minutes). If a user is updated, the cache is automatically invalidated.</p>"}, {"location": "cortex/installation-and-configuration/advanced-configuration/#analyzer-results", "title": "Analyzer Results", "text": "<p>Analyzer results (job reports) can also be cached. If an analyzer is executed against the same observable, the previous report can be returned without re-executing the analyzer. The cache is used only if the second job occurs within <code>cache.job</code> (the default is 10 minutes).</p> <pre><code>cache {\n  job = 10 minutes\n  user = 5 minutes\n  organization = 5 minutes\n}\n</code></pre> <p>Notes</p> <ol> <li>The global <code>cache.job</code> value can be overridden for each analyzer in the analyzer configuration Web dialog</li> <li>it is possible to bypass the cache altogether (for example to get extra fresh results) through the API as explained in the API Guide or by setting the cache to Custom in the Cortex UI for each analyzer and specifying <code>0</code> as the number of minutes.</li> </ol>"}, {"location": "cortex/installation-and-configuration/advanced-configuration/#streaming-aka-the-flow", "title": "Streaming (a.k.a The Flow)", "text": "<p>The user interface is automatically updated when data is changed in the back-end. To do this, the back-end sends events to all the connected front-ends. The mechanism used to notify the front-end is called long polling and its settings are:</p> <ul> <li><code>refresh</code> : when there is no notification, close the connection after this  duration (the default is 1 minute).</li> <li><code>cache</code> : before polling a session must be created, in order to make sure no  event is lost between two polls. If there is no poll during the cache setting,  the session is destroyed (the default is 15 minutes).</li> <li><code>nextItemMaxWait</code>, <code>globalMaxWait</code> : when an event occurs, it is not  immediately sent to the front-ends. The back-end waits nextItemMaxWait and up  to globalMaxWait in case another event can be included in the notification.  This mechanism saves many HTTP requests.</li> </ul> <p>The default values are:</p> <pre><code># Streaming\nstream.longpolling {\n  # Maximum time a stream request waits for new element\n  refresh = 1m\n  # Lifetime of the stream session without request\n  cache = 15m\n  nextItemMaxWait = 500ms\n  globalMaxWait = 1s\n}\n</code></pre>"}, {"location": "cortex/installation-and-configuration/advanced-configuration/#entity-size-limit", "title": "Entity Size Limit", "text": "<p>The Play framework used by Cortex sets the HTTP body size limit to 100KB by default for textual content (json, xml, text, form data) and 10MB for file uploads. This could be too small in some cases so you may want to change it with the following settings in the <code>application.conf</code> file:</p> <pre><code># Max textual content length\nplay.http.parser.maxMemoryBuffer=1M\n# Max file size\nplay.http.parser.maxDiskBuffer=1G\n</code></pre> <p>Note</p> <p>if you are using a NGINX reverse proxy in front of Cortex, be aware that it doesn't distinguish between text data and a file upload. So, you should also set the <code>client_max_body_size</code> parameter in your NGINX server configuration to the highest value among the two: file upload and text size as defined in Cortex <code>application.conf</code> file.</p>"}, {"location": "cortex/installation-and-configuration/analyzers-responders/", "title": "Analyzers &amp; Responders", "text": ""}, {"location": "cortex/installation-and-configuration/analyzers-responders/#analyzers-responders", "title": "Analyzers &amp; Responders", "text": ""}, {"location": "cortex/installation-and-configuration/analyzers-responders/#run-with-docker", "title": "Run with Docker", "text": "<p>Ensure Cortex is authorized to run use Docker</p> <p>To run docker images of Analyzers &amp; Responders, Cortex should have permissions to use docker. </p> <pre><code>sudo usermod -G docker cortex\n</code></pre>"}, {"location": "cortex/installation-and-configuration/analyzers-responders/#configure-cortex", "title": "Configure Cortex", "text": "<p>To run Analyzers&amp;Responders with Docker images, Cortex should be able have access to Internet: </p> <ul> <li>To download public catalogs from download.thehive-project.org </li> <li>To download Docker images from hub.docker.com  (https://hub.docker.com/search?q=cortexneurons).</li> </ul> /etc/cortex/application.conf<pre><code>[..]\nanalyzer {\n  # Directory that holds analyzers\n  urls = [\n    \"https://download.thehive-project.org/analyzers.json\"\n  ]\n\n  fork-join-executor {\n    # Min number of threads available for analyze\n    parallelism-min = 2\n    # Parallelism (threads) ... ceil(available processors * factor)\n    parallelism-factor = 2.0\n    # Max number of threads available for analyze\n    parallelism-max = 4\n  }\n}\n\nresponder {\n  # Directory that holds responders\n  urls = [\n    \"https://download.thehive-project.org/responders.json\"\n  ]\n\n  fork-join-executor {\n    # Min number of threads available for analyze\n    parallelism-min = 2\n    # Parallelism (threads) ... ceil(available processors * factor)\n    parallelism-factor = 2.0\n    # Max number of threads available for analyze\n    parallelism-max = 4\n  }\n}\n[..]\n</code></pre>"}, {"location": "cortex/installation-and-configuration/analyzers-responders/#store-run-programs-on-the-host", "title": "Store &amp; run programs on the host", "text": ""}, {"location": "cortex/installation-and-configuration/analyzers-responders/#additionnal-packages", "title": "Additionnal packages", "text": "<p>Some system packages are required to run Analyzers&amp;Responders programs successfully: </p> Debian <pre><code>sudo apt install -y --no-install-recommends python3-pip python3-dev ssdeep libfuzzy-dev libfuzzy2 libimage-exiftool-perl libmagic1 build-essential git libssl-dev\n</code></pre> <p>You may need to install Python's <code>setuptools</code> and update pip/pip3:</p> <pre><code>sudo pip3 install -U pip setuptools\n</code></pre>"}, {"location": "cortex/installation-and-configuration/analyzers-responders/#clone-the-repository", "title": "Clone the repository", "text": "<p>Once finished, clone the Cortex-analyzers repository in the directory of your choosing:</p> <pre><code>cd /opt\ngit clone https://github.com/TheHive-Project/Cortex-Analyzers\nchown -R cortex:cortex /opt/Cortex-Analyzers \n</code></pre>"}, {"location": "cortex/installation-and-configuration/analyzers-responders/#install-dependencies", "title": "Install dependencies", "text": "<p>Each analyzer comes with its own, pip compatible <code>requirements.txt</code> file. You can install all requirements with the following commands:</p> <pre><code>cd /opt\nfor I in $(find Cortex-Analyzers -name 'requirements.txt'); do sudo -H pip3 install -r $I || true; done\n</code></pre>"}, {"location": "cortex/installation-and-configuration/analyzers-responders/#configure-cortex_1", "title": "Configure Cortex", "text": "<p>Next, you'll need to tell Cortex where to find the analyzers. Analyzers may be in different directories as shown in this dummy example of the Cortex configuration file (<code>application.conf</code>):</p> /etc/cortex/application.conf<pre><code>[..]\nanalyzer {\n  # Directory that holds analyzers\n  urls = [\n    \"/opt/Cortex-Analyzers/responders\",\n  ]\n\n  fork-join-executor {\n    # Min number of threads available for analyze\n    parallelism-min = 2\n    # Parallelism (threads) ... ceil(available processors * factor)\n    parallelism-factor = 2.0\n    # Max number of threads available for analyze\n    parallelism-max = 4\n  }\n}\n\nresponder {\n  # Directory that holds responders\n  urls = [\n    \"/opt/Cortex-Analyzers/responders\"\n  ]\n\n  fork-join-executor {\n    # Min number of threads available for analyze\n    parallelism-min = 2\n    # Parallelism (threads) ... ceil(available processors * factor)\n    parallelism-factor = 2.0\n    # Max number of threads available for analyze\n    parallelism-max = 4\n  }\n}\n[..]\n</code></pre>"}, {"location": "cortex/installation-and-configuration/analyzers-responders/#run-you-own-analyzers-responders", "title": "Run you own Analyzers &amp; Responders", "text": "<p>Either you run them from the host or with Docker images, you can also run your own custom Analyzers and Responders. </p>"}, {"location": "cortex/installation-and-configuration/analyzers-responders/#dedicated-folder", "title": "Dedicated folder", "text": "<p>Create a dedicated folder to host your programs: </p> <pre><code>cd /opt\nmkdir -p Custom-Analyzers/{analyzers,responder}\nchown -R cortex:cortex /opt/Cortex-Analyzers \n</code></pre>"}, {"location": "cortex/installation-and-configuration/analyzers-responders/#update-cortex-configuration", "title": "Update Cortex configuration", "text": "<p>Update <code>analyzer.urls</code> and <code>responders.urls</code> accordingly.</p> /etc/cortex/application.conf<pre><code>[..]\nanalyzer {\n  # Directory that holds analyzers\n  urls = [\n    \"https://download.thehive-project.org/analyzers.json\",\n    \"/opt/Custom-Analyzers/analyzers\" \n  ]\n\n  fork-join-executor {\n    # Min number of threads available for analyze\n    parallelism-min = 2\n    # Parallelism (threads) ... ceil(available processors * factor)\n    parallelism-factor = 2.0\n    # Max number of threads available for analyze\n    parallelism-max = 4\n  }\n}\n\nresponder {\n  # Directory that holds responders\n  urls = [\n    \"https://download.thehive-project.org/responders.json\",\n    \"/opt/Custom-Analyzers/responders\" \n  ]\n\n  fork-join-executor {\n    # Min number of threads available for analyze\n    parallelism-min = 2\n    # Parallelism (threads) ... ceil(available processors * factor)\n    parallelism-factor = 2.0\n    # Max number of threads available for analyze\n    parallelism-max = 4\n  }\n}\n[..]\n</code></pre> <p>Then restart Cortex for the changes to take effect.</p> <p>How to develop your own Analyzers or Responders ?</p> <p>Have a look at the dedicated documentation: https://thehive-project.github.io/Cortex-Analyzers/dev_guides/how-to-create-an-analyzer/</p>"}, {"location": "cortex/installation-and-configuration/authentication/", "title": "Authentication", "text": ""}, {"location": "cortex/installation-and-configuration/authentication/#authentication", "title": "Authentication", "text": "<p>Like TheHive, Cortex supports local, LDAP, Active Directory (AD), X.509 SSO and/or API keys for authentication and OAuth2.</p> <p>Please note that API keys can only be used to interact with the Cortex API (for example when TheHive is interfaced with a Cortex instance, it must use an API key to authenticate to it). API keys cannot be used to authenticate to the Web UI. By default, Cortex relies on local credentials stored in Elasticsearch.</p> <p>Authentication methods are stored in the <code>auth.provider</code> parameter, which is multi-valued. When a user logs in, each authentication method is tried in order until one succeeds. If no authentication method works, an error is returned and the user cannot log in.</p> <p>The default values within the configuration file are:</p> <pre><code>auth {\n  # \"provider\" parameter contains authentication provider. It can be multi-valued (useful for migration)\n  # available auth types are:\n  # services.LocalAuthSrv : passwords are stored in user entity (in Elasticsearch). No configuration is required.\n  # ad : use ActiveDirectory to authenticate users. Configuration is under \"auth.ad\" key\n  # ldap : use LDAP to authenticate users. Configuration is under \"auth.ldap\" key\n  # oauth2 : use OAuth/OIDC to authenticate users. Configuration is under \"auth.oauth2\" and \"auth.sso\" keys\n  provider = [local]\n\n  # By default, basic authentication is disabled. You can enable it by setting \"method.basic\" to true.\n  method.basic = false\n\n  ad {\n    # The name of the Microsoft Windows domain using the DNS format. This parameter is required.\n    #domainFQDN = \"mydomain.local\"\n\n    # Optionally you can specify the host names of the domain controllers. If not set, Cortex uses \"domainFQDN\".\n    #serverNames = [ad1.mydomain.local, ad2.mydomain.local]\n\n    # The Microsoft Windows domain name using the short format. This parameter is required.\n    #domainName = \"MYDOMAIN\"\n\n    # Use SSL to connect to the domain controller(s).\n    #useSSL = true\n  }\n\n  ldap {\n    # LDAP server name or address. Port can be specified (host:port). This parameter is required.\n    #serverName = \"ldap.mydomain.local:389\"\n\n    # If you have multiple ldap servers, use the multi-valued settings.\n    #serverNames = [ldap1.mydomain.local, ldap2.mydomain.local]\n\n    # Use SSL to connect to directory server\n    #useSSL = true\n\n    # Account to use to bind on LDAP server. This parameter is required.\n    #bindDN = \"cn=cortex,ou=services,dc=mydomain,dc=local\"\n\n    # Password of the binding account. This parameter is required.\n    #bindPW = \"***secret*password***\"\n\n    # Base DN to search users. This parameter is required.\n    #baseDN = \"ou=users,dc=mydomain,dc=local\"\n\n    # Filter to search user {0} is replaced by user name. This parameter is required.\n    #filter = \"(cn={0})\"\n  }\n\n  oauth2 {\n    # URL of the authorization server\n    #clientId = \"client-id\"\n    #clientSecret = \"client-secret\"\n    #redirectUri = \"https://my-cortex-instance.example/api/ssoLogin\"\n    #responseType = \"code\"\n    #grantType = \"authorization_code\"\n\n    # URL from where to get the access token\n    #authorizationUrl = \"https://auth-site.com/OAuth/Authorize\"\n    #tokenUrl = \"https://auth-site.com/OAuth/Token\"\n\n    # The endpoint from which to obtain user details using the OAuth token, after successful login\n    #userUrl = \"https://auth-site.com/api/User\"\n    #scope = [\"openid profile\"]\n  }\n\n  # Single-Sign On\n  sso {\n    # Autocreate user in database?\n    #autocreate = false\n\n    # Autoupdate its profile and roles?\n    #autoupdate = false\n\n    # Autologin user using SSO?\n    #autologin = false\n\n    # Name of mapping class from user resource to backend user ('simple' or 'group')\n    #mapper = group\n    #attributes {\n    #  login = \"user\"\n    #  name = \"name\"\n    #  groups = \"groups\"\n    #  organization = \"org\"\n    #}\n    #defaultRoles = [\"read\"]\n    #defaultOrganization = \"csirt\"\n    #groups {\n    #  # URL to retreive groups (leave empty if you are using OIDC)\n    #  #url = \"https://auth-site.com/api/Groups\"\n    #  # Group mappings, you can have multiple roles for each group: they are merged\n    #  mappings {\n    #    admin-profile-name = [\"admin\"]\n    #    editor-profile-name = [\"write\"]\n    #    reader-profile-name = [\"read\"]\n    #  }\n    #}\n\n    #mapper = simple\n    #attributes {\n    #  login = \"user\"\n    #  name = \"name\"\n    #  roles = \"roles\"\n    #  organization = \"org\"\n    #}\n    #defaultRoles = [\"read\"]\n    #defaultOrganization = \"csirt\"\n  }\n\n}\n\n# Maximum time between two requests without requesting authentication\nsession {\n  warning = 5m\n  inactivity = 1h\n}\n</code></pre>"}, {"location": "cortex/installation-and-configuration/authentication/#oauth2openid-connect", "title": "OAuth2/OpenID Connect", "text": "<p>To enable authentication using OAuth2/OpenID Connect, edit the <code>application.conf</code> file and supply the values of <code>auth.oauth2</code> according to your environment. In addition, you need to supply:</p> <ul> <li><code>auth.sso.attributes.login</code>: name of the attribute containing the OAuth2 user's login in retreived user info (mandatory)</li> <li><code>auth.sso.attributes.name</code>: name of the attribute containing the OAuth2 user's name in retreived user info (mandatory)</li> <li><code>auth.sso.attributes.groups</code>: name of the attribute containing the OAuth2 user's groups (mandatory using groups mappings)</li> <li><code>auth.sso.attributes.roles</code>: name of the attribute containing the OAuth2 user's roles in retreived user info (mandatory using simple mapping)</li> </ul> <p>Important note</p> <p>Authenticate the user using an external OAuth2 authenticator server. The configuration is:</p> <ul> <li>clientId (string) client ID in the OAuth2 server.</li> <li>clientSecret (string) client secret in the OAuth2 server.</li> <li>redirectUri (string) the url of TheHive AOuth2 page (.../api/ssoLogin).</li> <li>responseType (string) type of the response. Currently only \"code\" is accepted.</li> <li>grantType (string) type of the grant. Currently only \"authorization_code\" is accepted.</li> <li>authorizationUrl (string) the url of the OAuth2 server.</li> <li>authorizationHeader (string) prefix of the authorization header to get user info: 'Bearer' by default</li> <li>tokenUrl (string) the token url of the OAuth2 server.</li> <li>userUrl (string) the url to get user information in OAuth2 server.</li> <li>scope (list of string) list of scope.</li> </ul> <p>Example configuration for SSO w/ Oauth2 &amp; Github</p> <pre><code>auth {\n\n  provider = [local, oauth2]\n\n  [..]\n\n  sso {\n    autocreate: false\n    autoupdate: false\n    mapper: \"simple\"\n    attributes {\n      login: \"login\"\n      name: \"name\"\n      roles: \"role\"\n    }\n    defaultRoles: [\"read\", \"analyze\"]\n    defaultOrganization: \"demo\"\n  }  \n  oauth2 {\n    name: oauth2\n    clientId: \"Client_ID\"\n    clientSecret: \"Client_ID\"\n    redirectUri: \"http://localhost:9001/api/ssoLogin\"\n    responseType: code\n    grantType: \"authorization_code\"\n    authorizationUrl: \"https://github.com/login/oauth/authorize\"\n    tokenUrl: \"https://github.com/login/oauth/access_token\"\n    userUrl: \"https://api.github.com/user\"\n    scope: [\"user\"]\n  }\n\n  [..]  \n}\n</code></pre>"}, {"location": "cortex/installation-and-configuration/database/", "title": "Database configuration", "text": ""}, {"location": "cortex/installation-and-configuration/database/#database-configuration", "title": "Database configuration", "text": "/etc/cortex/application.conf<pre><code>[..]\n## ElasticSearch\nsearch {\n  index = cortex\n  # For cluster, join address:port with ',': \"http://ip1:9200,ip2:9200,ip3:9200\"\n  uri = \"http://127.0.0.1:9200\"\n\n  ## Advanced configuration\n  # Scroll keepalive.\n  #keepalive = 1m\n  # Scroll page size.\n  #pagesize = 50\n  # Number of shards\n  #nbshards = 5\n  # Number of replicas\n  #nbreplicas = 1\n  # Arbitrary settings\n  #settings {\n  #  # Maximum number of nested fields\n  #  mapping.nested_fields.limit = 100\n  #}\n\n  ## Authentication configuration\n  #username = \"\"\n  #password = \"\"\n\n  ## SSL configuration\n  #keyStore {\n  #  path = \"/path/to/keystore\"\n  #  type = \"JKS\" # or PKCS12\n  #  password = \"keystore-password\"\n  #}\n  #trustStore {\n  #  path = \"/path/to/trustStore\"\n  #  type = \"JKS\" # or PKCS12\n  #  password = \"trustStore-password\"\n  #}\n}\n</code></pre>"}, {"location": "cortex/installation-and-configuration/docker/", "title": "Parameters for Docker", "text": ""}, {"location": "cortex/installation-and-configuration/docker/#parameters-for-docker", "title": "Parameters for Docker", "text": ""}, {"location": "cortex/installation-and-configuration/docker/#list-of-options", "title": "list of options", "text": "<ul> <li><code>docker.container.capAdd</code>: (array of string) Add Linux capabilities</li> <li><code>docker.container.capDrop</code>: (array of string) Drop Linux capabilities</li> <li><code>docker.container.cgroupParent</code>: (string) Cgroup to run a container in</li> <li><code>docker.container.cpuPeriod</code>: (integer) Limit the CPU CFS (Completely Fair Scheduler) period</li> <li><code>docker.container.cpuQuota</code>: (integer) Limit the CPU CFS (Completely Fair Scheduler) quota</li> <li><code>docker.container.dns</code>: (array of string) Set custom dns servers for the container</li> <li><code>docker.container.dnsSearch</code>: (array of string) Search list for host-name lookup.</li> <li><code>docker.container.extraHosts</code>: (array of string) Add a line to /etc/hosts (host:IP)</li> <li><code>docker.container.kernelMemory</code>: (integer) Kernel memory limit</li> <li><code>docker.container.memoryReservation</code>: (integer) Memory soft limit</li> <li><code>docker.container.memory</code>: (integer) Memory limit</li> <li><code>docker.container.memorySwap</code>: (integer) Total memory limit (memory + swap)</li> <li><code>docker.container.memorySwappiness</code>: (integer) Tune a container\u2019s memory swappiness behavior. Accepts an integer between 0 and 100</li> <li><code>docker.container.networkMode</code>: (string) name of the network</li> <li><code>docker.container.privileged</code>: (boolean) Give extended privileges to this container</li> <li><code>job.directory</code>: (string) Folder used by Cortex binary inside the container to share input and output data of Analyzers &amp; Responders</li> <li><code>job.dockerDirectory</code> = (string) Folder on the host used by Analyzers &amp; Responders to share input and output data with Cortex</li> </ul>"}, {"location": "cortex/installation-and-configuration/docker/#dockerized-analyzers-responders", "title": "Dockerized analyzers / responders", "text": "<p>To run Analyzers&amp;Responders as docker images, use our available catalogs to register them.</p> <p>In Cortex configuration file, update <code>analyzer.urls</code> and <code>responder.urls</code> and tell Cortex how to find analyzers and responders. These settings accept:    - a path to a directory where workers are installed (like previous version of Cortex)    - a path or an url (http(s)) to a JSON file containing all worker definitions (merge of all JSON in one array)</p> <p>If you want to use dockerized analyzers, you can add the following urls:  - analyzers-stable.json (once used, analyzer is never updated)   - analyzers.json (updated when new version is released)  - analyzers-devel.json (updated at each commit, used for development)</p> <p>For responders urls are:   - responders-stable.json (once used, analyzer is never updated)   - responders.json (updated when new version is released)   - responders-devel.json (updated at each commit, used for development)</p>"}, {"location": "cortex/installation-and-configuration/proxy-settings/", "title": "Proxy settings", "text": ""}, {"location": "cortex/installation-and-configuration/proxy-settings/#proxy-settings", "title": "Proxy settings", "text": ""}, {"location": "cortex/installation-and-configuration/proxy-settings/#make-cortex-use-a-http-proxy-server", "title": "Make Cortex use a HTTP proxy server", "text": "<p>Basically, Cortex required to connect to Internet, especially to gather  catalogs of docker images of public Analyzers &amp; Responders.</p> /etc/cortex/application.conf<pre><code>[..]\nplay.ws.proxy {\n  host = http://PROXYSERVERADDRESS:PORT\n  port = http://PROXYSERVERADDRESS:PORT\n}\n[..]\n</code></pre>"}, {"location": "cortex/installation-and-configuration/proxy-settings/#operating-system", "title": "Operating System", "text": "/etc/environment<pre><code>export http_proxy=http://PROXYSERVERADDRESS:PORT\nexport https_proxy=http://PROXYSERVERADDRESS:PORT  \n</code></pre> <p>Specific configuration for Debian apt application</p> /etc/apt/apt.conf.d/80proxy<pre><code>  HTTP::proxy \"http://PROXYSERVERADDRESS:PORT\";\n  HTTPS::proxy \"http://PROXYSERVERADDRESS:PORT\";\n</code></pre>"}, {"location": "cortex/installation-and-configuration/proxy-settings/#pip", "title": "pip", "text": "<p>If Analyzers and Responders requirements have to be installed on the host, and the host is behind a proxy server, configure the pip command to use the proxy server ; use the option <code>--proxy http://PROXYSERVERADDRESS:PORT\"</code>, and <code>--cert path/to/cacert.pem</code> if a custom certificate is used by the proxy.</p> <pre><code>pip3 install --proxy http://PROXYSERVERADDRESS:PORT\" -r analyzers/*/requirements.txt\n</code></pre> <p>or </p> <pre><code>pip3 install --proxy http://PROXYSERVERADDRESS:PORT\" --cert path/to/cacert.pem -r analyzers/*/requirements.txt\n</code></pre>"}, {"location": "cortex/installation-and-configuration/proxy-settings/#git", "title": "Git", "text": "<pre><code>sudo git config --global http.proxy http://PROXYSERVERADDRESS:PORT\nsudo git config --global https.proxy http://PROXYSERVERADDRESS:PORT\n</code></pre>"}, {"location": "cortex/installation-and-configuration/proxy-settings/#docker", "title": "Docker", "text": "<p>If using Analyzers &amp; Responders as docker images, setting up proxy parameters could be required to download images.</p> <p>Update Docker engine configuration by editing/creating the file <code>/etc/systemd/system/docker.service.d/http-proxy.conf</code>: </p> /etc/systemd/system/docker.service.d/http-proxy.conf<pre><code>[Service]\nEnvironment=http://PROXYSERVERADDRESS:PORT\"\nEnvironment=\"http://PROXYSERVERADDRESS:PORT\"\n</code></pre> <p>Then run: </p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl restart docker\n</code></pre>"}, {"location": "cortex/installation-and-configuration/run-cortex-with-docker/", "title": "Run cortex with docker", "text": ""}, {"location": "cortex/installation-and-configuration/run-cortex-with-docker/#docker", "title": "Docker", "text": "<p>To use the Docker image, you must use Docker (courtesy of Captain Obvious). Alternatively, it's also possible to run the image using Podman.</p> <p>By default, the docker image generate a configuration file for Cortex with:  - the Elasticsearch uri is determined by resolving the host name \"elasticsearch\",  - the analyzers and responders official location,  - a generated secret (used to protect the user sessions). The behaviour of the Cortex Docker image can be customized using environment variables or parameters:</p> Parameter Env variable Description <code>--no-config</code> <code>no_config=1</code> Do not configure Cortex <code>--no-config-secret</code> <code>no_config_secret=1</code> Do not add the random secret to the configuration <code>--no-config-es</code> <code>no_config_es=1</code> do not add elasticsearch hosts to configuration <code>--es-uri &lt;uri&gt;</code> <code>es_uri=&lt;uri&gt;</code> use this string to configure elasticsearch hosts (format: http(s)://host:port,host:port(/prefix)?querystring) <code>--es-hostname &lt;host&gt;</code> <code>es_hostname=host</code> resolve this hostname to find elasticsearch instances <code>--secret &lt;secret&gt;</code> <code>secret=&lt;secret&gt;</code> secret to secure sessions <code>--show-secret</code> <code>show_secret=1</code> show the generated secret <code>--job-directory &lt;dir&gt;</code> <code>job_directory=&lt;dir&gt;</code> use this directory to store job files <code>--docker-job-directory &lt;dir&gt;</code> <code>docker_job_directory=&lt;dir&gt;</code> indicate the job directory in the host (not inside container) <code>--analyzer-url &lt;url&gt;</code> <code>analyzer_urls=&lt;url&gt;,&lt;url&gt;,...</code> where analyzers are located (url or path) <code>--responder-url &lt;url&gt;</code> <code>responder_urls=&lt;url&gt;,&lt;url&gt;,...</code> where responders are located (url or path) <code>--start-docker</code> <code>start_docker=1</code> start an internal docker (inside container) to run analyzers/responders <code>--daemon-user &lt;user&gt;</code> <code>daemon_user=&lt;user&gt;</code> run cortex using this user <p>At the end of the generated configuration, the file <code>/etc/cortex/application.conf</code> is included. Thus you can override any setting by binding your own <code>application.conf</code> into this file:</p> <pre><code>docker run --volume /path/to/my/application.conf:/etc/cortex/application.conf thehiveproject/cortex:latest --es-uri http://elasticsearch.local:9200\n</code></pre> <p>Cortex uses docker to run analyzers and responders. If you run Cortex inside a docker, you can:</p> <ul> <li>give Cortex access to docker service or podman service (recommended solution)</li> <li>start a docker service inside Cortex docker container</li> </ul>"}, {"location": "cortex/installation-and-configuration/run-cortex-with-docker/#cortex-uses-main-docker-service", "title": "Cortex uses main docker service", "text": "<p>In order to use docker service the docker socket must be bound into Cortex container. Moreover, as Cortex shares files with analyzers, a folder must be bound between them.</p> <pre><code>docker run --volume /var/run/docker.sock:/var/run/docker.sock --volume /var/run/cortex/jobs:/tmp/cortex-jobs thehiveproject/cortex:latest --job-directory /tmp/cortex-jobs --docker-job-directory /var/run/cortex/jobs\n</code></pre> <p>Cortex can instantiate docker container by using the docker socket <code>/var/run/docker.sock</code>. The folder <code>/var/run/cortex/jobs</code> is used to store temporary file of jobs. The folder <code>/tmp/cortex-jobs</code> is job folder inside the docker. In order to make job file visible to analyzer docker, Cortex needs to know both folders (parameters <code>--job-directory</code> and <code>-docker-job-directory</code>). On most cases, job directories are the same and <code>--docker-job-directory</code> can be omitted.</p> <p>If you run Cortex in Windows, the docker service is accessible through the named pipe <code>\\\\.\\pipe\\docker_engine</code>. The command becomes</p> <pre><code>docker run --volume //./pipe/docker_engine://./pipe/docker_engine --volume C:\\\\CORTEX\\\\JOBS:/tmp/cortex-jobs thehiveproject/cortex:latest --job-directory /tmp/cortex-jobs --docker-job-directory C:\\\\CORTEX\\\\JOBS\n</code></pre>"}, {"location": "cortex/installation-and-configuration/run-cortex-with-docker/#docker-in-docker-docker-ception", "title": "Docker in docker (docker-ception)", "text": "<p>You can also run docker service inside Cortex container, a docker in a docker with <code>--start-docker</code> parameter. The container must be run in privileged mode.</p> <pre><code>docker run --privileged thehiveproject/cortex:latest --start-docker\n</code></pre> <p>In this case you don't need to bind job directory.</p>"}, {"location": "cortex/installation-and-configuration/run-cortex-with-docker/#use-docker-compose", "title": "Use Docker-compose", "text": "<p>Cortex requires Elasticsearch to run. You can use <code>docker-compose</code> to start them together in Docker or install and configure Elasticsearch manually. Docker-compose can start multiple dockers and link them together.</p> <p>The following docker-compose.yml file starts Elasticsearch and Cortex:</p> <pre><code>version: \"2\"\nservices:\n  elasticsearch:\n    image: elasticsearch:7.9.1\n    environment:\n      - http.host=0.0.0.0\n      - discovery.type=single-node\n      - script.allowed_types=inline\n      - thread_pool.search.queue_size=100000\n      - thread_pool.write.queue_size=10000\n    volumes:\n      - /path/to/data:/usr/share/elasticsearch/data\n  cortex:\n    image: thehiveproject/cortex:3.1.1\n    environment:\n      - job_directory=${job_directory}\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - ${job_directory}:${job_directory}\n    depends_on:\n      - elasticsearch\n    ports:\n      - \"0.0.0.0:9001:9001\"\n</code></pre> <p>Put this docker-compose file and .env in an empty folder and run <code>docker-compose up</code>. Cortex is exposed on 9001/tcp port. These ports can be changed by modifying the <code>docker-compose</code> file.</p> <p>For advanced configuration, visit our Docker Templates repository</p>"}, {"location": "cortex/installation-and-configuration/run-cortex-with-docker/#cortex-with-podman", "title": "Cortex with podman", "text": "<p>Like docker, podman will be able to run the container image of cortex and of its analyzers. The examples below assume that the containers are run as rootful.</p> <p>For Cortex to interact with podman, it needs to use the podman socket. On some systems, podman will automatically install and enable this service. You can check this on your system with:</p> <pre><code>systemctl status podman.socket\n</code></pre> <p>Here we assume that the podman socket is accessible on <code>/run/podman/podman.sock</code>. This may change based on your system.</p> <p>Cortex uses podman service</p> <p>You need to mount the podman socket inside the container to <code>/var/run/docker.sock</code></p> <pre><code>podman run \\\n  --rm \\\n  --name cortex \\\n  -p 9001:9001 \\\n  -v /var/run/cortex/jobs:/tmp/cortex-jobs \\\n  -v /run/podman/podman.sock:/var/run/docker.sock \\\n  docker.io/thehiveproject/cortex:3.1.7 \\\n  --job-directory /tmp/cortex-jobs \\\n  --docker-job-directory /var/run/cortex/jobs \\\n  --es-uri http://$ES_IP:9200\n</code></pre> <p>With this configuration, Cortex analyzers will be run by podman.</p> <p>Image not found</p> <p>Podman may have trouble pulling cortex neurons images from the regular docker registry. You may have to add docker.io as an unqualified registry. To do this, add this line to your config <code>/etc/containers/registries.conf</code>:</p> <pre><code>unqualified-search-registries = ['docker.io']\n</code></pre> <p>Then restart the podman socket service too</p> <p>Docker in podman</p> <p>By running with the flag <code>--privileged</code>, it is possible to start docker inside a podman container</p> <pre><code>podman run \\\n  --privileged \\\n  --rm \\\n  --name cortex \\\n  -p 9001:9001 \\\n  docker.io/thehiveproject/cortex:3.1.7 \\\n  --es-uri http://$ES_IP:9200\n  --start-docker\n</code></pre>"}, {"location": "cortex/installation-and-configuration/secret/", "title": "Secret key configuration", "text": ""}, {"location": "cortex/installation-and-configuration/secret/#secret-key-configuration", "title": "Secret key configuration", "text": "<p>Setup a secret key for this instance: </p> <pre><code>cat &gt; /etc/cortex/secret.conf &lt;&lt; _EOF_\nplay.http.secret.key=\"$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 64 | head -n 1)\"\n_EOF_\n</code></pre> <p>Then, in the file <code>/etc/cortex/application.conf</code>, replace the line including <code>play.http.secret.key=</code> by:</p> /etc/cortex/application.conf<pre><code>[..]\ninclude \"/etc/cortex/secret.conf\"\n[..]\n</code></pre>"}, {"location": "cortex/installation-and-configuration/ssl/", "title": "Configure SSL", "text": ""}, {"location": "cortex/installation-and-configuration/ssl/#configure-ssl", "title": "Configure SSL", "text": ""}, {"location": "cortex/installation-and-configuration/ssl/#connect-cortex-using-https", "title": "Connect Cortex using HTTPS", "text": "<p>We recommend using a reverse proxy to manage SSL layer; for example, Nginx. </p> Nginx <p>Reference: Configuring HTTPS servers on nginx.org</p> /etc/nginx/sites-available/cortex.conf<pre><code>server {\n  listen 443 ssl http2;\n  server_name cortex;\n\n  ssl on;\n  ssl_certificate       path-to/cortex-server-chained-cert.pem;\n  ssl_certificate_key   path-to/cortex-server-key.pem;\n\n  proxy_connect_timeout   600;\n  proxy_send_timeout      600;\n  proxy_read_timeout      600;\n  send_timeout            600;\n  client_max_body_size    2G;\n  proxy_buffering off;\n  client_header_buffer_size 8k;\n\n  location / {\n    add_header              Strict-Transport-Security \"max-age=31536000; includeSubDomains\";\n    proxy_pass              http://127.0.0.1:9001/;\n    proxy_http_version      1.1;\n  }\n}\n</code></pre>"}, {"location": "cortex/installation-and-configuration/ssl/#certificate-manager", "title": "Certificate manager", "text": "<p>Certificate manager is used to store client certificates and certificate authorities.</p>"}, {"location": "cortex/installation-and-configuration/ssl/#use-custom-certificate-authorities", "title": "Use custom Certificate Authorities", "text": "<p>The prefered way to use custom Certificate Authorities is to use the system configuration. </p> <p>If setting up a custom Certificate Authority (to connect web proxies, remote services like LPAPS server ...) is required globally in the application, the better solution consists of installing it on the OS and restarting Cortex. </p> DebianRPM <p>Ensure the package <code>ca-certificates-java</code> is installed , and copy the CA certificate in the right folder. Then run <code>dpkg-reconfigure ca-certificates</code> and restart Cortex service. </p> <pre><code>apt-get install -y ca-certificates-java\nmkdir /usr/share/ca-certificates/extra\ncp mycustomcert.crt /usr/share/ca-certificates/extra\ndpkg-reconfigure ca-certificates\nservice cortex restart\n</code></pre> <p>No additionnal packages is required on Fedora or RHEL. Copy the CA certificate in the right folder, run <code>update-ca-trust</code> and restart Cortex service.</p> <pre><code>cp mycustomcert.crt /etc/pki/ca-trust/source/anchors\nsudo update-ca-trust \nservice cortex restart\n</code></pre>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/", "title": "Step-by-Step guide", "text": ""}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#step-by-step-guide", "title": "Step-by-Step guide", "text": "<p>This page is a step by step installation and configuration guide to get a Cortex instance up and running. This guide is illustrated with examples for Debian and RPM packages based systems and for installation from binary packages.</p>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#required-packages", "title": "Required packages", "text": "DebianRPM <pre><code>apt install wget gnupg apt-transport-https git ca-certificates ca-certificates-java curl  software-properties-common python3-pip lsb_release\n</code></pre> <pre><code>yum install pkg-install gnupg chkconfig python3-pip git \n</code></pre>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#java-virtual-machine", "title": "Java Virtual Machine", "text": "<p>Manual installation required</p> <p>Starting with Cortex 3.2, the Java Virtual Machine is no longer installed automatically. You must manually install it before running Cortex.</p> <p>Install Java</p> <p>For enhanced security and long-term support, we recommend using Amazon Corretto, an OpenJDK build provided and maintained by Amazon.</p> DEBRPMOther <ol> <li>Open a terminal window.</li> <li> <p>Execute the following commands:</p> <pre><code>wget -qO- https://apt.corretto.aws/corretto.key | sudo gpg --dearmor -o /usr/share/keyrings/corretto.gpg\necho \"deb [signed-by=/usr/share/keyrings/corretto.gpg] https://apt.corretto.aws stable main\" | sudo tee -a /etc/apt/sources.list.d/corretto.sources.list\nsudo apt update\nsudo apt install java-common java-11-amazon-corretto-jdk\necho JAVA_HOME=\"/usr/lib/jvm/java-11-amazon-corretto\" | sudo tee -a /etc/environment\nexport JAVA_HOME=\"/usr/lib/jvm/java-11-amazon-corretto\"\n</code></pre> </li> <li> <p>Verify the installation by running:</p> <pre><code>java -version\n</code></pre> </li> <li> <p>You should see output similar to the following:</p> <pre><code>openjdk version \"11.0.12\" 2022-07-19\nOpenJDK Runtime Environment Corretto-11.0.12.7.1 (build 11.0.12+7-LTS)\nOpenJDK 64-Bit Server VM Corretto-11.0.12.7.1 (build 11.0.12+7-LTS, mixed mode)\n</code></pre> </li> </ol> <ol> <li>Open a terminal window.</li> <li> <p>Execute the following commands:</p> <pre><code>sudo rpm --import https://yum.corretto.aws/corretto.key &amp;&gt; /dev/null\nwget -qO- https://yum.corretto.aws/corretto.repo | sudo tee -a /etc/yum.repos.d/corretto.repo\nyum install java-11-amazon-corretto-devel &amp;&gt; /dev/null\necho JAVA_HOME=\"/usr/lib/jvm/java-11-amazon-corretto\" | sudo tee -a /etc/environment\nexport JAVA_HOME=\"/usr/lib/jvm/java-11-amazon-corretto\"\n</code></pre> </li> <li> <p>Verify the installation by running:</p> <pre><code>java -version\n</code></pre> </li> <li> <p>You should see output similar to the following:</p> <pre><code>openjdk version \"11.0.12\" 2022-07-19\nOpenJDK Runtime Environment Corretto-11.0.12.7.1 (build 11.0.12+7-LTS)\nOpenJDK 64-Bit Server VM Corretto-11.0.12.7.1 (build 11.0.12+7-LTS, mixed mode)\n</code></pre> </li> </ol> <p>The installation requires Java 11, so refer to your system documentation to install it.</p>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#elasticsearch", "title": "Elasticsearch", "text": "DebianRPM <pre><code>wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch |  sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg\necho \"deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/7.x/apt stable main\" |  sudo tee /etc/apt/sources.list.d/elastic-7.x.list \nsudo apt install elasticsearch   \n</code></pre> /etc/yum.repos.d/elasticsearch.repo<pre><code>[elasticsearch]\nname=Elasticsearch repository for 7.x packages\nbaseurl=https://artifacts.elastic.co/packages/7.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=0\nautorefresh=1\ntype=rpm-md\n</code></pre> <pre><code>sudo yum install --enablerepo=elasticsearch elasticsearch\n</code></pre>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#configuration", "title": "Configuration", "text": "/etc/elasticsearch/elasticsearch.yml<pre><code>http.host: 127.0.0.1\ntransport.host: 127.0.0.1\ncluster.name: hive\nthread_pool.search.queue_size: 100000\npath.logs: \"/var/log/elasticsearch\"\npath.data: \"/var/lib/elasticsearch\"\nxpack.security.enabled: false\nscript.allowed_types: \"inline,stored\"\n</code></pre> <p>Adjust this file according to the amount of RAM available on your server: </p> /etc/elasticsearch/jvm.options.d/jvm.options<pre><code>-Dlog4j2.formatMsgNoLookups=true\n-Xms4g\n-Xmx4g\n</code></pre>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#docker", "title": "Docker", "text": "<p>If using Docker images of Analyzers and Responders, Docker engine is required on the Operating System: </p> DebianRPM <pre><code>curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\\n$(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list\napt install docker-ce\n</code></pre> <pre><code>sudo yum remove -yq docker \\\n          docker-client \\\n          docker-client-latest \\\n          docker-common \\\n          docker-latest \\\n          docker-latest-logrotate \\\n          docker-logrotate \\\n          docker-engine\nsudo dnf -yq install dnf-plugins-core\nsudo dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo\nsudo dnf install -yq docker-ce docker-ce-cli containerd.io docker-compose-plugin\n</code></pre>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#cortex-installation-and-configuration", "title": "Cortex Installation and Configuration", "text": "<p>This section provides step-by-step instructions to install Cortex and configure it properly.</p>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#installation", "title": "Installation", "text": "<p>Cortex is available in Debian, RPM, and binary (zip archive) formats. All packages are signed using our GPG key 562CBC1C, with the following fingerprint:</p> <pre><code>0CD5 AC59 DE5C 5A8E 0EE1  3849 3D99 BB18 562C BC1C\n</code></pre>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#debian-based-installation", "title": "Debian-based Installation", "text": "<p>Ensure your system is up to date before installing Cortex. Run the following commands:</p> <pre><code>wget -qO- https://raw.githubusercontent.com/TheHive-Project/Cortex/master/PGP-PUBLIC-KEY | sudo tee /usr/share/keyrings/thehive-project.gpg &gt; /dev/null\n</code></pre> <p>Add the repository to your system:</p> <pre><code>echo \"deb [arch=all signed-by=/usr/share/keyrings/thehive-project.gpg] https://deb.thehive-project.org release main\" | sudo tee /etc/apt/sources.list.d/thehive-project.list\n</code></pre> <p>Update the package list and install Cortex:</p> <pre><code>sudo apt update\nsudo apt install cortex\n</code></pre>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#rpm-based-installation", "title": "RPM-based Installation", "text": "<p>For RPM-based distributions (CentOS, RHEL, Fedora), create a new repository configuration file:</p> <pre><code>sudo tee /etc/yum.repos.d/thehive-project.repo &lt;&lt;EOL\n[cortex]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=https://rpm.thehive-project.org/release/noarch\ngpgkey=https://raw.githubusercontent.com/TheHive-Project/Cortex/master/PGP-PUBLIC-KEY\ngpgcheck=1\nEOL\n</code></pre> <p>Then, install Cortex:</p> <pre><code>sudo yum install cortex\n</code></pre>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#binary-installation", "title": "Binary Installation", "text": "<p>For environments where package managers are not available, download and extract the Cortex binary package:</p> <pre><code>wget https://download.thehive-project.org/cortex-latest.zip\nunzip cortex-latest.zip -d /opt/cortex\ncd /opt/cortex\nchmod +x cortex\n</code></pre>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#post-installation-configuration", "title": "Post-Installation Configuration", "text": ""}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#running-analyzers-responders-with-docker", "title": "Running Analyzers &amp; Responders with Docker", "text": "<p>If you plan to use Cortex with Analyzers &amp; Responders running in Docker, ensure the <code>cortex</code> service account has appropriate permissions to interact with Docker:</p> <pre><code>sudo usermod -a -G docker cortex\n</code></pre>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#verify-installation", "title": "Verify Installation", "text": "<p>After installation, you can check if Cortex is properly installed by running:</p> <pre><code>cortex --version\n</code></pre> <p>This should return the installed version of Cortex.</p>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#configuration_1", "title": "Configuration", "text": "<p>Following settings are required to start Cortex successfully:</p> <ul> <li>Secret key configuration</li> <li>Database configuration</li> <li>Authentication</li> <li>Analyzers &amp; Responders configuration</li> </ul> <p>Advanced configuration settings might be added to run the application successfully: </p> <ul> <li>Specific Docker parameters</li> <li>Proxy settings</li> <li>SSL configuration</li> </ul>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#start-cortex-service", "title": "Start Cortex service", "text": "<p>Warning</p> <p>Before starting the service, ensure to have configured accordingly the application. Start by setting up the secret key.</p> <p>Save configuration file and run the service:</p> <pre><code>systemctl start cortex\n</code></pre> <p>Please note that the service may take some time to start. Once it is started, you may launch your browser and connect to <code>http://YOUR_SERVER_ADDRESS:9001/</code>. </p>"}, {"location": "cortex/installation-and-configuration/step-by-step-guide/#first-start", "title": "First start", "text": "<p>Refer to the First start guide for the next steps.</p>"}, {"location": "cortex/operations/backup-restore/", "title": "Backup & Restore", "text": ""}, {"location": "cortex/operations/backup-restore/#backup-and-restore-data", "title": "Backup and restore data", "text": "<p>All persistent data is stored in an Elasticsearch database. The backup and restore procedures are the ones that are detailed in Elasticsearch documentation.</p> <p>Note: you may have to adapt your indices in the examples below. To find the right index, use the following command :</p> <pre><code>curl 'localhost:9200/_cat/indices?v'\n</code></pre> <p>To save all your data you only need to backup the last indice. For example, if the previous command gives you the following results, all your data belongs to cortex_1.</p> <p>In the rest of this document, ensure to change  to your own last index in order to backup or restore all your data.</p>"}, {"location": "cortex/operations/backup-restore/#1-create-a-backup-repository", "title": "1. Create a backup repository", "text": "<p>First you must define a location in local filesystem (where Elasticsearch instance runs) where the backup will be written. This repository must be declared in the Elasticsearch configuration. Edit elasticsearch.yml file by adding:</p> <pre><code>path.repo: [\"/absolute/path/to/backup/directory\"]\n</code></pre> <p>Then, restart the Elasticsearch service.</p> <p>Note: Be careful if you run Elasticsearch in Docker, the directory must be mapped in host filesystem using <code>--volume</code> parameter (cf. Docker documentation).</p>"}, {"location": "cortex/operations/backup-restore/#2-register-a-snapshot-repository", "title": "2. Register a snapshot repository", "text": "<p>Create an Elasticsearch snapshot point named cortex_backup with the following command (set the same path in the location setting as the one set in the configuration file):</p> <pre><code>$ curl -XPUT 'http://localhost:9200/_snapshot/cortex_backup' -d '{\n    \"type\": \"fs\",\n    \"settings\": {\n        \"location\": \"/absolute/path/to/backup/directory\",\n        \"compress\": true\n    }\n}'\n</code></pre> <p>The result of the command should look like this :</p> <pre><code>{\"acknowledged\":true}\n</code></pre> <p>Since, everything is fine to backup and restore data.</p>"}, {"location": "cortex/operations/backup-restore/#3-backup-your-data", "title": "3. Backup your data", "text": "<p>Create a backup named snapshot_1 of all your data by executing the following command :</p> <p></p><pre><code>$ curl -XPUT 'http://localhost:9200/_snapshot/cortex_backup/snapshot_1?wait_for_completion=true&amp;pretty' -d '{\n  \"indices\": \"&lt;INDEX&gt;\"\n}'\n</code></pre> This command terminates only when the backup is complete and the result of the command should look like this: <pre><code>{\n  \"snapshots\": [{\n    \"snapshot\": \"snapshot_1\",\n    \"uuid\": \"ZQ3kv5-FQoeN3NFIhfKgMg\",\n    \"version_id\": 5060099,\n    \"version\": \"5.6.0\",\n    \"indices\": [\"cortex_1\"],\n    \"state\": \"SUCCESS\",\n    \"start_time\": \"2018-01-29T14:41:51.580Z\",\n    \"start_time_in_millis\": 1517236911580,\n    \"end_time\": \"2018-01-29T14:42:05.216Z\",\n    \"end_time_in_millis\": 1517236925216,\n    \"duration_in_millis\": 13636,\n    \"failures\": [],\n    \"shards\": {\n      \"total\": 41,\n      \"failed\": 0,\n      \"successful\": 41\n    }\n  }]\n}\n</code></pre> <p>Note: You can backup the last index of Cortex (you can list indices in your Elasticsearch cluster with <code>curl -s http://localhost:9200/_cat/indices | cut -d ' '  -f3</code> ) or all indices with <code>_all</code> value.</p>"}, {"location": "cortex/operations/backup-restore/#4-restore-data", "title": "4. Restore data", "text": "<p>Restore will do the reverse actions : it reads the backup in your snapshot directory and loads indices into the Elasticsearch cluster. This operation is done with the following command : </p><pre><code>$ curl -XPOST 'http://localhost:9200/_snapshot/cortex_backup/snapshot_1/_restore' -d '\n{\n  \"indices\": \"&lt;INDEX&gt;\"\n}'\n</code></pre> <p>The result of the command should look like this :</p> <pre><code>{\"accepted\":true}\n</code></pre> <p>Note: be sure to restore data from the same version of Elasticsearch.</p>"}, {"location": "cortex/operations/backup-restore/#5-moving-data-from-one-server-to-another", "title": "5. Moving data from one server to another", "text": "<p>If you want to move your data from one server from another: - Create your backup on the origin server (steps 1, 2, 3) - copy your backup directory from the origin server to the destination server - On the destination server :     - Register your backup repository in the Elasticsearch configuration (step 1)     - Register your snapshot repository with the same snapshot name (step 2)     - Restore your data (step 4)</p>"}, {"location": "cortex/operations/input-output/", "title": "Analyzers/Responders input and output", "text": ""}, {"location": "cortex/operations/input-output/#analyzers-responders-communication", "title": "Analyzers / Responders communication", "text": "<p>From version 3, cortexutils 2.x is required because communication between Cortex and the analyzers/responders has changed. Analyzers and responders doesn't need to be rewritten if they use cortexutils. Cortex 2 send data using stdin and receive result from stdout.</p> <p>Cortex 3 uses files: a job is stored in a folder with the following structure:</p> <pre><code>job_folder\n  \\_ input\n   |    \\_ input.json    &lt;- input data, equivalent to stdin with Cortex 2.x\n   |    |_ attachment    &lt;- optional extra file when analysis concerns a file\n   |_ output\n        \\_ output.json   &lt;- report of the analysis (generated by analyzer or responder)\n        |_ extra_file(s) &lt;- optional extra files linked to report (generated by analyzer)\n</code></pre> <p>Job folder is provided to analyzer/responder as argument. Currently, only one job is acceptable but in future release, analyzer/responder will accept several job at a time (bulk mode) in order to increase performance.</p>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/", "title": "Upgrade to Cortex 3.1", "text": ""}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#migration-from-elasticsearch-682-to-es-7x", "title": "Migration from Elasticsearch 6.8.2 to ES 7.x", "text": "<p>\u26a0\ufe0f IMPORTANT NOTE</p> <ul> <li>This migration process is intended for single node of Elasticsearch database</li> <li>The current version of this document is provided for testing purpose ONLY! </li> <li>This guide has been written and tested to migrate data from ES 6.8.2 to ES 7.8.1, and Cortex 3.0.1 to Cortex 3.1.0 only!</li> <li>This guide starts with Elasticsearch version 6.8.2  up and running, indexes and data. To test this guide, we recommend using a backup of you production server. (see Backup and Restore page for more information)</li> <li>This guide is illustrated with Cortex index. The process is identical for Cortex, you just have to adjust index names.</li> </ul>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#prerequisite", "title": "Prerequisite", "text": "<p>The software <code>jq</code> is required to manipulate JSON and create new indexes. More information at https://stedolan.github.io/jq/. </p>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#identify-if-your-index-should-be-reindexed", "title": "Identify if your index should be reindexed", "text": "<p>You can easily identify if indexes should be reindexed or not. On the index named <code>cortex_4</code> run the following command: </p> <pre><code>curl -s http://127.0.0.1:9200/cortex_4?human | jq '.cortex_4.settings.index.version.created'\n</code></pre> <p>if the output is similar to <code>\"5xxxxxx\"</code>  then reindexing is required, you should follow this guide. </p> <p>If it is   <code>\"6xxxxxx\"</code> then the index can be read by Elasticsearch 7.8.x. Upgrade Elasticsearch, and Cortex 3.1.0.</p>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#migration-guide", "title": "Migration guide", "text": ""}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#current-status", "title": "Current status", "text": "<p>Current context is:  - Elasticsearch 6.8.2 - Cortex 3.0.1</p> <p>All up and running. </p> <p>Start by identifying indices on you Elasticsearch instance.</p> <pre><code>curl  http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   cortex_4    Y5rDTO23RBC_n6pjFP0-Qw   5   0       8531            8       13mb           13mb \n</code></pre> <p>The index name is <code>cortex_4</code>. Record this somewhere.</p>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#stop-services", "title": "Stop services", "text": "<p>Before starting updating the database, lets stop applications:</p> <pre><code>sudo service cortex stop \n</code></pre>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#create-a-new-index", "title": "Create a new index", "text": "<p>The First operation lies in creating a new index named <code>new_cortex_4</code> with settings from current index <code>cortex_4</code> (ensure to keep index version, needed for future upgrade).</p> <pre><code>curl -XPUT 'http://localhost:9200/new_cortex_4' \\\n  -H 'Content-Type: application/json' \\\n  -d \"$(curl http://localhost:9200/cortex_4 |\\\n   jq '.cortex_4 |\n   del(.settings.index.provided_name,\n    .settings.index.creation_date,\n    .settings.index.uuid,\n    .settings.index.version,\n    .settings.index.mapping.single_type,\n    .mappings.doc._all)'\n    )\"\n</code></pre> <p>Check the new index is well created: </p> <pre><code>curl -XGET http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   new_cortex_4    wRX6rhzXTuW_F2wLNxqVyg   5   0          0            0      1.1kb          1.1kb\ngreen  open   cortex_4        Y5rDTO23RBC_n6pjFP0-Qw   5   0       8531            8       13mb           13mb\n</code></pre>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#proceed-to-reindex", "title": "Proceed to Reindex", "text": "<p>Next operation lies in running the reindex command in the newly created index:</p> <pre><code>curl -XPOST -H 'Content-Type: application/json' http://localhost:9200/_reindex -d '{\n  \"conflicts\": \"proceed\",\n  \"source\": {\n    \"index\": \"cortex_4\"\n  },\n  \"dest\": {\n    \"index\": \"new_cortex_4\"\n  }\n}'\n</code></pre> <p>After a moment, you should get a similar output:  </p> <pre><code>{\n    \"took\": 5119,\n    \"timed_out\": false,\n    \"total\": 5889,\n    \"updated\": 0,\n    \"created\": 5889,\n    \"deleted\": 0,\n    \"batches\": 6,\n    \"version_conflicts\": 0,\n    \"noops\": 0,\n    \"retries\": {\n        \"bulk\": 0,\n        \"search\": 0\n    },\n    \"throttled_millis\": 0,\n    \"requests_per_second\": -1.0,\n    \"throttled_until_millis\": 0,\n    \"failures\": []\n}\n</code></pre>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#ensure-new-index-has-been-created", "title": "Ensure new index has been created", "text": "<p>Run the following command, and ensure the new index is like the current one (size can vary):</p> <pre><code>curl -XGET http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   new_cortex_4    wRX6rhzXTuW_F2wLNxqVyg   5   0       8531            0     12.6mb         12.6mb\ngreen  open   cortex_4        Y5rDTO23RBC_n6pjFP0-Qw   5   0       8531            8       13mb           13mb\n</code></pre>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#delete-old-indices", "title": "Delete old indices", "text": "<p>This is the thrilling part.  Now the new index <code>new_cortex_4</code> is created and similar to <code>cortex_4</code>,  older indexes should be completely deleted from the database. To delete index named <code>cortex_4</code>, run the following command:  </p> <pre><code>curl -XDELETE http://localhost:9200/cortex_4\n</code></pre> <p>Run the same command for older indexes if exist (cortex_3, cortex_2....). Elasticsearch 7.x cannot run with index created with Elasticsearch 5.x.</p>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#create-an-alias", "title": "Create an alias", "text": "<p>Before stopping Elasticsearch service, let\u2019s create an alias to keep index names in the future.  </p> <pre><code>curl -XPOST -H 'Content-Type: application/json'  'http://localhost:9200/_aliases' -d '{\n    \"actions\": [\n        {\n            \"add\": {\n                \"index\": \"new_cortex_4\",\n                \"alias\": \"cortex_4\"\n            }\n        }\n    ]\n}'\n</code></pre> <p>Doing so will allow Cortex 3.1.0  to find the index without updating the configuration file. </p> <p>Check the alias has been well created by running the following command</p> <pre><code>curl -XGET http://localhost:9200/_alias?pretty\n</code></pre> <p>The output should look like:</p> <pre><code>{\n  \"new_cortex_4\" : {\n    \"aliases\" : {\n      \"cortex_4\" : { }\n    }\n  }\n}\n</code></pre>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#stop-elasticsearch-version-682", "title": "Stop Elasticsearch version 6.8.2", "text": "<pre><code>sudo service elasticsearch stop \n</code></pre>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#update-elasticsearch", "title": "Update Elasticsearch", "text": "<p>Update the configuration of Elastisearch. Configuration file should look like this:</p> <pre><code>[..]\nhttp.host: 127.0.0.1\ndiscovery.type: single-node\ncluster.name: hive\nscript.allowed_types: inline\nthread_pool.search.queue_size: 100000\nthread_pool.write.queue_size: 10000    \n</code></pre> <p>Now, upgrade Elasticsearch to version 7.x following the documentation for your Operating System, and ensure the service start successfully.</p>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#install-or-update-to-cortex-310", "title": "Install or update to Cortex 3.1.0", "text": ""}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#deb-package", "title": "DEB package", "text": "<p>If using Debian based Linux operating system, configure it to follow our beta repository:</p> <p></p><pre><code>curl https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY | sudo apt-key add -\necho 'deb https://deb.thehive-project.org release main' | sudo tee -a /etc/apt/sources.list.d/thehive-project.list\nsudo apt-get update\n</code></pre> Then install it by running: <pre><code>sudo apt install cortex\n</code></pre> <p>or</p> <pre><code>sudo apt install cortex=3.1.0-1\n</code></pre>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#rpm", "title": "RPM", "text": "<p>Setup your system to connect the RPM repository. Create and edit the file  <code>/etc/yum.repos.d/thehive-project.repo</code> :</p> <pre><code>[thehive-project]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=http://rpm.thehive-project.org/release/noarch\ngpgcheck=1\n</code></pre> <p>Then install it by running:</p> <pre><code>sudo yum install cortex\n</code></pre> <p>or </p> <pre><code>sudo yum install cortex-3.1.0-1\n</code></pre>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#install-binaries", "title": "Install binaries", "text": "<pre><code>cd /opt\nwget https://download.thehive-project.org/cortex-3.1.0-1.zip\nunzip cortex-3.1.0-1.zip\nln -s cortex-3.1.0-1 cortex\n</code></pre>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#docker-images", "title": "Docker images", "text": "<p>Docker images are also provided on Dockerhub. </p> <pre><code>docker pull thehiveproject/cortex:3.1.0-1\n</code></pre> <p>\u26a0\ufe0f  Starting from this version, docker image doesn't contain analyzers anymore. Analyzers__/__Responders and Cortex have different life-cycles, their update including their dependencies should not be correlated to Cortex update. </p> <p>It is recommended to use docker version of analyzers : this can be done by binding docker service docket inside cortex container (run with <code>-v /var/run/docker.sock:/var/run/docker.sock</code>).</p>"}, {"location": "cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#update-database", "title": "Update Database", "text": "<p>Connect to TheHive (and Cortex), the maintenance page should ask to update. </p> <p>Once updated, ensure a new index named <code>cortex_5</code> has been created.</p> <pre><code>curl -XGET http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   new_cortex_4 GV-3Y8QjTjWw0F-p2sjW6Q   5   0      30977            0       26mb           26mb\nyellow open   cortex_5     Nz0vCKqhRK2xkx1t_WF-0g   5   1      30977            0     26.1mb         26.1mb\n</code></pre>"}, {"location": "cortex/user-guides/first-start/", "title": "First start", "text": ""}, {"location": "cortex/user-guides/first-start/#quick-start-guide", "title": "Quick Start Guide", "text": "<p>This is the Quick Start guide for Cortex 3. It assumes that Cortex has been installed, and that the analyzers have been installed as well.</p>"}, {"location": "cortex/user-guides/first-start/#step-1-connect-to-cortex", "title": "Step 1: Connect to Cortex", "text": "<p>One Cortex is installed and configured, open your web browser and connect to http://cortexaddress:9001. </p>"}, {"location": "cortex/user-guides/first-start/#step-2-update-the-database", "title": "Step 2: Update the Database", "text": "<p>Cortex uses ElasticSearch to store users, organizations and analyzers configuration. The first time you connect to the Web UI (<code>http://&lt;CORTEX_IP&gt;:9001</code> by default), you have to create the database by clicking the <code>Update Database</code> button.</p> <p></p>"}, {"location": "cortex/user-guides/first-start/#step-3-create-the-cortex-super-administrator", "title": "Step 3: Create the Cortex Super Administrator", "text": "<p>You are then invited to create the first user. This is a Cortex global administration user or <code>superAdmin</code>. This user account will be able to create Cortex organizations and users.</p> <p></p> <p>You will then be able to log in using this user account. You will note that the default <code>cortex</code> organization has been created and that it includes your user account, a Cortex global admininistrator.</p> <p></p>"}, {"location": "cortex/user-guides/first-start/#step-4-create-an-organization", "title": "Step 4: Create an Organization", "text": "<p>The default <code>cortex</code> organization cannot be used for any other purpose than managing global administrators (users with the <code>superAdmin</code> role), organizations and their associated users. It cannot be used to enable/disable or configure analyzers. To do so, you need to create your own organization inside Cortex by clicking on the <code>Add organization</code>  button.</p> <p></p>"}, {"location": "cortex/user-guides/first-start/#step-5-create-a-organization-administrator", "title": "Step 5: Create a Organization Administrator", "text": "<p>Create the organization administrator account (user with an <code>orgAdmin</code> role).</p> <p></p> <p>Then, specify a password for this user. After doing so,  log out and log in with that new user account.</p>"}, {"location": "cortex/user-guides/first-start/#step-6-enable-and-configure-analyzers", "title": "Step 6: Enable and Configure Analyzers", "text": "<p>Enable the analyzers you need, configure them using the Organization &gt; Configuration and Organization &gt; Analyzers tabs. All analyzer configuration is done using the Web UI, including adding API keys and configuring rate limits.</p>"}, {"location": "cortex/user-guides/first-start/#step-7-optional-create-an-account-for-thehive-integration", "title": "Step 7 (Optional): Create an Account for TheHive integration", "text": "<p>If you are using TheHive, create a new account inside your organization with the <code>read, analyze</code> role and generate an API key that you will need to add to TheHive's configuration.</p> <p></p>"}, {"location": "cortex/user-guides/roles/", "title": "User roles", "text": ""}, {"location": "cortex/user-guides/roles/#user-roles", "title": "User Roles", "text": "<p>Cortex defines four roles:</p> <ul> <li><code>read</code>: the user can access all the jobs that have been performed by the Cortex 2 instance, including their results. However, this role cannot submit jobs. Moreover, this role cannot be used in the default <code>cortex</code> organization. This organization can only contain super administrators.</li> <li><code>analyze</code>: the <code>analyze</code> role implies the <code>read</code> role, described above. A user who has a <code>analyze</code> role can submit a new job using one of the configured analyzers for their organization. This role cannot be used in the default <code>cortex</code> organization. This organization can only contain super administrators.</li> <li><code>orgAdmin</code>: the <code>orgAdmin</code> role implies the <code>analyze</code> role. A user who has an <code>analyze</code> role can manage users within their organization. They can add users and give them <code>read</code>, <code>analyze</code> and/or <code>orgAdmin</code> roles. This role also permits to configure analyzers for the organization. This role cannot be used in the default  <code>cortex</code> organization. This organization can only contain super administrators.</li> <li><code>superAdmin</code>: this role is incompatible with all the other roles listed above (see chart below for examples). It can be used solely for managing organizations and their associated users. When you install Cortex, the first user that is created will have this role. Several users can have it as well but only in the default <code>cortex</code> organization, which is automatically created during installation.</li> </ul> <p>The chart below lists the roles and what they can and cannot do:</p> Actions read analyze orgAdmin superAdmin Read reports X X X Run jobs X X Enable/Disable analyzer X Configure analyzer X Create org analyst X X Delete org analyst X X Create org admin X X Delete org admin X X Create Org X Delete Org X Create Cortex admin user X"}, {"location": "resources/", "title": "Resources", "text": ""}, {"location": "resources/#resources", "title": "Resources", "text": "<p>In this section, you can find a collection of valuable resources regarding the applications. </p>"}, {"location": "resources/#demo-virtual-machine", "title": "Demo virtual machine", "text": "<p>Learn how to download and use our demo virtual Machine</p>"}, {"location": "resources/#iaas-environment", "title": "IaaS environment", "text": "<p>Your have your own cloud infrastruture and wish to manage and include TheHive and Cortex ; learn how to deploy our dedicated images by reading our usage instructions:</p> <ul> <li> Amazon AWS environment:<ul> <li>for TheHive and Cortex</li> <li>or Infra as Code deployment</li> </ul> </li> <li>:simple-microsoftazure: Microsoft Azure environment:<ul> <li>for TheHive and Cortex</li> <li>or Infra as Code deployment</li> </ul> </li> </ul> <p>Resources for the official cloud distributions of TheHive and Cortex</p> <p>This documentation contains sample Terraform and cloud-init code to easily launch and update TheHive and Cortex instances.</p>"}, {"location": "resources/#main-features-of-the-cloud-distributions-of-thehive-and-cortex", "title": "Main features of the cloud distributions of TheHive and Cortex", "text": ""}, {"location": "resources/#easy-to-use-and-deploy", "title": "Easy to use and deploy", "text": "<p>The cloud distributions were built with operations and automation in mind. We wanted DevSecOps-friendly products that would fit in most organizations, no matter how simple or complex their infrastructure.</p>"}, {"location": "resources/#always-up-to-date", "title": "Always up-to-date", "text": "<p>The images are updated whenever a new TheHive or Cortex version is released. No need to bother updating your instances anymore, just launch a new one with a fresh image as if it were a container!</p>"}, {"location": "resources/#production-ready", "title": "Production-ready", "text": "<ul> <li>Dedicated data volumes: All persistent data is stored on dedicated volumes, not in the root filesystem. </li> <li>Easy-resizing: Resizing independent data volumes is a lot easier as no action is required within the instance at the operating system level.</li> <li>Ubuntu-based: Our images are based on the official Ubuntu 20.04 LTS distributions from Canonical.</li> <li>Hardened OS: The underlying Ubuntu OS is hardened to comply with CSL1 - that's Common Sense Level 1. Ok that's not a real thing (yet) but the OS really was carefully configured to be as secured as possible by default while remaining usable in most contexts. Note that there are no iptables surprises inside the image to avoid conflicting behaviour with security groups of firewalls.</li> <li>Application only: The images include either the TheHive or Cortex application only. They are not meant to be public-facing on their own and should be deployed within your VPC and exposed with the public facing system of your choice (load balancer, reverse proxy). More information on the recommended reference architecture is provided in each cloud distribution user guide.</li> </ul>"}, {"location": "resources/cortex4py/", "title": "Cortex4py", "text": ""}, {"location": "resources/cortex4py/#cortex4py", "title": "Cortex4py", "text": "<p>Cortex4py is a Python API client for Cortex.</p> <p></p> <p> </p> <ul> <li>Sources: https://github.com/TheHive-Project/Cortex4py</li> <li>Documentation: https://github.com/TheHive-Project/Cortex4py</li> </ul>"}, {"location": "resources/cortexutils/", "title": "Cortexutils", "text": ""}, {"location": "resources/cortexutils/#cortexutils", "title": "Cortexutils", "text": "<p>Cortexutils is a Python library containing a set of classes that aims to make users write Cortex analyzers and responders easier.</p> <p></p> <p> </p> <ul> <li>Sources: https://github.com/TheHive-Project/Cortexutils</li> <li>Documentation: https://github.com/TheHive-Project/Cortexutils</li> </ul>"}, {"location": "resources/demo/", "title": "How to download the VM", "text": ""}, {"location": "resources/demo/#how-to-download-the-demo-vm", "title": "How to download the demo VM", "text": "<p>A ready-to-use virtual machine can be downloaded at https://www.strangebee.com/tryit. This VM is prepared and updated by StrangeBee and is powered by the latest versions of:</p> <ul> <li>TheHive: Security Incident Response and Case management platform</li> <li>Cortex: Extendable Analysis, Enrichment and Response automation framework</li> </ul> <p>Warning</p> <p>The VM is built for testing purposes and is NOT RECOMMENDED for production.</p> <p>Note</p> <p>Full documentation of this Virtual machine can be found here</p>"}, {"location": "resources/howto-vm-demo/", "title": "Use the Demo Virtual Machine", "text": ""}, {"location": "resources/howto-vm-demo/#use-the-demo-virtual-machine", "title": "Use the Demo Virtual Machine", "text": "<p>Warning</p> <p>Ensure good performance by allocating a minimum of 6 GB of RAM to run this Virtual Machine flawlessly. Adjusting the allocation below this threshold may lead to potential complications.</p>"}, {"location": "resources/howto-vm-demo/#start-the-vm", "title": "Start the VM", "text": "Using VMWareUsing VirtualBox <ol> <li>Start the Virtual Machine, and follow the instructions.</li> <li>Open the indicated url in your browser: http://IP-ADDRESS</li> </ol> <ol> <li>When importing, ensure to set Guest OS type information. </li> <li>Once imported, update the network settings of the VM before starting it. </li> <li>Add required port forwarding (update according to your needs) and save. </li> <li>Start the VM and open the follwing url in your browser: http://127.0.0.1:8888</li> <li>You might have to also adjust Display graphical controller and set it to <code>VMSVGA</code> before starting the VM. </li> </ol>"}, {"location": "resources/howto-vm-demo/#quick-connect", "title": "Quick connect", "text": "<p>Following instructions are also shared in the web page coming with the virtual machine</p> <p></p> <p>TheHive Credentials</p> <p>This VM comes with 2 accounts in TheHive: </p> <p>Administrator:</p> <ul> <li>Login: <code>admin@thehive.local</code></li> <li>Password: <code>secret</code></li> </ul> <p>A user named <code>thehive</code> has been created and is <code>org-admin</code> of the organization named <code>demo</code>: </p> <ul> <li>Login: <code>thehive@thehive.local</code></li> <li>Password: <code>thehive1234</code></li> </ul> <p>TheHive database comes with several samples of data, like custom fields, MISP taxonomies, MITRE Att&amp;ck data, a Case Template and an Alert. </p> <p></p> <p>Cortex credentials</p> <p>This VM comes with 2 accounts in Cortex:</p> <p>Administrator: </p> <ul> <li>Login: <code>admin</code></li> <li>Password: <code>thehive1234</code> </li> </ul> <p>An organization is also created with an <code>orgadmin</code> account: </p> <ul> <li>Login: <code>thehive</code></li> <li>Password: <code>thehive1234</code></li> </ul> <p>Warning</p> <p>The VM is solely intended to be used for testing purposes. We strongly encourage you to refrain from using it in production.</p>"}, {"location": "resources/howto-vm-demo/#content", "title": "Content", "text": "<p>The VM runs Debian 11. The most recent VM includes:</p> <ul> <li>TheHive 5.x using a local BerkeleyDB and file storage, </li> <li>Cortex 3.1.x , and Elasticsearch 7</li> <li>TheHive4py</li> <li>Cortex4py</li> <li>Public Cortex Analyzers and Responders are running with Docker </li> </ul>"}, {"location": "resources/howto-vm-demo/#configuration-details", "title": "Configuration details", "text": "<p>Applications launched with Docker-compose, as docker containers with attached volumes in <code>/opt/thp</code>. </p> <pre><code>.\n\u251c\u2500\u2500 cassandra\n\u251c\u2500\u2500 cortex\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 elasticsearch\n\u251c\u2500\u2500 nginx\n\u2514\u2500\u2500 thehive\n</code></pre>"}, {"location": "resources/howto-vm-demo/#thehive", "title": "TheHive", "text": "<p>TheHive is configured to use Cassandra as database and Elasticsearch to index data. Files are stored in a local path. </p> <pre><code>thehive\n\u251c\u2500\u2500 config\n\u251c\u2500\u2500 files\n\u2514\u2500\u2500 log\n</code></pre> <ul> <li><code>config</code>: all configuration files for TheHive</li> <li><code>files</code>: files storage </li> <li><code>log</code>: TheHive application logs </li> </ul>"}, {"location": "resources/howto-vm-demo/#cortex", "title": "Cortex", "text": "<p>Cortex uses Elasticsearch as database which is also run as a container with Docker-Compose. Dedicated volumes are configured: <code>/opt/thp/elasticsearch/data</code> to store data, and <code>/opt/thp/elasticsearch/log</code>, for logs.</p> <pre><code>cortex\n\u251c\u2500\u2500 config\n\u251c\u2500\u2500 jobs\n\u2514\u2500\u2500 log\n</code></pre> <ul> <li><code>config</code>: all configuration files for TheHive</li> <li><code>jobs</code>: shared volume for Analyzers and Responders jobs</li> <li><code>log</code>: Cortex application logs</li> </ul>"}, {"location": "resources/howto-vm-demo/#operations", "title": "Operations", "text": ""}, {"location": "resources/howto-vm-demo/#virtual-machine", "title": "Virtual Machine", "text": "<p>A system user account <code>thehive/thehive1234</code> can be used to operate the VM.</p> <p>All applications are run as docker containers, using docker-compose. The <code>docker-compose.yml</code> is in the folder <code>/opt/thp</code>. </p>"}, {"location": "resources/howto-vm-demo/#thehive_1", "title": "TheHive", "text": "<p>After each modification of TheHive configuration service should be restart.</p> <ul> <li> <p>Configuration file of TheHive is in <code>/opt/thp/thehive/config/application.conf</code></p> </li> <li> <p>Service can be restart by running following commands:</p> </li> </ul> <pre><code>cd /opt/thp\ndocker compose restart thehive\n</code></pre>"}, {"location": "resources/howto-vm-demo/#cortex_1", "title": "Cortex", "text": "<p>After each modification of Cortex configuration service should be restart.</p> <ul> <li> <p>Configuration file of TheHive is in <code>/opt/thp/cortex/config/application.conf</code></p> </li> <li> <p>Service can be restart by running following commands:</p> </li> </ul> <pre><code>cd /opt/thp\ndocker compose restart cortex\n</code></pre>"}, {"location": "resources/howto-vm-demo/#check-for-update", "title": "Check for update", "text": "<p>Check for update for TheHive and Cortex by running following commands (this will stop running applications): </p> <pre><code>cd /opt/thp\nbash update.sh\n</code></pre>"}, {"location": "resources/howto-vm-demo/#documentation", "title": "Documentation", "text": "<ul> <li>Documentation for TheHive 5 can be found there:  https://docs.strangebee.com. </li> </ul>"}, {"location": "resources/howto-vm-demo/#troubleshooting", "title": "Troubleshooting", "text": "<p>TheHive service logs are located in <code>/opt/thp/thehive/log/application.log</code>.</p> <p>Cortex service logs are located in <code>/opt/thp/cortex/log/application.log</code>.</p>"}, {"location": "resources/howto-vm-demo/#need-help", "title": "Need Help?", "text": "<p>Something does not work as expected? No worries, we got you covered. Join our community and contact us on Discord! </p>"}, {"location": "resources/security/", "title": "Security", "text": ""}, {"location": "resources/security/#security", "title": "Security", "text": "<p>Find our Responsible Vulnerability Disclosure policy and Security advisories on our dedicated repository: </p> <ul> <li>https://github.com/StrangeBeeCorp/Security</li> </ul>"}, {"location": "resources/templates/", "title": "TheHive templates", "text": ""}, {"location": "resources/templates/#thehive-templates", "title": "TheHive templates", "text": "<p>A repository dedicated to the sharing of TheHive Templates. Contributions are welcome ! Discover Cases, Dashboards, pages and Reports templates ready for TheHive 5.</p> <p></p> <p> </p> <ul> <li>Sources: https://github.com/StrangeBeeCorp/thehive-templates</li> <li>Documentation:<ul> <li>Case templates</li> <li>Page templates</li> <li>Report templates</li> <li>Dashboard templates</li> </ul> </li> </ul> <p>If you'd like to contribute and share your templates with TheHive 5 users community, feel free to create a pull request on the github repository. </p>"}, {"location": "resources/thehive4py/", "title": "TheHive4py", "text": ""}, {"location": "resources/thehive4py/#thehive4py", "title": "TheHive4py", "text": "<p>TheHive4py is a Python API client for TheHive.</p> <p></p> <p> </p> <ul> <li>Sources: https://github.com/TheHive-Project/TheHive4py</li> <li>Documentation: https://thehive-project.github.io/TheHive4py/</li> </ul>"}, {"location": "resources/iaas/aws/", "title": "Main Features", "text": ""}, {"location": "resources/iaas/aws/#aws-iaas-images", "title": "AWS IaaS images", "text": ""}, {"location": "resources/iaas/aws/#thehive-main-feature", "title": "TheHive main feature", "text": ""}, {"location": "resources/iaas/aws/#easy-to-use-and-deploy", "title": "Easy to use and deploy", "text": "<p>The AMI was built with operations and automation in mind. We wanted a DevSecOps-friendly product that would fit in most organizations, no matter how simple or complex their infrastructure.</p>"}, {"location": "resources/iaas/aws/#always-up-to-date", "title": "Always up-to-date", "text": "<p>The AMI is updated whenever a new Cortex version is released. No need to bother updating Cortex anymore, just launch a new instance as if it were a container!</p>"}, {"location": "resources/iaas/aws/#production-ready", "title": "Production-ready", "text": "<ul> <li>Dedicated data and Docker volumes: Cortex data is stored on a dedicated EBS volume, not in the root filesystem. With that in mind, the AMI will create a persistent 30GB EBS volume at launch that will not be deleted when the instance is terminated so that your Cortex data isn't accidentally lost. Docker images for analyzers and responders are also stored on a dedicated volume so you can adjust its size to your needs, the AMI will create a 20GB volume by default. Both volumes will be encrypted with your default KMS key. You can of course change the default volume size and encryption key.</li> <li>Ubuntu-based: The AMI is based on the official Ubuntu 20.04 LTS AMI from Canonical.</li> <li>Hardened OS: The underlying Ubuntu OS is hardened to comply with CSL1 - that's Common Sense Level 1. Ok that's not a real thing (yet) but the OS really was carefully configured to be as secured as possible by default while remaining usable in most contexts. Note that there are no iptables surprises inside the image to avoid conflicting behavior with security groups.</li> <li>Application only: The AMI includes Cortex application only. It is not meant to be public-facing on its own and should be deployed within your VPC and exposed with the public facing system of your choice (load balancer, reverse proxy). More information on the recommended reference architecture is provided in this user guide.</li> </ul>"}, {"location": "resources/iaas/aws/#cortex-main-features", "title": "Cortex main Features", "text": ""}, {"location": "resources/iaas/aws/#easy-to-use-and-deploy_1", "title": "Easy to use and deploy", "text": "<p>The AMI was built with operations and automation in mind. We wanted a DevSecOps-friendly product that would fit in most organizations, no matter how simple or complex their infrastructure.</p>"}, {"location": "resources/iaas/aws/#always-up-to-date_1", "title": "Always up-to-date", "text": "<p>The AMI is updated whenever a new Cortex version is released. No need to bother updating Cortex anymore, just launch a new instance as if it were a container!</p>"}, {"location": "resources/iaas/aws/#production-ready_1", "title": "Production-ready", "text": "<ul> <li>Dedicated data and Docker volumes: Cortex data is stored on a dedicated EBS volume, not in the root filesystem. With that in mind, the AMI will create a persistent 30GB EBS volume at launch that will not be deleted when the instance is terminated so that your Cortex data isn't accidentally lost. Docker images for analyzers and responders are also stored on a dedicated volume so you can adjust its size to your needs, the AMI will create a 20GB volume by default. Both volumes will be encrypted with your default KMS key. You can of course change the default volume size and encryption key.</li> <li>Ubuntu-based: The AMI is based on the official Ubuntu 20.04 LTS AMI from Canonical.</li> <li>Hardened OS: The underlying Ubuntu OS is hardened to comply with CSL1 - that's Common Sense Level 1. Ok that's not a real thing (yet) but the OS really was carefully configured to be as secured as possible by default while remaining usable in most contexts. Note that there are no iptables surprises inside the image to avoid conflicting behavior with security groups.</li> <li>Application only: The AMI includes Cortex application only. It is not meant to be public-facing on its own and should be deployed within your VPC and exposed with the public facing system of your choice (load balancer, reverse proxy). More information on the recommended reference architecture is provided in this user guide.</li> </ul>"}, {"location": "resources/iaas/aws/cortex/", "title": "Deploy Cortex AMI", "text": ""}, {"location": "resources/iaas/aws/cortex/#usage-instructions-for-the-official-ami-version-of-cortex", "title": "Usage instructions for the official AMI version of Cortex", "text": "<p> Official AMI This is the official Cortex v3 release for the AWS Marketplace.</p> <p>The AMI can be used to set up a shiny-new Cortex install or to launch an instance with existing data and configuration (for update / migration / restore purposes).</p>"}, {"location": "resources/iaas/aws/cortex/#introduction", "title": "Introduction", "text": "<ul> <li>Based on the official Ubuntu 20.04 AMI from Canonical</li> <li>The AMI is updated whenever a new Cortex version is released - no need to bother updating Cortex anymore, just launch a new instance as if it were a container!</li> <li>Cortex data and Docker images (for analyzers and responders) are stored on two dedicated EBS volumes, not in the root filesystem. With that in mind, the AMI will create two persistent EBS data volume at launch that will not be deleted when the instance is terminated so that your data isn't accidentally lost. The volumes will be encrypted with your default KMS key.<ul> <li>The Cortex data volume (/dev/sdh) is sized at 30GB by default</li> <li>The Docker volume (/dev/sdi) is sized at 20GB by default</li> </ul> </li> <li>The underlying Ubuntu OS is hardened to comply with CSL1 (that's Common Sense Level 1!) minus the network filtering. There are no iptables surprises inside the image to avoid conflicting behavior with security groups.</li> </ul>"}, {"location": "resources/iaas/aws/cortex/#run-context", "title": "Run context", "text": "<ul> <li>The Cortex app runs as unprivileged user cortex and is available on port http 9001 (that's http and NOT https). Needless to say we encourage you never to open that port outside your VPC and use a public-facing load balancer and / or reverse proxy to handle the TLS sessions with end-users. Since many Cortex users also run TheHive and MISP instances alongside and since the right load balancer / reverse proxy is obviously the one you know best, we elected not to include yet another one in this AMI. We provide more information on using the AWS Application Load Balancer or reverse proxies in our detailed Cortex AMI user guide.</li> <li>The default sudoer user is ubuntu and the ssh service listens on port 22.</li> <li>The Cortex configuration is set to look for custom analyzers under <code>/opt/cortexneurons/analyzers</code> and for custom responders under <code>/opt/cortexneurons/responders</code>.</li> <li>A cronjob for user cortex runs every night (@daily) to backup the application configuration and custom analyzers / custom responders to the data volume (/var/lib/elasticsearch/cortex/). If you wish to launch a new instance from existing data, this job must have run at least once after the initial install in order to restore the application's configuration  and custom analyzers / responders as well. </li> </ul>"}, {"location": "resources/iaas/aws/cortex/#launching-an-instance-with-no-existing-data-new-cortex-install", "title": "Launching an instance with no existing data (new Cortex install)", "text": "<ol> <li>Launch an instance from the AMI.</li> <li>SSH into the instance with the ubuntu user.</li> <li>Initialize and format the additional EBS volumes (/dev/sdh and /dev/sdi). Note that in Nitro-based instances, /dev/sdh and /dev/sdi might be available as something like /dev/nvme1n1 and /dev/nvme2n1. More information is available in Amazon EBS and NVMe on Linux Instances documentation.</li> <li>Launch the application initialization script with the EBS data volume block device names as arguments, which is /dev/sdh and /dev/sdi if you are using a default AMI setup. If you are using a Nitro-based instance, do not use the nvme names (like /dev/nvme1n1). Example: <code>/opt/cortex/ops/scripts/ops-cortex-init.sh /dev/sdh /dev/sdi</code></li> <li>That's it! Cortex is now available on port 9001. You can create the admin account on the first connection to the app.</li> </ol> <p>Alternatively, you can easily perform steps 3 and 4 by providing cloud-init user data to the AMI at launch. In the following example using an m5 instance (Nitro-based), we:</p> <ul> <li>launch a script that will expose the external volumes, seen by the instance as /dev/nvme1n1 and /dev/nvme2n1, with their block device mapping names (/dev/sdh, /dev/sdi)</li> <li>partition and format the EBS volumes using their block device mapping names (/dev/sdh, /dev/sdi)</li> <li>launch the initialisation script with the EBS block mapping names as arguments (/dev/sdh and /dev/sdi - not /dev/nvme0n1 and /dev/nvme1n1)</li> </ul> <pre><code>#cloud-config \nbootcmd:\n    - [ /usr/sbin/nvme-to-block-mapping ]\nfs_setup:\n    - filesystem: ext4\n      device: '/dev/sdh'\n      partition: auto\n      overwrite: false\n    - filesystem: ext4\n      device: '/dev/sdi'\n      partition: auto\n      overwrite: false\nruncmd:\n    - [ /opt/cortex/ops/scripts/ops-cortex-init.sh, /dev/sdh, /dev/sdi ]\n</code></pre> <p>You can also provision the whole thing using Terraform; check our GitHub repository for detailed sample code.</p>"}, {"location": "resources/iaas/aws/cortex/#launching-an-instance-with-existing-data-cortex-update-migration-restore", "title": "Launching an instance with existing data (Cortex update, migration, restore)", "text": "<ol> <li>Launch an instance from the AMI and base the additional EBS volumes (/dev/sdh and /dev/sdi by default) on existing Cortex data and Docker volume snapshots.</li> <li>SSH into the instance with the ubuntu user.</li> <li>Launch the Cortex restore script with the EBS data volume block device names as arguments, which are /dev/sdh and /dev/sdi if you are using a default AMI setup. If you are using a Nitro-based instance, do not use the nvme names (like /dev/nvme1n1). Example: <code>/opt/cortex/ops/scripts/ops-cortex-restore.sh /dev/sdh /dev/sdi</code>.</li> <li>That's it! Cortex is now available on port 9001 (or on the custom port you had configured) with all your existing configuration, users and data. Custom analyzers and responders stored under /opt/cortexneurons are also automatically restored and their pip requirements reinstalled.</li> </ol> <p>Alternatively, you can easily perform step 3 by providing cloud-init user data to the AMI at launch. In the following example using an m5 instance (Nitro-based), we:</p> <p>launch the restore script with the EBS block mapping names as arguments (/dev/sdh and /dev/sdi - not /dev/nvme1n1 and /dev/nvme2n1)</p> <pre><code>#cloud-config \nruncmd:\n    - [ /opt/cortex/ops/scripts/ops-cortex-restore.sh, /dev/sdh, /dev/sdi ]\n</code></pre> <p>You can also provision the whole thing using Terraform; check our GitHub repository for detailed sample code.</p>"}, {"location": "resources/iaas/aws/thehive/", "title": "Deploy TheHive AMI", "text": ""}, {"location": "resources/iaas/aws/thehive/#usage-instructions-for-the-official-thehive-v5-ami", "title": "Usage instructions for the official TheHive v5 AMI", "text": "<p> Official AMI</p> <p>The AMI can be used to set up a shiny-new TheHive v5 install or to launch an instance with existing data and configuration (for update / migration / restore purposes).</p>"}, {"location": "resources/iaas/aws/thehive/#introduction", "title": "Introduction", "text": "<ul> <li>You can easily initialise a new instance or restore a previous TheHive v5 instance using scripts included in the image.</li> <li>Data is stored on three dedicated volumes: one for the Cassandra database (/var/lib/cassandra), another one for storage attachments (/opt/thp_data/files) and a final one for indexes (/opt/thp_data/index).</li> <li>The AMI is based on the official Ubuntu 20.04 LTS AMI from Canonical .</li> <li>The default OS hardening has been further improved compared to our previous Ubuntu 18.04 based AMIs.</li> <li>The AMI is updated whenever a new TheHive version is released - no need to bother updating TheHive anymore, just launch a new instance as if it were a container!</li> <li>Migration from TheHive v3 is a manual operation detailed at length in the documentation: https://docs.strangebee.com/thehive/installation/migration/.</li> <li>Upgrading from TheHive v4 AMI is not yet automated or documented (it will be very soon in a coming AMI update). If you are in a hurry, the overall upgrade process is documented here: https://docs.strangebee.com/thehive/installation/upgrade-from-4.x/</li> </ul>"}, {"location": "resources/iaas/aws/thehive/#run-context", "title": "Run context", "text": "<ul> <li>TheHive app runs as an unprivileged user named thehive and is available on port http 9000 (that's http and NOT https). Needless to say we encourage you never to open that port outside your VPC and use a public-facing load balancer and / or reverse proxy to handle the TLS sessions with end-users. Since many TheHive users also run Cortex and MISP instances alongside and since the right load balancer / reverse proxy is obviously the one you know best, we elected not to include yet another one in this AMI.</li> <li>As an incentive to use https, TheHive is configured to use secure cookies by default. Connecting to the UI in http will fail. An override to this remains possible in the configuration: set <code>play.http.session.secure = false</code> in <code>/etc/thehive/application.conf</code>. You must restart the <code>thehive</code> service for the change to be effective.</li> <li>The default sudoer user is ubuntu and the ssh service listens on port 22.</li> <li>A cronjob for user thehive runs every night (@daily) to backup the application configuration to the data volume (/var/lib/cassandra/thehive/). If you wish to launch a new instance from existing data, this job must have run at least once after the initial install in order to restore the application's configuration as well.</li> </ul>"}, {"location": "resources/iaas/aws/thehive/#launching-an-instance-with-no-existing-data-new-thehive-install", "title": "Launching an instance with no existing data (new TheHive install)", "text": "<ol> <li>Launch an instance from the AMI.</li> <li>SSH into the instance with the ubuntu user.</li> <li>Initialize and format the additional EBS volumes (<code>/dev/sdh</code>, <code>/dev/sdi</code> and <code>/dev/sdj</code>). Note that in Nitro-based instances, <code>/dev/sdh</code> might be available as something like <code>/dev/nvme1n1</code>. More information is available in Amazon EBS and NVMe on Linux Instances documentation.</li> <li>Launch the application initialization script with the EBS data volumes block device names as arguments, which are <code>/dev/sdh</code>, <code>/dev/sdi</code> and <code>/dev/sdj</code> if you are using a default AMI setup. If you are using a Nitro-based instance, do not use the nvme names (like /dev/nvme0n1). Example: <code>/opt/thehive/ops/scripts/ops-thehive-init.sh /dev/sdh /dev/sdi /dev/sdj</code></li> <li>That's it! TheHive is now available on port 9000. The default admin account is \"admin@thehive.local\" with password \"secret\" (change it!).</li> </ol> <p>Alternately, you can easily perform steps 3 and 4 by providing cloud-init user data to the AMI at launch. In the following example using an m5 instance (Nitro-based), we: * launch a script that will expose the external volumes, seen by the instance as /dev/nvme1n1 and /dev/nvme2n1, with their block device mapping names (/dev/sdh, /dev/sdi) * partition and format the EBS volumes using their block device mapping names (/dev/sdh, /dev/sdi) *  launch the initialisation script with the EBS block mapping names as argument (<code>/dev/sdh</code>, <code>/dev/sdi</code> and <code>/dev/sdj</code>)</p> <pre><code>#cloud-config\nbootcmd:\n    - [ /usr/sbin/nvme-to-block-mapping ]\nfs_setup:\n    - filesystem: ext4\n      device: '/dev/sdh'\n      partition: auto\n      overwrite: false\n    - filesystem: ext4\n      device: '/dev/sdi'\n      partition: auto\n      overwrite: false\n    - filesystem: ext4\n      device: '/dev/sdj'\n      partition: auto\n      overwrite: false\nruncmd:\n    - [ /opt/thehive/ops/scripts/ops-thehive-init.sh, /dev/sdh, /dev/sdi, /dev/sdj ]\n</code></pre> <p>You can also provision the whole thing using Terraform; check our GitHub repository for detailed sample code.</p>"}, {"location": "resources/iaas/aws/thehive/#launching-an-instance-with-existing-data-thehive-update-migration-restore", "title": "Launching an instance with existing data (TheHive update, migration, restore)", "text": "<ol> <li>Launch an instance from the AMI and base the additional EBS volumes (<code>/dev/sdh</code>, <code>/dev/sdi</code> and <code>/dev/sdj</code> by default) on existing TheHive EBS volume snapshots for the Cassandra database (<code>/dev/sdh</code>), the storage attachments (<code>/dev/sdi</code>) and the database index (<code>/dev/sdj</code>).</li> <li>SSH into the instance with the ubuntu user.</li> <li>Launch the TheHive restore script with the EBS data volumes block device names as arguments, which are <code>/dev/sdh</code>, <code>/dev/sdi</code> and <code>/dev/sdj</code> if you are using a default AMI setup. If you are using a Nitro-based instance, do not use the nvme names (like /dev/nvme1n1). Example: <code>/opt/thehive/ops/scripts/ops-thehive-restore.sh /dev/sdh /dev/sdi /dev/sdj</code>.</li> <li>That's it! TheHive is now available on port 9000 (or on the custom port you had configured) with all your existing configuration, users and data.</li> </ol> <p>Alternately, you can easily perform step 3 by providing cloud-init user data to the AMI at launch. In the following example using an m5 instance (Nitro-based), we:</p> <ul> <li>launch the restore script with the EBS block mapping names as arguments (<code>/dev/sdh</code>, <code>/dev/sdi</code> and <code>/dev/sdj</code>)</li> </ul> <pre><code>#cloud-config\nruncmd:\n    - [ /opt/thehive/ops/scripts/ops-thehive-restore.sh, /dev/sdh, /dev/sdi, /dev/sdj ]\n</code></pre> <p>You can also provision the whole thing using Terraform; check our GitHub repository for detailed sample code.</p>"}, {"location": "resources/iaas/aws/infra-as-code/", "title": "AWS sample code", "text": ""}, {"location": "resources/iaas/aws/infra-as-code/#aws-sample-code", "title": "AWS sample code", "text": ""}, {"location": "resources/iaas/aws/infra-as-code/#overview", "title": "Overview", "text": "<p>The sample Terraform code in this repository allows the creation of a complete SecOps VPC to host your TheHive and Cortex instances and expose them using a load balancer.</p> <p></p> <p>The sample code is organised in two Terraform projects:</p> <ul> <li>ug-secops-vpc --&gt; to create and manage the SecOps VPC</li> <li>ug-secops-instances --&gt; to launch and manage TheHive v5 and Cortex instances within a SecOps VPC</li> </ul> <p>This code organization allows the creation of all required VPC resources if you do not already operate a VPC (or if you want to create a new one for your SecOps needs), independently from TheHive and Cortex deployments.</p> <p>The sample code to launch TheHive and Cortex instances defaults to this new VPC but can easily be adapted to fit your existing VPC by customising a few variables. Unless your architecture significantly differs from our reference VPC, you should not be required to modify the Terraform code itself.</p>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-instances/", "title": "TheHive v5 and Cortex within a SecOps VPC", "text": ""}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-instances/#deploying-thehive-v5-and-cortex-with-terraform", "title": "Deploying TheHive v5 and Cortex with Terraform", "text": "<p>This code will work out of the box with the reference SecOps VPC created with our sample code. You can nonetheless use it to deploy TheHive and Cortex within your own preexisting VPC with minimal adjustments (only a few variables to update if your setup is similar to our reference architecture).</p> <p>Our sample code can handle two use-cases:</p> <ul> <li>Deploying brand new TheHive and Cortex instances with empty databases - this is useful for an initial deployment.</li> <li>Deploying TheHive and Cortex instances while restoring existing databases - this is to be used for all other use-cases: AMI updates, instance type upgrades or downgrades, database restore, etc.</li> </ul> <p>Tip</p> <p>To switch between both use-cases, simply update the <code>secops_thehive_init</code> and/or <code>secops_cortex_init</code> variable values between <code>true</code> and <code>false</code> (<code>true</code> being the empty database, initialisation use-case).</p> <p>Files</p> <ul> <li>main.cf</li> <li>providers.cf</li> <li>outputs.cf</li> <li>variables.cf</li> <li>samples.tfvars</li> <li>files/bastion-cloud-config-new.tpl</li> </ul>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-instances/#tldr", "title": "TL;DR;", "text": "<ul> <li>Download all files</li> <li>Set the required variables</li> <li><code>terraform init</code> &amp;&amp; <code>terraform apply</code></li> <li>Once the <code>terraform apply</code> is over, wait up to 5 minutes for both instances to be fully operational. You can check the initiatisation or restore progress by tailing the <code>/var/log/cloud-init-output.log</code> file on each instance.</li> </ul>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-instances/#overview", "title": "Overview", "text": "<p>This is an overview of the resulting TheHive and Cortex instances when deployed with our Terraform sample code in our reference SecOps VPC.</p> <p></p>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-instances/#information-on-the-default-data-volumes-configuration", "title": "Information on the default data volumes configuration", "text": "<p>All data is stored on dedicated EBS volumes, not in the root EBS volume. This approach has many advantages:</p> <ul> <li>Your root volume is disposable, you can replace your instances in seconds to update TheHive and Cortex by launching a fresh AMI or to migrate to a more (or less) powerful instance.</li> <li>Your data volumes can be of any size while keeping the root volume to its default size. </li> <li>Increasing (or decreasing) the size of data volumes on an existing instance is a lot easier than changing the root volume size.</li> <li>You can easily restore your data from a previous states using volume snapshots. </li> </ul>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-instances/#about-ebs-volume-management-on-nitro-based-instances", "title": "About EBS volume management on Nitro based instances", "text": "<p>In Nitro-based instances, block devide mappings such as <code>/dev/sdh</code> will be seen by the instance as something like <code>/dev/nvme1n1</code>. You need to take this into consideration for everything that is executed inside the instance. As far as the EC2 APIs are concerned, the volume is still known as <code>/dev/sdh</code>. More information on this is available in Amazon EBS and NVMe on Linux Instances documentation.</p> <p>To illustrate this important aspect, consider the automated deployment of an instance using Terraform and some cloud-init user data code. In Terraform, you may want to change the default volume size or base your EBS volume on an existing snapshot. Since Terraform is interacting with the EC2 APIs, the EBS volume will alway be <code>/dev/sdh</code>. However, if you want to partition and format the volume using cloud-init, you need to adapt your code to how the instance \"sees\" the volume. In pre-Nitro instances the volume will remain <code>/dev/sdh</code> but in Nitro instances, it will be known as something like <code>/dev/nvme1n1</code>. </p> <p>To mount the volumes, the included initialisation and restore cloud-init bootstrap scripts were designed to be \"Nitro-aware\". These scripts expect the block device mapping as argument (such as <code>/dev/sdh</code>, <code>/dev/sdi</code> and <code>/dev/sdj</code>) and will then mount the volume based on its UUID to avoid any confusion going forward.</p>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-instances/#deploying-new-thehive-and-cortex-instances", "title": "Deploying new TheHive and Cortex instances", "text": "<p>When the <code>secops_thehive_init</code> and/or <code>secops_cortex_init</code> variable are set to <code>true</code>, the AMIs will create new empty EBS data volumes at launch that will not be deleted when the instances are terminated so that your data isn't accidentally lost.</p>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-instances/#replacing-existing-thehive-and-cortex-instances-to-use-a-new-ami-version", "title": "Replacing existing TheHive and Cortex instances to use a new AMI version", "text": "<p>When the <code>secops_thehive_init</code> and/or <code>secops_cortex_init</code> variable are set to <code>false</code>, the AMIs will create new EBS volumes at launch based on snapshots of volumes from the previous instances. The original volumes (from previous instances) are not automatically deleted. We recommend you keep them at least until the upgrade to the new AMI is completed.</p>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-instances/#restoring-data-from-earlier-snapshots-instead-of-latest-instance-volume-snapshots", "title": "Restoring data from earlier snapshots instead of latest instance volume snapshots", "text": "<p>If for any reason you wish to restore from specific snapshots and not from the latest volume state, you can edit the code and set the snapshot id for each volume. </p> <p>For example, to restore the TheHive data volume from a specific snapshot, the sample code should be edited to update the <code>snapshot_id</code> value.</p> <p>Original sample code:</p> <pre><code>  ebs_block_device {\n    device_name = \"/dev/sdh\"\n    snapshot_id = aws_ebs_snapshot.secops-thehive-data-snapshot[count.index].id\n    volume_type = \"gp2\"\n    volume_size = var.secops_thehive_instance_data_volume_size\n    delete_on_termination = false\n    tags = {\n      Name = \"${var.secops_thehive_instance_name}-data\"\n      SourceInstance = var.secops_thehive_instance_name\n      SourceInstanceVolume = \"/dev/sdh\"\n      Environment = var.secops_vpc_name\n    }  \n  } \n</code></pre> <p>Update code:</p> <pre><code>  ebs_block_device {\n    device_name = \"/dev/sdh\"\n    snapshot_id = \"snap-1234567890\"\n    volume_type = \"gp2\"\n    volume_size = var.secops_thehive_instance_data_volume_size\n    delete_on_termination = false\n    tags = {\n      Name = \"${var.secops_thehive_instance_name}-data\"\n      SourceInstance = var.secops_thehive_instance_name\n      SourceInstanceVolume = \"/dev/sdh\"\n      Environment = var.secops_vpc_name\n    }  \n  } \n</code></pre>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-instances/#connecting-to-your-instances-with-ssh", "title": "Connecting to your instances with SSH", "text": "<p>Since our TheHive and Cortex instance are located in a private subnet, we cannot directly SSH into them using their private IP addresses. If you have set up a bastion host configuration similarly to our reference architecture, you can seamlessly connect to private instances using the proxyjump functionality of the ssh client. The bastion host will be able to perform the hostname resolution with the private DNS zone we have set up in the VPC.</p> <p>The easiest way to do that is to create (or update) the <code>~/.ssh/config</code> file. Use the example below as a reference and replace the ip addresses and private key information.</p> <p>The default username is <code>ubuntu</code> in all our AMIs.</p> <pre><code>Host bastion\n        HostName 1.2.3.4 (public ip)\n        User ubuntu\n        Port 22\n        IdentityFile ~/.ssh/id_rsa_private_key_for_bastion\n\nHost thehive\n        HostName thehive.secops0.privatevpc\n        User ubuntu\n        Port 22\n        ProxyJump bastion\n        IdentityFile ~/.ssh/id_rsa_private_key_for_thehive\n\nHost cortex\n        HostName cortex.secops0.privatevpc\n        User ubuntu\n        Port 22\n        ProxyJump bastion\n        IdentityFile ~/.ssh/id_rsa_private_key_for_cortex\n</code></pre> <p>We use the secops0.privatevpc domain as an example but the best security practice is to use a domain name you own even for private DNS resolution in split-horizon.</p> <p>You will now be able to SSH into your instances directly using the bastion host as a proxy:</p> <p></p><pre><code>ssh thehive\n</code></pre> or <pre><code>ssh cortex\n</code></pre> <p>Tip</p> <p>Remember to autorize your local public IP address in the bastion SSH security group. In our sample code for the SecOps VPC, this is the <code>secops0-public-ssh-sg</code> security group.</p> <p>Terraform compatibility: v1.x</p>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-vpc/", "title": "Create and manage the SecOps VPC", "text": ""}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-vpc/#creating-a-new-secops-vpc", "title": "Creating a new SecOps VPC", "text": "<p>If you do not already have a VPC at hand to deploy TheHive and Cortex into, using our sample code will allow you to build a production-ready VPC very easily.</p> <p>Files</p> <ul> <li>main.cf</li> <li>providers.cf</li> <li>outputs.cf</li> <li>variables.cf</li> <li>samples.tfvars</li> <li>files/bastion-cloud-config-new.tpl</li> </ul>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-vpc/#overview", "title": "Overview", "text": "<p>The reference architecture VPC consists of the following resources</p> <p></p> <p>The VPC will include:</p> <ul> <li>Two public subnets (only one is depicted - two public subnets will be created in different availability zones since they are required for the Application Load Balancer configuration)</li> <li>Two private subnets (only one is depicted - we will not be using the second private subnet but it will be ready to use if you need it and it does not incur additional costs)</li> <li>Five security groups </li> <li>An internet gateway (IG)</li> <li>A NAT gateway in the first public subnet</li> <li>Route tables for both public and private subnets</li> <li>An Application Load Balancer (ALB) with a listener on port 443  using ACM-managed public certificates and two target groups for TheHive and Cortex</li> <li>Public Route53 DNS records for TheHive and Cortex to point to the ALB</li> <li>A private Route53 DNS zone for internal VPC name resolution</li> <li>A bastion host for remote SSH administration</li> </ul> <p>Since we will be building a new VPC from scratch, we will use AWS-managed services to expose our TheHive and Cortex instances:</p> <ul> <li>Application Load Balancer to handle secured TLS sessions with end-users. A single load balancer with a single listener on port 443 can forward traffic to both TheHive and Cortex instances based on forward rules.</li> <li>AWS Certificate Manager to issue and renew valid public certificates to enable TLS sessions between end-users and the load balancer. Once attached to an AWS-managed service such as the Application Load Balancer, public certificates are automatically renewed when nearing expiration. If you operate both TheHive and Cortex, you can share a single certificate for both services by including multiple hostnames in the certificate. You can also use separate certificates as the ALB supports attaching several certificates to a listener.</li> <li>Amazon Route53 to manage your public DNS records. You will need Route53 to manage at least one public DNS zone, but not necessarily a whole domain name. It can be a subdomain of an existing domain, such as aws.mydomain.com. Having Route53 manage your DNS records enables a lot of automation such as automatic certificate validation and renewal, automatic DNS registration of your load balancer and so on. We also recommend you use Route53 to manage a private DNS zone attached to your VPC to enable local name resolution within the private subnet (this is how TheHive can easily find its Cortex instance and it allows to SSH into private instances without having to bother with their private IPs).</li> </ul>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-vpc/#security-groups", "title": "Security Groups", "text": "<p>There are no default iptables rules implemented in the AMIs for either TheHive or Cortex (no OS-based IP filtering). Since we built the AMIs to be replaceable at each application update, somewhat like containers, we recommend limiting OS customisations to benefit from the easy update process. For that reason, filtering should be based on security groups or Network ACLs only.</p> <p>Keep in mind that the applications are listening on http, not https. Even though the default AMI security groups allow incoming traffic on the http ports (TCP 9000 for TheHive, TCP 9001 for Cortex), be careful not to expose them on a public-facing network interface.</p> <p>The required security groups depicted above are created automatically along with the SecOps VPC.</p>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-vpc/#bastion-host", "title": "Bastion host", "text": "<p>We launch a small instance to act as a bastion host. Bastion host hardening is not performed automatically but you should definitely harden this host going forward if you will use it in a production context. We do however strictly limit access to and from this host.</p> <p>The bastion host will run the latest Ubuntu AMI from Canonical. The default sudoer user is ubuntu.</p>"}, {"location": "resources/iaas/aws/infra-as-code/ug-secops-vpc/#secops-vpc-prerequisites", "title": "SecOps VPC prerequisites", "text": "<p>While most VPC resources will be provisioned with Terraform, there is one exception that should be created beforehand:</p> <ul> <li>The Route53 public DNS zone to register the load balancer and to automatically validate the ACM certificates</li> </ul> <p>You must provide the DNS hosted zone name before creating the VPC (set the <code>secops_r53_public_dns_zone_name</code> Terraform variable with the zone name).</p> <p>Info</p> <p>We will use a single load balancer, a single https listener and a single certificate for both TheHive and Cortex. Since the default configuration is to route TheHive and Cortex queries based on the host name, make sure you provide both TheHive and Cortex host names in the <code>secops_r53_records_san</code> Terraform variable so they are provisionned both in the load balancer listener certificate and DNS records.</p> <p>Terraform compatibility: v1.x</p>"}, {"location": "resources/iaas/azure/", "title": "Main Features", "text": ""}, {"location": "resources/iaas/azure/#thehive-azure-images", "title": "TheHive Azure images", "text": ""}, {"location": "resources/iaas/azure/#easy-to-use-and-deploy", "title": "Easy to use and deploy", "text": "<p>The Azure images were built with operations and automation in mind. We wanted DevSecOps-friendly products that would fit in most organizations, no matter how simple or complex their infrastructure.</p>"}, {"location": "resources/iaas/azure/#always-up-to-date", "title": "Always up-to-date", "text": "<p>The images are updated whenever a new TheHive version is released. No need to bother updating TheHive anymore, just launch a new instance as if it were a container!</p>"}, {"location": "resources/iaas/azure/#production-ready", "title": "Production-ready", "text": "<ul> <li>Dedicated data disks: TheHive data is stored on dedicated disks, not in the root filesystem.</li> <li>Ubuntu-based: The images are based on the official Ubuntu 20.04 LTS distribution from Canonical.</li> <li>Hardened OS: The underlying Ubuntu OS is hardened to comply with CSL1 (that's Common Sense Level 1!) minus the network filtering. There are no iptables surprises inside the image to avoid conflicting behavior with security groups.</li> <li>Application only: The images include the applications only. They are not meant to be public-facing on their own and should be deployed within your virtual network and exposed with the public facing system of your choice (load balancer, reverse proxy).</li> </ul>"}, {"location": "resources/iaas/azure/#cortex-azure-images", "title": "Cortex Azure images", "text": ""}, {"location": "resources/iaas/azure/#easy-to-use-and-deploy_1", "title": "Easy to use and deploy", "text": "<p>The image was built with operations and automation in mind. We wanted a DevSecOps-friendly product that would fit in most organizations, no matter how simple or complex their infrastructure.</p>"}, {"location": "resources/iaas/azure/#always-up-to-date_1", "title": "Always up-to-date", "text": "<p>The image is updated whenever a new Cortex version is released. No need to bother updating Cortex anymore, just launch a new instance as if it were a container!</p>"}, {"location": "resources/iaas/azure/#production-ready_1", "title": "Production-ready", "text": "<ul> <li>Dedicated data disks: Cortex data is stored on dedicated disks, not in the root filesystem. With that in mind, you must attach two persistent data disks on LUN 0 and LUN 1 at launch (30 GB each recommended).</li> <li>Ubuntu-based: The image is based on the official Ubuntu 20.04 LTS distribution from Canonical.</li> <li>Hardened OS: The underlying Ubuntu OS is hardened to comply with CSL1 (that's Common Sense Level 1!) minus the network filtering. There are no iptables surprises inside the image to avoid conflicting behavior with security groups.</li> <li>Application only: The image includes Cortex application only. It is not meant to be public-facing on its own and should be deployed within your virtual network and exposed with the public facing system of your choice (load balancer, reverse proxy).</li> </ul>"}, {"location": "resources/iaas/azure/cortex/", "title": "Deploy Cortex Azure image", "text": ""}, {"location": "resources/iaas/azure/cortex/#usage-instructions-for-the-official-azure-distribution-of-cortex", "title": "Usage instructions for the official Azure distribution of Cortex", "text": "<p>:simple-microsoftazure: Official Azure image This is the official Cortex v3 release for the AWS Marketplace.</p> <p>The image can be used to set up a shiny-new Cortex install or to launch an instance with existing data and configuration (for update / migration / restore purposes).</p>"}, {"location": "resources/iaas/azure/cortex/#introduction", "title": "Introduction", "text": "<ul> <li>Based on the official Ubuntu 18.04 image from Canonical</li> <li>The image is updated whenever a new Cortex version is released - no need to bother updating Cortex anymore, just launch a new instance as if it were a container!</li> <li>Cortex data is stored on dedicated disks, not in the root filesystem. With that in mind, you must attach two persistent data disks on LUN 0 (for the database) and LUN 1 (for Docker images) at launch (30 GB each recommended).</li> <li>The underlying Ubuntu OS is hardened to comply with CSL1 (that's Common Sense Level 1!) minus the network filtering. There are no iptables surprises inside the image to avoid conflicting behavior with security groups.</li> </ul>"}, {"location": "resources/iaas/azure/cortex/#run-context", "title": "Run context", "text": "<ul> <li>The Cortex app runs as unprivileged user cortex and is available on port http 9001 (that's http and NOT https). Needless to say we encourage you never to open that port outside your virtual network and use a public-facing load balancer and / or reverse proxy to handle the TLS sessions with end-users. Since many Cortex users also run TheHive and MISP instances alongside and since the right load balancer / reverse proxy is obviously the one you know best, we elected not to include yet another one in this image. </li> <li>The Cortex configuration is set to look for custom analyzers under <code>/opt/cortexneurons/analyzers</code> and for custom responders under <code>/opt/cortexneurons/responders</code>.</li> <li>A cronjob for user cortex runs every night (@daily) to backup the application configuration and custom analyzers / custom responders to the data volume (/var/lib/elasticsearch/cortex/). If you wish to launch a new instance from existing data, this job must have run at least once after the initial install in order to restore the application's configuration  and custom analyzers / responders as well.  </li> </ul>"}, {"location": "resources/iaas/azure/cortex/#launching-an-instance-with-no-existing-data-new-cortex-install", "title": "Launching an instance with no existing data (new Cortex install)", "text": "<ol> <li>Launch an instance from the image and attach two data disks on LUN 0 and LUN 1.</li> <li>SSH into the instance with a sudoer user.</li> <li>Initialize and format the additional data disks (LUN O and LUN 1). </li> <li>Launch the application initialization script with the target data disk names as arguments. Example: <code>/opt/cortex/ops/scripts/ops-cortex-init.sh /dev/sdh /dev/sdi</code> (the script will automatically mount the LUN 0 and LUN 1 disks at /dev/sdh and /dev/sdi)</li> <li>That's it! Cortex is now available on port 9001. You can create the admin account on the first connection to the app.</li> </ol> <p>Alternatively, you can easily perform steps 3 and 4 by providing a cloud-init bootstrap script at launch. In the following example, we:</p> <ul> <li>partition and format the data disks attached on LUN 0 and LUN 1 </li> <li>improve the random seed with pollinate (because we will generate a secret key in the initialisation process)</li> <li>and finally we launch the initialisation script with the target data disk mapping names as arguments (/dev/sdh and /dev/sdi) - the script will automatically mount the LUN 0 disk at /dev/sdh and LUN 1 at /dev/sdi</li> </ul> <pre><code>#cloud-config \ndisk_setup:\n  /dev/disk/azure/scsi1/lun0:\n    table_type: gpt\n    layout: True\n    overwrite: True\n  /dev/disk/azure/scsi1/lun1:\n    table_type: gpt\n    layout: True\n    overwrite: True\nfs_setup:\n  - device: /dev/disk/azure/scsi1/lun0\n    partition: none\n    filesystem: ext4\n  - device: /dev/disk/azure/scsi1/lun1\n    partition: none\n    filesystem: ext4\nrandom_seed:\n    file: /dev/urandom\n    command: [\"pollinate\", \"--server=https://entropy.ubuntu.com/\"]\n    command_required: true\nruncmd:\n    - /opt/cortex/ops/scripts/ops-cortex-init.sh /dev/sdh /dev/sdi\n</code></pre> <p>You can also provision the whole thing using Terraform - check our GitHub repository for sample initialisation code.</p>"}, {"location": "resources/iaas/azure/cortex/#launching-an-instance-with-existing-data-cortex-update-migration-restore", "title": "Launching an instance with existing data (Cortex update, migration, restore)", "text": "<ol> <li>Launch an instance from the image and attach existing Cortex data disks on LUN 0 and LUN 1 (we recommend you always create disk snapshots first).</li> <li>SSH into the instance with a sudoer user.</li> <li>Launch the Cortex restore script with the data disk names as argument, which are /dev/sdh and /dev/sdi if you are using the default setup. Example: <code>/opt/cortex/ops/scripts/ops-cortex-restore.sh /dev/sdh /dev/sdi</code>.</li> <li>That's it! Cortex is now available on port 9001 (or on the custom port you had configured) with all your existing configuration, users and data. Custom analyzers and responders stored under /opt/cortexneurons are also automatically restored and their pip requirements reinstalled.</li> </ol> <p>Alternatively, you can easily perform step 3 by providing a cloud-init bootstrap script at launch. In the following example, we:</p> <p>launch the restore script with the data disk names as arguments (/dev/sdh and /dev/sdi)</p> <pre><code>#cloud-config \nruncmd:\n    - /opt/cortex/ops/scripts/ops-cortex-restore.sh /dev/sdh /dev/sdi\n</code></pre> <p>You can also provision the whole thing using Terraform - check our GitHub repository for sample update / migration / restore code.</p>"}, {"location": "resources/iaas/azure/thehive/", "title": "Deploy TheHive Azure image", "text": ""}, {"location": "resources/iaas/azure/thehive/#usage-instructions-for-the-official-azure-distribution-of-thehive-v5", "title": "Usage instructions for the official Azure distribution of TheHive v5", "text": "<p>:simple-microsoftazure: Official Azure image</p> <p>The image can be used to set up a shiny-new TheHive v5 install or to launch an instance with existing data and configuration (for update / migration / restore purposes). The same image can also be used to launch Cortex on the same instance or on a separate, dedicated instance.</p>"}, {"location": "resources/iaas/azure/thehive/#introduction", "title": "Introduction", "text": "<ul> <li>Based on the official Ubuntu 20.04 LTS image from Canonical</li> <li>The image is updated whenever a new TheHive version is released - no need to bother updating TheHive anymore, just launch a new instance as if it were a container!</li> <li>TheHive / Cortex data is stored on two dedicated disks, not in the root filesystem. For that purpose, you must attach two persistent data disks at launch on LUN 0 (for the data) and LUN 1 (for Docker). The recommended minimal volume size are 32 GB per volume. If you install Cortex on a separate instance, simply apply the same configuration on the second instance.</li> <li>The underlying Ubuntu OS is hardened to comply with CSL1 (that's Common Sense Level 1!) minus the network filtering. There are no iptables surprises inside the image to avoid conflicting behaviour with security groups.</li> <li>Migration from TheHive v4 is possible using our migration script baked in the image (to be documented soon).</li> </ul>"}, {"location": "resources/iaas/azure/thehive/#run-context", "title": "Run context", "text": "<ul> <li>TheHive is available on port http 9000 and Cortex, when deployed alongside, is available on port http 9001 (that's http and NOT https). Needless to say we encourage you never to open these ports outside your virtual network and use a public-facing load balancer and / or reverse proxy to handle the TLS sessions with end-users. </li> <li>As an incentive to use https, both TheHive and Cortex are configured to use secure cookies by default. Connecting to their respective UIs in http will fail. An override to this remains possible in the configuration (for TheHive, set <code>play.http.session.secure = false</code> in <code>/opt/thp_data/nomad/tasks/thehive/application.conf</code> - for Cortex, set <code>play.http.session.secure = false</code> and <code>play.filters.csrf.cookie.secure = false</code> in <code>/opt/thp_data/nomad/tasks/cortex/application.conf</code>). You must restart the <code>thehive</code> and/or <code>cortex</code> service(s) for the change to be effective.</li> </ul>"}, {"location": "resources/iaas/azure/thehive/#launching-an-instance", "title": "Launching an instance", "text": "<ol> <li>Launch an instance from the image and attach two persistent disks: the data disk on LUN 0 and the docker disk LUN 1</li> <li>Set the admin username to be azureuser</li> <li>Provide the following cloud-init bootstrap script to configure the instance (you must update at least the <code>application.baseUrl</code> value for TheHive in this example):</li> </ol> <pre><code>#cloud-config \ndisk_setup:\n  /dev/disk/azure/scsi1/lun0:\n    table_type: gpt\n    layout: True\n    overwrite: True\n  /dev/disk/azure/scsi1/lun1:\n    table_type: gpt\n    layout: True\n    overwrite: True\nfs_setup:\n  - device: /dev/disk/azure/scsi1/lun0\n    partition: auto\n    filesystem: ext4\n  - device: /dev/disk/azure/scsi1/lun1\n    partition: auto\n    filesystem: ext4\nwrite_files:\n    - path: /opt/strangebee/ops/templates/nomad/tasks/thehive/application.conf.d/service.conf\n      content: |\n          application.baseUrl=\"https://thehive.mydomain.com/thehive\"\n          play.http.context=\"/thehive\"\n    - path: /opt/strangebee/ops/templates/nomad/tasks/cortex/application.conf.d/service.conf\n      content: |\n          play.http.context=\"/cortex\"\nruncmd:\n    - [ /opt/strangebee/ops/scripts/ops-launch.sh, \"-t 1\", \"-c 0\", \"-p /dev/sdh\", \"-d /dev/sdi\" ]\n</code></pre> <p>You can further customize this script as needed. In the example above we:</p> <ul> <li>partition and format the data disks attached on LUN 0 and LUN 1 </li> <li>launch the initialisation script with the target data disk mapping names as argument (/dev/sdh and /dev/sdi) - the script will automatically mount the LUN 0 disk at /dev/sdh and the LUN 1 disk at /dev/sdi</li> <li>install TheHive only (because of parameters <code>\"-t 1\", \"-c 0\"</code> when calling the <code>ops-launch.sh</code> script)</li> </ul> <p>Tip</p> <ol> <li>To install both TheHive and Cortex on the same instance, use <code>\"-t 1\", \"-c 1\"</code></li> <li>To install Cortex only on another instance, use <code>\"-t 0\", \"-c 1\"</code></li> </ol> <p>That's it! TheHive is now available (for your load balancer or reverse proxy) on port 9000 and Cortex on port 9001, if also installed. The default admin account on both applications is <code>admin</code> with password <code>secret</code> (change them!). </p> <p>Remember to access the apps through an internet-facing https system such as a reverse proxy or load balancer. In our example, TheHive is available at <code>https://thehive.mydomain.com/thehive</code> and Cortex at <code>https://thehive.mydomain.com/cortex</code>.</p>"}, {"location": "resources/iaas/azure/thehive/#even-easier-using-terraform", "title": "Even easier using Terraform", "text": "<p>You can also provision the whole thing using Terraform.</p> <p>Check our GitHub repository for turnkey deployment code, including a full SecOps vnet with an https Application Gateway.</p>"}, {"location": "resources/iaas/azure/infra-as-code/", "title": "Azure sample code", "text": ""}, {"location": "resources/iaas/azure/infra-as-code/#azure-sample-code", "title": "Azure sample code", "text": ""}, {"location": "resources/iaas/azure/infra-as-code/#overview", "title": "Overview", "text": "<p>The sample Terraform code in this repository allows the creation of a complete SecOps virtual network (vnet) to host your TheHive and Cortex instances and expose them using an Application Gateway.</p> <p></p> <p>The sample code is organised in two Terraform projects:</p> <ul> <li>ug-secops-vnet --&gt; to create and manage the SecOps virtual network and TheHive / Cortex data disks</li> <li>ug-secops-instances --&gt; to launch and manage TheHive v5 and Cortex instances within a SecOps vnet</li> </ul> <p>This code organization allows the creation of all required vnet resources if you do not already operate a vnet (or if you want to create a new one for your SecOps needs), independently from TheHive and Cortex deployments.</p> <p>The sample code to launch TheHive and Cortex instances defaults to this new vnet but can easily be adapted to fit your existing vnet by customising a few variables. Unless your architecture significantly differs from our reference vnet, you should not be required to modify the Terraform code itself.</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/", "title": "Deploying TheHive v5 and Cortex with Terraform", "text": ""}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/#deploying-thehive-v5-and-cortex-with-terraform", "title": "Deploying TheHive v5 and Cortex with Terraform", "text": "<p>This code will work out of the box with the reference SecOps vnet created with our sample code. You can nonetheless use it to deploy TheHive and Cortex within your own pre-existing vnet with minimal adjustments (only a few variables to update if your setup is similar to our reference architecture).</p> <p>Our sample code can handle two use-cases:</p> <ul> <li>Deploying brand new TheHive and Cortex instances with empty databases - this is useful for an initial deployment.</li> <li>Deploying TheHive and Cortex instances while restoring existing databases - this is to be used for all other use-cases: image updates, instance size upgrades or downgrades, database restore, etc.</li> </ul> <p>Note</p> <pre><code>The instance initialization script will automatically detect if the persistent disks already contain data and will behave accordingly (initial setup or restore).\n</code></pre>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/#files", "title": "Files", "text": "<p>Files</p> <pre><code>Terraform files are available on [Github](https://github.com/StrangeBeeCorp/cloud-distrib-resources/blob/master/azure/ug-secops-instances/):\n</code></pre> <ul> <li>000-provider.tf</li> <li>005-runcontext.tf</li> <li>040-securitygroup-th.tf</li> <li>040-securitygroup-th.tf</li> <li>090-instance-cortex.tf</li> <li>090-instance-th.tf</li> <li>output.tf</li> <li>variables.tf</li> <li>tarreform.tfvars</li> <li>files/cloud-config.tpl</li> </ul>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/#tldr", "title": "TL;DR;", "text": "<ul> <li>Download the files</li> <li>Set / update the required variables</li> <li><code>terraform init</code> &amp;&amp; <code>terraform apply</code></li> <li>Once the <code>terraform apply</code> is over, wait up to 5 minutes for both instances to be fully operational. You can check the initialisation or restore progress by tailing the <code>/var/log/cloud-init-output.log</code> and <code>/opt/strangebee/ops/logs/ops-launch.sh.log</code> files on each instance.</li> </ul>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/#overview", "title": "Overview", "text": "<p>This is an overview of the resulting TheHive and Cortex instances when deployed with our Terraform sample code in our reference SecOps vnet.</p> <p></p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/#information-on-the-default-data-disks-configuration", "title": "Information on the default data disks configuration", "text": "<p>All TheHive and Cortex data is stored on dedicated data disks, not in the OS disks. This approach has many advantages:</p> <ul> <li>Your OS disk is disposable, you can replace your instances in seconds to update TheHive or Cortex by launching a fresh image or to migrate to a more (or less) powerful instance.</li> <li>Your data disks can be of any size while keeping the OS disk to its default size. </li> <li>Increasing (or decreasing) the size of a data disk on an existing instance is a lot easier than changing the OS disk size.</li> <li>You can restore your database from a previous state using disk snapshots.</li> </ul> <p>By default, the sample code expects the four persistent data disks to already exist (two for each instance):</p> <ul> <li>TheHive data volume - <code>lun0</code> - mounted at <code>/opt/thp_data</code> on TheHive instance</li> <li>TheHive Docker volume - <code>lun1</code> - mounted at <code>/var/lib/docker</code> on TheHive instance</li> <li>Cortex data volume - <code>lun0</code> - mounted at <code>/opt/thp_data</code> on Cortex instance</li> <li>Cortex Docker volume - <code>lun1</code> - mounted at <code>/var/lib/docker</code> on Cortex instance</li> </ul> <p>We created these persistent disks along with the vnet, so if you are using a custom or existing vnet, create them first and input their names in the associated variables. This way, the disks will not be deleted when the instances are terminated. This ensures that your data isn't accidentally lost.</p> <p>Note</p> <pre><code>Note that the disks are automatically managed if you use our sample Terraform code, you do not need to partition, format and mount the volumes, everything is taken care of for you!\n</code></pre>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/#connecting-to-your-instances-with-ssh", "title": "Connecting to your instances with SSH", "text": "<p>Since our TheHive and Cortex instance are located in a private subnet, we cannot directly SSH into them using their private IP addresses. If you have set up a bastion host configuration similarly to our reference architecture, you can seamlessly connect to private instances using the proxyjump functionality of the ssh client. The bastion host will be able to perform the hostname resolution with the private DNS zone we have set up in the VPC.</p> <p>The easiest way to do that is to create (or update) the <code>~/.ssh/config</code> file. Use the example below as a reference and replace the ip addresses and private key information.</p> <p>The default username for both the bastion host and TheHive instance is <code>azureuser</code>.</p> <pre><code>```\nHost bastion\n    HostName 1.2.3.4 (public ip)\n    User azureuser\n    Port 22\n    IdentityFile ~/.ssh/id_rsa_private_key_for_bastion\n\nHost thehive\n    HostName thehive.secops.cloud\n    User azureuser\n    Port 22\n    ProxyJump bastion\n    IdentityFile ~/.ssh/id_rsa_private_key_for_thehive\n\nHost cortex\n    HostName cortex.secops.cloud\n    User azureuser\n    Port 22\n    ProxyJump bastion\n    IdentityFile ~/.ssh/id_rsa_private_key_for_cortex\n```\n</code></pre> <p>Note</p> <p>We use the <code>secops.cloud</code> domain as an example but the best security practice is to use a domain name you own even for private DNS resolution in split-horizon.</p> <p>You will now be able to SSH into your instances directly using the bastion host as a proxy:</p> <pre><code>`$ ssh thehive`\n\nor\n\n`$ ssh cortex`\n</code></pre> <p>Note</p> <pre><code>Remember to whitelist your local public IP address in the bastion network security group.\n</code></pre>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/#accessing-the-nomad-ui", "title": "Accessing the Nomad UI", "text": "<p>It can sometimes be useful to access the Nomad UI to control the running application stack or to easily access the container console logs for each running task.</p> <p></p> <p>Since we are running Nomad in a standalone mode, without ACLs being implemented, we do not automatically expose the UI outside the instance itself (in other words, it will not be reachable from the Application Gateway using our sample Terraform code).</p> <p>Note</p> <p>Starting with image version 5.1.4, basic Nomad ACLs have been enabled. The default anonymous access provides some <code>read</code> permissions and full access is possible using the <code>admin</code> token. The admin token is automatically created the first time the Nomad ACLs are bootstraped and is stored under <code>/opt/thp_data/nomad/nomad.mgmt</code>. This token is stored on the persistent data volume and will be reused when updating (replacing) the instance while keeping the same persistent data volume.</p> <p>If you need occasional Nomad UI access, you can simply set a temporary SSH tunnel to the instance and forward a local port to the UI (which listens locally on port 4646 on each TheHive / Cortex instance).</p> <p>Note</p> <pre><code>if you wish to access the Nomad UI for multiple instances this way, you must use a different local port for each instance.\n</code></pre> <p>The following examples show how to launch these tunnels using an openSSH client in a vnet where the application instances are on a private subnet that can be reached only through a bastion host (jump host).</p> <p>access the Nomad UI for your TheHive instance - locally on port 46461</p> <pre><code>`$ ssh -L 46461:localhost:4646 azureuser@your_thehive_instance -J azureuser@your_bastion_instance`\n\nThe Nomad UI for your TheHive instance can now be opened in your browser at `http://localhost:46461/ui/`\n</code></pre> <p>Access the Nomad UI for your Cortex instance - locally on port 46462</p> <pre><code>`$ ssh -L 46462:localhost:4646 azureuser@your_cortex_instance -J azureuser@your_bastion_instance`\n\nThe Nomad UI for your Cortex instance can now be opened in your browser at `http://localhost:46462/ui/`\n</code></pre> <p>The same configuration can be achieved by updating your <code>SSH config</code> file to include a <code>LocalForward</code> statement for each remote instance:</p> <pre><code>```\nHost bastion\n    HostName 1.2.3.4 (public ip)\n    User azureuser\n    Port 22\n    IdentityFile ~/.ssh/id_rsa_private_key_for_bastion\n\nHost thehive\n    HostName thehive.secops.cloud\n    User azureuser\n    Port 22\n    ProxyJump bastion\n    IdentityFile ~/.ssh/id_rsa_private_key_for_thehive\n    LocalForward 46461 localhost:4646\n\nHost cortex\n    HostName cortex.secops.cloud\n    User azureuser\n    Port 22\n    ProxyJump bastion\n    IdentityFile ~/.ssh/id_rsa_private_key_for_cortex\n    LocalForward 46462 localhost:4646\n```\n</code></pre> <p>Note</p> <pre><code>Setting up an SSH tunnel between your computer and the remote instances requires that tunnelling and TCP forwarding be allowed on all hosts involved in the process. When you use the sample Terraform code in this repository, this is possible OOTB.\n</code></pre>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/#updating-thehive-and-cortex-over-time", "title": "Updating TheHive and Cortex over time", "text": "<p>Once your instances are deployed, you can easily update TheHive and / or Cortex. In a nutshell, the process consists in replacing the image versions in a variable file and restarting the application stack on each instance. This process it detailed at length in this dedicated documentation page.</p> <p>Terraform compatibility: v1.x</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/", "title": "Upgrading your Azure instances", "text": ""}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#upgrading-your-azure-instances", "title": "Upgrading your Azure instances", "text": "<p>This documentation page describes how to upgrade the application stack on your instance (TheHive, Cortex and related services such as Cassandra and ElasticSearch).</p> <p>It does not cover operating system level updates such as Ubuntu patches, Docker updates, Nomad updates, etc. We recommend replacing your instance and using a fresh Azure Marketplace image to update all OS-level components to avoid any software version inconsistency / incompatibility.</p> <p>To avoid data loss / data corruption, you should ALWAYS backup or snapshot your persistent data volumes before performing any kind of update process.</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#tldr", "title": "TL;DR;", "text": "<p>All actions on the instances are to be performed as root</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#1-stop-the-running-nomad-job", "title": "1. Stop the running Nomad job", "text": "<pre><code>$ . /opt/strangebee/ops/scripts/ops-common.cfg &amp;&amp; stop_nomad_job thehive-job\n</code></pre>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#2-backup-your-nomad-job-specifications-and-var-files", "title": "2. Backup your Nomad job specifications and var files", "text": "<pre><code>$ /opt/strangebee/ops/scripts/ops-config-backup.sh -n nomad-jobs -f /opt/thp_data/nomad/jobs/\n</code></pre>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#3-backup-snapshot-your-instance-persistent-data-volume-using-the-azure-console-or-cli", "title": "3. Backup / snapshot your instance persistent data volume (using the Azure console or CLI)", "text": ""}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#4-edit-the-nomad-job-var-file-matching-the-running-job-on-the-instance-and-update-the-image-versions-you-wish-to-use-from-now-on", "title": "4. Edit the Nomad job var file matching the running job on the instance and update the image versions you wish to use from now on.", "text": "<p>All job specifications and var files are located under <code>/opt/thp_data/nomad/jobs</code> ex: <code>$ vi /opt/thp_data/nomad/jobs/thehive-job.vars</code></p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#5-schedule-the-nomad-job-dont-forget-to-set-the-matching-var-file", "title": "5. Schedule the Nomad job (don't forget to set the matching var file)", "text": "<pre><code>$ . /opt/strangebee/ops/scripts/ops-common.cfg &amp;&amp; run_nomad_job thehive-job\n</code></pre>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#context", "title": "Context", "text": "<p>The Azure Marketplace image for TheHive v5 can be used to deploy both TheHive v5 and / or Cortex v3. The image itself includes a hardened version of the official Ubuntu image from Canonical and a preconfigured Hashicorp Nomad engine. The image launch-time configuration you applied determined if TheHive or Cortex or both got installed on a given instance (as Nomad service jobs).</p> <p>To make things simpler for Azure admins with varying level of Hashicorp Nomad experience (including first-time Nomad users), we provide three different job specifications baked in the image to allow three instance deployment scenarios (instead of a more complex, dynamic one, that can adapt to all use-cases).</p> <p>The job specifications are named as follow:</p> <ul> <li>TheHive only --&gt; <code>thehive-job</code></li> <li>Cortex only --&gt; <code>cortex-job</code></li> <li>TheHive and Cortex on the same instance --&gt; <code>thehive-cortex-job</code></li> </ul> <p>Once your instances are deployed, you can check which profile is applied on a given instance with the following command (to be run on the instance):</p> <pre><code>$ nomad status\n</code></pre> <p>If you deployed TheHive only, the output is the following:</p> <pre><code>ID           Type     Priority  Status   Submit Date\nthehive-job  service  50        running  ***\n</code></pre> <p>Likewise, if you deployed Cortex only, the output is:</p> <pre><code>ID          Type     Priority  Status   Submit Date\ncortex-job  service  50        running  ***\n</code></pre> <p>And finally, if you deployed both TheHive and Cortex, the output is predictably:</p> <pre><code>ID                  Type     Priority  Status   Submit Date\nthehive-cortex-job  service  50        running  ***\n</code></pre>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#marketplace-image-storage-vs-persistent-instance-storage", "title": "Marketplace image storage vs. persistent instance storage", "text": "<p>Before we go any further, a quick note on image vs. persistent storage.</p> <p>As mentioned in the README, persistent data gets stored on a dedicated volume, not on the root filesystem. By default, your persistent data volume will be mounted at <code>/opt/thp_data</code>.</p> <pre><code>$ lsblk\n\nNAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\nloop0     7:0    0 67.8M  1 loop /snap/lxd/22753\nloop1     7:1    0   62M  1 loop /snap/core20/1587\nloop2     7:2    0   47M  1 loop /snap/snapd/16292\nloop3     7:3    0   48M  1 loop /snap/snapd/17029\nloop4     7:4    0 63.2M  1 loop /snap/core20/1623\nsda       8:0    0   16G  0 disk\n\u2514\u2500sda1    8:1    0   16G  0 part /opt/thp_data\nsdb       8:16   0   32G  0 disk\n\u2514\u2500sdb1    8:17   0   32G  0 part /var/lib/docker\nsdc       8:32   0   30G  0 disk\n\u251c\u2500sdc1    8:33   0 29.9G  0 part /\n\u251c\u2500sdc14   8:46   0    4M  0 part\n\u2514\u2500sdc15   8:47   0  106M  0 part /boot/efi\nsr0      11:0    1  638K  0 rom\n</code></pre> <p>The Docker volume mounted at <code>/var/lib/docker</code> is also persistent but contains no persistent data and does not need to be backed-up. We use a dedicated Docker volume only for size adaptability since Docker images could require a lot of storage space (say if you were to use all available Cortex analyzer / responder images) or not that much if you only run TheHive on the instance.</p> <p>We provide templates for the Nomad job specifications within the image. The templates are located at: <code>/opt/strangebee/ops/templates/nomad/jobs</code>. All files under the <code>templates</code> folder are only meant as templates to be used somewhere else (most likely on your persistent storage). So, the only time window where it can be useful to modify the templates is at first instance launch, before initialising the instance (and thus before copying them to the persistent storage).</p> <p>Every time you replace an instance and use a fresh Azure Marketplace image, the root filesystem gets completely reset based on the new image, including the <code>templates</code> folder.</p> <p>The effective runtime configuration files used to launch Nomad jobs are all located on the persistent storage at: <code>/opt/thp_data/nomad/jobs</code>.</p> <p>When you replace an instance and use a fresh Azure Marketplace image, the persistent storage remains exactly as you left it when you stopped the previous instance.</p> <p>To proceed with TheHive / Cortex updates, we will only modify files on the persistent volume, all located under <code>/opt/thp_data/nomad/jobs</code>.</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#update-step-13-stop-the-apps-and-perform-some-backups", "title": "Update step 1/3: stop the apps and perform some backups", "text": ""}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#stop-the-running-nomad-job", "title": "Stop the running Nomad job", "text": "<p>Before performing configuration and data backups, we will stop the running Nomad job on each instance (use the appropriate job name on each instance as identified earlier in the Context section). This will stop TheHive and / or Cortex along with all depending services such as Cassandra and ElasticSearch.</p> <p>Note</p> <p>All actions on the instances during the entire update process are to be performed as root**. Once connected to the instance, you can switch to the root context using the <code>sudo su</code> command.</p> <pre><code>$ . /opt/strangebee/ops/scripts/ops-common.cfg &amp;&amp; stop_nomad_job thehive-job\n\n[INFO] Stopping Nomad job: thehive-job\n[INFO] Fetching Nomad ACL management token\n</code></pre> <p>You can check the job is now stopped:</p> <pre><code>$ nomad status\n\nID           Type     Priority  Status          Submit Date\nthehive-job  service  50        dead (stopped)  ***\n</code></pre>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#backup-existing-nomad-job-specifications-and-variable-files", "title": "Backup existing Nomad job specifications and variable files", "text": "<p>We will now backup the existing Nomad job specifications and variable files before updating them. A script to do so is baked into the image, use it with the <code>-n</code> flag to set the backup name and <code>-f</code> flag to set the folder to backup. All backups will get stored on your persistent volume under <code>/opt/thp_data/backup</code>.</p> <pre><code>$ /opt/strangebee/ops/scripts/ops-config-backup.sh -n nomad-jobs -f /opt/thp_data/nomad/jobs/\n\n[INFO] Initial checks\n[INFO] Backup of /opt/thp_data/nomad/jobs/\n\n--- START of nomad-jobs config backup - Mon Oct 10 14:45:48 UTC 2022 ---\n\ntar: Removing leading `/' from member names\n/opt/thp_data/nomad/jobs/\n/opt/thp_data/nomad/jobs/thehive-job.nomad\n/opt/thp_data/nomad/jobs/thehive-db-init-job.nomad\n/opt/thp_data/nomad/jobs/thehive-cortex-job.nomad\n/opt/thp_data/nomad/jobs/thehive-db-init-job.vars\n/opt/thp_data/nomad/jobs/cortex-job.nomad\n/opt/thp_data/nomad/jobs/thehive-cortex-job.vars\n/opt/thp_data/nomad/jobs/cortex-job.vars\n/opt/thp_data/nomad/jobs/thehive-job.vars\n[INFO] Purging backups older than 7 days\n\n--- END of nomad-jobs config backup - Mon Oct 10 14:45:48 UTC 2022 ---\n</code></pre> <p>You can now check the resulting archive.</p> <pre><code>$ ll /opt/thp_data/backup\n\ntotal 16\ndrwxr-xr-x  2 root root 4096 Oct 10 14:45 ./\ndrwxr-xr-x 12 root root 4096 Oct 10 10:59 ../\n-rw-r-----  1 root root 3261 Oct 10 14:45 nomad-jobs.conf.backup.2022-10-10.tar.gz\n-rw-r-----  1 root root 3261 Oct 10 14:45 nomad-jobs.conf.latest.tar.gz\n</code></pre> <p>Note</p> <p>using the configuration backup script, the latest backup gets copied with the <code>latest</code> suffix. The latest backups never get deleted when older backups get purged.</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#backup-or-snapshot-your-persistent-data-volume", "title": "Backup or snapshot your persistent data volume", "text": "<p>Using the Azure console or CLI, snapshot your persistent data volume before performing any update:</p> <p></p> <p>Snapshot the persistent data volume for each instance you are updating.</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#update-step-23-update-the-image-versions-in-the-nomad-job-variable-file", "title": "Update step 2/3: update the image versions in the Nomad job variable file", "text": "<p>To make the update process easier, we have stored the image versions used in the Nomad job specifications in an external variables file. In most cases, it is not necessary to ever update the job specifications file unless you wish to fine tune some technical settings, such as the resources allocated to each task (CPU &amp; RAM).</p> <p>For example, we will update TheHive along with its dependencies on an instance running the <code>thehive-job</code> Nomad job. This job is described in two files:</p> <ul> <li>The job specifications file located at: <code>/opt/thp_data/nomad/jobs/thehive-job.nomad</code></li> <li>The job variables file located at: <code>/opt/thp_data/nomad/jobs/thehive-job.vars</code></li> </ul> <p>To update the image versions, we need to edit the variables file:</p> <ul> <li><code>$ vi /opt/thp_data/nomad/jobs/thehive-job.vars</code></li> </ul> /opt/thp_data/nomad/jobs/thehive-job.vars<pre><code>thehivecontext = \"/thehive\"\nimage_cassandra = \"cassandra:4.0.6\"\nimage_elasticsearch = \"elasticsearch:7.17.6\"\nimage_nginx = \"nginx:1.23.1\"\nimage_thehive = \"strangebee/thehive:5.0.16-1\"\n</code></pre> <p>Our instance was running TheHive v5.0.16 along with Cassandra v4.0.6 and ElasticSearch v7.17.6. </p> <p>Let's update the image versions (this is just an example, use the actual versions you wish to deploy):</p> <ul> <li><code>$ vi /opt/thp_data/nomad/jobs/thehive-job.vars</code></li> </ul> /opt/thp_data/nomad/jobs/thehive-job.vars<pre><code>thehivecontext = \"/thehive\"\nimage_cassandra = \"cassandra:4.1.0\"\nimage_elasticsearch = \"elasticsearch:7.17.9\"\nimage_nginx = \"nginx:1.24.0\"\nimage_thehive = \"strangebee/thehive:5.1.4-1\"\n</code></pre> <p>Tip</p> <p>We recommend never using the <code>:latest</code> tag and always using specific image versions to avoid problems or inconsistencies.</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#image-references", "title": "Image references", "text": "<p>You can find the available image versions for each component at the following links:</p> <ul> <li>TheHive images</li> <li>Cortex images</li> <li>Cassandra images</li> <li>ElasticSearch images</li> <li>Nginx images</li> </ul> <p>TheHive v5 is not yet compatible with ElasticSearch v8.x - only the 7.x versions are supported for the time being.</p> <p>You can find the changelog for TheHive and Cortex at the following links:</p> <ul> <li>TheHive changelog</li> <li>Cortex changelog</li> </ul>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-instances/docs/upgrade/#update-step-33-schedule-the-nomad-job", "title": "Update step 3/3: Schedule the Nomad job", "text": "<p>You can now schedule the Nomad job to start TheHive and / or Cortex. Do not forget to set the variable file we just modified when running the job, otherwise it will fail.</p> <pre><code>$ . /opt/strangebee/ops/scripts/ops-common.cfg &amp;&amp; run_nomad_job thehive-job\n\n[INFO] Scheduling Nomad job: thehive-job\n[INFO] Fetching Nomad ACL management token\n</code></pre> <p>To check the job is now running again:</p> <pre><code>$ nomad status\n\nID           Type     Priority  Status   Submit Date\nthehive-job  service  50        running  ***\n</code></pre> <p>To check the updated TheHive version:</p> <pre><code>$ . /opt/strangebee/ops/scripts/ops-common.cfg &amp;&amp; check_rp $(get_host_ip) thehive\n\n[INFO] Checking local reverse proxy on /thehive/api/status\n{\"versions\":{\"Scalligraph\":\"5.1.4-1\",\"TheHive\":\"5.1.4-1\",\"Play\":\"2.8.x\"},\"config\":{\"protectDownloadsWith\":\"malware\",\"authType\":[\"session\",\"local\",\"key\"],\"capabilities\":[\"changePassword\",\"setPassword\",\"authByKey\",\"mfa\"],\"ssoAutoLogin\":false,\"pollingDuration\":1000,\"freeTagDefaultColour\":\"#000000\"}}\n</code></pre> <p>To check the updated Cortex version:</p> <pre><code>$ . /opt/strangebee/ops/scripts/ops-common.cfg &amp;&amp; check_rp $(get_host_ip) cortex\n\n[INFO] Checking local reverse proxy on /cortex/api/status\n{\"versions\":{\"Cortex\":\"3.1.7-1\",\"Elastic4Play\":\"1.13.6\",\"Play\":\"2.8.16\",\"Elastic4s\":\"7.17.2\",\"ElasticSearch client\":\"7.17.1\"},\"config\":{\"protectDownloadsWith\":\"malware\",\"authType\":[\"key\",\"local\"],\"capabilities\":[\"authByKey\",\"changePassword\",\"setPassword\"],\"ssoAutoLogin\":false}}\n</code></pre>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-vnet/", "title": "Creating a new SecOps Virtual Network", "text": ""}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-vnet/#creating-a-new-secops-virtual-network", "title": "Creating a new SecOps Virtual Network", "text": "<p>If you do not already have a virtual network (vnet) at hand to deploy TheHive and Cortex into, using our sample code will allow you to build a production-ready vnet very easily.</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-vnet/#files", "title": "Files", "text": "<p>Files</p> <p>Terraform files are available on Github: </p> <ul> <li>000-provider.tf</li> <li>010-vnet.tf</li> <li>030-certificate-identity.tf</li> <li>050-bastion.tf</li> <li>060-nva.tf</li> <li>070-appgw-securitygroup.tf</li> <li>075-public-securitygroup.tf</li> <li>080-nva-nic-securitygroup.tf</li> <li>085-routes.tf</li> <li>085-routes.tf</li> <li>090-instance-disks.tf</li> <li>200-appgw.tf</li> <li>output.tf</li> <li>variables.tf</li> <li>tarreform.tfvars</li> <li>files/nva-nat-cloud-config.yaml</li> </ul>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-vnet/#overview", "title": "Overview", "text": "<p>The reference architecture vnet consists of the following resources</p> <p></p> <p>The vnet will include:</p> <ul> <li>Two public subnets (one for the Application Gateway, the other for the bastion and network virtual appliance hosts)</li> <li>One backend private subnet to host our TheHive and Cortex instances</li> <li>An Application Gateway to securely handle the public-facing traffic to our TheHive and Cortex instances</li> <li>All required Network Security Groups</li> <li>Public DNS records for TheHive and Cortex to point to the Application Gateway </li> <li>A bastion host to SSH into our TheHive and Cortex instance hosted in the private subnet</li> <li>A Network Virtual Appliance to allow Internet access for our instances in the private subnet through a NAT gateway</li> <li>Four storage disks to store the persistent TheHive and Cortex data. These disks could be created alongside the instances but creating them with the vnet further limits the risk of accidental destruction and data loss when updating or replacing the instances.</li> </ul>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-vnet/#network-security-groups", "title": "Network Security Groups", "text": "<p>There are no default iptables rules implemented in the images for either TheHive or Cortex (no OS-based IP filtering). Since we built them to be replaceable at each application update, somewhat like containers, we recommend limiting OS customisations to benefit from the easy update process. For that reason, filtering should be based on network security groups only.</p> <p>Keep in mind that the applications are listening on http, not https. Even though the default network security groups allow incoming traffic on the http ports (TCP 9000 for TheHive, TCP 9001 for Cortex), be careful not to expose them on a public-facing network interface.</p> <p>While all required security groups depicted above are automatically deployed with Terraform, please note the following:</p> <p>For secops-public-subnet Network Security Group (NSG) and secops-backend-private-subnet NSGs:</p> <ul> <li>All default Azure rules allowing internal Virtual Network traffic, AzureLoadBalancer traffic and Internet traffic are blocked.</li> </ul> <p>For secops-appgw-subnet NSG: </p> <ul> <li>Default Azure inbound rules allowing internal Virtual Network traffic and AzureLoadBalancer traffic are blocked.</li> <li>Inbound traffic with source address GatewayManager or AzureLoadBalancer (destination port TCP 65200-65535) is allowed as recommended by Azure for the Application Gateway.</li> <li>Default Azure outbound rules are allowed.</li> </ul>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-vnet/#bastion-host", "title": "Bastion host", "text": "<p>We launch an instance to act as a bastion host (defaults to B2s - 2 vCPUs / 4 GiB RAM). Bastion host hardening is not performed automatically but you should definitely harden this host going forward if you will use it in a production context. We do however strictly limit access to and from this host.</p> <p>The bastion host will run the latest Ubuntu image from Canonical. The default sudoer user is azureuser.</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-vnet/#mynva-host", "title": "myNVA host", "text": "<p>We launch an instance to act as a network virtual appliance (NVA - defaults to DS2_v2 - 2 vCPUs / 7 GiB RAM / Accelerated networking supported). This instances makes it possible to NAT outgoing traffic from the private subnet. NVA host hardening is not performed automatically but you should definitely harden this host going forward if you will use it in a production context. We do however strictly limit access to and from this host.</p> <p>The NVA host will run the latest Ubuntu image from Canonical. The default sudoer user is azureuser.</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-vnet/#secops-vnet-prerequisites", "title": "SecOps vnet prerequisites", "text": "<p>While most vnet resources will be provisioned with Terraform, there are some exceptions that must be created beforehand:</p> <ul> <li>The Azure account and subscription must already exist, along with the target resource group</li> <li>The public DNS zone to register the Application Gateway</li> <li>The service principal to build the environment (e.g app-name) with Owner Azure Role on the subscription</li> <li>The keyvault and associated certificate for the https listener</li> </ul> <p>You must provide the information for these resources before creating the vnet (populate the Terraform variables with the associated values).</p>"}, {"location": "resources/iaas/azure/infra-as-code/ug-secops-vnet/#providing-credentials-to-terraform", "title": "Providing credentials to Terraform", "text": "<p>Terraform requires Azure credentials in order to build the vnet and its associated resources. </p> <p>We highly recommend you never store your Azure credentials in the Terraform code or even in the same directory tree to avoid sharing / commiting the file accidentally. One way to provide the required credentials to Terraform is to create a file to set some environment variables and to source the file prior to running Terraform.</p> <p>Again, store this file in a secure location outside your Terraform project directory tree.</p> <p>Sample file:</p> <pre><code>export ARM_SUBSCRIPTION_ID=\"xxxx-xxxx-xxxx-xxxx-xxxx\"\nexport ARM_CLIENT_ID=\"xxxx-xxxx-xxxx-xxxx-xxxx\"\nexport ARM_CLIENT_SECRET=\"xxxx-xxxx-xxxx-xxxx-xxxx\"\nexport ARM_TENANT_ID=\"xxxx-xxxx-xxxx-xxxx-xxxx\"\nexport TF_VAR_thehive_key_vault_certificate_secret_id=\"xxxx-xxxx-xxxx-xxxx-xxxx\"\n</code></pre> <p>Where to find the associated values:</p> <ul> <li>ARM_SUBSCRIPTION_ID: The subscription ID (under Subscriptions --&gt; )</li> <li>ARM_CLIENT_ID: application ID (under Azure Active Directory --&gt; App registrations --&gt; All applications --&gt; app-name)</li> <li>ARM_CLIENT_SECRET: app-name Secret Key (under Azure Active Directory --&gt; App registrations --&gt; All applications --&gt; app-name --&gt; Certificates &amp; secrets)</li> <li>ARM_TENANT_ID: Active Directory tenant ID (under Azure Active Directory)</li> <li>TF_VAR_thehive_key_vault_certificate_secret_id: thehive certificate secret ID (under Keyvault --&gt; Certificates --&gt; thehive-certificate --&gt; CURRENT VERSION )</li> </ul> <p>Terraform compatibility: v1.x</p>"}, {"location": "thehive/", "title": "TheHive", "text": ""}, {"location": "thehive/administration/accounts/", "title": "Account Creation/Update Guide", "text": ""}, {"location": "thehive/administration/accounts/#manage-accounts", "title": "Manage Accounts", "text": "<p>Accounts can be created or edited in TheHive from multiple locations:</p> <ul> <li>As an Administrator, in the Users view</li> <li>As an Administrator, on the detailed page of an Organization</li> <li>As an Org-admin, on the Organization configuration page</li> </ul> <p>As a platform Administrator, go to the Users page to manage accounts.</p> <p></p>"}, {"location": "thehive/administration/accounts/#types-of-accounts", "title": "Types of Accounts", "text": "<p>Starting from TheHive 5.0, there are two types of accounts:</p>"}, {"location": "thehive/administration/accounts/#normal-accounts", "title": "Normal Accounts", "text": "<p>These are intended for standard users, such as analysts. Normal accounts support logging in via the web UI, use of all available authentication methods, and API key generation if enabled.</p>"}, {"location": "thehive/administration/accounts/#service-accounts", "title": "Service Accounts", "text": "<p>These accounts are designed for automation tasks within the application, such as creating alerts. Service accounts can only authenticate via the API using an API key and cannot log into the web UI.</p>"}, {"location": "thehive/administration/accounts/#creating-an-account", "title": "Creating an Account", "text": "<p>To create a new account, follow these steps:</p> <ol> <li>Click the  button to add an account.</li> </ol> <p></p> <ol> <li>Select the account type, either Normal or Service.</li> <li>Enter a login name formatted as an email address.</li> <li>Provide a name for the account.</li> <li>Assign organizations and set an associated profile for each. To establish the default organization, click Set as default.</li> </ol> <p>Once completed, click Confirm.</p>"}, {"location": "thehive/administration/accounts/#updating-an-account", "title": "Updating an Account", "text": "<p>To modify an existing account:</p> <ol> <li>In the account list, click Preview to open the account details.</li> </ol> <p></p> <ol> <li>You can add an avatar to the account by clicking the  icon and selecting a file.<sup>1</sup></li> <li>Update the email address, which is used for notifications and password resets.</li> <li>Verify if the user has enabled MFA (Multi-Factor Authentication).</li> <li>To change the account password, click Set a new password. An email informing the user of the change is sent to their registered email address.</li> <li>Click Reset the password to email the user a magic link for password reset. For more information, refer to Password Reset Guide.</li> <li>Update Roles and Organizations as needed.</li> <li>To delete the account, select the Delete option.</li> </ol>"}, {"location": "thehive/administration/accounts/#license-management-for-user-profiles-version-543-update", "title": "License Management for User Profiles (Version 5.4.3 Update)", "text": "<p>In version 5.4.3, TheHive introduces a new feature for license management in user profiles. During user creation or editing, administrators can now see which profiles require a license, as indicated by a \"License Required\" label in the profile selection dropdown. This label, displayed next to profiles with permissions that consume licenses, helps administrators manage license usage effectively.</p> <p>This enhancement is available in both the Org-admin and Global Users views, providing consistent visibility across user management settings.</p> <p></p> <p></p> <ol> <li> <p>Accepted formats are PNG or JPG files only.\u00a0\u21a9</p> </li> </ol>"}, {"location": "thehive/administration/alert-status/", "title": "Alert Status", "text": ""}, {"location": "thehive/administration/alert-status/#alert-status", "title": "Alert Status", "text": "<p>Alert Status can be configured in the Administrators space: open Entities Management page, and select Alert status tab.</p>"}, {"location": "thehive/administration/alert-status/#introduction", "title": "Introduction", "text": "<p>TheHive comes with a set of predifined statuses. Each status belongs to a Stage.</p> <p></p> <p>Stages are hardcoded; they cannot be updated or deleted, and not stage can be added in the platform. Status can be created, updated and deleted.</p>"}, {"location": "thehive/administration/alert-status/#create-a-status", "title": "Create a Status", "text": "<p>Click on the  button to add a new status.</p> <p></p> <p>A status is defined by:</p> <ol> <li>a stage: choose the stage of the new status</li> <li>a value: choose a name for the new status</li> <li>a color: choose a color for users to quickly identify the status in the application</li> </ol>"}, {"location": "thehive/administration/alert-status/#editdelete-a-status", "title": "Edit/Delete a Status", "text": "<p>The color can only be updated when updating a status.</p>"}, {"location": "thehive/administration/analyzers-templates/", "title": "Analyzers Templates", "text": ""}, {"location": "thehive/administration/analyzers-templates/#analyzer-templates", "title": "Analyzer templates", "text": "<p>TheHive requires HTML templates to diplay Analyzers reports. </p>"}, {"location": "thehive/administration/analyzers-templates/#install-or-update-templates-of-public-analyzers", "title": "Install or update templates of public Analyzers", "text": "<ol> <li> <p>As Administrator, go to Entities Management menu, and Analyzer templates</p> <p></p> </li> <li> <p>Download the ZIP archive, add it, and click on the Import button</p> <p></p> </li> </ol>"}, {"location": "thehive/administration/analyzers-templates/#edit-templates", "title": "Edit templates", "text": "<p>As soon as a new Analyzer is enabled in Cortex, and is available for TheHive, a template line is added in this list.</p> <ol> <li> <p>Find the template to edit</p> <p></p> </li> <li> <p>Edit and save</p> <p></p> </li> </ol> <p>Running the associated analyzer should display results with the new template applied.</p>"}, {"location": "thehive/administration/attack-patterns/", "title": "Att&ck Patterns", "text": ""}, {"location": "thehive/administration/attack-patterns/#attck-patterns", "title": "Att&amp;ck patterns", "text": "<p>The Att&amp;ck patterns configuration is available in the Administrators space: open Entities Management, then click on Att&amp;ck Patterns tab.</p>"}, {"location": "thehive/administration/attack-patterns/#introduction", "title": "Introduction", "text": "<p>By default, TheHive comes with Enterprise ATT&amp;CK patterns from MITRE. This is installed during the installation process, and de catalog name Enterprise Attack is created with all of the related techniques.</p> <p></p>"}, {"location": "thehive/administration/attack-patterns/#view-patterns", "title": "View patterns", "text": "<p>To view details of patterns included in a catalog, click on a catalog.  </p> <p>full details of each pattern can be reviewed by click on a technique ID (TXXXX) </p>"}, {"location": "thehive/administration/attack-patterns/#add-or-update-catalogs", "title": "Add or Update Catalogs", "text": "<p>The catalogs are not updated automatically, neither the Enterprise catalog cominng during the installation process. Sso if you want to benefits from last versions of the framework, you have to update it.</p> <p></p> <p>To add a new catalog:</p> <ol> <li>Click on the Import MITRE ATT&amp;CK patterns</li> <li>Choose the patterns you want to install</li> <li>Add a catalog name if creating a new catalog, or select the name of an existing one to update it</li> <li>Drop le downloaded file</li> <li>Click the Import button</li> </ol> <p>This action can take some time.</p>"}, {"location": "thehive/administration/branding/", "title": "Branding Guide", "text": ""}, {"location": "thehive/administration/branding/#branding", "title": "Branding", "text": "<p>Info</p> <p>This capability is only available with a license.</p> <p>You can change the brand name, login page logo, navigation page logo, and the favicon.</p> <p>To customize branding:</p> <ol> <li>On the Platform Management icon, select the Branding tab</li> <li>Make the necessary changes</li> <li>Click Confirm</li> </ol> <p></p>"}, {"location": "thehive/administration/case-status/", "title": "Case Status", "text": ""}, {"location": "thehive/administration/case-status/#case-status", "title": "Case Status", "text": "<p>Case Status can be configured in the Administrators space: open Entities Management page, and select Case status tab.</p>"}, {"location": "thehive/administration/case-status/#introduction", "title": "Introduction", "text": "<p>TheHive comes with a set of predifined statuses. Each status belongs to a Stage. </p> <p></p> <p>Stages are hardcoded; they cannot be updated or deleted, and not stage can be added in the platform. Status can be created, updated and deleted.</p>"}, {"location": "thehive/administration/case-status/#create-a-status", "title": "Create a Status", "text": "<p>Click on the  button to add a new status.</p> <p></p> <p>A status is defined by: </p> <ol> <li>a stage: choose the stage of the new status</li> <li>a value: choose a name for the new status</li> <li>a color: choose a color for users to quickly identify the status in the application</li> </ol>"}, {"location": "thehive/administration/case-status/#editdelete-a-status", "title": "Edit/Delete a Status", "text": "<p>The color can only be updated when updating a status.</p>"}, {"location": "thehive/administration/cortex/", "title": "Cortex Integration", "text": ""}, {"location": "thehive/administration/cortex/#about-cortex", "title": "About Cortex", "text": "<p>By default, TheHive is not connected to any Cortex server.</p> <p>Connect TheHive to Cortex and get benefits from Analyzers to gather information and intelligence about Observables, and run active actions on your network or third party services with Responders.</p>"}, {"location": "thehive/administration/cortex/#introduction", "title": "Introduction", "text": "<p>Info</p> <p>An account and an API key are required on a Cortex server to define a connection.</p> <ul> <li>Analyzers can be launched against Observables to get more details, contextual information, intelligence</li> <li>Responders can be launched against Case, Tasks, Observables, task Logs, and Alerts to run active actions during the investigation and incident response</li> </ul> <p>One or more Cortex instances can be connected to TheHive.</p>"}, {"location": "thehive/administration/cortex/#manage-cortex-connections", "title": "Manage Cortex connections", "text": ""}, {"location": "thehive/administration/cortex/#add-a-new-cortex-server", "title": "Add a new Cortex server", "text": "<p>Specify:</p> <ul> <li>A name for this connection, for example: <code>Cortex</code><sup>1</sup></li> <li>The URL of Cortex server to connect with, for example: <code>https://cortex.mycompany.com</code> </li> <li>The API key of the dedicated Cortex account</li> <li>Proxy settings if required for TheHive to connect with Cortex</li> </ul>"}, {"location": "thehive/administration/cortex/#advanced-settings", "title": "Advanced settings", "text": "<p>By default, all Analyzers and Responders made available by Cortex are available to ALL organizations in TheHive. Additionaly, 2 options are available:</p> <ul> <li>Make them available ONLY to a subset of existing organizations in TheHive</li> <li>Make them unavailable to a subset of existing organizations in TheHive</li> </ul>"}, {"location": "thehive/administration/cortex/#delete-a-connection", "title": "Delete a Connection", "text": "<ol> <li> <p>If you have several connections, this is useful to give explicit names\u00a0\u21a9</p> </li> </ol>"}, {"location": "thehive/administration/email-intake-connector/", "title": "Email Intake Connector", "text": ""}, {"location": "thehive/administration/email-intake-connector/#email-intake-connector", "title": "Email Intake Connector", "text": "<p>This documentation outlines the utilization of the Email Intake Connector for automatically generating alerts from a designated mailbox.</p> <p>The Email Intake Connector facilitates the connection of mailboxes used to receive cybersecurity alerts. It automatically transforms new emails into alerts within TheHive platform. Presently, the primary function supported is the creation of alerts regardless of the received email content.</p> <p></p>"}, {"location": "thehive/administration/email-intake-connector/#configuration", "title": "Configuration", "text": ""}, {"location": "thehive/administration/email-intake-connector/#global-configuration", "title": "Global Configuration", "text": "<p>The only parameter that requires adjustment is the <code>refresh interval</code>. By default, the connector polls mailboxes every 5 minutes. Adjust the frequency by increasing or decreasing the value.</p> <p></p> <p> </p>"}, {"location": "thehive/administration/email-intake-connector/#adding-a-mailbox", "title": "Adding a Mailbox", "text": "<p>Configuration options are available for Microsoft 365 (OAuth2) and Google Workspace (OAuth2). If you use another email provider service, configuration through IMAP is necessary.</p> <p></p> <p> </p> Microsoft MS365Google WorkspaceIMAP Mailbox <p>For IMAP configuration, you'll need to input the following information:</p> <ul> <li>Host: <code>host</code></li> <li>Port: <code>port</code> (default: 993)</li> </ul> <p>Additionally, provide your mailbox credentials. We recommend enabling SSL Check Certificate Authority.</p> <p></p>"}, {"location": "thehive/administration/email-intake-connector/#setting-up-microsoft365-for-thehive", "title": "Setting up Microsoft365 for TheHive", "text": "<p>This section provides detailed instructions to configure Microsoft 365 to allow TheHive access to a shared mailbox. Please follow these steps to ensure proper integration.</p> <p> </p>"}, {"location": "thehive/administration/email-intake-connector/#prerequisites", "title": "Prerequisites", "text": "<ul> <li>Administrator account on Microsoft 365.</li> <li>PowerShell installed and configured.</li> <li> <p>A shared mailbox already created in Microsoft 365 (e.g., <code>test-shared-mailbox@strangebee.com</code>).</p> <p></p> </li> </ul> <p> </p>"}, {"location": "thehive/administration/email-intake-connector/#step-by-step-configuration", "title": "Step-by-Step Configuration", "text": "<ol> <li> <p>Create a Mail-Enabled Security Group</p> <ul> <li>Create a security group that includes the shared mailbox. This group will be used to restrict access to the application for the shared mailbox only.</li> <li>Navigate to Admin &gt; Exchange Admin Center, and create a Mail-Enabled Security Group.</li> <li>Add the shared mailbox as a member of the security group.</li> </ul> <p></p> </li> <li> <p>Register a New Application in Microsoft Entra</p> <ul> <li>As an administrator, navigate to Microsoft Entra admin center.</li> <li>Go to Admin &gt; Identity &gt; Applications &gt; App registrations.</li> </ul> <p></p> <ul> <li>Gather the following information:<ul> <li>Tenant ID</li> <li>Client ID (App ID)</li> <li>Object ID of the enterprise application</li> </ul> </li> </ul> <p></p> </li> <li> <p>Create a Secret for the Application</p> <ul> <li>In the registered application page, go to Certificates &amp; Secrets.</li> <li>Create a new secret, which will be used as an OAuth2 input to authenticate the service.</li> <li>Save the secret value securely for later use.</li> </ul> <p></p> </li> <li> <p>Assign API Permissions</p> <ul> <li>In the registered application page, go to API Permissions.</li> <li>Ensure the application has the following permissions:<ul> <li>Office 365 Exchange Online / IMAP.AccessAsApp</li> </ul> </li> </ul> <p></p> </li> <li> <p>Configure PowerShell Access</p> <ul> <li> <p>Define the necessary values for the configuration:</p> <pre><code>$AppID = '{ClientID}'\n$TenantID = '{TenantID}'\n$ObjectID = '{ObjectID}'\n$SecurityGroup = '{SecurityGroup}'  # The mail-enabled security group\n$MailBox = '{MailBox}'  # The shared mailbox\n</code></pre> </li> <li> <p>Run the following PowerShell commands to configure access:</p> <ul> <li>Define App Permissions:</li> </ul> <pre><code>New-ServicePrincipal -AppId $AppID -ServiceId $ObjectID\n</code></pre> <ul> <li>Grant Security Group Full Access to the Mailbox:</li> </ul> <pre><code>Add-MailboxPermission -Identity $MailBox -User $SecurityGroup -AccessRights FullAccess\n</code></pre> <ul> <li>Restrict Access to Members of the Security Group Only:</li> </ul> <pre><code>New-ApplicationAccessPolicy -AppId $AppID -PolicyScopeGroupId $SecurityGroup -AccessRight RestrictAccess -Description \"Restrict this app to members of distribution group {$SecurityGroup}\"\n</code></pre> </li> </ul> </li> <li> <p>Test the Configuration</p> <ul> <li> <p>Run the following command to test if the application access policy is properly configured:</p> <pre><code>Test-ApplicationAccessPolicy -AppId $AppID -Identity $MailBox\n</code></pre> </li> <li> <p>The expected output should be similar to:</p> <pre><code>AppId             : 9367xxxx\nMailbox           : test-shared-mailbox20231107190659\nAccessCheckResult : Granted\n</code></pre> </li> <li> <p>Running the command with a different mailbox should return <code>AccessCheckResult: Denied</code>.</p> </li> </ul> </li> <li> <p>Configure Intake Connector Settings in TheHive</p> <p>To integrate TheHive with Microsoft 365, you will need the following information:</p> <ul> <li>Mailbox address</li> <li>Tenant ID</li> <li>Client ID</li> <li>Secret Value</li> <li>Authority: <code>https://login.microsoftonline.com</code></li> <li>Scope: <code>https://outlook.office365.com/.default</code></li> </ul> <p></p> </li> </ol>"}, {"location": "thehive/administration/email-intake-connector/#setting-up-google-workspace-for-thehive", "title": "Setting up Google Workspace for TheHive", "text": "<p>This section describes the necessary steps to configure Google Workspace to allow TheHive access to a mailbox. Please follow these steps to ensure proper integration.</p> <p> </p>"}, {"location": "thehive/administration/email-intake-connector/#prerequisites_1", "title": "Prerequisites", "text": "<ul> <li>Access to the Google Cloud Admin Console.</li> <li>Proper permissions to create projects and configure OAuth credentials.</li> </ul>"}, {"location": "thehive/administration/email-intake-connector/#step-by-step-configuration_1", "title": "Step-by-Step Configuration", "text": "<ol> <li> <p>Access Google Cloud Admin Console Navigate to the Google Cloud Admin Console at https://console.cloud.google.com/welcome.</p> </li> <li> <p>Create a New Project </p> <ul> <li>Click on API &amp; Services.</li> </ul> <p></p> <ul> <li>Select Create a Project.</li> </ul> <p></p> <ul> <li>Provide a meaningful name for the project and click Create.</li> </ul> <p></p> </li> <li> <p>Configure OAuth Consent Screen </p> <ul> <li>In the left-hand menu, select OAuth consent screen.</li> </ul> <p></p> <ul> <li>Choose User Type as Internal and click Create.</li> </ul> <p></p> <ul> <li>Assign a name to the app and specify a mailbox for support contact.</li> </ul> <p></p> <ul> <li>Provide a developer contact email address, then click Save and Continue.</li> </ul> <p></p> </li> <li> <p>Add Gmail API Scope </p> <ul> <li>In Step 2, click on Add or Remove Scopes.</li> </ul> <p></p> <ul> <li>In the search bar, type the following scope: <code>https://mail.google.com/</code>.</li> </ul> <p></p> <ul> <li>Click Add to Table to add the scope.</li> </ul> <p></p> <ul> <li>Ensure that the new scope is checked, then click Update.</li> </ul> <p></p> <ul> <li>Scroll down to verify that the Gmail scope exists, and click Save and Continue.</li> </ul> <p></p> </li> <li> <p>Return to Dashboard </p> <ul> <li>On the summary page, click Back to Dashboard to complete the OAuth consent configuration.</li> </ul> <p></p> </li> <li> <p>Create OAuth Credentials </p> <ul> <li>In the left-hand menu, select Credentials.</li> </ul> <p></p> <ul> <li>Click on Create Credentials and choose OAuth Client ID.</li> </ul> <p></p> <ul> <li>Set the application type as Web application.</li> </ul> <p></p> <ul> <li> <p>Provide a name for the OAuth client ID.</p> </li> <li> <p>Under Authorized JavaScript origins, add the appropriate URI.</p> </li> </ul> <p></p> <ul> <li>Under Authorized redirect URIs, add the necessary URIs and click Create.</li> </ul> <p></p> </li> <li> <p>Obtain Client ID and Secret </p> <ul> <li> <p>A dialog will appear with the Client ID and Client Secret.</p> </li> <li> <p>Copy these values or download the JSON file for future reference.</p> </li> </ul> <p></p> </li> <li> <p>Configure Intake Connector Settings in TheHive</p> <p>Set up the intake settings in TheHive by filling in the following values:</p> <ul> <li><code>Email</code></li> <li><code>clientId</code></li> <li><code>secret</code></li> </ul> <p></p> </li> </ol>"}, {"location": "thehive/administration/email-intake-connector/#settings", "title": "Settings", "text": "<p>After testing your mailbox configuration, select the organization to connect, determining where alerts will be created. Define the mailbox folder to monitor (typically INBOX). Finally, specify the action to take on incoming emails: <code>archive</code>, <code>mark as read</code>, or <code>no action</code>.</p> <p></p>"}, {"location": "thehive/administration/email-intake-connector/#generated-alerts-and-observables", "title": "Generated Alerts and Observables", "text": "<p>Following configuration, alerts and observables are generated in the selected organization.</p>"}, {"location": "thehive/administration/email-intake-connector/#alerts", "title": "Alerts", "text": "<p>Each alert will contain the following details:</p> <p>Mapping of email data in the Alert</p> <ul> <li>Title: The email subject or \"no subject\"</li> <li>Type: email-intake</li> <li>Source: The configuration name is formatted as <code>Google Workspace @strangebee.com</code> =&gt; <code>googleworkspace-strangebee</code></li> <li>Source reference: <code>{message-id}</code> or <code>{lastUidValidity}.{uidEmail}</code> if the message-id is inaccessible</li> <li>Last sync date: The date the email was received</li> <li>Severity:  low</li> <li>TLP: amber</li> <li>PAP: amber</li> <li>Follow: False</li> <li>Tags: [email-intake, {source}, {Provider Name}, {Inbox Folder Name}]</li> <li>Status: new</li> <li>Description: The content of the email</li> <li>Summary: [Summary of Alert]</li> <li>Custom Fields: [Custom Fields]</li> <li>Eternal link: [Link to External Source]</li> </ul>"}, {"location": "thehive/administration/email-intake-connector/#observables", "title": "Observables", "text": "<p>The email itself is included as a <code>.eml</code> file, along with its sender and all attached files, which are added to the alert as observables, with the following parameters:</p> <p>Observables metadata added with the email data</p> <ul> <li>Message: The pre-formatted message</li> <li>TLP: {alert.tlp}</li> <li>PAP: {alert.pap}</li> <li>IOC: false</li> <li>Sighted: false</li> <li>Sighted at: [Timestamp]</li> <li>Ignore similarity: false</li> <li>dataType: file if it's an attachment; otherwise, mail for the <code>.eml</code> file</li> <li>Tags: {alert.tags}</li> <li>attachment Id: {attachment.id}</li> </ul> <p> </p>"}, {"location": "thehive/administration/first-start/", "title": "TheHive - First Start", "text": ""}, {"location": "thehive/administration/first-start/#first-start-of-thehive", "title": "First Start of TheHive", "text": ""}, {"location": "thehive/administration/first-start/#initial-login", "title": "Initial Login", "text": "<p>After following the installation guides and ensuring TheHive is up and running, open your web browser, navigate to <code>http://IP_ADDRESS:9000</code>, and log in using the default account credentials:</p> Login <code>admin</code> Password <code>secret</code> <p></p>"}, {"location": "thehive/administration/first-start/#install-license", "title": "Install License", "text": "<p>To unlock all features and quotas, log in to your account on StrangeBee's customer portal, and follow this guide to setup the licence.</p> <p>Tip</p> <p>This action is particularly required if you are setting up TheHive as a cluster: </p> <ol> <li>When starting TheHive service, start only one node</li> <li>setup the license by connecting to the started node</li> <li>start others TheHive nodes</li> </ol>"}, {"location": "thehive/administration/first-start/#change-admin-password", "title": "Change <code>Admin</code> password", "text": "<p>It is crucial to change the default admin password immediately after your initial login to ensure the security of your TheHive instance. The default credentials are publicly known and leaving them unchanged poses a significant security risk. Unauthorized users can easily gain access to your system, potentially compromising sensitive data and operations.</p>"}, {"location": "thehive/administration/first-start/#1-go-to-user-settings", "title": "1. Go to User Settings", "text": ""}, {"location": "thehive/administration/first-start/#2-change-your-password", "title": "2. Change Your Password", "text": ""}, {"location": "thehive/administration/first-start/#3-confirm-changes", "title": "3. Confirm Changes", "text": "<p>Ensure you confirm the changes for them to take effect.</p>"}, {"location": "thehive/administration/first-start/#configuration", "title": "Configuration", "text": "<p>The Administrator's space is where all platform configurations are managed.</p> <ul> <li> <p>Integrate TheHive with SMTP servers, authentication directory servers, Cortex, and MISP servers: Go to the Platform Management page</p> <p></p> </li> <li> <p>Create organizations</p> <p></p> </li> <li> <p>Create Users</p> <p></p> </li> <li> <p>Customize Application Behavior for Users in the Entity Management page</p> <p></p> </li> </ul>"}, {"location": "thehive/administration/ldap-server/", "title": "Synchronise Users and Organization with LDAP", "text": ""}, {"location": "thehive/administration/ldap-server/#synchronise-users-and-organization-with-ldap", "title": "Synchronise Users and Organization with LDAP", "text": ""}, {"location": "thehive/administration/ldap-server/#user-synchronisation", "title": "User synchronisation", "text": "<p>Users can be provisionned and deprovisionned automatically based on the content of a directory. Users data is synchronised periodically. New users in LDAP are created in TheHive, removed users are disabled.</p> <p>The organization membership and the profile of an user are set using LDAP groups. The configuration contain the mapping of LDAP groups with organization/profile.</p> <p></p>"}, {"location": "thehive/administration/license/", "title": "License Management", "text": ""}, {"location": "thehive/administration/license/#install-or-update-the-license", "title": "Install or Update the License", "text": "<p>By default TheHive includes the community edition license.</p> <p>To unlock capabilities<sup>1</sup> and quotas<sup>2</sup>, a license is required.   Contact StrangeBee. WHen you buy the license from StrangeBee, StrangeBee will create an account for you on the customer portal that will allow you to activate the license.</p>"}, {"location": "thehive/administration/license/#activate-or-update-the-license", "title": "Activate or update the license", "text": "<ol> <li> <p>On the Platform Management page, in the License tab, click the Update the current license button</p> <p></p> <p>Set a License key window opens. You can see the challenge in the window.</p> </li> <li> <p>Click Copy this challenge</p> <p>You will see the challenge copied message. After copying the challenge, go to your account on the StrangeBee customer portal and activate the license using this challenge and the customer portal will give you an activation license key.</p> </li> <li> <p>Enter the activation key in the License field</p> </li> <li> <p>Click the Activate the license key button</p> <p>This will activate the license and update your instance with all the features included with that license.</p> <p></p> <p>The license is defined by the following capabilities:</p> <ol> <li>It defines how many users you can create in your platform</li> <li>The license is based on the number of users and the number of organizations</li> <li>It has a validation and an expiration date</li> <li>It allows unlimited number of ReadOnly users and Service accounts. Service accounts are those who do not have access to the TheHive interface but can use an API key to call all the APIs</li> </ol> </li> </ol> <ol> <li> <p>Capabilities included in the license: clustering, branding, Active directory, SAML and OAUTH2 authentication, Case timelines.\u00a0\u21a9</p> </li> <li> <p>Quotas concern organizations and Users.\u00a0\u21a9</p> </li> </ol>"}, {"location": "thehive/administration/misp/", "title": "MISP Integration", "text": ""}, {"location": "thehive/administration/misp/#misp", "title": "MISP", "text": ""}, {"location": "thehive/administration/misp/#introduction", "title": "Introduction", "text": "<p>Info</p> <p>An account and an API key are required on a MISP server to define a connection.</p> <ul> <li>One or more MISP instances can be connected to TheHive.</li> <li>For each one:</li> <li>MISP events can be imported as Alerts in TheHive. A set of filter can refine the imported events</li> <li>Observables flagged as IOCs in a Case can be exported in a new event in MISP</li> </ul>"}, {"location": "thehive/administration/misp/#manage-misp-connections", "title": "Manage MISP connections", "text": ""}, {"location": "thehive/administration/misp/#add-a-new-misp-server", "title": "Add a new MISP server", "text": "<p>Specify:</p> <ul> <li>A name for this connection, for example: <code>misp</code><sup>1</sup></li> <li>The URL of MISP server to connect with, for example: <code>https://misp.mycompany.com</code> </li> <li>The API key of the dedicated MISP account</li> <li>The purpose of this connection: Import only, Export Only, or both, Import &amp; Export</li> <li>Proxy settings if required for TheHive to connect with MISP</li> </ul>"}, {"location": "thehive/administration/misp/#advanced-settings", "title": "Advanced settings", "text": "<p>By default, ALL organizations in TheHive benefit from this connection. Additionaly, 2 options are available:</p> <ul> <li>Make this connection available ONLY to a subset of existing organizations in TheHive</li> <li>Make this connection unavailable to a subset of existing organizations in TheHive</li> </ul> <p>Additional options let you:</p> <ul> <li>Define tags that will be appended to Alerts when importing MISP events</li> <li>When exporting IOCs in MISP, also export tags from the Case in the new MISP event</li> <li>When exporting IOCs in MISP, also export tags from the observables</li> </ul>"}, {"location": "thehive/administration/misp/#filters", "title": "Filters", "text": "<p>When importing MISP events as TheHive Alerts, several options are available:</p> <ul> <li>Define the maximum age of a MISP event allowed to be imported</li> <li>Specify a list of organizations owner of the MISP events allowed to be imported</li> <li>Specify a list of organizations owner of the MISP events that are not allowed to be imported</li> <li>Define a limit for the number of attributes (~observables) included in the MISP event to import it</li> <li>Specify a list of tags that should exist in the MISP event to import it</li> <li>Specify a list of tags that should exist in the MISP event to ignore it</li> </ul>"}, {"location": "thehive/administration/misp/#delete-a-connection", "title": "Delete a Connection", "text": "<ol> <li> <p>If you have several connections, this is useful to give explicit names\u00a0\u21a9</p> </li> </ol>"}, {"location": "thehive/administration/observables-types/", "title": "Observable Types", "text": ""}, {"location": "thehive/administration/observables-types/#observable-types", "title": "Observable types", "text": "<p>Observables types define the available dataTypes of Observables that can be used in the application. TheHive comes with the predefined set of types, and this list can be enriched with custom datatypes.</p> <p>Observable types are configured in the Administrators space: open Entities Management and select the Observable types tab.</p>"}, {"location": "thehive/administration/observables-types/#create-a-new-observable-type", "title": "Create a new Observable Type", "text": "<p>Click the  button to create a new Observable Type.</p> <p></p> <ol> <li>Specify a name for this new type</li> <li>Define if this new Observable Type is defined by a file attachment or not. If yes, the data entered by analysts is a file; if not, this is a text area.</li> </ol> <p>Then click on Confirm observable type creation.</p>"}, {"location": "thehive/administration/profiles/", "title": "Profiles", "text": ""}, {"location": "thehive/administration/profiles/#profiles", "title": "Profiles", "text": ""}, {"location": "thehive/administration/profiles/#introduction", "title": "Introduction", "text": "<p>TheHive includes a set of predefined profiles for Administrators and Organizations. This set can be expanded by creating custom profiles tailored to specific needs.</p> <p></p> <p>A valid license is required to update profiles.</p>"}, {"location": "thehive/administration/profiles/#about-permissions", "title": "About Permissions", "text": "<p>Each profile is defined by a set of permissions. There are two profile types:</p> <ul> <li>Administration: Used by users in the Admin organization to manage the platform.</li> <li>Organization: Used within business organizations.</li> </ul> <p>Permissions follow the format <code>manageEntity</code>, where <code>Entity</code> represents an application entity. For example, <code>manageCase</code> grants the right to create, update, and delete cases.</p>"}, {"location": "thehive/administration/profiles/#manage-profiles", "title": "Manage Profiles", "text": "<p>All profiles, except for the admin profile, can be customized or deleted.</p>"}, {"location": "thehive/administration/profiles/#adding-a-profile", "title": "Adding a Profile", "text": "<ol> <li>Navigate to the Profiles tab on the Entities Management page and click the  button.</li> <li>Select the type of profile to create and assign the associated permissions.</li> </ol> <p>The Add a Profile window will open.</p> <ol> <li>Enter a Name for the new profile.</li> <li>Choose a Profile Type.</li> <li>Select the appropriate Permissions for the profile type.</li> <li>Click Confirm profile creation to finalize.</li> </ol> <p></p> <p></p>"}, {"location": "thehive/administration/profiles/#editing-or-deleting-a-profile", "title": "Editing or Deleting a Profile", "text": "<p>Profiles can be edited or deleted as required.</p> <p></p>"}, {"location": "thehive/administration/profiles/#version-543-updates", "title": "Version 5.4.3 Updates", "text": ""}, {"location": "thehive/administration/profiles/#license-consumption-for-permissions", "title": "License-Consumption for Permissions", "text": "<p>Starting with version 5.4.3, TheHive introduces a distinction between permissions that consume a license and those that do not. In the profile permission selection screen, permissions are now divided into two categories:</p> <ul> <li>Unlicensed Permissions: Permissions that do not consume a license.</li> <li>Licensed Permissions: Permissions that consume a license.</li> </ul> <p>Permissions that consume a license are grouped under Licensed Permissions, while those that do not consume a license are grouped under Unlicensed Permissions.</p>"}, {"location": "thehive/administration/profiles/#permission-groups", "title": "Permission Groups", "text": "<p>Here is a detailed list of permissions in each group:</p>"}, {"location": "thehive/administration/profiles/#unlicensed-permissions", "title": "Unlicensed Permissions", "text": "<p>The following permissions do not consume a license and are available under the Unlicensed group:</p> <ul> <li>Manage dashboards</li> <li>Manage users</li> <li>Manage config</li> <li>Manage knowledge base</li> </ul>"}, {"location": "thehive/administration/profiles/#licensed-permissions", "title": "Licensed Permissions", "text": "<p>The following permissions consume a license and are available under the Licensed group:</p> <ul> <li>Manage access to TheHive FS</li> <li>Manage actions</li> <li>Manage analysis</li> <li>Manage case report</li> <li>Manage case report template</li> <li>Manage case templates</li> <li>Manage comment</li> <li>Manage custom event</li> <li>Manage observables</li> <li>Manage pages</li> <li>Manage page templates</li> <li>Manage procedures</li> <li>Manage sharings</li> <li>Manage tag</li> <li>Manage tasks</li> <li>Manage alerts<ul> <li>Create</li> <li>Delete</li> <li>Import</li> <li>Restart</li> <li>Update</li> </ul> </li> <li>Manage cases<ul> <li>Change Ownership</li> <li>Create</li> <li>Delete</li> <li>Merge</li> <li>Reopen</li> <li>Update</li> </ul> </li> <li>Manage functions<ul> <li>Create</li> <li>Invoke</li> </ul> </li> </ul> <p></p>"}, {"location": "thehive/administration/profiles/#selecting-permissions-by-license-group", "title": "Selecting Permissions by License Group", "text": "<p>When adding or editing a profile, users can easily identify licensed and unlicensed permissions in the permission selection screen. This feature provides administrators with clear visibility into which permissions impact licensing and helps manage profile configurations efficiently.</p> <p> </p>"}, {"location": "thehive/administration/smtp/", "title": "SMTP Configuration", "text": ""}, {"location": "thehive/administration/smtp/#smtp", "title": "SMTP", "text": "<p>TheHive can connect to a SMTP server to send email notifications, and allow users to define or change their password when forgotten.</p>"}, {"location": "thehive/administration/smtp/#configure-smtp", "title": "Configure SMTP", "text": "<p>On the Platform Management page, select the SMTP tab.</p> <p></p>"}, {"location": "thehive/administration/smtp/#configure-server-settings", "title": "Configure Server Settings", "text": "<p>Define: </p> <ol> <li>Server name or IP address</li> <li>Port</li> <li>The email address you want to use as the Sender in Send emails from</li> </ol>"}, {"location": "thehive/administration/smtp/#configure-security-and-authentication-settings", "title": "Configure Security and Authentication settings", "text": "<p>Define additional security parameters, if required:</p> <ol> <li>Select the right protocol from the list in Connection security</li> <li>Enter the Username amd Password if required</li> </ol>"}, {"location": "thehive/administration/smtp/#confirm-changes", "title": "Confirm changes", "text": ""}, {"location": "thehive/administration/smtp/#create-user-account-and-send-a-notification", "title": "Create user account and send a notification", "text": ""}, {"location": "thehive/administration/smtp/#i-forgot-my-password", "title": "I forgot my password", "text": "<p>Learn how to request a magic link with the I forgot my password button.</p>"}, {"location": "thehive/administration/taxonomies/", "title": "Taxonomies", "text": ""}, {"location": "thehive/administration/taxonomies/#taxonomies", "title": "Taxonomies", "text": "<p>Taxonomies are used to defined structured tags in TheHive. Taxonomies can be configured in the Administrators space: open Entities Manamgement and select Taxonomies tab.</p> <p>By default, MISP taxonomies are imported.</p> <p></p>"}, {"location": "thehive/administration/taxonomies/#view-a-taxonomie", "title": "View a taxonomie", "text": "<p>To review the list of available tags in one specific taxonomie, click on the desired name; this will open a drawer with the list of tags.</p> <p></p>"}, {"location": "thehive/administration/taxonomies/#activate-or-delete-a-taxonomie", "title": "Activate or delete a taxonomie", "text": "<p>By default no taxonomie is activated; so none can be used in Cases or Alerts. To use a set of tags in Cases and Alerts, the related taxonomie should be activated.</p> <p></p>"}, {"location": "thehive/administration/taxonomies/#update-taxonomies", "title": "Update Taxonomies", "text": "<p>TheHive comes with the version of MISP taxonomies available at the moment of the installation. Updating TheHive does not update and add the last available version. So if you want to get the latest version released by MISP people you have to update it manually.</p> <p></p> <ol> <li>Click on the Import Taxonomies button</li> <li>Download the last archive available here: https://github.com/MISP/misp-taxonomies/archive/main.zip</li> <li>Drag&amp;Drop the downloaded file and click on the Import button</li> </ol>"}, {"location": "thehive/administration/taxonomies/#custom-taxonomies", "title": "Custom Taxonomies", "text": "<p>You can add you own taxonomies by following the JSON schema specified by MISP.</p>"}, {"location": "thehive/administration/authentication/ad/", "title": "Active Directory (AD) Authentication", "text": ""}, {"location": "thehive/administration/authentication/ad/#active-directory", "title": "Active Directory", "text": "<p>A license is required to configure Active Directory authentication</p> <p></p> <p>Following information are required to configure AD authentication:</p> <ul> <li>The addresses of the domain controllers</li> <li>The Windows Domain Name</li> <li>The DNS domain name</li> <li>if you are using SSL or not</li> </ul>"}, {"location": "thehive/administration/authentication/general/", "title": "General Settings", "text": ""}, {"location": "thehive/administration/authentication/general/#general-settings", "title": "General Settings", "text": "<p>Info</p> <ul> <li>Privileges required: administrator</li> <li>Organisation: admin</li> <li>Location: <ul> <li>Menu: Plateform Management</li> <li>Tab: Authentication</li> </ul> </li> </ul> <p></p>"}, {"location": "thehive/administration/authentication/general/#session-settings", "title": "Session settings", "text": "<ul> <li>Duration of user inactivity before session expiration: time before logging out a user if inactive</li> <li>Warning message display time, before session expiration: duration of displaying a warning message before logging out </li> </ul> <p>Several options are available:</p> <ol> <li>Enable Basic Authentication: Authenticates HTTP requests using the login and password provided</li> <li>Enable API Key authentication: Authenticates HTTP requests using an API key provided</li> <li>Enable HTTP Header Authentication: Authenticates HTTP requests using a HTTP header containing the user login</li> <li>Enable Multifactor authentication: Multi-Factor Authentication is enabled by default. This means users can configure their MFA through their User Settings page</li> <li>Default user domain: By default, users log in with an email address for example: user@domain.com. When set up, users are allowed to log in without the domain (for example user).</li> </ol>"}, {"location": "thehive/administration/authentication/general/#manage-authentication-providers", "title": "Manage Authentication Providers", "text": "<p>Several options exist to authenticate users: </p> <ul> <li>local accounts: manage a local user database where you can configure the password policy</li> <li>Using LDAP directory: configure TheHive to use a LDAP server </li> <li>Using Active directory: configure TheHive to use a LDAP server</li> <li>SAML: Use single sign-on through on or more SAML providers to authenticate users</li> <li>Oauth2: Use single sign-on through external Oauth2 server to authenticate users</li> </ul> <p>Use several providers</p> <p> TheHive can use several providers to authenticate users, use the arrows to change the priority order (for example: try the Oauth2 authentication, then the local database).</p>"}, {"location": "thehive/administration/authentication/ldap/", "title": "LDAP Authentication", "text": ""}, {"location": "thehive/administration/authentication/ldap/#setting-ldap-authentication", "title": "Setting LDAP Authentication", "text": "<p>To setup LDAP authentication:</p> <ol> <li>Click on Directory Authentication</li> <li>use the switch to enable directory </li> <li>then choose LDAP in the menu ; the list of required parameters appears   </li> <li>Confirm and save your changes</li> <li>move the Directories Authentication line to be the first provider to use in the list of authentication providers</li> </ol> <p>Using SSL with LDAP</p> <p>To setup a custom Certificate Authority in TheHive, please refer to this guide.</p>"}, {"location": "thehive/administration/authentication/ldap/#authenticating-with-ldap", "title": "Authenticating with LDAP", "text": "<p>Users able to authenticate should already have an account created in TheHive local database.</p>"}, {"location": "thehive/administration/authentication/local/", "title": "Local Authentication", "text": ""}, {"location": "thehive/administration/authentication/local/#local-account", "title": "Local account", "text": "<p>This is the default behaviour of TheHive. The applications store usernames and password in a local database.</p>"}, {"location": "thehive/administration/authentication/local/#configuration", "title": "Configuration", "text": "<p>By default, no policy is activated for local accounts. Nevertheless, a password policy and blocking settings can be adjusted:</p> <ul> <li>A number of failed attempts to authenticate before a user be temporay blocked</li> <li>The related duration before unblock a user</li> </ul>"}, {"location": "thehive/administration/authentication/local/#password-policy", "title": "Password policy", "text": "<p>This options is disabled by default. When enabled following items can be configured: </p> <ul> <li>Minimum lenght of passwords</li> <li>Minimum number of lower cases characters included in the password</li> <li>Minimum number of upper cases characters included in the password</li> <li>Minimum number of digits included in the password</li> <li>Minimum number of special characters included in the password</li> <li>Allowing or disollowing the usage of usernames as passwords</li> </ul>"}, {"location": "thehive/administration/authentication/oauth2/", "title": "OAUTH2 Authentication", "text": ""}, {"location": "thehive/administration/authentication/oauth2/#oauth2-openid-connect", "title": "OAuth2 / OpenID-Connect", "text": ""}, {"location": "thehive/administration/authentication/oauth2/#introduction", "title": "Introduction", "text": "<p>OAuth2 and OpenID-Connect are widely used authentication protocols that enable secure and seamless user authentication. This article provides instructions on configuring TheHive to authenticate users using an external OAuth2 authentication server. By following this guide, you will be able to integrate various OAuth2 providers, such as Keycloak, Okta, Github, Microsoft 365, and Google, with TheHive.</p> <p></p>"}, {"location": "thehive/administration/authentication/oauth2/#configuration", "title": "Configuration", "text": "<p>To authenticate users using an external OAuth2 server, you need to specify the following configuration parameters:</p> Parameter Description Client ID Client ID in the OAuth2 server Client Secret Client Secret in the OAuth2 server TheHive Redirect URL The URL of TheHive OAuth2 page (<code>https://xxx/api/ssoLogin</code>) Authorization URL The URL of the OAuth2 server Token URL The Token URL of the OAuth2 server User Information URL The URL to get user information in the OAuth2 server List of Scope List of scopes Field that contains the ID of the user in user info The field that contains the ID of the user in user info <p> </p>"}, {"location": "thehive/administration/authentication/oauth2/#examples", "title": "Examples", "text": "KeycloakOktaGithubMicrosoft 365Google Parameter Value Client ID <code>CLIENT_ID</code> Client secret <code>CLIENT_SECRET</code> TheHive redirect URL https://THEHIVE_URL/api/ssoLogin Authorization URL http://KEYCLOAK/auth/realms/TENANT/protocol/openid-connect/auth Token URL http://KEYCLOAK/auth/realms/TENANT/protocol/openid-connect/token User information URL http://KEYCLOAK/auth/realms/TENANT/protocol/openid-connect/userinfo List of scope <code>[\"openid\", \"email\"]</code> Field that contains the id of the user in user info \"email\" Parameter Value Client ID <code>CLIENT_ID</code> Client secret <code>CLIENT_SECRET</code> TheHive redirect URL http://THEHIVE_URL/api/ssoLogin Authorization URL https://OKTA/oauth2/v1/authorize Token URL http://OKTA/oauth2/v1/token User information URL http://OKTA/oauth2/v1/userinfo List of scope <code>[\"openid\", \"email\"]</code> Field that contains the id of the user in user info \"email\" Parameter Value Client ID <code>CLIENT_ID</code> Client secret <code>CLIENT_SECRET</code> TheHive redirect URL https://THEHIVE_URL/api/ssoLogin Authorization URL https://github.com/login/oauth/authorize Token URL https://github.com/login/oauth/access_token User information URL https://api.github.com/user List of scope <code>[\"user\"]</code> Field that contains the id of the user in user info \"email\" <p>Note</p> <ul> <li><code>CLIENT_ID</code> and <code>CLIENT_SECRET</code> are created in the OAuth Apps section at https://github.com/settings/developers.</li> <li>this configuration requires that users set the Public email in their Public Profile on https://github.com/settings/profile.</li> </ul> Parameter Value Client ID <code>CLIENT_ID</code> Client secret <code>CLIENT_SECRET</code> TheHive redirect URL https://THEHIVE_URL/api/ssoLogin Authorization URL https://login.microsoftonline.com/TENANT/oauth2/v2.0/authorize Token URL https://login.microsoftonline.com/TENANT/oauth2/v2.0/token User information URL https://graph.microsoft.com/v1.0/me List of scope <code>[\"User.Read\"]</code> Field that contains the id of the user in user info \"mail\" <p>Note</p> <p>To create <code>CLIENT_ID</code>, <code>CLIENT_SECRET</code> and <code>TENANT</code>, register a new app at https://aad.portal.azure.com/#blade/Microsoft_AAD_IAM/ActiveDirectoryMenuBlade/RegisteredApps.</p> Parameter Value Client ID <code>CLIENT_ID</code> Client secret <code>CLIENT_SECRET</code> TheHive redirect URL https://THEHIVE_URL/api/ssoLogin Authorization URL https://accounts.google.com/o/oauth2/v2/auth Token URL https://oauth2.googleapis.com/token User information URL https://openidconnect.googleapis.com/v1/userinfo List of scope <code>[\"email\", \"profile\", \"openid\"]</code> Field that contains the id of the user in user info \"email\" <p>Note</p> <ul> <li><code>CLIENT_ID</code> and <code>CLIENT_SECRET</code> are created in the <code>_APIs &amp; Services_ &gt; _Credentials_</code> section of the GCP Console</li> <li>Instructions on how to create Oauth2 credentials at https://support.google.com/cloud/answer/6158849</li> <li>For the latest reference for Google auth URLs please check Google's .well-known/openid-configuration</li> </ul>"}, {"location": "thehive/administration/authentication/oauth2/#user-autocreation", "title": "User Autocreation", "text": "<p>To enable users to log in without prior manual creation, you can activate autocreation and specify the following options:</p> <ul> <li>Field that contains the name of the user in user info</li> <li>Field that contains the name of the organization in user info</li> <li>Default organization applied to new users</li> <li>Default profile applied to new users</li> </ul> <p></p> <p> </p>"}, {"location": "thehive/administration/authentication/saml/", "title": "SAML Authentication", "text": ""}, {"location": "thehive/administration/authentication/saml/#saml", "title": "SAML", "text": "<p>TheHive supports SAMLv2.0 authentication providers.</p>"}, {"location": "thehive/administration/authentication/saml/#configuration", "title": "Configuration", "text": "<p>An SAML authentication provider accepts the following configuration parameters:</p> Parameter Description Name Give a name to the provider in TheHive Identity Provider metadata type Select how TheHive gathers configuration information: <code>xml</code> or `url Identity Provider metadata value Give the URL or the XML content with service information Login Name Indicate the name of the custom attribute containing the user login information Maximum authentication life time This value must match the value from the identity provider <p></p> <p></p> Configuration using XML content"}, {"location": "thehive/administration/authentication/saml/#using-several-providers", "title": "Using several providers", "text": "<p>Several providers can be configured. In this case, when a user tries to log in, TheHive queries each provider in the order listed. Queries stops when one replies with the authorization to log in.</p> <p></p> Using several providers"}, {"location": "thehive/administration/custom-fields/about-custom-fields/", "title": "About Custom Fields", "text": ""}, {"location": "thehive/administration/custom-fields/about-custom-fields/#about-custom-fields", "title": "About Custom Fields", "text": "<p>Custom fields let you add additional information to cases and alerts.</p> <p>By default, TheHive includes predefined fields for cases and alerts. To better suit your needs, you can create custom fields to tailor cases and alerts.</p> <p>This topic provides a general overview of custom field usage in TheHive.</p>"}, {"location": "thehive/administration/custom-fields/about-custom-fields/#use-cases", "title": "Use cases", "text": "<p>You can use custom fields to:</p> <ul> <li>Provide context to cases or alerts, such as the geographic location of an incident or its severity level</li> <li>Support organizational alignment by specifying the relevant business unit or team</li> <li>Enable integration with tools and feeders by including identifiers or other data from external systems, or linking directly to external system data</li> <li>Streamline processes by indicating internal classification levels</li> <li>Manage checklists to validate specific steps when handling a case or alert</li> <li>Enhance data analysis through tagging, for example, identifying incidents involving VIPs</li> </ul>"}, {"location": "thehive/administration/custom-fields/about-custom-fields/#types", "title": "Types", "text": "<p>You can define custom fields in the following formats:</p> <ul> <li>String: Text input</li> <li>Boolean: True/false values</li> <li>Integer: Whole numbers</li> <li>Float: Decimal numbers</li> <li>Date: Specific dates</li> <li>URL: Web links</li> </ul>"}, {"location": "thehive/administration/custom-fields/about-custom-fields/#permissions", "title": "Permissions", "text": "<p>Required permissions for managing custom fields</p> <p>Only users with an admin-type profile that has the <code>manageCustomField</code> permission can create, edit, or delete custom fields in TheHive.</p> <p>After creation, custom fields are automatically available to all users across your organizations, allowing them to add the fields to cases and alerts. You can configure these fields to be either optional or mandatory for analysts to complete.</p>"}, {"location": "thehive/administration/custom-fields/about-custom-fields/#next-steps", "title": "Next steps", "text": "<p>How to Create a Custom Field</p>"}, {"location": "thehive/administration/custom-fields/create-a-custom-field/", "title": "Create a Custom Field", "text": ""}, {"location": "thehive/administration/custom-fields/create-a-custom-field/#how-to-create-a-custom-field", "title": "How to Create a Custom Field", "text": "<p>This topic provides step-by-step instructions for creating a custom field in TheHive.</p> <p>Required permissions for managing custom fields</p> <p>Only users with an admin-type profile that has the <code>manageCustomField</code> permission can create, edit, or delete custom fields in TheHive.</p>"}, {"location": "thehive/administration/custom-fields/create-a-custom-field/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Entities management view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Custom fields tab.</p> <p></p> </li> <li> <p>Select .</p> </li> <li> <p>Enter the following information:</p> <p>Display name *</p> <p>Enter the name users will see when adding this custom field to their cases or alerts.</p> <p>Technical name *</p> <p>By default, the technical name is automatically generated from the display name, but you can adjust it if needed. Users don't see the technical name when adding a custom field, but it's used when accessing the custom field via the API.</p> <p>Description *</p> <p>Provide a description to help users understand and use this custom field appropriately.</p> <p>Group name *</p> <p>Choose an existing group name or type a new one to create a new group.</p> <p>Data type *</p> <p>Specify the type of data the custom field will contain:</p> <ul> <li>String: Text input</li> <li>Boolean: True/false values</li> <li>Integer: Whole numbers</li> <li>Float: Decimal numbers</li> <li>Date: Specific dates</li> <li>URL: Web links</li> </ul> <p>Predefined values</p> <p>For the string, integer, and float formats, you can define predefined values by entering each value on a separate line. If you choose to do this, users will only be able to select from the predefined values you specify.</p> <p>Turn on the Mandatory toggle to require users to enter a value in this custom field.</p> </li> <li> <p>Select Confirm custom field creation.</p> </li> </ol>"}, {"location": "thehive/administration/custom-fields/create-a-custom-field/#next-steps", "title": "Next steps", "text": "<ul> <li>Add Custom Fields</li> </ul>"}, {"location": "thehive/administration/organizations/about-organizations-sharing-rules/", "title": "About Organizations Sharing Rules", "text": ""}, {"location": "thehive/administration/organizations/about-organizations-sharing-rules/#about-organizations-sharing-rules", "title": "About Organizations Sharing Rules", "text": "<p>Sharing rules determine how cases, along with their tasks and observables, are shared with linked organizations.</p> <p>This topic explains how sharing rules work and interact.</p>"}, {"location": "thehive/administration/organizations/about-organizations-sharing-rules/#global-sharing-rules", "title": "Global sharing rules", "text": "<p>Required permissions for managing organizations</p> <ul> <li>Only users with an admin-type profile that has the <code>manageOrganisation</code> permission can create, link, or lock organizations in TheHive.  </li> <li>Only users with the <code>manageUser</code> permission can assign users to organizations in TheHive.</li> </ul> <p>Global sharing rules define how newly created cases and their related tasks and observables are shared at the organization level with linked organizations. The configuration determines whether this sharing occurs automatically.</p> <p>You must set global sharing rules:</p> <ul> <li>For cases when linking organizations</li> <li>For tasks and observables when creating an organization</li> </ul> <p>Managing sharing rules for existing cases</p> <p>Global sharing rules apply only to newly created cases. Existing cases and their related tasks and observables remain unaffected. To apply sharing rules to existing cases, you must configure them manually, one case at a time.</p>"}, {"location": "thehive/administration/organizations/about-organizations-sharing-rules/#local-sharing-rules", "title": "Local sharing rules", "text": "<p>Local sharing rules let you customize sharing settings with linked organizations for both new and existing cases, including their related tasks and observables. They override the global sharing rules set at the organization level when linking organizations and creating organizations.</p> <p>Local sharing rules are useful in the following scenarios:</p> <ul> <li>You have defined global sharing rules for newly created cases but want to apply the same rules to an existing case.</li> <li>You need to apply different sharing rules to one or more cases instead of following the global sharing rules.</li> </ul> <p>Required permissions for setting local sharing rules</p> <p>Only users with the <code>manageCase/update</code> and <code>manageShare</code> permissions can modify sharing rules of an existing case in TheHive.</p> <p>Follow these step-by-step instructions to see:</p> <ul> <li>How to set up local sharing rules for an existing case</li> <li>How to set up local sharing rules for a new case</li> </ul>"}, {"location": "thehive/administration/organizations/about-organizations-sharing-rules/#manual-sharing-of-tasks-and-observables-in-a-shared-case", "title": "Manual sharing of tasks and observables in a shared case", "text": "<p>You can manually share tasks and observables in a shared case. </p> <p>This is useful when task and observable sharing rules are set to manual, ensuring that users share only the relevant tasks and observables.</p> <p>Follow these step-by-step instructions to learn how to:</p> <ul> <li>Share a Task with Other Organizations</li> <li>Share an Observable with Other Organizations</li> </ul>"}, {"location": "thehive/administration/organizations/about-organizations-sharing-rules/#how-sharing-rules-work-together", "title": "How sharing rules work together", "text": "Cases \u2193 \\ Tasks and observables \u2192 manual autoShare default New cases aren't automatically shared. New cases aren't automatically shared, and neither are their tasks and observables. supervised New cases are automatically shared without their linked tasks and observables. New cases are automatically shared with their linked tasks and observables. notify New cases are automatically shared without their linked tasks and observables. New cases are automatically shared with their linked tasks and observables."}, {"location": "thehive/administration/organizations/about-organizations-sharing-rules/#next-steps", "title": "Next steps", "text": "<ul> <li>Link an Organization</li> <li>Share a Case</li> <li>Share a Task with Other Organizations</li> <li>Share an Observable with Other Organizations</li> </ul>"}, {"location": "thehive/administration/organizations/about-organizations/", "title": "About Organizations", "text": ""}, {"location": "thehive/administration/organizations/about-organizations/#about-organizations", "title": "About Organizations", "text": "<p>Organizations are the customers or tenants, such as separate divisions or business units, that use TheHive independently.</p>"}, {"location": "thehive/administration/organizations/about-organizations/#default-setup", "title": "Default setup", "text": "<p>TheHive includes a default Admin organization for users with administrator-type permissions. This organization manages global configurations, such as organizations, users, entities, and platform settings. </p> <p>Non-Admin organizations manage operations on cases, alerts, and tasks.</p> <p>By default, organizations are isolated and can't see or share data with each other. To enable data sharing, users with the necessary permissions must link organizations.</p>"}, {"location": "thehive/administration/organizations/about-organizations/#organizations-and-users", "title": "Organizations and users", "text": "<p>You can assign a user to one or more organizations.</p> <p>When assigning a user to an organization, the system suggests only permission profiles that match the organization's type (Admin or Non-Admin).</p>"}, {"location": "thehive/administration/organizations/about-organizations/#permissions", "title": "Permissions", "text": "<p>Required permissions for managing organizations</p> <ul> <li>Only users with an admin-type profile that has the <code>manageOrganisation</code> permission can create, link, or lock organizations in TheHive.  </li> <li>Only users with the <code>manageUser</code> permission can assign users to organizations in TheHive.</li> </ul>"}, {"location": "thehive/administration/organizations/about-organizations/#next-steps", "title": "Next steps", "text": "<ul> <li>Create an Organization</li> <li>Add Users to an Organization</li> <li>Link an Organization</li> <li>Lock an Organization</li> </ul>"}, {"location": "thehive/administration/organizations/add-users-to-an-organization/", "title": "Add Users to an Organization", "text": ""}, {"location": "thehive/administration/organizations/add-users-to-an-organization/#how-to-add-users-to-an-organization", "title": "How to Add Users to an Organization", "text": "<p>This topic provides step-by-step instructions for adding new and existing users to an organization in TheHive.</p> <p>Required permissions for managing organizations</p> <ul> <li>Only users with an admin-type profile that has the <code>manageOrganisation</code> permission can create, link, or lock organizations in TheHive.  </li> <li>Only users with the <code>manageUser</code> permission can assign users to organizations in TheHive.</li> </ul>"}, {"location": "thehive/administration/organizations/add-users-to-an-organization/#add-an-existing-user-to-an-organization", "title": "Add an existing user to an organization", "text": "<ol> <li> <p>Go to the Users view from the sidebar menu.</p> <p></p> </li> <li> <p>Locate the user you're looking for, hover over it, and select .</p> </li> <li> <p>In the drawer, go to the Organizations section, select the organizations to assign the user to, and choose their permission profile.</p> </li> <li> <p>Select Confirm.</p> </li> </ol>"}, {"location": "thehive/administration/organizations/add-users-to-an-organization/#add-a-new-user-to-an-organization", "title": "Add a new user to an organization", "text": "<ol> <li> <p>Go to the Organizations view from the sidebar menu.</p> <p> </p> </li> <li> <p>Select the organization to add the user to, then select . Alternatively, hover over the organization, select , and select Add in the Users section.</p> </li> <li> <p>In the Adding a user drawer, enter:</p> <p>Type *</p> <p>The user type you want to create.</p> <p>Pick an option from the dropdown list:      - Normal: Allows the user to access TheHive through the user interface.     - Service: Allows the user to access TheHive through the API.</p> <p>Login *</p> <p>The login used for the user to sign in. It can be an email address or another identifier, depending on your TheHive configuration.</p> <p>Name *</p> <p>The user's display name.</p> <p>Profile *</p> <p>Pick a permission profile for the user from the dropdown list.</p> </li> <li> <p>Select Confirm, or Save and add another if you want to add another new user.</p> </li> <li> <p>In the users list, hover over the user you just created and select .</p> </li> <li> <p>Optional: Select the default user image to modify it, then upload a new image.</p> </li> <li> <p>Optional: If the login isn't an email, add an email address in the Email field.</p> </li> <li> <p>Optional: If you set the user's type to Service, select Create to generate an API key.</p> </li> <li> <p>Select Set a new password to create a default password for the user.</p> </li> <li> <p>Select Confirm.</p> </li> </ol>"}, {"location": "thehive/administration/organizations/add-users-to-an-organization/#next-steps", "title": "Next steps", "text": "<ul> <li>Link an Organization</li> <li>Lock an Organization</li> </ul>"}, {"location": "thehive/administration/organizations/create-an-organization/", "title": "Create an Organization", "text": ""}, {"location": "thehive/administration/organizations/create-an-organization/#how-to-create-an-organization", "title": "How to Create an Organization", "text": "<p>This topic provides step-by-step instructions for creating an organization in TheHive.</p> <p>License</p> <p>The number of organizations you can create depends on your TheHive license.</p> <p>Required permissions for managing organizations</p> <ul> <li>Only users with an admin-type profile that has the <code>manageOrganisation</code> permission can create, link, or lock organizations in TheHive.  </li> <li>Only users with the <code>manageUser</code> permission can assign users to organizations in TheHive.</li> </ul>"}, {"location": "thehive/administration/organizations/create-an-organization/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organizations view from the sidebar menu.</p> <p></p> </li> <li> <p>Select .</p> </li> <li> <p>In the Adding an organization drawer, enter:</p> <p>Name *</p> <p>The name of your new organization.</p> <p>Description *</p> <p>The description of your new organization.</p> <p>Tasks sharing rule *</p> <p>How tasks linked to a case are handled when the case is shared with another organization.</p> <p>Pick an option from the dropdown list:     - manual (default): Tasks aren't shared automatically. Users must share them manually.     - autoShare: Tasks are shared automatically.</p> <p>Observables sharing rule *</p> <p>How observables linked to a case are handled when the case is shared with another organization.</p> <p>Pick an option from the dropdown list:     - manual (default): Observables aren't shared automatically. Users must share them manually.     - autoShare: Observables are shared automatically.</p> <p>To learn more about how sharing rules function and interact, refer to About Organizations Sharing Rules.</p> </li> <li> <p>Select Confirm.</p> </li> <li> <p>Optional: In the Organizations view, locate your new organization, hover over it, select , select the default organization logo to modify it, and upload an image to set it as the new logo for your organization.</p> </li> </ol>"}, {"location": "thehive/administration/organizations/create-an-organization/#next-steps", "title": "Next steps", "text": "<ul> <li>Add Users to an Organization</li> <li>Link an Organization</li> <li>Lock an Organization</li> </ul>"}, {"location": "thehive/administration/organizations/link-an-organization/", "title": "Link an Organization", "text": ""}, {"location": "thehive/administration/organizations/link-an-organization/#how-to-link-an-organization", "title": "How to Link an Organization", "text": "<p>This topic provides step-by-step instructions for linking an organization to another in TheHive.</p> <p>By default, organizations in TheHive aren't linked. Each organization operates independently and can't access others on the instance.</p> <p>Link organizations to enable data sharing and define the applicable sharing rules.</p> <p>Required permissions for managing organizations</p> <ul> <li>Only users with an admin-type profile that has the <code>manageOrganisation</code> permission can create, link, or lock organizations in TheHive.  </li> <li>Only users with the <code>manageUser</code> permission can assign users to organizations in TheHive.</li> </ul>"}, {"location": "thehive/administration/organizations/link-an-organization/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organizations view</p> <p></p> </li> <li> <p>Select the organization to link to another, then select Linked organizations. Alternatively, hover over the organization and select .</p> <p></p> </li> <li> <p>Select Manage linked organizations.</p> </li> <li> <p>Select the organizations you want to link to your organization.</p> </li> <li> <p>Choose the case-sharing rules between the organizations in both directions using the Choose a link type dropdown lists.</p> <p>Options are the followings: - default: Cases aren't automatically shared with the other organization. Users must share them manually. - supervised: Cases are automatically shared with the other organization with an analyst-type permission profile, which grants both read and write access to cases. - notify: Cases are automatically shared with the other organization with a read-only permission profile.</p> <p>To learn more about how sharing rules function and interact, refer to About Organizations Sharing Rules.</p> </li> <li> <p>Select Confirm.</p> </li> </ol>"}, {"location": "thehive/administration/organizations/link-an-organization/#next-steps", "title": "Next steps", "text": "<ul> <li>Share a Case with Other Organizations</li> <li>Share a Task with Other Organizations</li> <li>Share an Observable with Other Organizations</li> </ul>"}, {"location": "thehive/administration/organizations/lock-an-organization/", "title": "Lock an Organization", "text": ""}, {"location": "thehive/administration/organizations/lock-an-organization/#how-to-lock-an-organization", "title": "How to Lock an Organization", "text": "<p>This topic provides step-by-step instructions for locking an organization in TheHive.</p> <p>Locking an organization is useful when you want to prevent users from logging in with that organization.</p> <p>Deleting an organization</p> <p>In TheHive, users can't delete organizations to ensure database integrity and safety.</p> <p>Required permissions for managing organizations</p> <ul> <li>Only users with an admin-type profile that has the <code>manageOrganisation</code> permission can create, link, or lock organizations in TheHive.  </li> <li>Only users with the <code>manageUser</code> permission can assign users to organizations in TheHive.</li> </ul>"}, {"location": "thehive/administration/organizations/lock-an-organization/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organizations view.</p> <p></p> </li> <li> <p>Select the checkbox on the left of the organization to lock and select . Alternatively, hover over the organization, select , and turn on the Locked toggle to lock the organization.</p> <p></p> </li> <li> <p>Select OK or Confirm.</p> </li> </ol>"}, {"location": "thehive/administration/organizations/lock-an-organization/#next-steps", "title": "Next steps", "text": "<ul> <li>Create an Organization</li> <li>Link an Organization</li> <li>Add Users to an Organization</li> </ul>"}, {"location": "thehive/configuration/akka/", "title": "Akka Configuration", "text": ""}, {"location": "thehive/configuration/akka/#akka-configuration", "title": "Akka Configuration", "text": "<p>Note</p> <p>This documentation applies to TheHive versions earlier than 5.4. For version 5.4 and later, please refer to the Pekko Configuration.</p> <p>Akka is a powerful toolkit designed for building highly concurrent, distributed, and resilient message-driven applications in Java and Scala. </p> <p>https://akka.io/</p> <p>Akka plays a crucial role in enabling multiple nodes of TheHive to communicate with each other seamlessly, thereby enhancing the overall user experience. </p>"}, {"location": "thehive/configuration/akka/#basic-configuration", "title": "Basic Configuration", "text": "<p>For a reliable cluster setup, it's essential to have a minimum of three nodes for TheHive application. Each node should be configured with Akka as outlined below: </p> <pre><code>## Akka server\nakka {\n  cluster.enable = on\n  actor {\n    provider = cluster\n  }\n  remote.artery {\n    canonical {\n      hostname = \"&lt;HOSTNAME OR IP_ADDRESS&gt;\"\n      port = 2551\n    }\n  }\n# seed node list contains at least one active node\n  cluster.seed-nodes = [ \"akka://application@HOSTNAME1:2551\", \"akka://application@HOSTNAME2:2551\", \"akka://application@HOSTNAME3:2551\" ]\n}\n</code></pre> <p>In this configuration:</p> <ul> <li><code>remote.artery.hostname</code> should be set to the hostname or IP address of the node.</li> <li><code>cluster.seed-nodes</code> should contain the same list of Akka nodes, ensuring consistency across all nodes.</li> </ul> <p>Configuration of a Cluster with 3 Nodes</p> Node 1Node 2Node 3 <p>Akka configuration for Node 1:</p> <pre><code>akka {\n    cluster.enable = on\n    actor {\n      provider = cluster\n    }\n    remote.artery {\n      canonical {\n          hostname = \"10.1.2.1\"\n          port = 2551\n      }\n    }\n    # seed node list contains at least one active node\n    cluster.seed-nodes = [ \"akka://application@10.1.2.1:2551\", \"akka://application@10.1.2.2:2551\", \"akka://application@10.1.2.3:2551\" ]\n}\n</code></pre> <p>Akka configuration for Node 2:</p> <pre><code>akka {\n    cluster.enable = on\n    actor {\n    provider = cluster\n    }\n    remote.artery {\n    canonical {\n        hostname = \"10.1.2.2\"\n        port = 2551\n    }\n    }\n    # seed node list contains at least one active node\n    cluster.seed-nodes = [ \"akka://application@10.1.2.1:2551\", \"akka://application@10.1.2.2:2551\", \"akka://application@10.1.2.3:2551\" ]\n}\n</code></pre> <p>Akka configuration for Node 3:</p> <pre><code>akka {\n    cluster.enable = on\n    actor {\n    provider = cluster\n    }\n    remote.artery {\n    canonical {\n        hostname = \"10.1.2.3\"\n        port = 2551\n    }\n    }\n    # seed node list contains at least one active node\n    cluster.seed-nodes = [ \"akka://application@10.1.2.1:2551\", \"akka://application@10.1.2.2:2551\", \"akka://application@10.1.2.3:2551\" ]\n}\n</code></pre>"}, {"location": "thehive/configuration/akka/#ssltls-support", "title": "SSL/TLS Support", "text": "<p>Akka offers robust support for SSL/TLS encryption, guaranteeing secure communication between nodes. Below, you'll find a standard configuration to enable SSL/TLS support:</p> <pre><code>## Akka server\nakka {\n  cluster.enable = on\n  actor {\n    provider = cluster\n  }\n  remote.artery {\n    transport = tls-tcp\n    canonical {\n      hostname = \"&lt;HOSTNAME OR IP_ADDRESS&gt;\"\n      port = 2551\n    }\n\n    ssl.config-ssl-engine {\n      key-store = \"&lt;PATH TO KEYSTORE&gt;\"\n      trust-store = \"&lt;PATH TO TRUSTSTORE&gt;\"\n\n      key-store-password = \"chamgeme\"\n      key-password = \"chamgeme\"\n      trust-store-password = \"chamgeme\"\n\n      protocol = \"TLSv1.2\"\n    }\n  }\n# seed node list contains at least one active node\n  cluster.seed-nodes = [ \"akka://application@HOSTNAME1:2551\", \"akka://application@HOSTNAME2:2551\", \"akka://application@HOSTNAME3:2551\" ]\n}\n</code></pre> <p>Note</p> <p>Note that <code>akka.remote.artery.transport</code> has changed and <code>akka.ssl.config-ssl-engine</code> needs to be configured.</p> <p>For more details, refer to: Akka Remoting with Artery - Remote Security</p> <p>Certificate Considerations</p> <p>Ensure you use your internal PKI (Public Key Infrastructure) or keytool commands to generate certificates.</p> <p>For detailed instructions, see: Using keytool for Certificate Generation</p> <p>Your server certificates should include the following KeyUsage and ExtendedkeyUsage extensions for proper functioning:</p> <ul> <li>KeyUsage extensions<ul> <li><code>nonRepudiation</code></li> <li><code>dataEncipherment</code></li> <li><code>digitalSignature</code></li> <li><code>keyEncipherment</code></li> </ul> </li> <li>ExtendedkeyUsage extensions<ul> <li><code>serverAuth</code></li> <li><code>clientAuth</code></li> </ul> </li> </ul> <p>Akka Configuration with SSL/TLS for Node 1</p> <pre><code>## Akka server\nakka {\n  cluster.enable = on\n  actor {\n    provider = cluster\n  }\n  remote.artery {\n    transport = tls-tcp\n    canonical {\n      hostname = \"10.1.2.1\"\n      port = 2551\n    }\n\n    ssl.config-ssl-engine {\n      key-store = \"/etc/thehive/application.conf.d/certs/10.1.2.1.jks\"\n      trust-store = \"/etc/thehive/application.conf.d/certs/internal_ca.jks\"\n\n      key-store-password = \"chamgeme\"\n      key-password = \"chamgeme\"\n      trust-store-password = \"chamgeme\"\n\n      protocol = \"TLSv1.2\"\n    }\n  }\n# seed node list contains at least one active node\n  cluster.seed-nodes = [ \"akka://application@10.1.2.1:2551\", \"akka://application@10.1.2.2:2551\", \"akka://application@10.1.2.3:2551\" ]\n}\n</code></pre> <p>Ensure to apply the same principle for configuring other nodes, and remember to restart all services afterward.</p> <p> </p>"}, {"location": "thehive/configuration/connectors/", "title": "Connectors Configuration", "text": ""}, {"location": "thehive/configuration/connectors/#thehive-connectors", "title": "TheHive Connectors", "text": "<p>TheHive comes with built-in connectors to seamlessly integrate with Cortex and MISP. </p> <p>By default, these connectors are enabled in the /etc/thehive/application.conf configuration file. However, if you are not using one or both of these integrations, you can easily disable them by commenting out the relevant line(s):</p> /etc/thehive/application.conf<pre><code>[..]\nscalligraph.modules += org.thp.thehive.connector.cortex.CortexModule\n# scalligraph.modules += org.thp.thehive.connector.misp.MispModule  # (1)\n</code></pre> <ol> <li>The line for the MISP connector has been commented out, indicating that it is disabled.</li> </ol> <p>Updating this configuration file requires restarting TheHive service for the changes to take effect.</p> <p> </p>"}, {"location": "thehive/configuration/database/", "title": "Database & Index Configuration", "text": ""}, {"location": "thehive/configuration/database/#database-and-index-configuration", "title": "Database and Index Configuration", "text": "<p>TheHive utilizes Cassandra and Elasticsearch databases for data management and indexing purposes. Below outlines the configuration options available:</p>"}, {"location": "thehive/configuration/database/#basic-configuration", "title": "Basic Configuration", "text": "<p>A typical database configuration for TheHive is structured as follows:</p> <pre><code>## Database configuration\ndb {\n  provider = janusgraph\n  janusgraph {\n    ## Storage configuration\n    storage {\n      backend = cql\n      hostname = [\"IP_ADDRESS\"]\n      cql {\n        cluster-name = thp\n        keyspace = thehive\n      }\n    }\n    ## Index configuration\n    index.search {\n      backend = elasticsearch\n      hostname = [\"127.0.0.1\"]\n      index-name = thehive\n    }\n  }\n}\n</code></pre> <p>This configuration specifies the following components:</p> <p>Database Provider: </p> <ul> <li>The database provider is set to JanusGraph, a distributed graph database.</li> </ul> <p>Storage Configuration:</p> <ul> <li> <p>Backend: Cassandra is specified as the backend storage system.</p> </li> <li> <p>Hostname: The IP address of the Cassandra cluster is provided.</p> </li> <li> <p>Cluster Name: The name of the Cassandra cluster is set to 'thp'.</p> </li> <li> <p>Keyspace: The keyspace within Cassandra where TheHive data will be stored is named 'thehive'.</p> </li> </ul> <p>Index Configuration:</p> <ul> <li> <p>Backend: Elasticsearch is designated as the backend for indexing.</p> </li> <li> <p>Hostname: The IP address of the Elasticsearch instance is set to '127.0.0.1'.</p> </li> <li> <p>Index Name: The index name within Elasticsearch for TheHive is specified as 'thehive'.</p> </li> </ul>"}, {"location": "thehive/configuration/database/#list-of-parameters", "title": "List of Parameters", "text": "Parameter Type Description <code>provider</code> string Provider name. Default: <code>janusgraph.</code> <code>storage</code> dict Storage configuration. <code>storage.backend</code> string Storage type. Can be <code>cql</code> or <code>berkeleyje</code>. <code>storage.hostname</code> list of string List of IP addresses or hostnames when using the <code>cql</code> backend. <code>storage.directory</code> string Local path for data when using the berkeleyje backend. <code>storage.username</code> string Account username with the cql backend if Cassandra authentication is configured. <code>storage.password</code> string Account password with the cql backend if Cassandra authentication is configured. <code>storage.port</code> integer Port number with the cql backend (9042 by default). Change this if using an alternate port or a dedicated port number when using SSL with Cassandra. <code>storage.cql</code> dict Configuration for the cql backend if used. <code>storage.cql.cluster-name</code> string Name of the cluster used in the configuration of Apache Cassandra. <code>storage.cql.keyspace</code> string Keyspace name used to store TheHive data in Apache Cassandra. <code>storage.cql.ssl.enabled</code> boolean false by default. Set it to true if SSL is used with Cassandra. <code>storage.cql.ssl.truststore.location</code> string Path to the truststore. Specify it when using SSL with Cassandra. <code>storage.cql.ssl.password</code> string Password to access the truststore. <code>storage.cql.ssl.client-authentication-enabled</code> boolean Enables the use of a client key to authenticate with Cassandra. <code>storage.cql.ssl.keystore.location</code> string Path to the keystore. Specify it when using SSL and client authentication with Cassandra. <code>storage.cql.ssl.keystore.keypassword</code> string Password to access the key in the keystore. <code>storage.cql.ssl.truststore.storepassword</code> string Password to access the keystore. <code>index.search</code> dict Configuration for indexes. <code>index.search.backend</code> string Index engine. Default: elasticsearch <code>index.search.directory</code> string Path to the folder where indexes should be stored when using the elasticsearch engine. <code>index.search.hostname</code> list of string List of IP addresses or hostnames when using the elasticsearch engine. <code>index.search.index-name</code> string Name of index when using the elasticsearch engine. <code>index.search.elasticsearch.http.auth.type: basic</code> string basic is the only possible value. <code>index.search.elasticsearch.http.auth.basic.username</code> string Username account on Elasticsearch. <code>index.search.elasticsearch.http.auth.basic.password</code> string Password of the account on Elasticsearch. <code>index.search.elasticsearch.ssl.enabled</code> boolean Enable SSL (true/false). <code>index.search.elasticsearch.ssl.truststore.location</code> string Location of the truststore. <code>index.search.elasticsearch.ssl.truststore.password</code> string Password of the truststore. <code>index.search.elasticsearch.ssl.keystore.location</code> string Location of the keystore for client authentication. <code>index.search.elasticsearch.ssl.keystore.storepassword</code> string Password of the keystore. <code>index.search.elasticsearch.ssl.keystore.keypassword</code> string Password of the client certificate. <code>index.search.elasticsearch.ssl.disable-hostname-verification</code> boolean Disable SSL verification (true/false). <code>index.search.elasticsearch.ssl.allow-self-signed-certificates</code> boolean Allow self-signed certificates (true/false). <p>The initial start, or first start after configuring indexes, might take some time if the database contains a large amount of data. This time is due to the index creation process.</p> <p>For more detailed information on configuring Elasticsearch connection, refer to the official JanusGraph documentation.</p>"}, {"location": "thehive/configuration/database/#use-cases", "title": "Use Cases", "text": "<p>The database and index engine configurations can vary depending on the use case and target setup.</p> Standalone Server with Cassandra &amp; Elasticsearch <p>To set up TheHive on a standalone server with Cassandra and Elasticsearch:</p> <ol> <li>Install a Cassandra server locally.</li> <li>Install Elasticsearch.</li> <li> <p>Configure TheHive with the following settings:</p> <p><code>hocon   ## Database Configuration   db {     provider = janusgraph     janusgraph {       ## Storage configuration       storage {         backend = cql         hostname = [\"127.0.0.1\"]         ## Cassandra authentication (if configured)         username = \"thehive_account\"         password = \"cassandra_password\"         cql {           cluster-name = thp           keyspace = thehive         }       }       ## Index configuration       index.search {         backend = elasticsearch         hostname = [\"127.0.0.1\"]         index-name = thehive       }     }</code></p> </li> </ol> Cluster with Cassandra &amp; Elasticsearch <p>To deploy TheHive on a cluster with Cassandra and Elasticsearch:</p> <ol> <li>Install a cluster of Cassandra servers.</li> <li>Set up access to an Elasticsearch server.</li> <li> <p>Configure TheHive with the following settings:</p> <pre><code>## Database Configuration\ndb {\n  provider = janusgraph\n  janusgraph {\n    ## Storage configuration\n    storage {\n      backend = cql\n      hostname = [\"10.1.2.1\", \"10.1.2.2\", \"10.1.2.3\"]\n      ## Cassandra authentication (if configured)\n      username = \"thehive_account\"\n      password = \"cassandra_password\"\n      cql {\n        cluster-name = thp\n        keyspace = thehive\n      }\n    }\n    ## Index configuration\n    index {\n      search {\n        backend  = elasticsearch\n        hostname  = [\"10.1.2.5\"]\n        index-name  = thehive\n        elasticsearch {\n          http {\n            auth {\n              type = basic\n              basic {\n                username = httpuser\n                password = httppassword\n              }\n            }\n          }\n          ssl {\n            enabled = true\n            truststore {\n              location = /path/to/your/truststore.jks\n              password = truststorepwd\n            }\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre> </li> </ol> <p>Warning</p> <p>In this configuration, all TheHive nodes should have the same configuration.</p> <p>Elasticsearch configuration should use the default value for <code>script.allowed_types</code>, or contain the following configuration line = </p> <pre><code>script.allowed_types: inline,stored\n</code></pre> <p> </p>"}, {"location": "thehive/configuration/file-storage/", "title": "File Storage Configuration", "text": ""}, {"location": "thehive/configuration/file-storage/#file-storage-configuration", "title": "File Storage Configuration", "text": "<p>TheHive offers flexible configurations for file storage, accommodating both local and distributed filesystem setups.</p> Local or NFS <p>To configure TheHive to use a local or NFS (Network File System) storage:</p> <pre><code>1. Create a dedicated folder named files, ensuring it is owned by the user and group thehive:thehive.\n\n    ```bash\n    mkdir /opt/thp/thehive/files\n    chown thehive:thehive /opt/thp/thehive/files\n    ```\n\n2. Configure TheHive accordingly in the YAML configuration file:\n\n    ```yaml\n    ## Attachment storage configuration\n    storage {\n      ## Local filesystem\n      provider: localfs\n      localfs {\n        location: /opt/thp/thehive/files\n      }\n    }\n    ```\n</code></pre> Min.IO <p>For Min.IO integration with TheHive, follow these steps:</p> <pre><code>1. Install a Min.IO cluster. Follow [**these step-by-step**](../installation/3-node-cluster.md#minio-setup) instructions.\n2. Configure each node of TheHive accordingly:\n\n    ```yaml title=\"/etc/thehive/application.conf with TheHive 5.0.x\"\n    ## Attachment storage configuration\n    storage {\n      provider: s3\n      s3 {\n        bucket = \"thehive\"\n        readTimeout = 1 minute\n        writeTimeout = 1 minute\n        chunkSize = 1 MB\n        endpoint = \"http://&lt;IP_MINIO_1&gt;:9100\"\n        accessKey = \"thehive\"\n        secretKey = \"password\"\n        region = \"us-east-1\"\n      }\n    }\n    alpakka.s3.access-style = path\n    ```\n\n    ```yaml title=\"/etc/thehive/application.conf with TheHive &gt; 5.0\"\n    storage {\n      provider: s3\n      s3 {\n        bucket = \"thehive\"\n        readTimeout = 1 minute\n        writeTimeout = 1 minute\n        chunkSize = 1 MB\n        endpoint = \"http://&lt;IP_MINIO_1&gt;:9100\"\n        accessKey = \"thehive\"\n        aws.credentials.provider = \"static\"\n        aws.credentials.secret-access-key = \"password\"\n        access-style = path\n        aws.region.provider = \"static\"\n        aws.region.default-region = \"us-east-1\"\n      }\n    }\n    ```\n\n  Note:\n\n  - The configuration remains backward compatible.\n\n  - The default region is us-east-1, but it's optional if not specified in the MinIO configuration.\n</code></pre> <p> </p>"}, {"location": "thehive/configuration/gdpr/", "title": "General Data Protection Regulation (GDPR)", "text": ""}, {"location": "thehive/configuration/gdpr/#gdpr-compliance-in-thehive-5x", "title": "GDPR Compliance in TheHive 5.x", "text": "<p>TheHive includes a specialized feature for managing data retention policies within the database. By default, this feature is not enabled and must be configured based on your organization's GDPR compliance needs.</p> <p>Info</p> <p>This feature is exclusively available with TheHive 5.x Platinum plan.</p>"}, {"location": "thehive/configuration/gdpr/#strategies", "title": "Strategies", "text": "<p>There are two primary strategies available:</p> <ul> <li>Replace Sensitive Values with <code>&lt;redacted&gt;</code></li> <li>Delete Data</li> </ul> <p> </p>"}, {"location": "thehive/configuration/gdpr/#replace-sensitive-values-with-redacted", "title": "Replace Sensitive Values with <code>&lt;redacted&gt;</code>", "text": "<p>Under this strategy, sensitive information is redacted from specific fields within TheHive, including:</p> <p> </p> <p>For cases, the following fields are redacted:</p> <ul> <li><code>summary</code> and <code>message</code> of the case</li> <li><code>message</code> of comments</li> <li><code>message</code> in task logs</li> <li><code>message</code> of observables, for datatypes selected and filled in the <code>gdpr.dataTypesToDelete</code> configuration property</li> <li><code>content</code> of pages</li> <li><code>description</code> of procedures in TTPs</li> </ul> <p> </p> <p>For alerts, the following fields are redacted:</p> <ul> <li><code>message</code> of the alert</li> <li><code>message</code> of observables (<code>gdpr.dataTypesToDelete</code> configuration property)</li> <li><code>description</code> of procedures (TTP)</li> </ul> <p> </p> <p>For audits:</p> <ul> <li>the field <code>details</code> is redacted</li> </ul> <p> </p>"}, {"location": "thehive/configuration/gdpr/#delete-data", "title": "Delete Data", "text": "<p>Selecting the <code>delete</code> strategy will permanently remove the following components:</p> <ul> <li>Cases and associated components (tasks, task logs, procedures, comments, pages, custom events in timelines, custom field values, and observables)</li> <li>Alerts and associated components (procedures, comments, custom field values, and observables)</li> <li>Audits</li> </ul>"}, {"location": "thehive/configuration/gdpr/#retention", "title": "Retention", "text": "<p>The <code>retentionPeriod</code> parameter specifies the minimum age of data subject to deletion or redaction. The GDPR process is applied to data older than this specified period, calculated based on the last update date (or creation date if never updated). The format for <code>retentionPeriod</code> supports various time units:</p> <ul> <li>day:         <code>d</code>, <code>day</code></li> <li>hour:        <code>h</code>, <code>hr</code>, <code>hour</code></li> <li>minute:      <code>m</code>, <code>min</code>, <code>minute</code></li> <li>second:      <code>s</code>, <code>sec</code>, <code>second</code></li> <li>millisecond: <code>ms</code>, <code>milli</code>, <code>millisecond</code></li> </ul> <p>For example, 365 days denotes a retention period of 1 year.</p>"}, {"location": "thehive/configuration/gdpr/#configuration", "title": "Configuration", "text": "<p>To enable GDPR compliance, follow these steps:</p> <ol> <li>Update the configuration file /etc/thehive/application.conf with the following settings:</li> </ol> <pre><code>gdpr {\n    enabled = true\n\n    ## Format http://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html\n    ## Every Sunday at 02:30\n\n    schedule = \"0 30 2 ? * SUN\"\n\n    ## Possible GDPR strategies:\n    ##   delete: remove the documents\n    ##   redact: replace sensitive values by \"&lt;redacted&gt;\" (cf. dataTypesToDelete)\n\n    strategy = \"delete\"\n\n    ## if the strategy is \"redacted\", the observable with dataType in \n    ## \"dataTypesToDelete\" will be removed\n    ## for other observables, message will be \"&lt;redacted&gt;\", not the data\n    ## Uncomment following line to select datatypes\n\n    # dataTypesToDelete = [] ## [\"ip\", \"domain\"]\n\n    ## only documents older than the \"retentionPeriod\" will be processed\n\n    retentionPeriod = 730 days # 2 years\n\n    ## Advanced parameters (should not be modified)\n\n    jobTimeout = 24 days ## maximum time the job is executed\n    batchSizeCase = 5     ## how many cases is processed per transaction\n    batchSizeAlert = 10   ## how many cases is processed per transaction\n    batchSizeAudit = 100  ## how many cases is processed per transaction\n}\n</code></pre> <ol> <li> <p>Save the changes to the configuration file.</p> </li> <li> <p>Restart TheHive application to apply the new settings.</p> </li> </ol> <p>By following these steps, you can effectively implement GDPR-compliant data retention policies within TheHive 5.x. Adjust the configuration parameters as per your organization's specific requirements and compliance standards.</p> <p> </p>"}, {"location": "thehive/configuration/logs/", "title": "Logs Configuration", "text": ""}, {"location": "thehive/configuration/logs/#logs-configuration", "title": "Logs Configuration", "text": "<p>TheHive utilizes logback for logging purposes, allowing users to monitor the running process effectively. The logging settings are managed through the configuration file located at <code>/etc/thehive/logback.xml</code>. Changes made to this file require a service reload to take effect.</p> <p>By default, logs are stored in <code>/var/log/thehive/</code>, with the most recent log file named application.log, while older files are compressed and stored as <code>application.%i.log.zip</code>.</p>"}, {"location": "thehive/configuration/logs/#adjusting-log-levels", "title": "Adjusting Log Levels", "text": "<p>Logback offers various log levels to control the amount of information logged. To increase or decrease the log level: </p> <p>Update the root level to DEBUG or TRACE to log more information:</p> logback.xml<pre><code>    &lt;!-- ... --&gt;\n    &lt;root level=\"DEBUG\"&gt;\n        &lt;!-- ... --&gt;\n    &lt;/root&gt;\n</code></pre> <p>Alternatively, adjust the log level for specific loggers:</p> logback.xml<pre><code>    &lt;logger name=\"org.thp\" level=\"DEBUG\"/&gt;\n</code></pre> <p>You have the option to select from the following additional log levels: WARN, ERROR, or OFF.</p>"}, {"location": "thehive/configuration/logs/#docker-logs-configuration", "title": "Docker Logs Configuration", "text": "<p>In a Docker container, TheHive logs to stdout and <code>/var/log/thehive/application.log</code> by default. To customize this behavior, mount your own logback file to <code>/etc/thehive/logback.xml</code>.</p>"}, {"location": "thehive/configuration/logs/#debugging-logback-configuration", "title": "Debugging Logback Configuration", "text": "<p>To troubleshoot logback configuration issues, set the debug flag to true in logback.xml:</p> logback.xml<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;configuration debug=\"true\"&gt;\n</code></pre> <p>This will log the logback configuration in the console during application startup.</p>"}, {"location": "thehive/configuration/logs/#creating-an-access-log", "title": "Creating an Access Log", "text": "<p>To redirect certain logs from the application, such as access logs, modify the logback configuration. Here's an example configuration for redirecting access logs to a file named access.log using a rolling file strategy:</p> <p>To add this into your configuration, duplicate the definitions of <code>appender</code> and <code>logger</code> as demonstrated below.</p> logback.xml<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;configuration debug=\"false\"&gt;\n\n    &lt;!-- ... other appenders and settings --&gt;\n\n    &lt;appender name=\"ACCESSFILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;\n        &lt;file&gt;/var/log/thehive/access.log&lt;/file&gt;\n        &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.FixedWindowRollingPolicy\"&gt;\n            &lt;fileNamePattern&gt;/var/log/thehive/access.%i.log.zip&lt;/fileNamePattern&gt;\n            &lt;minIndex&gt;1&lt;/minIndex&gt;\n            &lt;maxIndex&gt;10&lt;/maxIndex&gt;\n        &lt;/rollingPolicy&gt;\n        &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt;\n            &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt;\n        &lt;/triggeringPolicy&gt;\n\n        &lt;encoder&gt;\n            &lt;pattern&gt;%date [%level] from %logger [%traceID] %message%n%xException&lt;/pattern&gt;\n        &lt;/encoder&gt;\n    &lt;/appender&gt;\n\n    &lt;appender name=\"ASYNCACCESSFILE\" class=\"ch.qos.logback.classic.AsyncAppender\"&gt;\n        &lt;appender-ref ref=\"ACCESSFILE\"/&gt;\n    &lt;/appender&gt;\n\n    &lt;logger name=\"org.thp.scalligraph.AccessLogFilter\"&gt;\n        &lt;appender-ref ref=\"ASYNCACCESSFILE\" /&gt;\n    &lt;/logger&gt;\n    &lt;logger name=\"org.thp.scalligraph.controllers.Entrypoint\"&gt;\n        &lt;appender-ref ref=\"ASYNCACCESSFILE\" /&gt;\n    &lt;/logger&gt;\n\n    &lt;root level=\"INFO\"&gt;\n        &lt;!-- other appender-refs ... --&gt;\n    &lt;/root&gt;\n\n&lt;/configuration&gt;\n</code></pre>"}, {"location": "thehive/configuration/logs/#sending-logs-to-syslog", "title": "Sending Logs to Syslog", "text": "<p>To send logs to syslog, add a <code>SyslogAppender</code> to the logback configuration:</p> logback.xml<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;configuration debug=\"false\"&gt;\n\n    &lt;!-- ... other appenders and settings --&gt;\n\n    &lt;appender name=\"SYSLOG\" class=\"ch.qos.logback.classic.net.SyslogAppender\"&gt;\n        &lt;syslogHost&gt;remote_host&lt;/syslogHost&gt;\n        &lt;facility&gt;AUTH&lt;/facility&gt;\n        &lt;suffixPattern&gt;[%thread] %logger %msg&lt;/suffixPattern&gt;\n    &lt;/appender&gt;\n\n    &lt;root level=\"INFO\"&gt;\n        &lt;appender-ref ref=\"SYSLOG\" /&gt;\n        &lt;!-- other appender-refs ... --&gt;\n    &lt;/root&gt;\n</code></pre> <p>Refer to the official documentation for more details.</p> <p>Limitations: The official syslog appender only supports sending logs via UDP to a server and does not support TCP and TLS.</p> <p> </p>"}, {"location": "thehive/configuration/pekko/", "title": "Pekko Configuration (TheHive 5.4+)", "text": ""}, {"location": "thehive/configuration/pekko/#pekko-configuration-thehive-54", "title": "Pekko Configuration (TheHive 5.4+)", "text": "<p>Note</p> <p>This documentation applies to TheHive version 5.4 and later. For earlier versions, please refer to the Akka Configuration.</p>"}, {"location": "thehive/configuration/pekko/#introduction", "title": "Introduction", "text": "<p>With the release of TheHive version 5.4, we have transitioned from the Scala framework Akka to Apache Pekko. This change enhances performance and introduces several updates that may require modifications to your <code>application.conf</code> file.</p> <p>This guide provides instructions on updating your configuration to support this change.</p>"}, {"location": "thehive/configuration/pekko/#basic-configuration", "title": "Basic Configuration", "text": "<p>For a reliable cluster setup, it's essential to have a minimum of three nodes for TheHive application. Each node should be configured with Pekko as outlined below:</p> <pre><code>## Pekko server\npekko {\n  cluster.enable = on\n  actor {\n    provider = cluster\n  }\n  remote.artery {\n    canonical {\n      hostname = \"&lt;HOSTNAME OR IP_ADDRESS&gt;\"\n      port = 7355\n    }\n  }\n\n  cluster.seed-nodes = [ \n    \"pekko://application@HOSTNAME1:7355\", \n    \"pekko://application@HOSTNAME2:7355\", \n    \"pekko://application@HOSTNAME3:7355\" \n  ]\n\n  cluster.min-nr-of-members = 2  # Set to the minimum number of nodes required\n}\n</code></pre> <p>In this configuration:</p> <ul> <li><code>remote.artery.canonical.hostname</code> should be set to the hostname or IP address of the node.</li> <li><code>cluster.seed-nodes</code> should contain the same list of Pekko nodes, ensuring consistency across all nodes.</li> </ul> <p>Configuration of a Cluster with 3 Nodes</p> Node 1Node 2Node 3 <p>Pekko configuration for Node 1:</p> <pre><code>pekko {\n  cluster.enable = on\n  actor {\n    provider = cluster\n  }\n  remote.artery {\n    canonical {\n      hostname = \"10.1.2.1\"\n      port = 7355\n    }\n  }\n  cluster.seed-nodes = [\n    \"pekko://application@10.1.2.1:7355\",\n    \"pekko://application@10.1.2.2:7355\",\n    \"pekko://application@10.1.2.3:7355\"\n  ]\n\n  cluster.min-nr-of-members = 2\n}\n</code></pre> <p>Pekko configuration for Node 2:</p> <pre><code>pekko {\n  cluster.enable = on\n  actor {\n    provider = cluster\n  }\n  remote.artery {\n    canonical {\n      hostname = \"10.1.2.2\"\n      port = 7355\n    }\n  }\n  cluster.seed-nodes = [\n    \"pekko://application@10.1.2.1:7355\",\n    \"pekko://application@10.1.2.2:7355\",\n    \"pekko://application@10.1.2.3:7355\"\n  ]\n\n  cluster.min-nr-of-members = 2\n}\n</code></pre> <p>Pekko configuration for Node 3:</p> <pre><code>pekko {\n  cluster.enable = on\n  actor {\n    provider = cluster\n  }\n  remote.artery {\n    canonical {\n      hostname = \"10.1.2.3\"\n      port = 7355\n    }\n  }\n  cluster.seed-nodes = [\n    \"pekko://application@10.1.2.1:7355\",\n    \"pekko://application@10.1.2.2:7355\",\n    \"pekko://application@10.1.2.3:7355\"\n  ]\n\n  cluster.min-nr-of-members = 2\n}\n</code></pre>"}, {"location": "thehive/configuration/pekko/#ssltls-support", "title": "SSL/TLS Support", "text": "<p>Pekko offers robust support for SSL/TLS encryption, ensuring secure communication between nodes. Below is a standard configuration to enable SSL/TLS support:</p> <pre><code>## Pekko server with SSL/TLS\npekko {\n  cluster.enable = on\n  actor {\n    provider = cluster\n  }\n  remote.artery {\n    transport = tls-tcp\n    canonical {\n      hostname = \"&lt;HOSTNAME_OR_IP_ADDRESS&gt;\"\n      port = 7355\n    }\n    ssl.config-ssl-engine {\n      key-store = \"&lt;PATH_TO_KEYSTORE&gt;\"\n      trust-store = \"&lt;PATH_TO_TRUSTSTORE&gt;\"\n      key-store-password = \"change_me\"\n      key-password = \"change_me\"\n      trust-store-password = \"change_me\"\n      protocol = \"TLSv1.2\"\n    }\n  }\n  cluster.seed-nodes = [\n    \"pekko://application@HOSTNAME1:7355\",\n    \"pekko://application@HOSTNAME2:7355\",\n    \"pekko://application@HOSTNAME3:7355\"\n  ]\n\n  cluster.min-nr-of-members = 2\n}\n</code></pre> <p>Certificate Considerations</p> <p>Ensure you use your internal PKI (Public Key Infrastructure) or keytool commands to generate certificates.</p> <p>For detailed instructions, see: Using keytool for Certificate Generation</p> <p>Your server certificates should include the following KeyUsage and ExtendedkeyUsage extensions for proper functioning:</p> <ul> <li>KeyUsage extensions<ul> <li><code>nonRepudiation</code></li> <li><code>dataEncipherment</code></li> <li><code>digitalSignature</code></li> <li><code>keyEncipherment</code></li> </ul> </li> <li>ExtendedkeyUsage extensions<ul> <li><code>serverAuth</code></li> <li><code>clientAuth</code></li> </ul> </li> </ul> <p>Pekko Configuration with SSL/TLS for Node 1</p> <pre><code>## Pekko server\npekko {\n  cluster.enable = on\n  actor {\n    provider = cluster\n  }\n  remote.artery {\n    transport = tls-tcp\n    canonical {\n      hostname = \"10.1.2.1\"\n      port = 7355\n    }\n\n    ssl.config-ssl-engine {\n      key-store = \"/etc/thehive/application.conf.d/certs/10.1.2.1.jks\"\n      trust-store = \"/etc/thehive/application.conf.d/certs/internal_ca.jks\"\n\n      key-store-password = \"chamgeme\"\n      key-password = \"chamgeme\"\n      trust-store-password = \"chamgeme\"\n\n      protocol = \"TLSv1.2\"\n    }\n  }\n\n  cluster.seed-nodes = [ \n    \"pekko://application@10.1.2.1:7355\", \n    \"pekko://application@10.1.2.2:7355\", \n    \"pekko://application@10.1.2.3:7355\" \n  ]\n\n  cluster.min-nr-of-members = 2\n}\n</code></pre> <p>Ensure to apply the same principle for configuring other nodes, and remember to restart all services afterward.</p> <p>Note</p> <p>From version 5.4 onwards, the <code>secret.conf</code> file must include a secret key of at least 32 characters for session security, as required by Play Framework 3. For clustered setups, all nodes must share the same key, ensuring consistency across the deployment.</p> <p> </p>"}, {"location": "thehive/configuration/proxy/", "title": "Proxy Configuration", "text": ""}, {"location": "thehive/configuration/proxy/#proxy-settings", "title": "Proxy Settings", "text": ""}, {"location": "thehive/configuration/proxy/#global-application-proxy", "title": "Global Application Proxy", "text": "<p>Proxy settings can be configured for the application. By default, the JVM's proxy settings are used, but it's possible to define specific configurations for individual HTTP clients.</p> <p> </p>"}, {"location": "thehive/configuration/proxy/#configuration-parameters", "title": "Configuration Parameters", "text": "Parameter Type Description <code>wsConfig.proxy.host</code> string Hostname of the proxy server. <code>wsConfig.proxy.port</code> integer Port of the proxy server. <code>wsConfig.proxy.protocol</code> string Protocol of the proxy server. Use \"http\" or \"https\". Defaults to \"http\" if not specified. <code>wsConfig.proxy.user</code> string Username for proxy server credentials. <code>wsConfig.proxy.password</code> string Password for proxy server credentials. <code>wsConfig.proxy.ntlmDomain</code> string NTLM domain for proxy authentication. <code>wsConfig.proxy.encoding</code> string Charset for the realm. <code>wsConfig.proxy.nonProxyHosts</code> list List of hosts for which the proxy should not be used."}, {"location": "thehive/configuration/secret/", "title": "Secrets Configuration", "text": ""}, {"location": "thehive/configuration/secret/#secret-configuration-file-secretconf", "title": "Secret Configuration File - <code>secret.conf</code>", "text": "<p>Note</p> <p>Starting from version 5.4 of TheHive, the secret key must be at least 32 characters long as required by Play Framework 3. Ensure that the secret key complies with this requirement for secure session management.</p> <p>The <code>secret.conf</code> file contains a secret key that is utilized to define cookies responsible for managing user sessions within TheHive application. It is crucial that one instance of TheHive uses a unique secret key to ensure session security and integrity.</p> <ul> <li> <p>Single Instance Deployment: For a single instance of TheHive, ensure that the <code>secret.conf</code> file contains a unique secret key.</p> </li> <li> <p>Clustered Deployment: In the scenario where multiple nodes of TheHive are clustered together, all nodes should have a <code>secret.conf</code> file with the same secret key.</p> </li> </ul> <p>Example</p> <pre><code>## Example secret key configuration\nplay.http.secret.key=\"dgngu325mbnbc39cxas4l5kb24503836y2vsvsg465989fbsvop9d09ds6df6\"\n</code></pre> <p> </p> <p>Warning</p> <p>Do not copy the key provided above. Instead, generate and use your own unique secret key for enhanced security and confidentiality.</p> <p> </p>"}, {"location": "thehive/configuration/service/", "title": "Service Configuration", "text": ""}, {"location": "thehive/configuration/service/#service-configuration", "title": "Service Configuration", "text": ""}, {"location": "thehive/configuration/service/#listen-address-port", "title": "Listen Address &amp; Port", "text": "<p>By default, the application listens on <code>all network interfaces (0.0.0.0)</code> on <code>port 9000</code>. You can customize the listen address and port by editing the <code>application.conf</code> file as follows:</p> <pre><code>http.address=127.0.0.1\nhttp.port=9000\n</code></pre> <p>Specify the desired IP address and port based on your requirements.</p>"}, {"location": "thehive/configuration/service/#setting-a-context-path", "title": "Setting a Context Path", "text": "<p>If you are using a reverse proxy and need to define a specific context path (e.g., <code>/thehive</code>), you must update TheHive's configuration accordingly:</p> <p>Example</p> <pre><code>play.http.context: \"/thehive\"\n</code></pre> <p>This sets the base context path for accessing TheHive via the reverse proxy.</p>"}, {"location": "thehive/configuration/service/#configuring-streams-for-reverse-proxies", "title": "Configuring Streams for Reverse Proxies", "text": "<p>When using a reverse proxy like Nginx, you may encounter <code>504 Gateway Time-Out</code> errors related to long polling. Adjust the <code>stream.longPolling.refresh</code> setting to resolve this issue:</p> <p>Example</p> <pre><code>stream.longPolling.refresh: 45 seconds\n</code></pre> <p>This setting controls the refresh interval for long-polling requests.</p>"}, {"location": "thehive/configuration/service/#using-web-proxy", "title": "Using Web Proxy", "text": "<p>If you are employing an NGINX reverse proxy in front of TheHive, note that NGINX does not differentiate between text data and file uploads. To ensure proper handling, set the <code>client_max_body_size</code> parameter in your NGINX configuration file to accommodate the larger value between the file upload size and the text size defined in TheHive's application.conf</p> <p>To configure <code>client_max_body_size</code>, follow these steps:</p> <ol> <li> <p>Edit your NGINX configuration file. This file is typically located at <code>/etc/nginx/nginx.conf</code> or within a specific server block configuration file.</p> </li> <li> <p>Locate the <code>http</code> block in the NGINX configuration file.</p> </li> <li> <p>Add or modify the <code>client_max_body_size</code> directive within the <code>http</code> block to specify the maximum allowable size for incoming requests. For example:</p> </li> </ol> <pre><code>http {\n    ...\n    client_max_body_size 100M;  # Adjust to your desired value\n    ...\n}\n</code></pre> <p>For more detailed information, please refer to the article Limit File Upload Size in NGINX.</p> <p> </p>"}, {"location": "thehive/configuration/ssl/", "title": "SSL Configuration", "text": ""}, {"location": "thehive/configuration/ssl/#ssl-configuration", "title": "SSL Configuration", "text": ""}, {"location": "thehive/configuration/ssl/#connect-thehive-using-https", "title": "Connect TheHive using HTTPS", "text": "<p>It is recommended to set up a reverse proxy, such as Nginx, to manage the SSL layer for TheHive.</p> Nginx <p>For detailed instructions on configuring HTTPS servers with Nginx, refer to the Nginx documentation</p> /etc/nginx/sites-available/thehive.conf<pre><code>server {\n  listen 443 ssl http2;\n  server_name thehive;\n\n  ssl on;\n  ssl_certificate       /path-to/thehive-server-chained-cert.pem;\n  ssl_certificate_key   /path-to/thehive-server-key.pem;\n\n  proxy_connect_timeout   600;\n  proxy_send_timeout      600;\n  proxy_read_timeout      600;\n  send_timeout            600;\n  client_max_body_size    2G;\n  proxy_buffering off;\n  client_header_buffer_size 8k;\n\n  location / {\n    add_header              Strict-Transport-Security \"max-age=31536000; includeSubDomains\";\n    proxy_pass              http://127.0.0.1:9000/;\n    proxy_http_version      1.1;\n  }\n}\n</code></pre>"}, {"location": "thehive/configuration/ssl/#client-configuration", "title": "Client Configuration", "text": "<p>SSL configuration settings may be necessary to connect remote services. Below are the parameters that can be defined:</p> Parameter Type Description <code>wsConfig.ssl.keyManager.stores</code> list Stores client certificates (see #certificate-manager ) <code>wsConfig.ssl.trustManager.stores</code> list Stores custom Certificate Authorities (see #certificate-manager <code>wsConfig.ssl.protocol</code> string Defines a different default protocol (see #protocols) <code>wsConfig.ssl.enabledProtocols</code> list List of enabled protocols (see #protocols) <code>wsConfig.ssl.enabledCipherSuites</code> list List of enabled cipher suites (see #ciphers) <code>wsConfig.ssl.loose.acceptAnyCertificate</code> boolean Accept any certificates true / false <p> </p>"}, {"location": "thehive/configuration/ssl/#certificate-manager", "title": "Certificate Manager", "text": "<p>The certificate manager is used to store client certificates and certificate authorities.</p> <p> </p>"}, {"location": "thehive/configuration/ssl/#using-custom-certificate-authorities", "title": "Using Custom Certificate Authorities", "text": "<p>The preferred method for using custom Certificate Authorities is to use the system configuration.</p> DebianRPM <p>Ensure the <code>ca-certificates-java</code> package is installed, copy the CA certificate to the appropriate folder, then reconfigure certificates and restart TheHive service.</p> <pre><code>apt-get install -y ca-certificates-java\nmkdir /usr/share/ca-certificates/extra\ncp mycustomcert.crt /usr/share/ca-certificates/extra\ndpkg-reconfigure ca-certificates\nservice thehive restart\n</code></pre> <p>Copy the CA certificate to the correct folder, update CA trust, and restart TheHive service.</p> <pre><code>cp mycustomcert.crt /etc/pki/ca-trust/source/anchors\nsudo update-ca-trust \nservice thehive restart\n</code></pre> <p>An alternative approach is to use dedicated trust stores, although this is not the recommended option. Use the <code>trustManager</code> key in TheHive configuration to establish secure connections with remote hosts. Ensure that server certificates are signed by trusted certificate authorities.</p> <pre><code>  wsConfig.ssl.trustManager {\n    stores = [\n      {\n        type = \"JKS\" // JKS or PEM\n        path = \"keystore.jks\"\n        password = \"password1\"\n      }\n    ]\n  }\n</code></pre> <p> </p>"}, {"location": "thehive/configuration/ssl/#client-certificates", "title": "Client Certificates", "text": "<p>The <code>keyManager</code> parameter specifies which certificate the HTTP client can use for authentication on remote hosts when certificate-based authentication is required.</p> <pre><code>  wsConfig.ssl.keyManager {\n    stores = [\n      {\n        type = \"pkcs12\" // JKS or PEM\n        path = \"mycert.p12\"\n        password = \"password1\"\n      }\n    ]\n  }\n</code></pre> <p> </p>"}, {"location": "thehive/configuration/ssl/#protocols", "title": "Protocols", "text": "<p>To define a different default protocol use the following configuration:</p> <pre><code>wsConfig.ssl.protocol = \"TLSv1.2\"\n</code></pre> <p>To define a list of enabled protocols, use the following configuration:</p> <pre><code>wsConfig.ssl.enabledProtocols = [\"TLSv1.2\", \"TLSv1.1\", \"TLSv1\"]\n</code></pre> <p> </p>"}, {"location": "thehive/configuration/ssl/#advanced-options", "title": "Advanced Options", "text": ""}, {"location": "thehive/configuration/ssl/#ciphers", "title": "Ciphers", "text": "<p>Configure cipher suites using <code>wsConfig.ssl.enabledCipherSuites</code>:</p> <pre><code>wsConfig.ssl.enabledCipherSuites = [\n  \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\",\n  \"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n  \"TLS_DHE_RSA_WITH_AES_256_GCM_SHA384\",\n  \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n]\n</code></pre> <p> </p>"}, {"location": "thehive/configuration/ssl/#debugging", "title": "Debugging", "text": "<p>Enable debugging flags to troubleshoot key managers and trust managers:</p> <pre><code>  wsConfig.ssl.debug = {\n    ssl = true\n    trustmanager = true\n    keymanager = true\n    sslctx = true\n    handshake = true\n    verbose = true\n    data = true\n    certpath = true\n  }\n</code></pre> <p> </p>"}, {"location": "thehive/download/", "title": "Download", "text": ""}, {"location": "thehive/download/#download-thehive", "title": "Download TheHive", "text": "<p>TheHive is available in multiple binary package formats, allowing for seamless installation on various operating systems. Below are the available options for obtaining and installing TheHive on different platforms.</p>"}, {"location": "thehive/download/#debian-ubuntu", "title": "Debian /  Ubuntu", "text": "<p>If you are running an operating system based on Debian/Ubuntu, TheHive can be installed by following the steps in the Step-by-Step Installation Guide. These steps will guide you through the necessary configurations and prerequisites to get TheHive fully operational.</p> <p> </p>"}, {"location": "thehive/download/#redhat-enterprise-linux-fedora", "title": "RedHat Enterprise Linux /  Fedora", "text": "<p>If you are running an operating system based on RedHat or Fedora, TheHive can be installed by following the steps in the Step-by-Step Installation Guide. These steps will guide you through the necessary configurations and prerequisites to get TheHive fully operational.</p> <p>Note: Make sure to select the correct RPM tab when following the step-by-step instructions to ensure the proper commands are used.</p> <p> </p>"}, {"location": "thehive/download/#docker", "title": "Docker", "text": "<p>If you prefer using Docker, you can leverage pre-built Docker images available on Docker Hub for convenient deployment and containerization of TheHive. </p> <p>The Docker image can be found on TheHive Docker Hub, and instructions to run it can be found here. These steps will guide you through the necessary configurations and prerequisites to get TheHive fully operational.</p> <p> </p>"}, {"location": "thehive/download/#kubernetes", "title": "Kubernetes", "text": "<p>If you prefer using Kubernetes, you can leverage pre-built Docker images available on Docker Hub for convenient deployment and containerization of TheHive. </p> <p>The Docker image can be found on TheHive Docker Hub, and instructions to run it on Kubernetes can be found here. These steps will guide you through the necessary configurations and prerequisites to get TheHive fully operational.</p> <p> </p>"}, {"location": "thehive/download/archives/", "title": "Archives", "text": "<p>In addition to the download methods explained on the Step-by-Step Installation Guide, users can also download TheHive as a ZIP archive for manual installation or deployment scenarios. Follow these steps:</p> <ol> <li> <p>Visit the following URL to download the latest ZIP archive: thehive-latest.zip</p> </li> <li> <p>Once the download is complete, extract the contents of the ZIP archive to your desired location.</p> </li> <li> <p>Proceed with the installation or configuration process as per your requirements.</p> </li> </ol> <p> </p>"}, {"location": "thehive/download/archives/#deb-packages", "title": "DEB Packages", "text": "<p>Access DEB packages from the following URL: DEB Packages. Please follow the instructions provided here to install the downloaded package.</p>"}, {"location": "thehive/download/archives/#rpm-packages", "title": "RPM Packages", "text": "<p>Access RPM packages from the following URL: RPM Packages. Please follow the instructions provided here to install the downloaded package.</p>"}, {"location": "thehive/download/archives/#zip-archives", "title": "ZIP Archives", "text": "<p>Access ZIP archives from the following URL: ZIP Archives. Please follow the instructions provided here to install the downloaded package.</p> <p> </p>"}, {"location": "thehive/how-to/alert-management/", "title": "Alert Management", "text": ""}, {"location": "thehive/how-to/alert-management/#alert-management", "title": "Alert Management", "text": ""}, {"location": "thehive/how-to/alert-management/#alert-list", "title": "Alert list", "text": "<p>Alerts received by your organization can be viewed in TheHive:</p> <p></p> <p>Every user inside the organization can view the alerts. But you will need the permission <code>manageAlert</code> to be able to edit alerts.</p> <p>A user can use predefined filter or custom filters to view only selected alerts:</p> <p></p>"}, {"location": "thehive/how-to/alert-management/#alert-details", "title": "Alert details", "text": "<p>From the alert list, an alert can be opened for more investigation. Details are filled, comments by analysts can be made on the alert too:</p> <p></p> <p>You can use tags, comments, severity, tlp, pap, custom fields and custom statuses to help categorize your alerts.</p> <p>Observables from the alert can be further analyzed either by the analysts or by using Cortex analyzers:</p> <p></p> <p></p> <p>Finally, depending on the analyst investigation, an alert can be closed (marked as \"False Positive\", \"Duplicate\", \"Ignored\" or an other custom status) or a case can be created to pursue the investigation.</p>"}, {"location": "thehive/how-to/authentication/", "title": "Authentication", "text": ""}, {"location": "thehive/how-to/authentication/#authentication", "title": "Authentication", "text": "<p>TheHive supports several authentication providers:</p> <ul> <li>local (credential are securely stored in TheHive database)</li> <li>directory (LDAP and Active Directory)</li> <li>OAuth2/OpenID-Connect</li> <li>SAML</li> <li>based on HTTP header to delegate authentication to reverse proxy</li> </ul> <p></p> <p>Multi-factor authentication can be enabled to enforce security on user authentication.</p> <p>Several authentication providers can be enable. Each of them is check sequentially (order is important).</p>"}, {"location": "thehive/how-to/authentication/#active-directory", "title": "Active Directory", "text": ""}, {"location": "thehive/how-to/authentication/#ldap", "title": "LDAP", "text": ""}, {"location": "thehive/how-to/authentication/#oauth2-openid-connect", "title": "OAuth2 / OpenID-Connect", "text": ""}, {"location": "thehive/how-to/authentication/#saml", "title": "SAML", "text": ""}, {"location": "thehive/how-to/authentication/#user-synchronisation", "title": "User synchronisation", "text": "<p>The user can be provisionned and deprovisionned automatically based on the content of a directory. The user data are synchronised periodically. New users in LDAP are created in TheHive, removed users are disabled.</p> <p>The organization membership and the profile of an user are set using LDAP groups. The configuration contain the mapping of LDAP groups with organization/profile. </p>"}, {"location": "thehive/how-to/dashboards/", "title": "Dashboards and Reporting", "text": ""}, {"location": "thehive/how-to/dashboards/#dashboards-and-reporting", "title": "Dashboards and Reporting", "text": "<p>TheHive comes with a reporting module that allows designing shared and private dashbords using various widgets for data visualisation. Reports can gather metrics from any data stored in TheHive like cases, alerts, tasks, observables...</p>"}, {"location": "thehive/how-to/dashboards/#dashboards", "title": "Dashboards", "text": "<p>Every user has read access to the dashboards defined in the organization (s)he belongs to. If the <code>manageDashboard</code> permission is part of the user's profile, the user can create dashboards.</p>"}, {"location": "thehive/how-to/dashboards/#create-a-dashboard", "title": "Create a dashboard", "text": ""}, {"location": "thehive/how-to/dashboards/#list-dashboards", "title": "List dashboards", "text": ""}, {"location": "thehive/how-to/dashboards/#view-dashboard", "title": "View dashboard", "text": ""}, {"location": "thehive/how-to/dashboards/#configure-widgets", "title": "Configure widgets", "text": ""}, {"location": "thehive/how-to/dashboards/#case-timelines", "title": "Case timelines", "text": "<p>Case timelines are a second part of TheHive's reporting capabilities. Case timelines display any event that happened during the lifecycle of a given case:</p> <ul> <li>Alert occurences</li> <li>Case creation</li> <li>Investigation start</li> <li>Task completion</li> <li>Flagged task logs</li> <li>IoC sightings</li> <li>Mitre Attack patterns</li> <li>Additional custom events</li> </ul> <p></p> <p></p>"}, {"location": "thehive/how-to/fail2ban/", "title": "Fail2ban Configuration", "text": ""}, {"location": "thehive/how-to/fail2ban/#fail2ban", "title": "Fail2ban", "text": "<p>Fail2ban is an intrusion prevention software designed to enhance the security of Linux systems by actively monitoring logs for suspicious activity and dynamically blocking malicious IP addresses. By automatically responding to potential threats such as repeated failed login attempts or suspicious access patterns, Fail2ban acts as a proactive defense mechanism, fortifying servers against various forms of cyberattacks.</p>"}, {"location": "thehive/how-to/fail2ban/#adding-thehive-into-fail2ban", "title": "Adding TheHive into Fail2ban", "text": "<p>To integrate TheHive logs with Fail2ban, follow the steps below. Assume TheHive logs are located at <code>/var/log/thehive/application.log</code> and Fail2ban configuration files are located in <code>/etc/fail2ban</code>.</p> <ol> <li> <p>Step 1: Create a Filter File</p> <ul> <li>Create a filter file in <code>/etc/fail2ban/filter.d</code> named <code>thehive.conf</code> with the following content:</li> </ul> <pre><code>[INCLUDES]\nbefore = common.conf\n\n[Definition]\nfailregex = ^.*- &lt;HOST&gt; (?:POST \\/api\\/login|GET .*) .*returned 401.*$\nignoreregex =\n</code></pre> </li> <li> <p>Step 2: Create a Jail File</p> <ul> <li>Create a jail file in <code>/etc/fail2ban/jail.d</code> named <code>thehive.local</code> with the following content:</li> </ul> <pre><code>[thehive]\nenabled = true\nport = 80,443\nfilter = thehive\naction = iptables-multiport[name=thehive, port=\"80,443\"]\nlogpath = /var/log/thehive/application.log\nmaxretry = 5\nbantime = 14400\nfindtime = 1200\n</code></pre> <p>This configuration will ban any IP address for 4 hours after 5 failed authentication attempts within a 20-minute period.</p> </li> <li> <p>Step 3: Reload Fail2ban Configuration</p> <ul> <li>Reload the Fail2ban configuration to apply the changes:</li> </ul> <pre><code>fail2ban-client reload\n</code></pre> </li> </ol>"}, {"location": "thehive/how-to/fail2ban/#review-banned-ip-addresses", "title": "Review Banned IP Addresses", "text": "<p>Here is a step-by-step guide to reviewing banned IP addresses on Fail2ban:</p> <ol> <li> <p>Step 1: Check Fail2ban Status:</p> <p>Use the following command to get an overview of Fail2ban's status and active jails:</p> <pre><code>sudo fail2ban-client status\n</code></pre> </li> <li> <p>Step 2: Review Banned IPs for a Specific Jail</p> <p>Use this command to view banned IPs in a particular jail.</p> <pre><code>sudo fail2ban-client status thehive\n</code></pre> </li> </ol>"}, {"location": "thehive/how-to/fail2ban/#unban-an-ip-address", "title": "Unban an IP Address", "text": "<p>Use the following command to remove the ban on a specific IP address. Replace <code>jail_name</code> with the jail's name and <code>IP_address</code> with the specific IP address you want to unban:</p> <pre><code>sudo fail2ban-client set thehive unbanip 1.1.1.1\n</code></pre> <p> </p>"}, {"location": "thehive/how-to/knowledge-base/", "title": "Knwoledge Base", "text": ""}, {"location": "thehive/how-to/knowledge-base/#knwoledge-base", "title": "Knwoledge Base", "text": "<p>TheHive has a knowledge base module that allow writing Markdown pages at two levels:</p> <ul> <li>Organization level</li> <li>Case level</li> </ul>"}, {"location": "thehive/how-to/knowledge-base/#organization-wiki", "title": "Organization wiki", "text": "<p>Every organization is able to define a set of Markdown pages accessible to all the users. Adding pages requires a <code>manageKnowledgeBase</code> user permission.</p> <p></p>"}, {"location": "thehive/how-to/knowledge-base/#case-pages", "title": "Case pages", "text": "<p>Within every case, users with <code>managePage</code> permissions, can create and write Markdown pages. This feature ca, be used for:</p> <ul> <li>meeting notes</li> <li>reports</li> <li>pasties</li> <li>any other content</li> </ul> <p></p>"}, {"location": "thehive/how-to/markdown/", "title": "How to Markdown: A Comprehensive Guide", "text": ""}, {"location": "thehive/how-to/markdown/#how-to-markdown-a-comprehensive-guide", "title": "How to Markdown: A Comprehensive Guide", "text": "<p>Welcome to the \"How to Markdown\" guide! In this comprehensive guide, we'll explore the powerful features and capabilities of Markdown \u2013 a lightweight markup language that simplifies text formatting while retaining its readability. Whether you're new to Markdown or looking to enhance your existing knowledge, this guide will walk you through each feature step by step, providing you with practical examples and clear explanations.</p>"}, {"location": "thehive/how-to/markdown/#table-of-contents", "title": "Table of Contents", "text": "<ol> <li><code>Heading</code></li> <li><code>Horizontal Rules</code></li> <li><code>Emphasis</code></li> <li><code>Blockquotes</code></li> <li><code>Lists</code></li> <li><code>Code</code></li> <li><code>Tables</code></li> <li><code>Links</code></li> <li><code>Images</code></li> </ol>"}, {"location": "thehive/how-to/markdown/#heading", "title": "Heading", "text": ""}, {"location": "thehive/how-to/markdown/#code", "title": "Code", "text": "<pre><code># h1 Heading\n## h2 Heading\n### h3 Heading\n#### h4 Heading\n##### h5 Heading\n###### h6 Heading\n</code></pre>"}, {"location": "thehive/how-to/markdown/#example", "title": "Example", "text": ""}, {"location": "thehive/how-to/markdown/#h1-heading", "title": "h1 Heading", "text": ""}, {"location": "thehive/how-to/markdown/#h2-heading", "title": "h2 Heading", "text": ""}, {"location": "thehive/how-to/markdown/#h3-heading", "title": "h3 Heading", "text": ""}, {"location": "thehive/how-to/markdown/#h4-heading", "title": "h4 Heading", "text": ""}, {"location": "thehive/how-to/markdown/#h5-heading", "title": "h5 Heading", "text": ""}, {"location": "thehive/how-to/markdown/#h6-heading", "title": "h6 Heading", "text": ""}, {"location": "thehive/how-to/markdown/#horizontal-rules", "title": "Horizontal Rules", "text": ""}, {"location": "thehive/how-to/markdown/#code_1", "title": "Code", "text": "<pre><code>--- or *** or ___\n</code></pre>"}, {"location": "thehive/how-to/markdown/#example_1", "title": "Example", "text": ""}, {"location": "thehive/how-to/markdown/#emphasis", "title": "Emphasis", "text": ""}, {"location": "thehive/how-to/markdown/#code_2", "title": "Code", "text": "<pre><code>**This is bold text** or __This is bold text__    \n*This is italic text* or _This is italic text_    \n~~Strikethrough~~\n</code></pre>"}, {"location": "thehive/how-to/markdown/#example_2", "title": "Example", "text": "<p>This is bold text</p> <p>This is italic text</p> <p>~~Strikethrough~~</p>"}, {"location": "thehive/how-to/markdown/#blockquotes", "title": "Blockquotes", "text": ""}, {"location": "thehive/how-to/markdown/#code_3", "title": "Code", "text": "<pre><code>&gt; Blockquotes can also be nested...\n&gt;&gt; ...by using additional greater-than signs right next to each other...\n&gt; &gt; &gt; ...or with spaces between arrows.\n</code></pre>"}, {"location": "thehive/how-to/markdown/#example_3", "title": "Example", "text": "<p>Blockquotes can also be nested...</p> <p>...by using additional greater-than signs right next to each other...</p> <p>...or with spaces between arrows.</p>"}, {"location": "thehive/how-to/markdown/#lists", "title": "Lists", "text": ""}, {"location": "thehive/how-to/markdown/#unordered", "title": "Unordered", "text": ""}, {"location": "thehive/how-to/markdown/#code_4", "title": "Code", "text": "<pre><code>+ Create a list by starting a line with `+`, `-`, or `*`\n+ Sub-lists are made by indenting 2 spaces:\n- Marker character change forces new list start:\n    * Ac tristique libero volutpat at\n    + Facilisis in pretium nisl aliquet\n    - Nulla volutpat aliquam velit\n+ Very easy!\n</code></pre>"}, {"location": "thehive/how-to/markdown/#example_4", "title": "Example", "text": "<ul> <li>Create a list by starting a line with <code>+</code>, <code>-</code>, or <code>*</code></li> <li>Sub-lists are made by indenting 2 spaces:</li> <li>Marker character change forces new list start:<ul> <li>Ac tristique libero volutpat at</li> <li>Facilisis in pretium nisl aliquet</li> <li>Nulla volutpat aliquam velit</li> </ul> </li> <li>Very easy!</li> </ul>"}, {"location": "thehive/how-to/markdown/#ordered", "title": "Ordered", "text": ""}, {"location": "thehive/how-to/markdown/#code_5", "title": "Code", "text": "<pre><code>1. Lorem ipsum dolor sit amet\n2. Consectetur adipiscing elit\n3. Integer molestie lorem at massa\n</code></pre>"}, {"location": "thehive/how-to/markdown/#example_5", "title": "Example", "text": "<ol> <li>Lorem ipsum dolor sit amet</li> <li>Consectetur adipiscing elit</li> <li> <p>Integer molestie lorem at massa</p> </li> <li> <p>You can use sequential numbers...</p> </li> <li>...or keep all the numbers as <code>1.</code></li> </ol> <p>Start numbering with offset:</p> <ol> <li>foo</li> <li>bar</li> </ol>"}, {"location": "thehive/how-to/markdown/#code_6", "title": "Code", "text": "<p>Inline <code>code</code> with `</p> <p>Indented code with tab</p> <pre><code>// Some comments\nline 1 of code\nline 2 of code\nline 3 of code\n</code></pre> <p>Block code \"fences\" with ```</p> <pre><code>Sample text here...\n</code></pre>"}, {"location": "thehive/how-to/markdown/#tables", "title": "Tables", "text": ""}, {"location": "thehive/how-to/markdown/#code_7", "title": "Code", "text": "<pre><code>| Option | Description |\n| ------ | ----------- |\n| data   | path to data files to supply the data that will be passed into templates. |\n| engine | engine to be used for processing templates. Handlebars is the default. |\n| ext    | extension to be used for dest files. |\n</code></pre>"}, {"location": "thehive/how-to/markdown/#example_6", "title": "Example", "text": "Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files."}, {"location": "thehive/how-to/markdown/#right-aligned-columns", "title": "Right aligned columns", "text": ""}, {"location": "thehive/how-to/markdown/#code_8", "title": "Code", "text": "<pre><code>| Option | Description |\n| ------:| -----------:|\n| data   | path to data files to supply the data that will be passed into templates. |\n| engine | engine to be used for processing templates. Handlebars is the default. |\n| ext    | extension to be used for dest files. |\n</code></pre>"}, {"location": "thehive/how-to/markdown/#example_7", "title": "Example", "text": "Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files."}, {"location": "thehive/how-to/markdown/#links", "title": "Links", "text": ""}, {"location": "thehive/how-to/markdown/#code_9", "title": "Code", "text": "<pre><code>[link text](https://docs.strangebee.com/thehive/administration/organizations/)\n[link with title](https://docs.strangebee.com/thehive/administration/organizations/ \"title text!\")\n</code></pre>"}, {"location": "thehive/how-to/markdown/#example_8", "title": "Example", "text": "<p>link text</p> <p>link with title</p>"}, {"location": "thehive/how-to/markdown/#images", "title": "Images", "text": ""}, {"location": "thehive/how-to/markdown/#code_10", "title": "Code", "text": "<pre><code>![TheHive](https://www.strangebee.com/images/logos/theHivePlatformBlock.svg)\n![Cortex](https://www.strangebee.com/images/logos/cortexPlatformBlock.svg \"Cortex\")\n\nLike links, Images also have a footnote style syntax\n\n![Alt text][id]\n\nWith a reference later in the document defining the URL location:\n\n[id]: https://www.strangebee.com/images/logos/theHiveCloudPlatformBlock.svg  \"TheHive Cloud Platform\"\n</code></pre>"}, {"location": "thehive/how-to/markdown/#example_9", "title": "Example", "text": ""}, {"location": "thehive/how-to/misp-integration/", "title": "MISP Integration", "text": ""}, {"location": "thehive/how-to/misp-integration/#misp-integration", "title": "MISP Integration", "text": "<p>TheHive in strongly integrated with MISP (Malware Information Sharing Platform).</p> <p>Using it's connector, TheHive has the capabilities to:</p> <ul> <li>Receive MISP events and ingest them as alerts</li> <li>Send TheHive <code>Cases</code> to MISP as events</li> </ul> <p>This integration is highly configurable and allows TheHive to synchronize with one or multiple MISP servers.</p>"}, {"location": "thehive/how-to/misp-integration/#configuration", "title": "Configuration", "text": "<p>To add or configure a MISP server, open the Admin organization page (1), go to the Platform Management menu (2) and navigate to the MISP tab (3).</p> <p>Click the \"+\" button to add a new MISP server (4).</p> <p></p>"}, {"location": "thehive/how-to/misp-integration/#general-settings", "title": "General settings", "text": "<p>This configuration is common to all MISP servers connected to TheHive.</p> <ul> <li>Interval: define the time interval between each events polling from TheHive to MISP</li> </ul>"}, {"location": "thehive/how-to/misp-integration/#servers-general-settings", "title": "Servers General settings", "text": "<p>While clicking on add or edit a MISP server, a drawer will appear where you can define the following settings:</p> <ul> <li>Server name: MISP server name to display within TheHive</li> <li>Server URL: URL of the MISP server</li> <li>API Key: secret with sufficient permission to get &amp; create MISP events</li> <li>Purpose: Chose the synchronization way; Import: only import events from MISP to TheHive. Export: only exports cases from TheHive to MISP. Import and Export allow both ways synchronization</li> </ul> <p></p>"}, {"location": "thehive/how-to/misp-integration/#server-proxy-settings", "title": "Server Proxy Settings", "text": "<p>Proxy settings should be set only if a proxy is required to reach the MISP server from TheHive.</p> <ul> <li>Type of protocol: Define on which protocol (HTTP/HTTPS) the proxy is listening</li> <li>Address: Define the proxy address</li> <li>Authentication: If the proxy require authentication, check this box. Username and password to authenticate must be provided when this box is checked.</li> <li>Do not check certificate authority: Do not verify the certificate authority when communicating with the proxy (not recommended, for HTTPS connection only)</li> <li>Disable hostname verification: Do not verify the hostname match with the certificate hostname.</li> </ul> <p></p>"}, {"location": "thehive/how-to/misp-integration/#server-advanced-settings", "title": "Server Advanced Settings", "text": "<ul> <li>Chose the filter on TheHive organizations: For each server, you can define which TheHive organization(s) to include or exclude of the synchronization (excluded or not included organizations will not receive the MISP events as <code>Alerts</code>)</li> <li>Tags: Append one or several tags to each MISP event ingested as <code>Alert</code> </li> <li>Export case tags: If enabled, the export will include the <code>Case</code> tags. </li> <li>Export observables tags: If enabled, the exported <code>Observables</code> will include the <code>Observables</code> tags.</li> </ul>"}, {"location": "thehive/how-to/misp-integration/#server-filter-settings", "title": "Server Filter Settings", "text": "<p>This section allows to define filters for MISP events import. </p> <ul> <li>Maximum age: define the maximum age (based on creation date) for an event to be imported in TheHive.</li> <li>Organizations to include: Import only events created by the MISP organization(s) defined in this field.</li> <li>Organizations to exclude: Import only events NOT created by the MISP organization(s) defined in this field.</li> <li>Maximum number of attributes: Define a maximum number of MISP attributes (observables) per event to import. </li> <li>List of allowed tags: Import only events that contains the tags defined in this field</li> <li>Prohibited tags list: Import only events that DON'T contains the tags defined in this field</li> </ul> <p></p>"}, {"location": "thehive/how-to/notifications/", "title": "Notification Configuration", "text": ""}, {"location": "thehive/how-to/notifications/#notifications", "title": "Notifications", "text": "<p>TheHive Notifications allow you to automatically react on specific events occurring in TheHive and send notification to defined Endpoints that can be:</p> <ul> <li> <p>Cortex</p> </li> <li> <p>Webhook listener</p> </li> <li> <p>Http listener</p> </li> <li> <p>Slack</p> </li> <li> <p>Mattermost</p> </li> </ul> <p>Endpoints need to be configured prior to use them in Notifications. You can also send an Email as notification. </p>"}, {"location": "thehive/how-to/notifications/#notifications-management", "title": "Notifications management", "text": "<p>Notifications are unique to each organization. With an org admin account open the Organization menu (1), and navigate to the Notifications tab (2).</p> <p>To create a notification, clic on the \"+\" button (3)</p> <p></p>"}, {"location": "thehive/how-to/notifications/#configure-a-notification", "title": "Configure a Notification", "text": "<p>While clicking on add or edit a notifier, a drawer will appear where you can define the following settings:</p> <ul> <li>Name: Notification name to display within TheHive</li> <li>Send notification to every user in the organization: Check this box to notify by email every users of the organization this Notifier has triggered</li> <li>Trigger: Chose in a list of triggers on which event you want to react. You can also select \"FilteredEvent\" to create your own event filter.</li> <li>Enable notification: Check this box to enable the notifier. Uncheck the box to disable the notifier.</li> </ul> <p>Finally, select which endpoint will receive the notification.</p>"}, {"location": "thehive/how-to/notifications/#pre-defined-triggers-filteredevent", "title": "Pre-defined triggers &amp; FilteredEvent", "text": "<p>While configuring the Trigger setting, you can pick a pre-defined trigger from a list, or chose to create your own filters. </p> <p>Current pre-defined filters list: </p> <ul> <li> <p>AnyEvent</p> </li> <li> <p>Case Created</p> </li> <li> <p>Case Closed</p> </li> <li> <p>Case Shared</p> </li> <li> <p>Alert Created</p> </li> <li> <p>Alert Imported</p> </li> <li> <p>Job Finished</p> </li> <li> <p>Alert Observable Created</p> </li> <li> <p>Case Observable Created </p> </li> <li> <p>Observable Created</p> </li> <li> <p>Log in my task</p> </li> <li> <p>Task Assigned</p> </li> <li> <p>Task Closed</p> </li> <li> <p>Task Mandatory</p> </li> </ul> <p>But you can also chose to use a custom filter to react on specific events. </p> <p>Custom filters are JSON format written and can use common operators. Example with a filter for cases which Severity is updated to High or Critical:</p> <p></p>"}, {"location": "thehive/how-to/notifications/#use-variables-in-notifications", "title": "Use variables in notifications", "text": "<p>You can include variables in your Email &amp; HTTP notification. </p> <p>Use the \"add variable\" bouton to see the list of available variables. Example with an email notification:</p> <p></p> <p>The templating engine is based on mustache so you can add some logic to your template. Example:</p> <pre><code>{{#if (eq object.severity 2) }}MEDIUM {{else}}Other {{/if}}\n</code></pre> <p>Some helpers are available to format your data:</p> Helper Description Usage Output <code>tlpLabel</code> Format the <code>tlp</code> field of the object <code>{{ tlpLabel object.tlp }}</code> <code>Amber</code> <code>papLabel</code> Format the <code>pap</code> field of the object <code>{{ papLabel object.pap }}</code> <code>Amber</code> <code>severityLabel</code> Format the <code>severity</code> field of the object <code>{{ severityLabel object.severity }}</code> <code>Critical</code> <code>dateFormat</code> Format a date field of the object, uses java date time patterns <code>{{dateFormat audit._createdAt \"EEEEE dd MMMMM yyyy\" \"fr\" }}</code> <code>jeudi 01 septembre 2022</code> <p>See our Leveraging TheHive 5 notifications capabilities blog articles to know more about Notifications</p>"}, {"location": "thehive/how-to/splunk-integration/", "title": "Splunk Integration Guide", "text": ""}, {"location": "thehive/how-to/splunk-integration/#introduction", "title": "Introduction", "text": "<p>This integration, available as a Threat Intelligence Add-on (TA), streamlines the process of creating alerts in TheHive from Splunk search results. The process involves several key steps:</p> <ol> <li>Search for events and collect observables and custom fields.</li> <li>Rename Splunk fields to match the field names listed in the <code>thehive_datatypes.csv</code> lookup table.</li> <li>Save the search as an alert.</li> <li>Configure the alert action \"thehive_create_a_new_alert\" to generate alerts in TheHive.</li> <li>Customize alerts by adding additional information such as TLP per observables, custom fields, titles, descriptions, and more.</li> </ol>"}, {"location": "thehive/how-to/splunk-integration/#use-cases-examples", "title": "Use Cases Examples", "text": "<p>In order to understand the practical application of this integration, several use cases (UC1 to UC5) are presented, demonstrating how to configure alerts and cases in TheHive based on various scenarios.</p> <p>Each use case provides insights into prerequisites, Splunk search configurations, Splunk screenshots, and TheHive screenshots.</p>"}, {"location": "thehive/how-to/splunk-integration/#use-cases-detailed", "title": "Use Cases Detailed", "text": "<p>For a comprehensive understanding of each use case's parameters, including title, description, TLP, PAP, severity, observables, TTPs, and more, please refer to the original documentation.</p>"}, {"location": "thehive/how-to/splunk-integration/#tips-tricks", "title": "Tips &amp; Tricks", "text": "<p>Discover valuable insights in the \"Tips &amp; Tricks\" section, where you can learn how to efficiently populate form fields, manage observables and inline fields, and make the most of tags to enhance your alerts.</p>"}, {"location": "thehive/how-to/splunk-integration/#advanced-search-results-with-additional-tags", "title": "Advanced Search Results with Additional Tags", "text": "<p>Explore advanced techniques to enrich your search results with additional tags, including the utilization of the <code>th_inline_msg</code> field and the creative renaming of fields for improved tagging.</p> <p>For comprehensive details and examples, we encourage you to explore the original documentation to set up your connector effectively.</p> <p>To integrate this connector into your workflow, please refer to the original documentation. Your success starts there!</p>"}, {"location": "thehive/how-to/splunk-integration/#support", "title": "Support", "text": "<p>Should you have any inquiries or feedback, feel free to reach out to the author on GitHub, or seek assistance from TheHive support through the portal.</p>"}, {"location": "thehive/how-to/user-management/", "title": "User Management", "text": ""}, {"location": "thehive/how-to/user-management/#user-management", "title": "User Management", "text": "<p>In TheHive users can be created once an added to different organistions. User lists are available to <code>admin</code> and <code>org-admin</code> users:</p> <p></p> <p>When adding a user in an organization, a user profile can be choosen for every organization:</p> <p></p> <p></p> <p>Users can be created by administrators or organization administrators or any user having the <code>manageUser</code> permission. This permission is included by default in the <code>admin</code> and <code>org-admin</code> user profiles.</p> <p>In TheHive, there are two types of users:</p> <ul> <li>Users with GUI access</li> <li>Service account aka. API users</li> </ul> <p></p> <p>Once created, users can be assigned a password and an API key </p>"}, {"location": "thehive/installation/activate-license/", "title": "Activating TheHive License", "text": ""}, {"location": "thehive/installation/activate-license/#activating-thehive-license", "title": "Activating TheHive License", "text": ""}, {"location": "thehive/installation/activate-license/#overview", "title": "Overview", "text": "<p>TheHive provides different types of licenses to meet the needs of various teams. It includes a free Community License, which offers essential features. For more advanced needs, there are two paid options: the Gold License and the Platinum License.</p> <ul> <li> <p>Gold License: The Gold License is designed for internal response teams who benefit from enhanced case management lifecycles and integration within their organizational infrastructure.</p> </li> <li> <p>Platinum License: The Platinum License is best suited for large teams needing extensive server connections, clustering, and dedicated, continuous support for mission-critical, large-scale incident response operations.</p> </li> </ul> <p>With version 5.3 and later, TheHive is provided with a 14-day Platinum trial, which supports up to 2 organizations and 5 users. After this trial period, TheHive transitions to read-only mode, requiring a valid license for continued full functionality. All users are required to generate a valid license on StrangeBee's portal to use the platform.</p> <p>Note</p> <p>A free Community license with essential features is available. Paid licenses providing access to advanced features are also available, by contacting us.</p> <p>If you are already using TheHive 5.x Community version, please create your account on the License Portal before upgrading to version 5.3 or later. Without this Community License, your interface will be limited to read-only mode.</p>"}, {"location": "thehive/installation/activate-license/#requesting-a-free-community-license", "title": "Requesting a Free Community License", "text": "<p>Follow the steps below to request a free Community License:</p>"}, {"location": "thehive/installation/activate-license/#1-create-an-account-on-the-strangebee-license-portal", "title": "1. Create an Account on the StrangeBee License Portal", "text": "<p>Visit the StrangeBee License Portal registration page, and register using your professional email address.</p> <p></p> <p> </p>"}, {"location": "thehive/installation/activate-license/#2-confirm-your-email-address", "title": "2. Confirm Your Email Address", "text": "<p>Check your email inbox for a confirmation message, click the confirmation link to verify your email address, and wait for your account to be validated by the StrangeBee team.</p> <p></p> <p> </p>"}, {"location": "thehive/installation/activate-license/#3-set-up-your-password", "title": "3. Set Up Your Password", "text": "<p>Once your account is validated, you will receive a notification. Follow the instructions to configure your password.</p> <p></p> <p>The license includes the following capabilities:</p> <ul> <li>Defines the number of users you can create on your platform.</li> <li>Based on the number of users and the number of organizations.</li> <li>Includes a validation and an expiration date.</li> <li>Allows an unlimited number of Unlicensed users and Service users. Service users can use an API key to call all APIs but do not have access to TheHive interface.</li> </ul> <p> </p>"}, {"location": "thehive/installation/activate-license/#4-log-in-to-the-strangebee-license-portal", "title": "4. Log In to the StrangeBee License Portal", "text": "<p>Log in to the portal using your credentials.</p> <p></p> <p> </p>"}, {"location": "thehive/installation/activate-license/#5-request-a-community-license", "title": "5. Request a Community License", "text": "<p>Click on \"Request a Community License\" to proceed to the license generation page.</p> <p></p> <p> </p> <p></p> <p> </p>"}, {"location": "thehive/installation/activate-license/#activating-your-license", "title": "Activating your license", "text": "<p>Follow the steps below to activate your license:</p> <p>Note</p> <p>This procedure applies to both Community and Gold/Platinum licenses. </p>"}, {"location": "thehive/installation/activate-license/#1-retrieve-the-challenge-from-your-thehive-instance", "title": "1. Retrieve the Challenge from Your TheHive Instance", "text": "<p>Open your TheHive instance in a new browser tab, navigate to Admin &gt; Platform Management &gt; License Management, and click \"Update the current license\" to display the challenge.</p> <p></p> <p> </p>"}, {"location": "thehive/installation/activate-license/#2-generate-your-license-key", "title": "2. Generate Your License Key", "text": "<p>Copy the Challenge from TheHive, return to the StrangeBee License Portal, and paste it into the corresponding field on the license request page. Submit the form to generate your license key.</p> <p></p> <p> </p> <p></p> <p> </p>"}, {"location": "thehive/installation/activate-license/#3-activate-your-license-in-thehive", "title": "3. Activate Your License in TheHive", "text": "<p>Copy the generated license key, go back to your TheHive instance, paste the license key into the appropriate field, and confirm to activate your Community License.</p> <p></p> <p> </p>"}, {"location": "thehive/installation/activate-license/#4-enjoy-thehive-community-version", "title": "4. Enjoy TheHive Community Version", "text": "<p>Your TheHive Community edition is now fully activated. You can now explore and use all the features available to you.</p> <p> </p>"}, {"location": "thehive/installation/activate-license/#video-guide", "title": "Video guide", "text": ""}, {"location": "thehive/installation/automated-installation-script/", "title": "Automated Installation Script", "text": ""}, {"location": "thehive/installation/automated-installation-script/#using-the-installation-script", "title": "Using the Installation Script", "text": "<p>TheHive provides users with a streamlined installation process through the automated installation script. This script is designed to simplify the setup process across supported operating systems, ensuring efficiency and ease of deployment.</p> <p>To obtain and install TheHive via our automated installation script, execute the following command in your terminal:</p> <pre><code>wget -q -O /tmp/install.sh https://archives.strangebee.com/scripts/install.sh ; sudo -v ; bash /tmp/install.sh\n</code></pre> <p>This script streamlines the installation procedure, ensuring a successful setup provided that hardware requirements are met. It automates the process of fetching necessary components and configuring the system for optimal performance.</p> <p></p> <p>Upon execution, users are presented with several customizable options tailored to their specific requirements:</p> <ol> <li>Setup Proxy Settings: Configure the host to work seamlessly with an HTTP proxy and integrate custom CA certificates for enhanced security and network compatibility.</li> <li>Install TheHive: Effortlessly deploy TheHive 5 along with its dependencies, enabling users to leverage its powerful features for their projects.</li> <li>Install Cortex: Facilitate the installation of Cortex and its dependencies to enable the execution of Analyzers &amp; Responders as Docker images, ensuring scalability and efficient resource utilization.</li> <li>Install Cortex on the Host: Alternatively, install Cortex and its dependencies directly on the host machine (compatible with Debian and Ubuntu ONLY), offering flexibility in deployment options and optimizing system resources.</li> </ol> <p></p> <p>Note</p> <p>For users requiring more detailed guidance, comprehensive installation guides are available for various deployment scenarios on the following links:</p> <ul> <li>Linux/Unix Based Systems Installation Guide</li> <li>TheHive Cluster Deployment</li> <li>Running with Docker</li> <li>Kubernetes Deployment</li> </ul>"}, {"location": "thehive/installation/deploying-a-cluster/", "title": "Deploying a Cluster", "text": ""}, {"location": "thehive/installation/deploying-a-cluster/#setting-up-a-cluster-with-thehive", "title": "Setting up a Cluster with TheHive", "text": "<p>Note</p> <ul> <li>This documentation applies to TheHive versions 5.4 and later. For earlier versions, please refer to the Akka Configuration.</li> <li>This documentation applies for a fresh installationm for a new instance.</li> </ul> <p>This guide presents configuration examples for setting up a fault-tolerant cluster for TheHive. Each cluster comprises three active nodes, featuring:</p> <ul> <li>Cassandra for the database</li> <li>Elasticsearch for the indexing engine</li> <li>NFS (recommanded), or S3 file storage (for example MINIO)</li> <li>TheHive</li> <li>Haproxy (to demonstrate load balancing)</li> <li>Keepalived (to demonstrate virtual IP setup)</li> </ul> <p>Info</p> <p>These applications can either be installed on separate servers or on the same server. For the purpose of this documentation, we've chosen to demonstrate the setup on three distinct operating systems.</p>"}, {"location": "thehive/installation/deploying-a-cluster/#architecture-diagram", "title": "Architecture Diagram", "text": "<p>The diagram above illustrates the key components and their interactions within the cluster architecture.</p> <p>Each component fulfills a critical role in the functionality and resilience of the cluster:</p> <ul> <li>Cassandra: Acts as the primary database, ensuring robust data storage and retrieval capabilities.</li> <li>Elasticsearch: Serves as the indexing engine, facilitating efficient search operations within TheHive platform.</li> <li>MinIO: Provides S3-compatible object storage, offering scalable and resilient storage solutions for TheHive.</li> <li>TheHive: Central component responsible for incident response management and collaboration within the cluster.</li> <li>Haproxy: Functions as a load balancer, evenly distributing incoming traffic across multiple nodes for improved performance and availability.</li> <li>Keepalived: Facilitates the setup of a virtual IP address, ensuring seamless failover and high availability by redirecting traffic to a standby node in case of failure.</li> </ul> <p>The subsequent sections will provide detailed configuration examples and step-by-step instructions for setting up each component within the cluster environment.</p>"}, {"location": "thehive/installation/deploying-a-cluster/#cassandra-setup", "title": "Cassandra Setup", "text": "<p>When configuring a Cassandra cluster, we aim to establish a setup comprising three active nodes with a replication factor of 3. This configuration ensures that all nodes are active and data is replicated across each node, thus providing tolerance to the failure of a single node, meaning that if one node experiences hardware issues or network disruptions, the other two nodes continue to store and process incident data seamlessly. This fault-tolerant configuration guarantees uninterrupted access to critical security information, enabling the SOC to effectively manage and respond to cyber threats without downtime or data loss.</p> <p>Note: Note: For the purposes of this documentation, we assume that all nodes reside within the same network environment. Ideally, the nodes should be deployed in different racks within the same data center.</p> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#installation-instructions", "title": "Installation Instructions", "text": "<p>To ensure the successful deployment of Cassandra within your cluster, it's essential to install Cassandra on each individual node. Follow the steps outlined in the provided guide.</p> <p>A <code>node</code> in this context refers to each server or machine designated to participate in the Cassandra cluster.</p> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#configuration-instructions", "title": "Configuration Instructions", "text": "<p>For each node in the Cassandra cluster, it's crucial to update the configuration files located at <code>/etc/cassandra/cassandra.yaml</code> with specific parameters to ensure proper functionality. Follow the steps below to modify the configuration:</p> <ol> <li> <p>Update Cassandra Configuration File: Open the <code>/etc/cassandra/cassandra.yaml</code> file on each node using a text editor.</p> /etc/cassandra/cassandra.yaml<pre><code>cluster_name: 'thp'\nnum_tokens: 4\nauthenticator: PasswordAuthenticator\nauthorizer: CassandraAuthorizer\nrole_manager: CassandraRoleManager\ndata_file_directories:\n    - /var/lib/cassandra/data\ncommitlog_directory: /var/lib/cassandra/commitlog\nsaved_caches_directory: /var/lib/cassandra/saved_caches\nseed_provider:\n    - class_name: org.apache.cassandra.locator.SimpleSeedProvider\n    parameters:\n        - seeds: \"&lt;ip node 1&gt;, &lt;ip node 2&gt;, &lt;ip node 3&gt;\"  # (1)\nlisten_interface : eth0 # (2)\nrpc_interface: eth0 # (3)\nendpoint_snitch: GossipingPropertyFileSnitch\n</code></pre> <ol> <li>Ensure to list all IP addresses of the nodes that are included in the cluster</li> <li>Ensure to setup the right interface name</li> <li>Ensure to setup the right interface name</li> </ol> <ul> <li>Cluster Name: Set the name of the Cassandra cluster.</li> <li>Number of Tokens: Configure the number of tokens for each node.</li> <li>Authentication and Authorization: Specify the authenticator, authorizer, and role manager.</li> <li>Directories: Define directories for data, commit logs, and saved caches.</li> <li>Seed Provider: List all IP addresses of nodes included in the cluster (Ensure to list all IP addresses of the nodes that are included in the cluster).</li> <li>Network Interfaces: Set up the appropriate network interfaces (Ensure to setup the right interface name).</li> <li>Endpoint Snitch: Specify the snitch for determining network topology.</li> </ul> <p>For detailed explanations of each parameter in the YAML file, refer to our article on Cassandra configuration which can be found in the following page.</p> </li> <li> <p>Delete Cassandra Topology Properties File: Remove the <code>cassandra-topology.properties</code> file to prevent any conflicts.</p> <pre><code>rm /etc/cassandra/cassandra-topology.properties\n</code></pre> <p> </p> </li> <li> <p>Configure Cassandra GossipingPropertyFileSnitch: In the <code>cassandra-rackdc.properties</code>  file assign the datacenter and rack names for each node.</p> cassandra-rackdc.properties<pre><code>## On node1, edit /etc/cassandra/cassandra-rackdc.properties and add the following conf\ndc=datacenter1\nrack=rack1\n\n## On node2, edit /etc/cassandra/cassandra-rackdc.properties and add the following conf\ndc=datacenter1\nrack=rack2\n\n## On node3, edit /etc/cassandra/cassandra-rackdc.properties and add the following conf\ndc=datacenter1\nrack=rack3\n</code></pre> <p> </p> </li> </ol>"}, {"location": "thehive/installation/deploying-a-cluster/#starting-the-nodes", "title": "Starting the Nodes", "text": "<p>To initiate the Cassandra service on each node, follow these steps:</p> <ol> <li> <p>Start Cassandra Service: Start Cassandra Service: Execute the following command on each node one at a time to start the Cassandra service::</p> <pre><code>service cassandra start\n</code></pre> </li> <li> <p>Verify Node Status: Ensure that all nodes are up and running by checking their status using the <code>nodetool status</code> command. Open a terminal and run:</p> <pre><code>root@cassandra:/# nodetool status\nDatacenter: datacenter1\n===============\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address      Load       Tokens       Owns (effective)  Host ID                               Rack\nUN  &lt;ip node 1&gt;  776.53 KiB  256          100.0%            a79c9a8c-c99b-4d74-8e78-6b0c252abd86  rack1\nUN  &lt;ip node 2&gt;  671.72 KiB  256          100.0%            8fda2906-2097-4d62-91f8-005e33d3e839  rack1\nUN  &lt;ip node 3&gt;  611.54 KiB  256          100.0%            201ab99c-8e16-49b1-9b66-5444044fb1cd  rack1\n</code></pre> </li> </ol> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#initializing-the-database", "title": "Initializing the Database", "text": "<p>To initialize the database, perform the following steps:</p> <ol> <li> <p>Access CQL Shell: On one of the nodes, access the Cassandra Query Language (CQL) shell by running the following command, providing the IP address of the respective node:</p> <pre><code>cqlsh &lt;ip node X&gt; -u cassandra\n</code></pre> <p>Note that the default password for the cassandra account is <code>cassandra</code></p> <p>to prevent security issue, the cassandra default user will be removed from the base.</p> </li> <li> <p>Configure the system authentification replication: Before creating a new users, you have to modify the default replication factor for the keyspace system_auth using the following cql command:</p> <pre><code>ALTER KEYSPACE system_auth WITH replication = {'class': 'NetworkTopologyStrategy', 'replication_factor': 3 };\n</code></pre> </li> <li> <p>Create a custom administrator account: Create a new administrator cassandra role that will replace the default user:</p> <pre><code>CREATE ROLE admin WITH PASSWORD password = 'admin_password' AND LOGIN = true AND SUPERUSER = true;\n</code></pre> <p>After executing the query, exit the CQL shell and reconnect  using the new admin role.</p> <p>Remove the default cassandra user using the following CQL query</p> <pre><code>DROP ROLE cassandra;\n</code></pre> </li> <li> <p>Create Keyspace: Create a keyspace named thehive with a replication factor of 3 and durable writes enabled:</p> <pre><code>CREATE KEYSPACE thehive WITH replication = {'class': 'NetworkTopologyStrategy', 'replication_factor': '3' } AND durable_writes = 'true';\n</code></pre> </li> <li> <p>Create Role and Grant Permissions: Finally, create a role named thehive and grant permissions on the thehive keyspace. Choose a password for the role:</p> <pre><code>CREATE ROLE thehive WITH LOGIN = true AND PASSWORD = 'PASSWORD';\nGRANT ALL PERMISSIONS ON KEYSPACE thehive TO 'thehive';\n</code></pre> </li> </ol>"}, {"location": "thehive/installation/deploying-a-cluster/#optional-enable-encryption-for-client-and-inter-node-communication", "title": "OPTIONAL: Enable encryption for client and inter-node communication", "text": "<p>The following steps aim to enable encryption secure communication between a client machine and a database cluster and between nodes within a cluster.</p>"}, {"location": "thehive/installation/deploying-a-cluster/#client-to-node-encryption", "title": "Client to Node Encryption", "text": "<p>Prerequisite: having configured the necessary certificates for encryption (Keystores and Truststores).</p> <ol> <li> <p>Open the <code>cassandra.yaml</code> Configuration File and edit the <code>client_encryption_options</code> section:</p> cassandra.yaml<pre><code>client_encryption_options:\nenabled: true\noptional: false\nkeystore: &lt;/path/to/node1.keystore&gt;\nkeystore_password: &lt;your_keystore_password&gt;\nrequire_client_auth: true\ntruststore: &lt;/path/to/cassandra.truststore&gt;\ntruststore_password: &lt;your_truststore_password&gt;\nprotocol: TLS\nalgorithm: SunX509\nstore_type: JKS\ncipher_suites: [TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_256_CBC_SHA]\n</code></pre> <ol> <li>Restart the Cassandra Service on All Nodes:</li> </ol> <pre><code>sudo service cassandra restart\n</code></pre> <ol> <li>Check Cassandra Logs: Review the Cassandra logs to ensure there are no errors related to SSL/TLS.</li> </ol> <pre><code>tail -n 100 /var/log/cassandra/system.log | grep -iE \"error|warning\"\n</code></pre> </li> </ol> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#inter-node-encryption", "title": "Inter Node Encryption", "text": "<p>!!! Prerequisite: having configured the necessary certificates for encryption (Keystores and Truststores).</p> <ol> <li> <p>Open the <code>cassandra.yaml</code> Configuration File and edit the <code>server_encryption_options</code> section:</p> cassandra.yaml<pre><code>    server_encryption_options:\n    internode_encryption: all\n    keystore: &lt;/etc/cassandra/node1.keystore&gt;\n    keystore_password: cassandra\n    truststore: &lt;/etc/cassandra/cassandra.truststore&gt;\n    truststore_password: &lt;cassandra&gt;\n    protocol: TLS\n    algorithm: SunX509\n    store_type: JKS\n    cipher_suites: [TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_256_CBC_SHA]\n    require_client_auth: true\n    enabled: true\n</code></pre> <ol> <li>Restart the Cassandra Service on All Nodes:</li> </ol> <pre><code>sudo service cassandra restart\n</code></pre> <ol> <li>Check Cassandra Logs: Review the Cassandra logs to ensure there are no errors related to SSL/TLS.</li> </ol> <pre><code>tail -n 100 /var/log/cassandra/system.log | grep -iE \"error|warning\"\n</code></pre> </li> </ol>"}, {"location": "thehive/installation/deploying-a-cluster/#elasticsearch-setup", "title": "Elasticsearch Setup", "text": ""}, {"location": "thehive/installation/deploying-a-cluster/#installation-instructions_1", "title": "Installation Instructions", "text": "<p>To establish a cluster of 3 active Elasticsearch nodes, follow the installation instructions provided on this page for each node.</p> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#configuration-instructions_1", "title": "Configuration Instructions", "text": "<p>For each node, update the configuration files located at <code>/etc/cassandra/elasticsearch.yml</code> with the following parameters, ensuring to adjust the network.host accordingly.</p> <pre><code>http.host:  0.0.0.0\nnetwork.bind_host:  0.0.0.0\nscript.allowed_types:  inline,stored\ncluster.name: thehive\nnode.name: 'es1'\npath.data: /usr/share/elasticsearch/data\npath.logs: /usr/share/elasticsearch/logs\nnetwork.host: 'es1' # (1)\nhttp.port: 9200\ncluster.initial_master_nodes: \n  - es1\nnode.master: true\ndiscovery.seed_hosts: # (2)\n  - 'es1'\n  - 'es2'\n  - 'es3'\nthread_pool.search.queue_size: 100000\nthread_pool.write.queue_size: 100000\nxpack.security.enabled: true\nxpack.security.http.ssl.enabled: true\nxpack.security.transport.ssl.enabled: true\nxpack.security.http.ssl.key: /usr/share/elasticsearch/config/certs/es1/es1.key\nxpack.security.http.ssl.certificate: /usr/share/elasticsearch/config/certs/es1/es1.crt\nxpack.security.http.ssl.certificate_authorities: /usr/share/elasticsearch/config/certs/ca/ca.crt\nxpack.security.transport.ssl.key: /usr/share/elasticsearch/config/certs/es1/es1.key\nxpack.security.transport.ssl.certificate: /usr/share/elasticsearch/config/certs/es1/es1.crt\nxpack.security.transport.ssl.certificate_authorities: /usr/share/elasticsearch/config/certs/ca/ca.crt\n</code></pre> <ol> <li>Replace es1 with the IP or hostname of the respective node.</li> <li>Keep this parameter with the same value for all nodes to ensure proper cluster discovery.</li> </ol> <p>Warning</p> <p>When configuring Xpack and SSL with Elasticsearch, it's essential to review the documentation specific to your Elasticsearch version for accurate setup instructions. </p> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#custom-jvm-options", "title": "Custom JVM Options", "text": "<p>To customize Java Virtual Machine (JVM) options for Elasticsearch, create a JVM Options File named jvm.options in the directory <code>/etc/elasticsearch/jvm.options.d/</code> with the following lines:</p> <pre><code>-Dlog4j2.formatMsgNoLookups=true\n-Xms4g\n-Xmx4g\n</code></pre> <p>Adjust according to Available Memory - It's important to adjust the heap size values based on the amount of memory available on your system to ensure optimal performance and resource utilization.</p> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#starting-the-nodes_1", "title": "Starting the Nodes", "text": "<p>To start the Elasticsearch service on each node, execute the following command:</p> <pre><code>service elasticsearch start\n</code></pre> <p>This command initiates the Elasticsearch service, allowing the node to join the cluster and begin handling data requests.</p>"}, {"location": "thehive/installation/deploying-a-cluster/#file-storage", "title": "File storage", "text": "<p>To set up a shared file storage for TheHive in a clustered environment, several options are available. The primary goal is to establish a common storage space accessible to all nodes. </p> NFSMinio <p>Using NFS is one of the simplest methods to implement shared file storage. By configuring a single NFS endpoint, all nodes in the cluster can access and share files seamlessly.</p> <ol> <li>Mount the NFS endpoint to /opt/thp/thehive/files on each node.</li> <li>Set permissions: Ensure the thehive user has both read and write access to this directory, including the ability to create subdirectories. This allows TheHive to manage files as required across the cluster.</li> </ol> <p>  MinIO is a scalable, cloud-native object storage system designed to efficiently manage data storage and retrieval in cloud-native environments. Its primary purpose is to provide seamless scalability and reliability for storing and accessing large volumes of data across distributed systems. Within TheHive, MinIO efficiently handles vast amounts of data distributed across multiple nodes, ensuring robustness and optimal performance.</p> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#installation-instructions_2", "title": "Installation Instructions", "text": "<p>To implement MinIO with TheHive, follow the procedure outlined below on all servers in the cluster. For this example, we assume a cluster setup consisting of 3 servers named minio1, minio2, and minio3.</p> <p>Warning</p> <p>Unlike Cassandra and Elasticsearch, MinIO requires a load balancer to be installed in front of the nodes to distribute connections effectively.</p> <ol> <li> <p>Create a Dedicated System Account: First, create a dedicated user and group for MinIO:</p> <pre><code>adduser minio-user\naddgroup minio-user\n</code></pre> </li> <li> <p>Create Data Volumes: Next, create at least 2 data volumes on each server by executing the following commands:</p> <pre><code>mkdir -p /srv/minio/{1,2}\nchown -R minio-user:minio-user /srv/minio\n</code></pre> </li> <li> <p>Setting up Hosts Files: To ensure proper communication between servers in your environment, it's necessary to configure the <code>/etc/hosts</code> file on all servers:</p> /etc/hosts<pre><code>ip-minio-1     minio1\nip-minio-2     minio2\nip-minio-3     minio3\n</code></pre> <p>In the above example, replace ip-minio-1, ip-minio-2, and ip-minio-3 with the respective IP addresses of your MinIO servers. These entries map the server names (minio1, minio2, minio3) to their corresponding IP addresses, ensuring that they can be resolved correctly within your network.</p> </li> <li> <p>Install MinIO: Installing MinIO and MC Command Line Tool, by first downloading the latest DEB packages for MinIO and MC from the official MinIO website and then installing the downloaded DEB packages using the dpkg command:</p> <p>Example for DEB packages</p> <pre><code>wget https://dl.min.io/server/minio/release/linux-amd64/minio.deb\nwget https://dl.min.io/client/mc/release/linux-amd64/mcli.deb\ndpkg -i minio.deb\ndpkg -i mcli.deb\n</code></pre> </li> </ol> <p>You can find the latest versions of the required packages on the MinIO download page. Ensure that you download the appropriate packages for your system architecture and MinIO version requirements.</p> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#configuration-instructions_2", "title": "Configuration Instructions", "text": "<p>To configure MinIO, create or edit the file <code>/etc/default/minio</code> with the following settings:</p> /etc/default/minio<pre><code>MINIO_OPTS=\"--address :9100 --console-address :9001\"\nMINIO_VOLUMES=\"http://minio{1...3}:9100/srv/minio/{1...2}\"\nMINIO_ROOT_USER=thehive\nMINIO_ROOT_PASSWORD=password\nMINIO_SITE_REGION=\"us-east-1\"\n</code></pre> <p>Ensure to replace placeholders such as <code>thehive</code>, <code>password</code>, and <code>us-east-1</code> with your desired values. These settings define the address, volumes, root user credentials, and site region for your MinIO setup.</p> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#enable-and-start-the-service", "title": "Enable and Start the Service", "text": "<p>Once configured, enable and start the MinIO service using the following commands:</p> <pre><code>systemctl daemon-reload\nsystemctl enable minio\nsystemctl start minio.service\n</code></pre> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#prepare-the-service-for-thehive", "title": "Prepare the Service for TheHive", "text": "<p>Before proceeding, ensure that all servers are up and running. The following operations should be performed once all servers are operational, as adding a new server afterward is not supported.</p> <p>Following operations should be performed once all servers are up and running. A new server CAN NOT be added afterward.</p> <ol> <li> <p>Connect to one of the MinIO servers using your browser at port 9100: <code>http://minio:9100</code>. You will need to use the access key and secret key provided during the MinIO setup process.</p> <p></p> </li> <li> <p>Create a bucket named thehive.</p> <p></p> </li> </ol> <p>Ensure that the bucket is successfully created and available on all your MinIO servers. This ensures uniformity and accessibility across your MinIO cluster.</p>"}, {"location": "thehive/installation/deploying-a-cluster/#thehive-setup", "title": "TheHive Setup", "text": "<p>TheHive utilizes the pekko toolkit to effectively manage clusters and enhance scalability. pekko facilitates efficient management of threads and multi-processing, enabling TheHive to handle concurrent tasks seamlessly.</p> <p>Note</p> <p>Apache Pekko is a toolkit designed for building highly concurrent, distributed, and resilient message-driven applications for Java and Scala.  Incorporating Pekko into TheHive's configuration ensures robustness and enhances its ability to handle distributed workloads effectively.  Source: https://pekko.apache.org</p> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#configuration", "title": "Configuration", "text": ""}, {"location": "thehive/installation/deploying-a-cluster/#cluster", "title": "Cluster", "text": "<p>When configuring TheHive for a clustered environment, it's essential to configure pekko to ensure efficient management of the cluster by the application.</p> <p>In this guide, we assume that node 1 serves as the master node. Begin by configuring the <code>pekko</code> component in the <code>/etc/thehive/application.conf</code> file of each node as follows:</p> /etc/thehive/application.conf<pre><code>pekko {\n  cluster.enable = on \n  actor {\n    provider = cluster\n  }\nremote.artery {\n  canonical {\n    hostname = \"&lt;My IP address&gt;\" # (1)\n    port = 2551\n  }\n}\n# seed node list contains at least one active node\ncluster.seed-nodes = [\n                      \"pekko://application@&lt;Node 1 IP address&gt;:2551\",  # (2)\n                      \"pekko://application@&lt;Node 2 IP address&gt;:2551\",\n                      \"pekko://application@&lt;Node 3 IP address&gt;:2551\"\n                    ]\ncluster.min-nr-of-members = 2    # (3)\n}\n</code></pre> <ol> <li>Set the IP address of the current node.</li> <li>Ensure consistency of this parameter across all nodes.</li> <li>Choose a value corresponding to half the number of nodes plus one (for 3 nodes, use 2).</li> </ol> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#database-and-index-engine-configuration", "title": "Database and Index Engine Configuration", "text": "<p>To ensure proper database and index engine configuration for TheHive, update the /etc/thehive/application.conf file as follows:</p> /etc/thehive/application.conf<pre><code>## Database configuration\ndb.janusgraph {\n  storage {\n    ## Cassandra configuration\n    # More information at https://docs.janusgraph.org/basics/configuration-reference/#storagecql\n    backend = cql\n    hostname = [\"&lt;ip node 1&gt;\", \"&lt;ip node 2&gt;\", \"&lt;ip node 3&gt;\"] #(1)\n    # Cassandra authentication (if configured)\n    username = \"thehive\"\n    password = \"PASSWORD\"\n    cql {\n      cluster-name = thp\n      keyspace = thehive\n    }\n  }\n</code></pre> <p>Ensure that you replace <code>&lt;ip node 1&gt;</code>, <code>&lt;ip node 2&gt;</code>, and <code>&lt;ip node 3&gt;</code> with the respective IP addresses of your Cassandra nodes. This configuration ensures proper communication between TheHive and the Cassandra database, facilitating seamless operation of the platform. Additionally, if authentication is enabled for Cassandra, provide the appropriate username and password in the configuration.</p> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#file-storage_1", "title": "File storage", "text": "Using NFS file storageS3 file storage with MINIO (Optional) <p>All nodes should have access to the same file storage. So, ideally, all TheHive nodes should have a similar NFS mount point. Then, on each node:</p> <ol> <li> <p>Ensure thehive user has permissions on the destination folder:</p> <pre><code>chown -R thehive:thehive /opt/thp/thehive/files\n</code></pre> </li> <li> <p>Update the application.conf TheHive configuration file </p> /etc/thehive/application.conf<pre><code># Attachment storage configuration\n# By default, TheHive is configured to store files locally in the folder.\n# The path can be updated and should belong to the user/group running thehive service. (by default: thehive:thehive)\nstorage {\nprovider = localfs\nlocalfs.location = /opt/thp/thehive/files\n}\n</code></pre> </li> </ol> <p>It you decide to go with S3 file storage, this section details how to configure your cluster.</p> <p>To enable S3 file storage for each node in TheHive cluster, add the relevant storage configuration to the <code>/etc/thehive/application.conf</code> file. Below is an example configuration for the first node:</p> /etc/thehive/application.conf<pre><code>storage {\nprovider: s3\ns3 {\n    bucket = \"thehive\"\n    readTimeout = 1 minute\n    writeTimeout = 1 minute\n    chunkSize = 1 MB\n    endpoint = \"http://&lt;IP_MINIO_1&gt;:9100\"\n    accessKey = \"thehive\"\n    aws.credentials.provider = \"static\"\n    aws.credentials.secret-access-key = \"password\"\n    access-style = path\n    aws.region.provider = \"static\"\n    aws.region.default-region = \"us-east-1\"\n    }\n}\n</code></pre> <ul> <li> <p>The provided configuration is backward compatible, ensuring compatibility with existing setups.</p> </li> <li> <p>Each TheHive server can connect to one MinIO server, or you can choose to distribute connections across all nodes of the cluster using a load balancer (refer to the example for TheHive).</p> </li> </ul> <p> </p>"}, {"location": "thehive/installation/deploying-a-cluster/#start-the-service", "title": "Start the service", "text": "<p>Once the configuration is updated, start TheHive service using the following command:</p> <pre><code>systemctl start thehive\n</code></pre> <p>This command initiates TheHive service, enabling S3 file storage functionality as configured. Make sure to execute this command on each node of TheHive cluster to ensure proper functionality across the entire setup.</p>"}, {"location": "thehive/installation/deploying-a-cluster/#load-balancing-with-haproxy", "title": "Load Balancing with HAProxy", "text": "<p>  To enhance the availability and distribution of HTTP requests across TheHive cluster, you can integrate a load balancer. The load balancer efficiently distributes incoming requests among the cluster nodes, ensuring optimal resource utilization. Notably, client affinity is not required, meaning that a client does not need to consistently connect to the same node.</p> <p>Below is a basic example of what should be added to the HAProxy configuration file, typically located at <code>/etc/haproxy/haproxy.cfg</code>. This configuration should be consistent across all HAProxy instances:</p> <pre><code># Listen on all interfaces, on port 80/tcp\nfrontend thehive-in\n        bind &lt;VIRTUAL_IP&gt;:80                # (1)\n        default_backend thehive\n# Configure all cluster node\nbackend thehive\n            balance roundrobin\n            server node1 THEHIVE-NODE1-IP:9000 check   # (2)\n            server node2 THEHIVE-NODE2-IP:9000 check\n            server node3 THEHIVE-NODE3-IP:9000 check\n</code></pre> <ol> <li>Configure the virtual IP address dedicated to the cluster.</li> <li>Specify the IP addresses and ports of all TheHive nodes to distribute traffic evenly across the cluster.</li> </ol> <p>This configuration ensures that incoming HTTP requests are efficiently distributed among the cluster nodes.</p>"}, {"location": "thehive/installation/deploying-a-cluster/#virtual-ip-with-keepalived", "title": "Virtual IP with Keepalived", "text": "<p>  If you choose to use Keepalived to set up a virtual IP address for your load balancers, this section provides a basic example of configuration.</p> <p>Keepalived is a service that monitors the status of load balancers (such as HAProxy) installed on the same system. In this setup, LB1 acts as the master, and the virtual IP address is assigned to LB1. If the HAProxy service stops running on LB1, Keepalived on LB2 takes over and assigns the virtual IP address until the HAProxy service on LB1 resumes operation.</p> <pre><code>vrrp_script chk_haproxy {     # (1)\n      script \"/usr/bin/killall -0 haproxy\"  # cheaper than pidof\n      interval 2 # check every 2 seconds\n      weight 2 # add 2 points of priority if OK\n    }\n    vrrp_instance VI_1 {\n      interface eth0\n      state MASTER\n      virtual_router_id 51\n      priority 101 # 101 on primary, 100 on secondary      # (2)\n      virtual_ipaddress {\n        10.10.1.50/24 brd 10.10.1.255 dev eth0 scope global  # (3)\n      }\n      track_script {\n        chk_haproxy\n    } \n}\n</code></pre> <ol> <li>Requires Keepalived version &gt; 1.1.13.</li> <li>Set `priority 100`` for a secondary node.</li> <li> This is an example. Replace it with your actual IP address and broadcast address.</li> </ol>"}, {"location": "thehive/installation/deploying-a-cluster/#troubleshooting", "title": "Troubleshooting", "text": "<p>Issues can be encountered during cluster deployment with TheHive. Here are some of the most commonly encountered ones and their solutions:</p> <ul> <li> <p>Example 1: InvalidRequest Error</p> <pre><code>InvalidRequest: code=2200 [Invalid query] message=\u201dorg.apache.cassandra.auth.CassandraRoleManager doesn\u2019t support PASSWORD\u201d.`\n</code></pre> <p>Resolution:</p> <p>To resolve this error, set the value <code>authenticator: PasswordAuthenticator</code> in the <code>cassandra.yaml</code> configuration file.</p> </li> </ul> <p> </p> <ul> <li> <p>Example 2: UnauthorizedException Caused by Inconsistent Replication</p> <pre><code>Caused by: java.util.concurrent.ExecutionException: com.datastax.driver.core.exceptions.UnauthorizedException: Unable to perform authorization of permissions: Unable to perform authorization of super-user permission: Cannot achieve consistency level LOCAL_ONE\n</code></pre> <p>Resolution:</p> <p>To address this issue, execute the following CQL command to adjust the replication settings for the system_auth keyspace:</p> <pre><code>ALTER KEYSPACE system_auth WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3 };\n</code></pre> <p>After making this adjustment, perform a full repair using the <code>nodetool repair -full</code> command to ensure data consistency across the cluster.</p> </li> </ul> <p> </p>"}, {"location": "thehive/installation/docker/", "title": "Running with Docker", "text": ""}, {"location": "thehive/installation/docker/#running-thehive-with-docker", "title": "Running TheHive with Docker", "text": "<p>TheHive fully supports Docker, allowing users to quickly deploy and manage their instance of the platform using Docker containers.</p> <p>We provides and maintain several setup profiles for TheHive and Cortex available on GitHub. This guide will walk you through choose the right profile and setting up TheHive using Docker.</p>"}, {"location": "thehive/installation/docker/#prerequisites", "title": "Prerequisites", "text": ""}, {"location": "thehive/installation/docker/#software-requirements", "title": "Software Requirements", "text": "<ul> <li>Docker Engine: Version <code>v23.0.15</code> or later. Installation instructions</li> <li>Docker Compose Plugin: Version <code>v2.20.2</code> or later. Installation instructions</li> <li>jq: jq installation instructions</li> <li>Permissions: The current user should have at least <code>sudo</code> permissions.</li> </ul>"}, {"location": "thehive/installation/docker/#hardware-requirements", "title": "Hardware Requirements", "text": "<p>Hardware requirements will depend on the deployment profile being used. For example, for testing deployments, a CPU with 4 vCPUs and 8 GB RAM is recommended, while for high-performance deployments for TheHive on a dedicated server, a CPU with 8 vCPUs and 32 GB RAM is recommended. For more detailed requirements, please refer to the GitHub link provided below.</p> <p>Basically, two hardware profiles are recommended to run the full stack for TheHive on a single server (virtual of physical): </p> <ol> <li>4vCPUs, 16 GB of RAM and 100GB of storage is recommended for most use cases, </li> <li>8vCPUs, 32GB of RAM and 150GB of storage for intensive use cases.</li> </ol>"}, {"location": "thehive/installation/docker/#clone-the-repository", "title": "Clone the Repository", "text": "<p>Clone the StrangeBee Docker repository to your local machine:</p> <pre><code>git clone https://github.com/StrangeBeeCorp/docker.git\n</code></pre> <p></p>"}, {"location": "thehive/installation/docker/#deployment-profiles", "title": "Deployment Profiles", "text": "<p>BEFORE RUNNING ANY COMMAND</p> <p>Please, read carefully the documentation related to the profile you want to use (the <code>README.md</code> files you'll find in the GitHub repository).</p> <p>The prebuilt deployment profiles allow you to quickly set up TheHive based on your specific use case. Choose from the following deployment options:</p> Testing Environment <p>Deploys both TheHive (and Cortex) on a single server for testing purposes. Link to the testing profile</p> Production Environment #1 - TheHive <p>Single server deployment for intensive use of TheHive. Link to the production profile</p> Production Environment #2 - TheHive <p>High-performance deployment for TheHive on a dedicated server. Link to the high-performance production profile</p> <p>You can choose the scenario that best suits your needs by selecting the appropriate Docker Compose YAML file.</p>"}, {"location": "thehive/installation/docker/#starting-thehive", "title": "Starting TheHive", "text": "<p>The application stack includes several utility scripts, one of which is the <code>init.sh</code> script, which performs the following tasks for you:</p> <ul> <li>Prompt for a service name to include in the Nginx server certificate.</li> <li>Initialize the <code>secret.conf</code> files for TheHive and Cortex.</li> <li>Generate a self-signed certificate if none is found in the <code>./certificates</code> directory.</li> <li>Create a <code>.env</code> file containing user/group information and other application settings.</li> <li>Verify file and folder permissions to ensure proper access rights.</li> </ul> <p>Note</p> <p>TheHive application will run under the user account and group that execute the initialization script.</p> <p>Follow the steps below to initialize the environment.</p>"}, {"location": "thehive/installation/docker/#step-1-run-the-initialization-script", "title": "Step 1: Run the Initialization Script", "text": "<p>Execute the <code>init.sh</code> script to set up the necessary configurations:</p> <pre><code>bash ./scripts/init.sh\n</code></pre>"}, {"location": "thehive/installation/docker/#step-2-run-the-application-stack", "title": "Step 2: Run the application stack", "text": "<pre><code>docker compose up\n</code></pre> <p>or </p> <pre><code>docker compose up -d\n</code></pre> <p> </p> <p>How to start quickly with prod1-thehive environment ?</p> <ol> <li>Clone the repository</li> <li>Open prod1-thehive folder</li> <li>Initialize the environment</li> <li>Start the application stack</li> </ol> <p></p>"}, {"location": "thehive/installation/docker/#step-3-access-the-application", "title": "Step 3: Access the application", "text": "<p>Open your browser, and navigate to: </p> <ul> <li><code>https://HOSTNAME_OR_IP/thehive</code> to connect to TheHive if using the testing profile</li> <li><code>https://HOSTNAME_OR_IP/</code> to connect to TheHive if using the production profiles</li> </ul> <p> </p> <p></p>"}, {"location": "thehive/installation/docker/#additional-configuration", "title": "Additional Configuration", "text": "<p>For more detailed information on the directory structure, services, scripts, and their respective functions, please refer to the <code>README.md</code> file located within each deployment profile:</p> <ul> <li>Testing Environment</li> <li>Production Environment #1 - TheHive</li> <li>Production Environment #2 - TheHive</li> </ul>"}, {"location": "thehive/installation/docker/#thehive-docker-entrypoint-options", "title": "TheHive Docker Entrypoint Options", "text": "<p>To view a list of all supported options for the Docker entry point, use the -h flag:</p> <pre><code>docker run --rm strangebee/thehive:&lt;version&gt; -h\n</code></pre> <p>The output will display available options, allowing you to configure TheHive according to your requirements.</p> <p>Available Options:</p> <ul> <li><code>--config-file &lt;file&gt;</code>: Specifies the path to the configuration file.</li> <li><code>--no-config</code>: Prevents TheHive from attempting to configure itself, including adding secrets and Elasticsearch settings.</li> <li><code>--no-config-secret</code>: Excludes the addition of a randomly generated secret from the configuration.</li> <li><code>--secret &lt;secret&gt;</code>: Sets the secret used to secure sessions.</li> <li><code>--show-secret</code>: Displays the generated secret.</li> <li><code>--no-config-db</code>: Disables automatic configuration of the database.</li> <li><code>--cql-hostnames &lt;host&gt;,&lt;host&gt;,...</code>: Resolves these hostnames to locate Cassandra instances.</li> <li><code>--cql-username &lt;username&gt;</code>: Specifies the username for the Cassandra database.</li> <li><code>--cql-password &lt;password&gt;</code>: Specifies the password for the Cassandra database.</li> <li><code>--cql-datacenter &lt;datacenter&gt;</code>: Specifies the name of the Cassandra datacenter used by the TheHive node. This parameter is new as of version 5.4.7 and can have different values for each node in cluster mode.</li> <li><code>--no-cql-wait</code>: Skips waiting for Cassandra to become available.</li> <li><code>--bdb-directory &lt;path&gt;</code>: Defines the location of the local database if Cassandra is not used (default: /data/db).</li> <li><code>--index-backend</code>: Specifies the backend to use for index, either 'lucene' or 'elasticsearch' (default: lucene).</li> <li><code>--es-hostnames</code>: Specifies the Elasticsearch instances used for index.</li> <li><code>--es-index</code>: Specifies the Elasticsearch index name to be used (default: thehive).</li> <li><code>--no-config-storage</code>: Disables automatic configuration of storage.</li> <li><code>--storage-directory &lt;path&gt;</code>: Specifies the location of local storage if S3 is not used (default: /data/files).</li> <li><code>--s3-endpoint &lt;endpoint&gt;</code>: Specifies the endpoint of S3 or other object storage if used, with 's3.amazonaws.com' for AWS S3.</li> <li><code>--s3-region &lt;region&gt;</code>: Specifies the S3 region, optional for MinIO.</li> <li><code>--s3-bucket &lt;bucket&gt;</code>: Specifies the name of the bucket to use (default: thehive), which must already exist.</li> <li><code>--s3-access-key &lt;key&gt;</code>: Specifies the S3 access key (required for S3).</li> <li><code>--s3-secret-key &lt;key&gt;</code>: Specifies the S3 secret key (required for S3).</li> <li><code>--s3-use-path-access-style</code>: Sets this flag if using MinIO or another non-AWS S3 provider, defaulting to virtual host style.</li> <li><code>--no-config-cortex</code>: Excludes Cortex configuration.</li> <li><code>--cortex-proto &lt;proto&gt;</code>: Defines the protocol to connect to Cortex (default: http).</li> <li><code>--cortex-port &lt;port&gt;</code>: Defines the port to connect to Cortex (default: 9001).</li> <li><code>--cortex-hostnames &lt;host&gt;,&lt;host&gt;,...</code>: Resolves these hostnames to locate Cortex instances.</li> <li><code>--cortex-keys &lt;key&gt;,&lt;key&gt;,...</code>: Defines Cortex keys.</li> <li><code>--kubernetes</code>: Utilizes the Kubernetes API to join other nodes.</li> <li><code>--kubernetes-pod-label-selector &lt;selector&gt;</code>: Specifies the selector to use to select other pods running the app (default app=thehive).</li> <li><code>--cluster-min-nodes-count &lt;count&gt;</code>: Specifies the minimum number of nodes to form a cluster (default to 1).</li> <li><code>migrate &lt;param&gt; &lt;param&gt; ...</code>: Runs the migration tool.</li> <li><code>cloner &lt;param&gt; &lt;param&gt; ...</code>: Runs the cloner tool. </li> </ul> <p> </p>"}, {"location": "thehive/installation/kubernetes/", "title": "Kubernetes Deployment", "text": ""}, {"location": "thehive/installation/kubernetes/#deploy-on-kubernetes", "title": "Deploy on Kubernetes", "text": "<p>To deploy TheHive on Kubernetes, you can utilize the Docker image. For detailed instructions on how to use the Docker image, please refer to the docker image documentation</p>"}, {"location": "thehive/installation/kubernetes/#important-considerations", "title": "Important Considerations", "text": "<ul> <li> <p>While this setup is suitable for testing TheHive, it's recommended to enhance the data stores (Elasticsearch, Cassandra, and Minio) for production use by setting up clustering and storage volumes. Refer to the respective documentation for instructions on deploying on Kubernetes for production use.</p> </li> <li> <p>The volumes used in this configuration are <code>emptyDir</code>s, which means the data will be lost when a pod is restarted. If you want to persist your data, update the volume description accordingly.</p> </li> <li> <p>To deploy multiple nodes, you will need to update your license as only one node is included in the Community License.</p> </li> </ul>"}, {"location": "thehive/installation/kubernetes/#deploying-thehive", "title": "Deploying TheHive", "text": "<p>You can download the Kubernetes configuration file here. This configuration will deploy the following components:</p> <ul> <li>1 instance of TheHive</li> <li>1 instance of Cassandra</li> <li>1 instance of Elasticsearch</li> <li>1 instance of Minio</li> </ul> <p>You can initiate the deployment by executing the following command:</p> <pre><code>kubectl apply -f kubernetes.yml\n</code></pre> <p>This command will create a namespace named <code>thehive</code> and deploy the instances within it.</p>"}, {"location": "thehive/installation/kubernetes/#kubernetes-configuration", "title": "Kubernetes Configuration", "text": "<p>In a Kubernetes environment with multiple TheHive pods, the application needs to form a cluster between its nodes. To achieve this, it utilizes the pekko discovery method with the Kubernetes API.</p> <p>To enable this functionality, you need:</p> <ul> <li>A service account with permissions to connect to the Kubernetes API</li> <li>Configuration to instruct TheHive to use the Kubernetes API for discovering other nodes</li> </ul> <p> </p>"}, {"location": "thehive/installation/kubernetes/#role-based-access-control-rbac", "title": "Role-Based Access Control (RBAC)", "text": "<p>Create a ServiceAccount named thehive with the necessary permissions to access the running pods:</p> <pre><code>---\n#\n# Create a role, `pod-reader`, that can list pods and\n# bind the default service account in the namespace\n# that the binding is deployed to to that role.\n#\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: pod-reader\nrules:\n  - apiGroups: [\"\"] # \"\" indicates the core API group\n    resources: [\"pods\"]\n    verbs: [\"get\", \"watch\", \"list\"]\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: thehive\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: read-pods\nsubjects:\n  - kind: ServiceAccount\n    name: thehive\nroleRef:\n  kind: Role\n  name: pod-reader\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p> </p>"}, {"location": "thehive/installation/kubernetes/#deployment", "title": "Deployment", "text": "<p>In your pod/deployment specification, specify the created service account. Also, ensure to add a label and a <code>POD_IP</code> environment variable.</p> <pre><code>metadata:\n  labels:\n    app: thehive\nspec:\n  serviceAccountName: thehive\n  containers:\n  - name: thehive\n    image: ...\n    env:\n      # Make sure that the container can know its own IP\n      - name: POD_IP\n        valueFrom:\n          fieldRef:\n            fieldPath: status.podIP\n</code></pre> <p> </p>"}, {"location": "thehive/installation/kubernetes/#configuration", "title": "Configuration", "text": ""}, {"location": "thehive/installation/kubernetes/#using-docker-entrypoint", "title": "Using Docker Entrypoint", "text": "<p>If you use the Docker entry point, include the <code>--kubernetes</code> flag. Additionally, you can use the following options:</p> <pre><code>--kubernetes-pod-label-selector &lt;selector&gt;  | Selector to use to select other pods running the app (default app=thehive)\n--cluster-min-nodes-count &lt;count&gt;           | Minimum number of nodes to form a cluster (default to 1)\n</code></pre> <p> </p>"}, {"location": "thehive/installation/kubernetes/#using-custom-applicationconf", "title": "Using Custom application.conf", "text": "<p>If you use your own application.conf file, add the following configurations:</p> <pre><code>pekko.remote.artery.canonical.hostname = ${?POD_IP}\nsingleInstance = false\npekko.management {\n  cluster.bootstrap {\n    contact-point-discovery {\n      discovery-method = kubernetes-api\n      # Set the minimum number of pods to form a cluster\n      required-contact-point-nr = 1\n    }\n  }\n}\npekko.extensions += \"pekko.management.cluster.bootstrap.ClusterBootstrap\"\n\npekko.discovery {\n  kubernetes-api {\n    # Set here the pod selector to use for thehive pods\n    pod-label-selector = \"thehive\"\n  }\n}\n</code></pre> <p> </p>"}, {"location": "thehive/installation/kubernetes/#pod-probes", "title": "Pod Probes", "text": "<p>You can use the following probes to ensure the application starts and runs correctly. It's recommended to enable these probes after validating the correct start of the application.</p> <p>Tip</p> <p>When applying a large migration, deactivate these probes as the HTTP server will not start until the migration is complete.</p> <pre><code>startupProbe:\n    httpGet:\n        path: /api/v1/status/public\n        port: 9000\n    failureThreshold: 30\n    periodSeconds: 10\nlivenessProbe:\n    httpGet:\n        path: /api/v1/status/public\n        port: 9000\n    periodSeconds: 10\n</code></pre>"}, {"location": "thehive/installation/kubernetes/#cleanup", "title": "Cleanup", "text": "<p>To delete all resources belonging to the <code>thehive</code> namespace, use the following command:</p> <pre><code>kubectl delete namespace thehive\n</code></pre>"}, {"location": "thehive/installation/kubernetes/#troubleshooting", "title": "Troubleshooting", "text": "<p>Below are some common issues that may arise when running TheHive with Docker:</p> <ul> <li> <p>Example 1: Error during Database Initialization</p> <p>If your logs contain the following lines:</p> <pre><code>[error] o.t.s.m.Database [|] ***********************************************************************\n[error] o.t.s.m.Database [|] * Database initialization has failed. Restart application to retry it *\n[error] o.t.s.m.Database [|] ***********************************************************************\n</code></pre> <p>This indicates that an error occurred when attempting to create the database schema. Beneath these lines, you should find additional details regarding the cause of the error.</p> <p>Resolution:</p> <ol> <li> <p>Cassandra / Elasticsearch Unavailability: Ensure that both databases are running correctly and that TheHive can establish connections to them.</p> <p>You can try starting both databases in the Kubernetes cluster before initiating TheHive by setting TheHive deployment to <code>replicas: 0</code>.</p> </li> <li> <p>Invalid Data in Cassandra / Elasticsearch: Elasticsearch acts as an index for Cassandra, and if the data between the two becomes unsynchronized, errors may occur when accessing the data.</p> <p>If this is the first setup of the cluster, consider deleting both database volumes/data and restarting both the databases and TheHive.</p> </li> </ol> </li> </ul> <p> </p>"}, {"location": "thehive/installation/migration/", "title": "Migration from TheHive 3.x", "text": ""}, {"location": "thehive/installation/migration/#migration-from-thehive-3x", "title": "Migration from TheHive 3.x", "text": "<p>This documentation outlines the supported versions, prerequisites, configuration steps, and the migration process.</p> <p>The migration from TheHive 3.x to TheHive 5.x involves transferring data stored in Elasticsearch. TheHive 5.x is provided with a tool to help you migrate your data.</p> <p>The migration tool is located in <code>/opt/thehive/bin/migrate</code>. </p>"}, {"location": "thehive/installation/migration/#supported-versions", "title": "Supported Versions", "text": "<p>The migration tool facilitates the transition from both TheHive 3.4.x and 3.5.x versions.</p>"}, {"location": "thehive/installation/migration/#pre-requisites", "title": "Pre-requisites", "text": "<p>Before initiating the migration, ensure the following:</p> <ul> <li> <p>TheHive v5.x must be installed on the system where the migration tool will run.</p> </li> <li> <p>TheHive must be properly configured, including database, index, and file storage settings.</p> </li> <li> <p>Stop the <code>thehive</code> service on the target server using the command: service thehive stop.</p> </li> <li> <p>Ensure the migration tool has access to the Elasticsearch database used by TheHive 3.x and the configuration file of TheHive 3.x instance.</p> </li> </ul>"}, {"location": "thehive/installation/migration/#configuration-of-thehive", "title": "Configuration of TheHive", "text": ""}, {"location": "thehive/installation/migration/#user-domain-configuration", "title": "User Domain Configuration", "text": "<p>Users in TheHive are identified by their email addresses. To migrate users from TheHive 3, a domain must be appended to usernames. By default, TheHive v5.x includes a domain named <code>thehive.local</code>. Starting the migration without explicitly specifying a domain name will result in migrating all users with a username formatted like  <code>user@thehive.local</code>. </p> <p>To specify a custom domain, update the <code>auth.defaultUserDomain</code> setting in the configuration file (<code>/etc/thehive/application.conf</code>):</p> <pre><code>    auth.defaultUserDomain: \"mydomain.com\"\n</code></pre> <p>This ensures that imported users from TheHive 3.x are formatted as <code>user@mydomain.com</code>.</p>"}, {"location": "thehive/installation/migration/#running-the-migration", "title": "Running the Migration", "text": "<p>Follow the steps below to execute the migration:</p> <ol> <li> <p>Prepare, install, and configure TheHive v5.x as per the associated guides</p> </li> <li> <p>Ensure TheHive 5 is not running before initiating the migration for optimal performance.</p> </li> <li> <p>Execute the <code>migrate</code> command:</p> </li> </ol> <pre><code>  /opt/thehive/bin/migrate\n</code></pre> <p>Warning</p> <p>The migration tool works on a single node only, thus the configuration file must not contain cluster configuration (<code>akka.cluster</code>).</p> <p>Info</p> <p>It is recommended to execute this program under the user responsible for running TheHive service (thehive if you are installing the application using DEB or RPM packages).</p> <p> </p>"}, {"location": "thehive/installation/migration/#thehive-migration-tool-options", "title": "TheHive Migration Tool Options", "text": "<p>The migration tool for TheHive offers a comprehensive set of options to facilitate the migration process. Below is a detailed list of available options:</p> <ul> <li><code>-v, --version</code>: Displays the version of the migration tool.</li> <li><code>-h, --help</code>: Displays the help message detailing the usage of the migration tool.</li> <li><code>-l, --logger-config &lt;file&gt;</code>: Specifies the path to the logback configuration file.</li> <li><code>-c, --config &lt;file&gt;</code>: Specifies the global configuration file for TheHive.</li> <li><code>-i, --input &lt;file&gt;</code>: Specifies the path to the configuration file of TheHive 3.</li> <li><code>-o, --output &lt;file&gt;</code>: Specifies the path to the configuration file for TheHive 5.</li> <li><code>-d, --drop-database</code>: Drops TheHive 5 database before migration.</li> <li><code>-r, --resume</code>: Resumes migration or migrates on an existing database.</li> <li><code>-m, --main-organisation &lt;organisation&gt;</code>: Specifies the main organization for migration.</li> <li><code>-u, --es-uri http://ip1:port,ip2:port</code>: Specifies the Elasticsearch URIs for TheHive 3.</li> <li><code>-x, --es-index &lt;index&gt;</code>: Specifies the Elasticsearch index name for TheHive 3.</li> <li><code>-x, --es-index-version &lt;index&gt;</code>: Specifies the version number for the Elasticsearch index name (default: autodetect).</li> <li><code>-a, --es-keepalive &lt;duration&gt;</code>: Specifies the Elasticsearch keepalive duration.</li> <li><code>-p, --es-pagesize &lt;value&gt;</code>: Specifies the page size for Elasticsearch queries.</li> <li><code>-s, --es-single-type &lt;bool&gt;</code>: Specifies whether Elasticsearch uses a single type.</li> <li><code>-y, --transaction-pagesize &lt;value&gt;</code>: Specifies the page size for each transaction.</li> <li><code>-t, --thread-count &lt;value&gt;</code>: Specifies the number of threads for migration.</li> <li><code>-k, --integrity-checks</code>: Runs integrity checks after migration.</li> <li><code>--max-case-age &lt;duration&gt;</code>: Migrates cases younger than the specified duration.</li> <li><code>--min-case-age &lt;duration&gt;</code>: Migrates cases older than the specified duration.</li> <li><code>--case-from-date &lt;date&gt;</code>: Migrates cases created from the specified date.</li> <li><code>--case-until-date &lt;date&gt;</code>: Migrates cases created until the specified date.</li> <li><code>--case-from-number &lt;number&gt;</code>: Migrates cases starting from the specified case number.</li> <li><code>--case-until-number &lt;number&gt;</code>: Migrates cases up to the specified case number.</li> <li><code>--max-alert-age &lt;duration&gt;</code>: Migrates alerts younger than the specified duration.</li> <li><code>--min-alert-age &lt;duration&gt;</code>: Migrates alerts older than the specified duration.</li> <li><code>--alert-from-date &lt;date&gt;</code>: Migrates alerts created from the specified date.</li> <li><code>--alert-until-date &lt;date&gt;</code>: Migrates alerts created until the specified date.</li> <li><code>--include-alert-types &lt;type&gt;,&lt;type&gt;...</code>: Migrates only alerts with the specified types.</li> <li><code>--exclude-alert-types &lt;type&gt;,&lt;type&gt;...</code>: Excludes alerts with the specified types from migration.</li> <li><code>--include-alert-sources &lt;source&gt;,&lt;source&gt;...</code>: Migrates only alerts with the specified sources.</li> <li><code>--exclude-alert-sources &lt;source&gt;,&lt;source&gt;...</code>: Excludes alerts with the specified sources from migration.</li> <li><code>--max-audit-age &lt;duration&gt;</code>: Migrates audits younger than the specified duration.</li> <li><code>--min-audit-age &lt;duration&gt;</code>: Migrates audits older than the specified duration.</li> <li><code>--audit-from-date &lt;date&gt;</code>: Migrates audits created from the specified date.</li> <li><code>--audit-until-date &lt;date&gt;</code>: Migrates audits created until the specified date.</li> <li><code>--include-audit-actions &lt;value&gt;</code>: Migrates only audits with the specified actions (Update, Creation, Delete).</li> <li><code>--exclude-audit-actions &lt;value&gt;</code>: Excludes audits with the specified actions from migration.</li> <li><code>--include-audit-objectTypes &lt;value&gt;</code>: Migrates only audits with the specified object types (case, case_artifact, case_task, etc.).</li> <li><code>--exclude-audit-objectTypes &lt;value&gt;</code>: Excludes audits with the specified object types from migration.</li> <li><code>--case-number-shift &lt;value&gt;</code>: Transposes case numbers by adding the specified value.</li> </ul> <p> </p>"}, {"location": "thehive/installation/migration/#usage-examples", "title": "Usage Examples", "text": "<ul> <li>Import Cases/Alerts not older than X days/hours.</li> <li>Import Cases/Alerts with specific ID numbers.</li> <li>Import a portion of the Audit trail.</li> <li>...</li> </ul>"}, {"location": "thehive/installation/migration/#basic-migration-command", "title": "Basic Migration Command", "text": "<p>To migrate data to a new instance of TheHive, use the following command:</p> <pre><code>/opt/thehive/bin/migrate \\\n  --output /etc/thehive/application.conf \\\n  --main-organisation myOrganisation \\\n  --es-uri http://ELASTICSEARCH_IP_ADDRESS:9200 \\\n  --es-index the_hive\n</code></pre> <p>Options Description:</p> <ul> <li>--output: Specifies the configuration file path for TheHive 5, which must include database and file storage configurations.</li> <li>--main-organisation: Specifies the organization to create during migration.</li> <li>--es-uri: Specifies the URL of the Elasticsearch server. If Elasticsearch authentication is enabled, a configuration file for TheHive3 (--input) is required.</li> <li>--es-index: Specifies the Elasticsearch index used for migration.</li> </ul> Option Description <code>--output</code> Specifies the configuration file path for TheHive 5, which must include database and file storage configurations; <code>--main-organisation</code> Specifies the organization to create during migration; <code>--es-uri</code> Specifies the URL of the Elasticsearch server. If Elasticsearch authentication is enabled, a configuration file for TheHive3 (--input) is required; <code>--es-index</code> Specifies the Elasticsearch index used for migration; <p>Info</p> <p>The migration process duration varies significantly based on data volume, ranging from several hours to days. It is strongly advised not to start TheHive application during migration to ensure data integrity.</p>"}, {"location": "thehive/installation/migration/#resuming-an-incomplete-migration", "title": "Resuming an Incomplete Migration", "text": "<p>If your migration process has been interrupted or only a portion of the data has been migrated, you can resume the migration using the tool with the <code>--resume</code> parameter. This parameter ensures that data is not duplicated if it already exists in the destination system.</p>"}, {"location": "thehive/installation/migration/#merging-multiple-thehive-3-data-into-one-thehive-5-instance", "title": "Merging Multiple TheHive 3 Data into One TheHive 5 Instance", "text": "<p>The migration tool supports multiple executions to merge different TheHive 3 datasets into a single TheHive 5 instance. Each migration execution can specify a different target organization. To avoid conflicts in case numbers, where a case with the same number already exists, you can use the <code>--case-number-shift</code> parameter to adjust the case numbers accordingly.</p>"}, {"location": "thehive/installation/migration/#using-authentication-on-cassandra", "title": "Using Authentication on Cassandra", "text": "<p>If you're utilizing a dedicated account on Cassandra to access TheHive 4 data, ensure that the user has permissions to create keyspaces in the database.</p> <pre><code>GRANT CREATE on ALL KEYSPACES to username;\n</code></pre>"}, {"location": "thehive/installation/migration/#migration-logs", "title": "Migration Logs", "text": "<p>During the migration process, the tool generates logs to provide insights into the progress. By default, a log is generated approximately every 10 seconds, detailing various aspects of the migration, including the status of cases, alerts, and other entities.</p> <pre><code>[info] o.t.t.m.Migrate - [Migrate cases and alerts] CaseTemplate/Task:32 Organisation:1/1 Case/Task:160/201 Case:31/52 Job:103/138 ObservableType:3/17 Alert:25/235 Audit:3207/2986 CaseTemplate:6/6 Alert/Observable:700(52ms) Case/Observable:1325/1665 User:9/9 CustomField:13/13 Case/Task/Log:20/27\n</code></pre> <p>Please note that the numbers of observables, cases, and other entities are estimations and may not represent exact values due to the complexity of computation involved.</p> <p>Files from MISP imported with TheHive 2.13 and earlier</p> <p>It is important to notice that migrating Cases/Alerts containing MISP event that were imported with TheHive 2.13 (Sept 2017) or older will cause observable files not being imported in TheHive 5. </p> <p>Indeed, until this version, TheHive referenced the file to the <code>AttributeId</code> in MISP and was not automatically downloaded. It then could generate a log like this: </p> <pre><code>[warn] o.t.t.m.t.Input - Pre 2.13 file observables are ignored in MISP alert ffa3a8503ab0cd4f99fc6937a8e9b827\n</code></pre>"}, {"location": "thehive/installation/migration/#starting-thehive", "title": "Starting TheHive", "text": "<p>Once the migration process has successfully completed, you can start TheHive. However, during the initial startup, data indexing occurs, and the service may not be immediately available. This indexing process may take some time.</p> <p>Warning</p> <p>During the initial startup, refrain from stopping or restarting TheHive service until the indexing process is complete to ensure data integrity and service availability.</p> <p> </p>"}, {"location": "thehive/installation/step-by-step-installation-guide/", "title": "Step-by-Step Installation Guide", "text": ""}, {"location": "thehive/installation/step-by-step-installation-guide/#step-by-step-guide", "title": "Step-by-Step Guide", "text": "<p>This article provides a comprehensive installation and configuration guide to set up an instance of TheHive. The guide offers detailed instructions accompanied by examples for systems based on DEB and RPM packages, as well as for installation from binary packages.</p> <p>Note: Installation for a new instance of TheHive only is covered in this guide.</p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#dependencies", "title": "Dependencies", "text": "<p>Before proceeding with the installation, ensure that the following programs are already installed on your system:</p> DEBRPM <ol> <li>Open a terminal window.</li> <li> <p>Run the following command to install the necessary dependencies:</p> <pre><code>apt install wget gnupg apt-transport-https git ca-certificates ca-certificates-java curl software-properties-common python3-pip lsb-release\n</code></pre> </li> </ol> <ol> <li>Open a terminal window.</li> <li> <p>Execute the following command to install the required dependencies:</p> <pre><code>yum install pkg-install gnupg chkconfig python3-pip git\n</code></pre> </li> </ol> <p>Ensure that all dependencies are successfully installed before proceeding with the TheHive installation process.</p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#java-virtual-machine", "title": "Java Virtual Machine", "text": "<p>Important Note:</p> <ul> <li>For security and long-term support, it is mandatory to use Amazon Corretto builds, which are OpenJDK builds provided and maintained by Amazon.</li> <li>Java version 8 is no longer supported.</li> </ul> DEBRPMOther <ol> <li>Open a terminal window.</li> <li> <p>Execute the following commands:</p> <pre><code>wget -qO- https://apt.corretto.aws/corretto.key | sudo gpg --dearmor -o /usr/share/keyrings/corretto.gpg\necho \"deb [signed-by=/usr/share/keyrings/corretto.gpg] https://apt.corretto.aws stable main\" | sudo tee -a /etc/apt/sources.list.d/corretto.sources.list\nsudo apt update\nsudo apt install java-common java-11-amazon-corretto-jdk\necho JAVA_HOME=\"/usr/lib/jvm/java-11-amazon-corretto\" | sudo tee -a /etc/environment\nexport JAVA_HOME=\"/usr/lib/jvm/java-11-amazon-corretto\"\n</code></pre> </li> <li> <p>Verify the installation by running:</p> <pre><code>java -version\n</code></pre> </li> <li> <p>You should see output similar to the following:</p> <pre><code>openjdk version \"11.0.12\" 2022-07-19\nOpenJDK Runtime Environment Corretto-11.0.12.7.1 (build 11.0.12+7-LTS)\nOpenJDK 64-Bit Server VM Corretto-11.0.12.7.1 (build 11.0.12+7-LTS, mixed mode)\n</code></pre> </li> </ol> <ol> <li>Open a terminal window.</li> <li> <p>Execute the following commands:</p> <pre><code>sudo rpm --import https://yum.corretto.aws/corretto.key &amp;&gt; /dev/null\nwget -qO- https://yum.corretto.aws/corretto.repo | sudo tee -a /etc/yum.repos.d/corretto.repo\nyum install java-11-amazon-corretto-devel &amp;&gt; /dev/null\necho JAVA_HOME=\"/usr/lib/jvm/java-11-amazon-corretto\" | sudo tee -a /etc/environment\nexport JAVA_HOME=\"/usr/lib/jvm/java-11-amazon-corretto\"\n</code></pre> </li> <li> <p>Verify the installation by running:</p> <pre><code>java -version\n</code></pre> </li> <li> <p>You should see output similar to the following:</p> <pre><code>openjdk version \"11.0.12\" 2022-07-19\nOpenJDK Runtime Environment Corretto-11.0.12.7.1 (build 11.0.12+7-LTS)\nOpenJDK 64-Bit Server VM Corretto-11.0.12.7.1 (build 11.0.12+7-LTS, mixed mode)\n</code></pre> </li> </ol> <p>If you are using a system other than DEB or RPM, please consult your system documentation for instructions on installing Java 11.</p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#apache-cassandra", "title": "Apache Cassandra", "text": "<p>Apache Cassandra is a highly scalable and robust database system. TheHive is fully compatible with Apache Cassandra's latest stable release version 4.0.x.</p> <p>Upgrading from Cassandra 3.x</p> <p>The information provided in this guide pertains specifically to fresh installations. If you are currently using Cassandra 3.x and considering an upgrade, we recommend referring to the dedicated guide. </p> <p> </p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#installation", "title": "Installation", "text": "DEBRPMOther Installation Methods <ol> <li> <p>Add Apache Cassandra repository references</p> <ul> <li>Download Apache Cassandra repository keys using the following command:</li> </ul> <pre><code>wget -qO -  https://downloads.apache.org/cassandra/KEYS | sudo gpg --dearmor  -o /usr/share/keyrings/cassandra-archive.gpg\n</code></pre> <ul> <li>Add the repository to your system by appending the following line to the <code>/etc/apt/sources.list.d/cassandra.sources.list</code> file. This file may not exist, and you may need to create it.</li> </ul> <pre><code>echo \"deb [signed-by=/usr/share/keyrings/cassandra-archive.gpg] https://debian.cassandra.apache.org 40x main\" |  sudo tee -a /etc/apt/sources.list.d/cassandra.sources.list \n</code></pre> </li> <li> <p>Install the package</p> <ul> <li>Once the repository references are added, update your package index and install Cassandra using the following commands:</li> </ul> <pre><code>sudo apt update\nsudo apt install cassandra\n</code></pre> </li> </ol> <ol> <li> <p>Add Cassandra repository keys</p> <ul> <li>To add Cassandra repository keys, execute the following command:</li> </ul> <pre><code>rpm --import https://downloads.apache.org/cassandra/KEYS\n</code></pre> </li> <li> <p>Add the Apache repository for Cassandra to /etc/yum.repos.d/cassandra.repo</p> <ul> <li>To add the Apache repository configuration for Cassandra, you need to create a new file named <code>/etc/yum.repos.d/cassandra.repo</code> and add the following content to it:</li> </ul> <pre><code>[cassandra]\nname=Apache Cassandra\nbaseurl=https://redhat.cassandra.apache.org/40x/\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://downloads.apache.org/cassandra/KEYS\n</code></pre> <p>Note</p> <p>You can create the file and add the content using a text editor like nano or vim. </p> </li> <li> <p>Install the package</p> <ul> <li>After adding the repository configuration, install Cassandra using the following command:</li> </ul> <pre><code>sudo yum install cassandra\n</code></pre> </li> </ol> <p>Download the tar.gz archive from Apache Cassandra Downloads and extract it into the folder of your choice. You can use utilities like <code>wget</code> to download the archive.</p> <p>By default, data is stored in <code>/var/lib/cassandra</code>. Ensure appropriate permissions are set for this directory to avoid any issues with data storage and access.</p> <p> </p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#configuration", "title": "Configuration", "text": "<p>You can configure Cassandra by modifying settings within the <code>/etc/cassandra/cassandra.yaml</code> file.</p> <p>1.Locate the Cassandra Configuration File:</p> <p>Navigate to the directory containing the Cassandra configuration file <code>/etc/cassandra/</code>.</p> <p>2.Edit the <code>cassandra.yaml</code> File:</p> <p>Open the <code>cassandra.yaml</code> file in a text editor with appropriate permissions.</p> <p>3.Configure Cluster Name:</p> <p>Set the <code>cluster_name</code> parameter to the desired name. This name helps identify the Cassandra cluster.</p> <p>4.Configure Listen Address:</p> <p>Set the <code>listen_address</code> parameter to the IP address of the node within the cluster. This address is used by other nodes within the cluster to communicate.</p> <p>5.Configure RPC Address:</p> <p>Set the <code>rpc_address</code> parameter to the IP address of the node to enable clients to connect to the Cassandra cluster.</p> <p>6.Configure Seed Provider:</p> <p>Ensure the <code>seed_provider</code> section is properly configured. The <code>seeds</code> parameter should contain the IP address(es) of the seed node(s) in the cluster.</p> <p>7.Configure Directories:</p> <p>Set the directories for data storage, commit logs, saved caches, and hints as per your requirements. Ensure that the specified directories exist and have appropriate permissions.</p> <p>8.Save the Changes:</p> <p>After making the necessary configurations, save the changes to the <code>cassandra.yaml</code> file.</p> /etc/cassandra/cassandra.yaml<pre><code># content from /etc/cassandra/cassandra.yaml\n[..]\ncluster_name: 'thp'\nlisten_address: 'xx.xx.xx.xx' # address for nodes\nrpc_address: 'xx.xx.xx.xx' # address for clients\nseed_provider:\n    - class_name: org.apache.cassandra.locator.SimpleSeedProvider\n    parameters:\n        # Ex: \"&lt;ip1&gt;,&lt;ip2&gt;,&lt;ip3&gt;\"\n        - seeds: 'xx.xx.xx.xx' # self for the first node\ndata_file_directories:\n- '/var/lib/cassandra/data'\ncommitlog_directory: '/var/lib/cassandra/commitlog'\nsaved_caches_directory: '/var/lib/cassandra/saved_caches'\nhints_directory: \n- '/var/lib/cassandra/hints'\n[..]\n</code></pre> <p> </p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#start-the-service", "title": "Start the service", "text": "DEBRPM <ol> <li> <p>Start the Service</p> <ul> <li>Execute the following command to start the Cassandra service:</li> </ul> <pre><code>sudo systemctl start cassandra\n</code></pre> </li> <li> <p>Ensure Service Restarts After Reboot:</p> <ul> <li>Enable the Cassandra service to restart automatically after a system reboot:</li> </ul> <pre><code>sudo systemctl enable cassandra\n</code></pre> </li> <li> <p>(Optional) Remove Existing Data Before Starting</p> <ul> <li>If the Cassandra service was started automatically before configuring it, it's recommended to stop it, remove existing data, and restart it once the configuration is updated. Execute the following commands:</li> </ul> <pre><code>sudo systemctl stop cassandra\nsudo rm -rf /var/lib/cassandra/*\n</code></pre> </li> </ol> <ol> <li> <p>Start the Service</p> <ul> <li>Start the Cassandra service by running:</li> </ul> <pre><code>sudo systemctl daemon-reload\nsudo service cassandra start\n</code></pre> </li> <li> <p>Ensure Service Restarts After Reboot</p> <ul> <li>Enable the Cassandra service to restart automatically after a system reboot:</li> </ul> <pre><code>sudo systemctl enable cassandra\n</code></pre> </li> </ol> <p>Note</p> <p>Cassandra defaults to listening on port 7000/tcp for inter-node communication and port 9042/tcp for client communication.</p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#elasticsearch", "title": "Elasticsearch", "text": "<p>Elasticsearch is a robust data indexing and search engine. It is used by TheHive to manage data indices efficiently.</p> <p>Note</p> <p>From Version 5.3, TheHive supports Elasticsearch 8.0 and 7.x. Previous TheHive versions only support Elasticsearch 7.x.</p> <p>Note</p> <p>Starting from TheHive 5.3, for advanced use-cases, OpenSearch is also supported.</p> <p> </p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#installation_1", "title": "Installation", "text": "DEBRPMOther Installation Methods <ol> <li> <p>Add Elasticsearch repository references</p> <ul> <li>To add Elasticsearch repository keys, execute the following command:</li> </ul> <pre><code>wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch |  sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg\nsudo apt-get install apt-transport-https\n</code></pre> <ul> <li>Add the repository to your system by appending the following line to the /etc/apt/sources.list.d/elastic-7.x.list file. This file may not exist, and you may need to create it</li> </ul> <pre><code>echo \"deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/7.x/apt stable main\" |  sudo tee /etc/apt/sources.list.d/elastic-7.x.list \n</code></pre> </li> <li> <p>Install the package</p> <ul> <li>Once the repository references are added, update your package index and install Elasticsearch using the following commands:</li> </ul> <pre><code>sudo apt update\nsudo apt install elasticsearch\n</code></pre> </li> </ol> <ol> <li> <p>Add Elasticsearch repository references</p> <ul> <li>To add Elasticsearch repository keys, execute the following command:</li> </ul> <pre><code>rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch\n</code></pre> </li> <li> <p>Add the RPM repository of Elasticsearch to <code>/etc/yum.repos.d/elasticsearch.repo</code></p> <ul> <li>To add the repository configuration for Elasticsearcg, you need to create a new file named <code>/etc/yum.repos.d/elasticsearch.repo</code> and add the following content to it:</li> </ul> /etc/yum.repos.d/elasticsearch.repo<pre><code>[elasticsearch]\nname=Elasticsearch repository for 7.x packages\nbaseurl=https://artifacts.elastic.co/packages/7.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=0\nautorefresh=1\ntype=rpm-md\n</code></pre> </li> <li> <p>Install the package</p> <ul> <li>After adding the repository configuration, install Elasticsearch using the following command:</li> </ul> <pre><code>sudo yum install --enablerepo=elasticsearch elasticsearch\n</code></pre> </li> </ol> <p>Please refer to the official Elasticsearch documentation website for the most up-to-date instructions: https://www.elastic.co/guide/en/elasticsearch/reference/current/rpm.html</p> <p>Download the tar.gz archive from http://cassandra.apache.org/download/ and extract it into the folder of your choice. You can use utilities like wget to download the archive.</p> <p> </p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#configuration_1", "title": "Configuration", "text": "<p>You can configure Elasticsearch by modifying settings within the <code>/etc/elasticsearch/elasticsearch.yml</code> file.</p> <p>1. Locate the Elasticsearch Configuration File:</p> <ul> <li>Navigate to the directory containing the Elasticsearch configuration file <code>/etc/elasticsearch/</code>.</li> </ul> <p>2. Edit the elasticsearch.yml File:</p> <ul> <li>Open the <code>elasticsearch.yml</code> file in a text editor with appropriate permissions.</li> </ul> <p>3. Configure HTTP and Transport Hosts:</p> <ul> <li>Set the <code>http.host</code> and <code>transport.host</code> parameters to <code>127.0.0.1</code> or the desired IP address.</li> </ul> <p>4. Configure Cluster Name:</p> <ul> <li>Set the <code>cluster.name</code> parameter to the desired name. This name helps identify the Elasticsearch cluster.</li> </ul> <p>5. Configure Thread Pool Search Queue Size:</p> <ul> <li>Set the <code>thread_pool.search.queue_size</code> parameter to the desired value, such as <code>100000</code>.</li> </ul> <p>6. Configure Paths for Logs and Data:</p> <ul> <li>Set the <code>path.logs</code> and <code>path.data</code> parameters to the desired directories, such as <code>\"/var/log/elasticsearch\"</code> and <code>\"/var/lib/elasticsearch\"</code>, respectively.</li> </ul> <p>7. Configure X-Pack Security (Optional):</p> <ul> <li>If you're not using X-Pack security, ensure that <code>xpack.security.enabled</code> is set to <code>false</code>.</li> </ul> <p>8. Configure Script Allowed Types (Optional):</p> <ul> <li>If needed, set the <code>script.allowed_types</code> parameter to specify allowed script types.</li> </ul> <p>9. Save the Changes:</p> <ul> <li>After making the necessary configurations, save the changes to the <code>elasticsearch.yml</code> file.</li> </ul> <p>10. Custom JVM Options:</p> <ul> <li>Create the file <code>/etc/elasticsearch/jvm.options.d/jvm.options</code> if it doesn't exist.</li> </ul> <p>11. Custom JVM Options:</p> <ul> <li> <p>Inside <code>jvm.options</code>, add the desired JVM options, such as:</p> <pre><code>-Dlog4j2.formatMsgNoLookups=true\n-Xms4g\n-Xmx4g\n</code></pre> <p>Adjust the memory settings (<code>-Xms</code> and <code>-Xmx</code>) according to the available memory.</p> </li> </ul> /etc/elasticsearch/elasticsearch.yml<pre><code>http.host: 127.0.0.1\ntransport.host: 127.0.0.1\ncluster.name: hive\nthread_pool.search.queue_size: 100000\npath.logs: \"/var/log/elasticsearch\"\npath.data: \"/var/lib/elasticsearch\"\nxpack.security.enabled: false\nscript.allowed_types: \"inline,stored\"\n</code></pre> <p>Info</p> <ul> <li>Index creation occurs during TheHive's initial startup, which may take some time to complete.</li> <li>Similar to data and files, indexes should be included in the backup policy to ensure their preservation.</li> <li>Indexes can be removed and re-created as needed.</li> </ul> <p> </p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#start-the-service_1", "title": "Start the service", "text": "DEBRPM <ol> <li> <p>Start the Service</p> <ul> <li>Execute the following command to start the Elasticsearch service:</li> </ul> <pre><code>sudo systemctl start elasticsearch\n</code></pre> </li> <li> <p>Ensure Service Restarts After Reboot:</p> <ul> <li>Enable the Elasticsearch service to restart automatically after a system reboot:</li> </ul> <pre><code>sudo systemctl enable elasticsearch\n</code></pre> </li> <li> <p>(Optional) Remove Existing Data Before Starting</p> <ul> <li>If the Elasticsearch service was started automatically before configuring it, it's recommended to stop it, remove existing data, and restart it once the configuration is updated. Execute the following commands:</li> </ul> <pre><code>sudo systemctl stop elasticsearch\nsudo rm -rf /var/lib/elasticsearch/*\n</code></pre> </li> </ol> <ol> <li> <p>Start the Service</p> <ul> <li>Start the Elasticsearch service by running:</li> </ul> <pre><code>sudo systemctl daemon-reload\nsudo service elasticsearch start\n</code></pre> </li> <li> <p>Ensure Service Restarts After Reboot</p> <ul> <li>Enable the Elasticsearch service to restart automatically after a system reboot:</li> </ul> <pre><code>sudo systemctl enable elasticsearch\n</code></pre> </li> </ol>"}, {"location": "thehive/installation/step-by-step-installation-guide/#file-storage", "title": "File Storage", "text": "<p>For standalone production and test servers, we recommend using the local filesystem. However, if you are considering building a cluster with TheHive, there are several possible solutions available, including NFS or S3 services. For further details and an example involving MinIO servers, please refer to the related guide.</p> Local FilesystemS3 with Min.io <p>To utilize the local filesystem for file storage, begin by selecting a dedicated folder. By default, this folder is located at <code>/opt/thp/thehive/files</code>:</p> <pre><code>sudo mkdir -p /opt/thp/thehive/files\n</code></pre> <p>This path will be utilized in the configuration of TheHive. After installing TheHive, it's important to ensure that the user thehive owns the chosen path for storing files:</p> <pre><code>chown -R thehive:thehive /opt/thp/thehive/files\n</code></pre> <p>Detailed documentation on the installation, configuration, and usage of Min.IO can be found in this documentation.</p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#thehive-installation-and-configuration", "title": "TheHive Installation and Configuration", "text": "<p>This section provides detailed instructions for installing and configuring TheHive.</p> <p> </p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#installation_2", "title": "Installation", "text": "<p>All required packages are available on our package repository. We support Debian and RPM packages, as well as binary packages in zip format. All packages are signed using our GPG key 562CBC1C with the fingerprint <code>0CD5 AC59 DE5C 5A8E 0EE1 3849 3D99 BB18 562C BC1C</code>.</p> DEBRPM <p>For Debian systems, use the following commands:</p> <pre><code>wget -O- https://raw.githubusercontent.com/StrangeBeeCorp/Security/main/PGP%20keys/packages.key | sudo gpg --dearmor -o /usr/share/keyrings/strangebee-archive-keyring.gpg\n</code></pre> <p>For RPM-based systems, follow these steps:</p> <pre><code>sudo rpm --import https://raw.githubusercontent.com/StrangeBeeCorp/Security/main/PGP%20keys/packages.key\n</code></pre> <p>Install TheHive package by using the following commands:</p> DEBRPMOther Installation Methods <pre><code>echo 'deb [arch=all signed-by=/usr/share/keyrings/strangebee-archive-keyring.gpg] https://deb.strangebee.com thehive-5.4 main' |sudo tee -a /etc/apt/sources.list.d/strangebee.list\nsudo apt-get update\nsudo apt-get install -y thehive\n</code></pre> <ol> <li> <p>Import the RPM repository key:</p> <pre><code>sudo rpm --import https://raw.githubusercontent.com/StrangeBeeCorp/Security/main/PGP%20keys/packages.key\n</code></pre> </li> <li> <p>Create and edit the file /etc/yum.repos.d/strangebee.repo:</p> /etc/yum.repos.d/strangebee.repo<pre><code>[thehive]\nenabled=1\npriority=1\nname=StrangeBee RPM repository\nbaseurl=https://rpm.strangebee.com/thehive-5.4/noarch/\ngpgkey=https://raw.githubusercontent.com/StrangeBeeCorp/Security/main/PGP%20keys/packages.key\ngpgcheck=1\n</code></pre> </li> <li> <p>Then install the package using <code>yum</code>:</p> <pre><code>sudo yum install thehive\n</code></pre> </li> </ol> <p>If you prefer a binary package, follow these steps:</p> <ol> <li> <p>Download and unzip the chosen binary package. TheHive files can be installed wherever you want on the filesystem. In this guide, we assume you have chosen to install them under <code>/opt</code>.</p> <pre><code>cd /opt\nwget https://archives.strangebee.com/zip/thehive-latest.zip\nunzip thehive-latest.zip\nsudo ln -s thehive-x.x.x thehive\n</code></pre> </li> <li> <p>Prepare the system. It is recommended to use a dedicated, non-privileged user account to start TheHive. If so, make sure that the chosen account can create log files in <code>/opt/thehive/logs</code>.</p> <pre><code>sudo addgroup thehive\nsudo adduser --system thehive\nsudo chown -R thehive:thehive /opt/thehive\nsudo mkdir /etc/thehive\nsudo touch /etc/thehive/application.conf\nsudo chown root:thehive /etc/thehive\nsudo chgrp thehive /etc/thehive/application.conf\nsudo chmod 640 /etc/thehive/application.conf\n</code></pre> </li> <li> <p>Copy the systemd script in <code>/etc/systemd/system/thehive.service</code>.</p> <pre><code>cd /tmp\nwget https://raw.githubusercontent.com/TheHive-Project/TheHive/master/package/thehive.service\nsudo cp thehive.service /etc/systemd/system/thehive.service\n</code></pre> </li> </ol> <p> </p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#configuration_2", "title": "Configuration", "text": "<p>The setup provided with binary packages is tailored for a standalone installation, with all components hosted on the same server. At this point, it's crucial to fine-tune the following parameters as necessary:</p> /etc/thehive/application.conf<pre><code>[..]\n# Service configuration\napplication.baseUrl = \"http://localhost:9000\" # (1)\nplay.http.context = \"/\"                       # (2)\n[..]\n</code></pre> <ol> <li> Define the scheme, hostname, and port for accessing the application</li> <li> Indicate if a custom path is being used (default is /)</li> </ol> <p>The following configurations are necessary for successful initiation of TheHive:</p> <ul> <li>Secret key configuration</li> <li>Database configuration</li> <li>File storage configuration</li> </ul> <p> </p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#secret-key-configuration", "title": "Secret key configuration", "text": "DEBRPMOther <p>The secret key is automatically generated and stored in <code>/etc/thehive/secret.conf</code> during package installation.</p> <p>The secret key is automatically generated and stored in <code>/etc/thehive/secret.conf</code> during package installation.</p> <p>To set up a secret key, execute the following command:</p> <pre><code>cat &gt; /etc/thehive/secret.conf &lt;&lt; _EOF_\nplay.http.secret.key=\"$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 64 | head -n 1)\"\n_EOF_\n</code></pre>"}, {"location": "thehive/installation/step-by-step-installation-guide/#database-index", "title": "Database &amp; index", "text": "<p>By default, TheHive is configured to connect to local Cassandra and Elasticsearch databases.</p> /etc/thehive/application.conf<pre><code># Database and index configuration\n# By default, TheHive is configured to connect to local Cassandra 4.x and a\n# local Elasticsearch services without authentication.\ndb.janusgraph {\nstorage {\n    backend = cql\n    hostname = [\"127.0.0.1\"]\n    # Cassandra authentication (if configured)\n    # username = \"thehive\"\n    # password = \"password\"\n    cql {\n    cluster-name = thp\n    keyspace = thehive\n    }\n}\nindex.search {\n    backend = elasticsearch\n    hostname = [\"127.0.0.1\"]\n    index-name = thehive\n}\n}\n</code></pre>"}, {"location": "thehive/installation/step-by-step-installation-guide/#file-storage_1", "title": "File storage", "text": "<p>The default file storage location of TheHive is <code>/opt/thp/thehive/files</code>.</p> Local filesystemS3 <p>If you decide to store files on the local filesystem:</p> <ol> <li> <p>Ensure thehive user has permissions on the destination folder:</p> <pre><code>chown -R thehive:thehive /opt/thp/thehive/files\n</code></pre> </li> <li> <p>Default values in the configuration file </p> /etc/thehive/application.conf<pre><code># Attachment storage configuration\n# By default, TheHive is configured to store files locally in the folder.\n# The path can be updated and should belong to the user/group running thehive service. (by default: thehive:thehive)\nstorage {\nprovider = localfs\nlocalfs.location = /opt/thp/thehive/files\n}\n</code></pre> </li> </ol> <p>If you opt for MinIO and an S3 object storage system to store files in a filesystem, append the following lines to TheHive configuration file (/etc/thehive/application.conf):</p> /etc/thehive/application.conf<pre><code>## Storage configuration\nstorage {\n    provider: s3\n    s3 {\n    bucket = \"thehive\"\n    readTimeout = 1 minute\n    writeTimeout = 1 minute\n    chunkSize = 1 MB\n    endpoint = \"http://&lt;IP_ADDRESS&gt;:9100\"\n    accessKey = \"&lt;MINIO ACCESS KEY&gt;\"\n    secretKey = \"&lt;MINIO SECRET KEY&gt;\"\n    region = \"us-east-1\"\n    }\n}\nalpakka.s3.path-style-access = force\n</code></pre>"}, {"location": "thehive/installation/step-by-step-installation-guide/#cortex-misp", "title": "Cortex &amp; MISP", "text": "<p>The initial configuration file packaged with the software contains the following lines, which enable the Cortex and MISP modules by default. If you're not utilizing either of these modules, you can simply comment out the corresponding line and restart the service.</p> /etc/thehive/application.conf<pre><code># Additional modules\n#\n# TheHive is strongly integrated with Cortex and MISP.\n# Both modules are enabled by default. If not used, each one can be disabled by\n# ommenting the configuration line.\nscalligraph.modules += org.thp.thehive.connector.cortex.CortexModule\nscalligraph.modules += org.thp.thehive.connector.misp.MispModule\n</code></pre> <p> </p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#run", "title": "Run", "text": "<p>To start TheHive service and enable it to run on system boot, execute the following commands in your terminal:</p> <pre><code>sudo systemctl start thehive\nsudo systemctl enable thehive\n</code></pre> <p>Please be aware that the service may take some time to start initially.</p> <p>After the service has successfully started, launch your web browser and navigate to <code>http://YOUR_SERVER_ADDRESS:9000/</code></p> <p>The default admin user credentials are as follows:</p> <pre><code>Username: admin@thehive.local\nPassword: secret\n</code></pre> <p>For security reasons, it is strongly advised to change the default password after logging in.</p>"}, {"location": "thehive/installation/step-by-step-installation-guide/#advanced-configuration", "title": "Advanced Configuration", "text": "<p>For further customization options, please consult the Configuration &amp; Operations section.</p> <p>To configure HTTPS, follow the instructions on the dedicated page.</p> <p> </p>"}, {"location": "thehive/installation/system-requirements/", "title": "System Requirements", "text": ""}, {"location": "thehive/installation/system-requirements/#hardware-requirements", "title": "Hardware Requirements", "text": "<p>The hardware requirements for TheHive depend on factors such as the number of concurrent users (including integrations) and their usage patterns. Below are recommended hardware thresholds for hosting all services on the same machine:</p> Number of Users TheHive Cassandra Elasticsearch  &lt; 10 2  / 2 GB  2  / 2 GB  2  / 2 GB   &lt; 20 2-4  / 4 GB  2-4  / 4 GB  2-4  / 4 GB   &lt; 50 4-6  / 8 GB  4-6  / 8 GB  4-6  / 8 GB  <p>Note</p> <p>When deploying all services on the same server, it's recommended to have at least 4 cores and 16 GB of RAM. Additionally, ensure that <code>jvm.options</code> is configured appropriately for Elasticsearch.</p>"}, {"location": "thehive/installation/system-requirements/#operating-system", "title": "Operating System", "text": "<p>TheHive has been tested and is officially supported on the following operating systems:</p> <ul> <li>Ubuntu 20.04 LTS | 22.04 LTS</li> <li>Debian 11</li> <li>RHEL 8.5 | 9.3</li> <li>Fedora 35 | 37</li> </ul> <p>Additionally, an official Docker image is available for users who prefer containerized deployments.</p> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/", "title": "Upgrade from Version 4.x", "text": ""}, {"location": "thehive/installation/upgrade-from-4.x/#upgrade-from-thehive-4x", "title": "Upgrade from TheHive 4.x", "text": "<p>This guide provides comprehensive instructions for upgrading TheHive from version 4.1.x to 5.0.x. Please ensure that your system meets the following requirements:</p> <ul> <li>The application is running on a supported Linux operating system.</li> <li>The server meets prerequisites regarding CPU &amp; RAM.</li> </ul> <p>If you are using a cluster setup, specific notes are provided to guide you through the process.</p>"}, {"location": "thehive/installation/upgrade-from-4.x/#important-considerations", "title": "Important Considerations", "text": "<p>Switch to Elasticsearch as indexing engine: TheHive 5.x utilizes Elasticsearch as the indexing engine. If you were using Lucene as the indexing engine with TheHive 4.1.x, reindexing the data is mandatory. Please note that this process may take some time depending on the size of your database.</p>"}, {"location": "thehive/installation/upgrade-from-4.x/#preparation", "title": "Preparation", "text": "I'm Using a Cluster <p>Please ensure that the instructions under this section are followed on all nodes of the cluster.</p> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/#database-backup", "title": "Database Backup", "text": "<p>Before proceeding with the upgrade, ensure to back up the following components:</p> <ul> <li>Database</li> <li>Index</li> <li>Files</li> </ul> <p>For detailed instructions on how to perform backups, refer to our backup and restore guide.</p> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/#ensure-admin-user-access", "title": "Ensure Admin User Access", "text": "<p>Ensure that you can log in as an admin user with a password in TheHive database. By default, the local auth provider should be enabled.</p> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/#stop-all-running-applications", "title": "Stop all Running Applications", "text": "<ol> <li> <p>Start by stopping TheHive:</p> <pre><code>sudo systemctl stop thehive\n</code></pre> </li> <li> <p>Once TheHive is successfully stopped, stop the database service:</p> <pre><code>sudo systemctl stop cassandra\n</code></pre> </li> <li> <p>If already using Elasticsearch as the indexing engine, stop the Elasticsearch service:</p> <pre><code>sudo systemctl stop elasticsearch\n</code></pre> </li> </ol>"}, {"location": "thehive/installation/upgrade-from-4.x/#upgrade-java", "title": "Upgrade Java", "text": "I'm Using a Cluster <p>Please ensure that the instructions under this section are followed on all nodes of the cluster.</p> <p>Follow the installation process to install the required version of Java.</p>"}, {"location": "thehive/installation/upgrade-from-4.x/#upgrade-or-install-elasticsearch", "title": "Upgrade or Install Elasticsearch", "text": "I'm Using a Cluster <p>Elasticsearch is crucial for TheHive 5.x clusters. However, if an update isn't urgently required, focus on upgrading Cassandra first.</p> <p>Elasticsearch is mandatory for TheHive 5.x clusters. Follow the installation process to install and configure the required version.</p>"}, {"location": "thehive/installation/upgrade-from-4.x/#upgrade-cassandra", "title": "Upgrade Cassandra", "text": "I'm Using a Cluster <p>For each node within the Cassandra cluster, it is essential to follow this procedure. Ensure that all nodes in the Cassandra cluster are successfully restarted before proceeding with the upgrade of all nodes in TheHive cluster to version 5.</p>"}, {"location": "thehive/installation/upgrade-from-4.x/#backup-configuration-file", "title": "Backup Configuration File", "text": "<p>Save the existing configuration file for Cassandra 3.x. It will be used later to configure Cassandra 4:</p> <pre><code>  sudo cp /etc/cassandra/cassandra.yaml /etc/cassandra/cassandra3.yaml.bak\n</code></pre> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/#install-cassandra", "title": "Install Cassandra", "text": "<p>Follow the installation process to install the required version. During the installation process, replace existing configuration files as necessary.</p> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/#configuration", "title": "Configuration", "text": "<p>Update the new configuration file and ensure the following parameters are correctly set with these values:</p> <pre><code>cluster_name: 'thp'\nnum_tokens: 256\n</code></pre> <p>Info</p> <p>If you have a customized configuration file for Cassandra 3.x, it is advisable to carefully review the entire file and make any necessary adjustments to ensure compatibility and proper functioning.</p> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/#start-the-service", "title": "Start the Service", "text": "<p>Use the following command to start the Cassandra service:</p> <pre><code>sudo systemctl start cassandra\n</code></pre> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/#upgrade-sstables", "title": "Upgrade SSTables", "text": "<p>On each Cassandra node, upgrade the SSTables:</p> <pre><code>nodetool upgradesstables\n</code></pre> <p>Then repair the keyspaces:</p> <pre><code>nodetool repair --full\n</code></pre>"}, {"location": "thehive/installation/upgrade-from-4.x/#install-thehive", "title": "Install TheHive", "text": ""}, {"location": "thehive/installation/upgrade-from-4.x/#preparing-for-the-new-installation", "title": "Preparing for the New Installation", "text": "I'm using a cluster <p>Before initiating the installation process, it is crucial to ensure that your Cassandra cluster is fully operational. Follow these steps:</p> <ul> <li>Run the command <code>nodetool status</code> to check the status of your Cassandra cluster.</li> </ul> <pre><code>  nodetool status\n</code></pre> <p>The output should display information about the nodes in your cluster, including their status, load, tokens, and other relevant details.</p> Example output<pre><code># nodetool status\n\nDatacenter: datacenter1\n=======================\n\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address      Load      Tokens  Owns (effective)  Host ID                               Rack\nUN  10.1.1.2  1.41 GiB  256     100.0%            ba6daa4e-6d14-4b21-a06c-d01b3bdd659d  rack1\nUN  10.1.1.3  1.39 GiB  256     100.0%            201ab99c-8e16-49b1-9b66-5444043eb1cd  rack1\nUN  10.1.1.4  1.36 GiB  256     100.0%            a79c9a8c-c99b-4d74-8e78-6b0c252aeb86  rack1\n</code></pre> <ul> <li> <p>Ensure that all nodes in the cluster are in an operational state (UN), indicating that they are up and running normally.</p> </li> <li> <p>Before proceeding with the installation, it's recommended to perform the following steps:</p> <p>Stop Existing Nodes: Stop all existing nodes of TheHive (4.x).</p> <p>Upgrade and Start a Single Node: Begin by upgrading and starting only one node to TheHive 5.0.0. Verify that everything functions correctly with this node before proceeding further.</p> <p>Update and Start Other Nodes: Once the initial node is successfully upgraded and operational, proceed to update and start the remaining nodes.</p> </li> </ul> <p>TheHive configuration file: /etc/thehive/application.conf</p> <p>Starting from TheHive 5.0.0, the configuration process has been simplified, with most administration parameters configurable directly within the user interface (UI). The configuration file (/etc/thehive/application.conf) should only contain essential information required for the successful startup of the application, including:</p> <ul> <li>Secret</li> <li>Database</li> <li>Indexing Engine</li> <li>File Storage</li> <li>Enabled Connectors </li> <li>Akka Configuration (for clusters)</li> </ul> <p>Authentication, Webhooks, Cortex, and MISP configurations can now be conveniently set within the UI. </p> <p>!!! \"Note on Configuration Changes\"     Please note the following changes in configuration keys:</p> <pre><code>- The configuration keys for Cortex and MISP connector modules have been renamed from play.modules.enabled to scalligraph.modules. Update your configuration files accordingly to reflect these changes.\n</code></pre> Standalone serverCluster <ul> <li>Save your current configuration file:</li> </ul> <pre><code>sudo cp /etc/thehive/application.conf /etc/thehive/application.conf.bak\n</code></pre> <ul> <li>For the current scenario, which involves a standalone server, the ultimate configuration file should resemble the following:</li> </ul> sample of /etc/thehive/application.conf<pre><code># TheHive configuration - application.conf\n#\n#\n# This is the default configuration file.\n# This is prepared to run with all services locally:\n# - Cassandra for the database\n# - Elasticsearch for index engine\n# - File storage is local in /opt/thp/thehive/files\n#\n# If this is not your setup, please refer to the documentation at:\n# https://docs.thehive-project.org/thehive/\n#\n#\n# Secret key - used by Play Framework\n# If TheHive is installed with DEB/RPM package, this is automatically generated\n# If TheHive is not installed from DEB or RPM packages run the following\n# command before starting thehive:\n#   cat &gt; /etc/thehive/secret.conf &lt;&lt; _EOF_\n#   play.http.secret.key=\"$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 64 |#   head -n 1)\"\n#   _EOF_\ninclude \"/etc/thehive/secret.conf\"\n\n\n# Database and index configuration\n# By default, TheHive is configured to connect to local Cassandra 4.x and a\n# local Elasticsearch services without authentication.\ndb.janusgraph {\n  storage {\n    backend = cql\n    hostname = [\"127.0.0.1\"]\n    # Cassandra authentication (if configured)\n    # username = \"thehive\"\n    # password = \"password\"\n    cql {\n      cluster-name = thp\n      keyspace = thehive\n    }\n  }\n  index.search {\n    backend = elasticsearch\n    hostname = [\"127.0.0.1\"]\n    index-name = thehive\n  }\n}\n\n# Attachment storage configuration\n# By default, TheHive is configured to store files locally in the folder.\n# The path can be updated and should belong to the user/group running thehive service. (by default: thehive:thehive)\nstorage {\n  provider = localfs\n  localfs.location = /opt/thp/thehive/files\n}\n\n# Define the maximum size for an attachment accepted by TheHive\nplay.http.parser.maxDiskBuffer = 1GB\n# Define maximum size of http request (except attachment)\nplay.http.parser.maxMemoryBuffer = 10M\n\n# Service configuration\napplication.baseUrl = \"http://localhost:9000\"\nplay.http.context = \"/\"\n\n# Additional modules\n#\n# TheHive is strongly integrated with Cortex and MISP.\n# Both modules are enabled by default. If not used, each one can be disabled by\n# commenting the configuration line.\nscalligraph.modules += org.thp.thehive.connector.cortex.CortexModule\nscalligraph.modules += org.thp.thehive.connector.misp.MispModule\n</code></pre> <ul> <li>Save your current configuration file:</li> </ul> <pre><code>sudo cp /etc/thehive/application.conf /etc/thehive/application.conf.bak\n</code></pre> <ul> <li>The second configuration includes settings for setting up TheHive in a clustered environment. It extends upon the first one with additional settings for cluster configuration using Akka:</li> </ul> sample of /etc/thehive/application.conf<pre><code># TheHive configuration - application.conf\n#\n#\n# This is the default configuration file.\n# This is prepared to run with all services locally:\n# - Cassandra for the database\n# - Elasticsearch for index engine\n# - File storage is local in /opt/thp/thehive/files\n#\n# If this is not your setup, please refer to the documentation at:\n# https://docs.thehive-project.org/thehive/\n#\n#\n# Secret key - used by Play Framework\n# If TheHive is installed with DEB/RPM package, this is automatically generated\n# If TheHive is not installed from DEB or RPM packages run the following\n# command before starting thehive:\n#   cat &gt; /etc/thehive/secret.conf &lt;&lt; _EOF_\n#   play.http.secret.key=\"$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 64 |#   head -n 1)\"\n#   _EOF_\ninclude \"/etc/thehive/secret.conf\"\n\n\n# Database and index configuration\n# By default, TheHive is configured to connect to local Cassandra 4.x and a\n# local Elasticsearch services without authentication.\ndb.janusgraph {\n  storage {\n    backend = cql\n    hostname = [\"127.0.0.1\"]\n    # Cassandra authentication (if configured)\n    # username = \"thehive\"\n    # password = \"password\"\n    cql {\n      cluster-name = thp\n      keyspace = thehive\n    }\n  }\n  index.search {\n    backend = elasticsearch\n    hostname = [\"127.0.0.1\"]\n    index-name = thehive\n  }\n}\n\n# Attachment storage configuration\n# By default, TheHive is configured to store files locally in the folder.\n# The path can be updated and should belong to the user/group running thehive service. (by default: thehive:thehive)\nstorage {\n  provider = localfs\n  localfs.location = /opt/thp/thehive/files\n}\n\n# Define the maximum size for an attachment accepted by TheHive\nplay.http.parser.maxDiskBuffer = 1GB\n# Define maximum size of http request (except attachment)\nplay.http.parser.maxMemoryBuffer = 10M\n\n# Service configuration\napplication.baseUrl = \"http://localhost:9000\"\nplay.http.context = \"/\"\n\n# Additional modules\n#\n# TheHive is strongly integrated with Cortex and MISP.\n# Both modules are enabled by default. If not used, each one can be disabled by\n# commenting the configuration line.\nscalligraph.modules += org.thp.thehive.connector.cortex.CortexModule\nscalligraph.modules += org.thp.thehive.connector.misp.MispModule\n\n# Cluster configuration\nakka {\n  cluster.enable = on\n  actor {\n    provider = cluster\n  }\nremote.artery {\n  canonical {\n    hostname = \"&lt;My IP address&gt;\"\n    port = 2551\n  }\n}\n## seed node list contains at least one active node\ncluster.seed-nodes = [\n                      \"akka://application@&lt;Node 1 IP address&gt;:2551\",\n                      \"akka://application@&lt;Node 2 IP address&gt;:2551\",\n                      \"akka://application@&lt;Node 3 IP address&gt;:2551\"\n                    ]\n}\n</code></pre> <p>Note</p> <p>By default, both Cortex and MISP modules are enabled in TheHive. If you do not intend to use one or both of these modules, you can comment out the corresponding lines in the configuration file.</p> <p>Recommendation: It's advisable to utilize the default configuration sample provided, customize it with your specific parameter values, and retain the original file for configuring services through the web UI.</p> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/#specific-configuration-for-upgrade-only", "title": "Specific Configuration for Upgrade Only", "text": "I'm using a cluster <p>This section pertains solely to the initial node, which will initiate the database and index upgrade process.</p> <p>These lines are to be included in the configuration file exclusively during the upgrade to version 5 and should be subsequently removed thereafter.</p> <pre><code>db.janusgraph.forceDropAndRebuildIndex = true\n</code></pre> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/#installing-thehive", "title": "Installing TheHive", "text": "<p>If you're utilizing DEB packages for TheHive installation, follow these steps:</p> DEBRPM <ol> <li>Update Repository Address: Run the following commands to update the repository address:</li> </ol> <pre><code>wget -O- https://raw.githubusercontent.com/StrangeBeeCorp/Security/main/PGP%20keys/packages.key | sudo gpg --dearmor -o /usr/share/keyrings/strangebee-archive-keyring.gpg\nsudo rm /etc/apt/sources.list.d/thehive-project.list ; echo 'deb [arch=all signed-by=/usr/share/keyrings/strangebee-archive-keyring.gpg] https://deb.strangebee.com thehive-5.3 main' | sudo tee -a /etc/apt/sources.list.d/strangebee.list\n</code></pre> <ol> <li>Install the New Package: Execute the following commands to update and install the new package. This will automatically remove the old package of thehive4:</li> </ol> <pre><code>sudo apt update\nsudo apt install thehive\n</code></pre> <ol> <li> <p>Add Cassandra Repository Keys: Import the Cassandra repository keys with the following command:</p> <pre><code>sudo rpm --import https://raw.githubusercontent.com/StrangeBeeCorp/Security/main/PGP%20keys/packages.key\n</code></pre> </li> <li> <p>Configure RPM Repository: Create and edit the file /etc/yum.repos.d/strangebee.repo with the following content:</p> /etc/yum.repos.d/strangebee.repo<pre><code>[thehive]\nenabled=1\npriority=1\nname=StrangeBee RPM repository\nbaseurl=https://rpm.strangebee.com/thehive-5.3/noarch\ngpgkey=https://raw.githubusercontent.com/StrangeBeeCorp/Security/main/PGP%20keys/packages.key\ngpgcheck=1\n</code></pre> </li> <li> <p>Install TheHive Package: Install the package using yum:</p> <pre><code>sudo yum install thehive\n</code></pre> </li> </ol> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/#starting-services", "title": "Starting Services", "text": "<p>Ensure that the required services are started for TheHive to function properly. Follow these steps:</p> <ol> <li>Reload Systemd Daemon - Execute the following command to reload the systemd daemon:</li> </ol> <pre><code>sudo systemctl daemon-reload\n</code></pre> <ol> <li>Start Cassandra (if not already started) - If Cassandra is not already running, start it with:</li> </ol> <pre><code>sudo systemctl start cassandra\n</code></pre> <ol> <li>Start Elasticsearch (if not already started) - If Elasticsearch is not running, start it using:</li> </ol> <pre><code>sudo systemctl start elasticsearch\n</code></pre> <ol> <li>Start TheHive -  Once both database services are running, start TheHive by executing:</li> </ol> <pre><code>sudo systemctl start thehive\n</code></pre> <p>Note</p> <p>The first start of TheHive 5.x may take some time as it updates the database schema and proceeds with reindexing. Progress can be monitored in the log file <code>/var/log/thehive/application.log</code>. Refer to the troubleshooting section for further assistance.</p> <p> </p>"}, {"location": "thehive/installation/upgrade-from-4.x/#restarting-the-service", "title": "Restarting the Service", "text": "<p>After successfully starting the service, follow these steps to update the configuration file and restart TheHive:</p> <ol> <li>Update Configuration File - Remove the following lines from the configuration file <code>/etc/thehive/application.conf</code>:</li> </ol> <pre><code>db.janusgraph.forceDropAndRebuildIndex = true\n</code></pre> <ol> <li>Restart TheHive - Restart TheHive using the following command:</li> </ol> <pre><code>sudo systemctl restart thehive\n</code></pre> I'm using a cluster <p>If you're deploying TheHive in a cluster, you can proceed to install and start TheHive on all other nodes following similar steps.</p>"}, {"location": "thehive/installation/upgrade-from-4.x/#troubleshooting", "title": "Troubleshooting", "text": "<p>During the update, few logs can be seen in TheHive <code>application.log</code> file. </p> <p>Example of logs and what they mean</p> <pre><code>[INFO] from org.janusgraph.graphdb.database.management.GraphIndexStatusWatcher in application-akka.actor.default-dispatcher-11 [|] Some key(s) on index global2 do not currently have status(es) [REGISTERED, ENABLED]: dateValue=INSTALLED,externalLink=INSTALLED,origin=INSTALLED,patternId=INSTALLED,revoked=INSTALLED,mandatory=INSTALLED,content=INSTALLED,isAttachment=INSTALLED,writable=INSTALLED,tactic=INSTALLED,stringValue=INSTALLED,owningOrganisation=INSTALLED,permissions=INSTALLED,actionRequired=INSTALLED,integerValue=INSTALLED,details=INSTALLED,locked=INSTALLED,slug=INSTALLED,cortexId=INSTALLED,owner=INSTALLED,workerId=INSTALLED,apikey=INSTALLED,level=INSTALLED,floatValue=INSTALLED,version=INSTALLED,occurDate=INSTALLED,url=INSTALLED,report=INSTALLED,tactics=INSTALLED,booleanValue=INSTALLED,cortexJobId=INSTALLED,category=INSTALLED,workerName=INSTALLED\n</code></pre> TheHive install indexes of the new schema in the database <pre><code>[INFO] from org.janusgraph.graphdb.olap.job.IndexRepairJob in Thread-97 [|] Index global2 metrics: success-tx: 1 doc-updates: 100 succeeded: 100\n</code></pre> TheHive reindexes all data <pre><code>* UPDATE SCHEMA OF thehive-enterprise (1): Create initial values\n[INFO] from org.thp.scalligraph.models.Operations in application-akka.actor.default-dispatcher-11 [d471d8b643d17b6d|d88fe62679b77ab1] Adding initial values for GDPRDummy\n[..]\n[INFO] from org.thp.scalligraph.models.Operations in application-akka.actor.default-dispatcher-11 [|] Update graph in progress (100): Add pap and ignoreSimilarity to observables\n</code></pre> Migrating data from v4. to v5 <pre><code>[WARN] from org.thp.thehive.enterprise.services.LicenseSrv in main [ef39c95eaa6de532|0ccf187e40a4cd34] No license found\n</code></pre> No license found. This is a normal behavior during the upgrade from versions 4 to 5 <pre><code>INFO] from play.core.server.AkkaHttpServer in main [|] Listening for HTTP on /0:0:0:0:0:0:0:0:9000\n</code></pre> The service is available. Users/Administrators can log in <pre><code>[INFO] from org.thp.thehive.connector.cortex.services.CortexDataImportActor in application-akka.actor.default-dispatcher-16 [|] Analyzer templates already present (found 203), skipping\n[..]\n[INFO] from org.thp.thehive.services.ttp.PatternImportActor in application-akka.actor.default-dispatcher-14 [|] Import finished, 707 patterns imported\n</code></pre> Few operations are processed after making the service available, like installing MITRE Enterprise ATT&amp;CK patterns catalog or Analyzers templates. <pre><code>[ERROR] from org.janusgraph.diskstorage.log.util.ProcessMessageJob in pool-22-thread-1 [|] Encountered exception when processing message [Message@2022-03-24T16:50:40.655134Z:7f0001017672-ubuntu2=0x809F9F0568850528850550850558850570850600850610850618850650850668850710850738850758850760850808850900850910850A60850A70850A78850B00850B08853520853B3885150E8941608541688541788542088542688542708581] by reader [org.janusgraph.graphdb.database.management.ManagementLogger@3e1a6eae]:java.lang.IllegalStateException: Cannot access element because its enclosing transaction is closed and unbound\nat org.janusgraph.graphdb.transaction.StandardJanusGraphTx.getNextTx(StandardJanusGraphTx.java:380)\nat org.janusgraph.graphdb.vertices.AbstractVertex.it(AbstractVertex.java:61)\nat org.janusgraph.graphdb.relations.CacheVertexProperty.&lt;init&gt;(CacheVertexProperty.java:38)\nat org.janusgraph.graphdb.transaction.RelationConstructor.readRelation(RelationConstructor.java:88)\nat org.janusgraph.graphdb.transaction.RelationConstructor.readRelation(RelationConstructor.java:71)\nat org.janusgraph.graphdb.transaction.RelationConstructor$1.next(RelationConstructor.java:57)\nat org.janusgraph.graphdb.transaction.RelationConstructor$1.next(RelationConstructor.java:45)\nat org.janusgraph.graphdb.types.vertices.JanusGraphSchemaVertex.getDefinition(JanusGraphSchemaVertex.java:94)\nat org.janusgraph.graphdb.transaction.StandardJanusGraphTx.expireSchemaElement(StandardJanusGraphTx.java:1599)\nat org.janusgraph.graphdb.database.management.ManagementLogger.read(ManagementLogger.java:97)\nat org.janusgraph.diskstorage.log.util.ProcessMessageJob.run(ProcessMessageJob.java:46)\nat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\nat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\nat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)\nat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\nat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\nat java.base/java.lang.Thread.run(Thread.java:829)\n</code></pre> During indexing, Janusgraph may display this message, this error is coming from a bug in janusgraph, don't mind it as the indexing will continue normally. This will have no impact on TheHive <p> </p>"}, {"location": "thehive/installation/upgrade-from-5.x/", "title": "Upgrade from Version 5.x", "text": ""}, {"location": "thehive/installation/upgrade-from-5.x/#upgrade-from-thehive-5x", "title": "Upgrade from TheHive 5.x", "text": "<p>Important: Starting with version 5.4, our web framework has been upgraded to Play3/Pekko. Depending on your TheHive installation and configuration, certain updates may be required in your configuration files. Refer to the configuration guide for details.</p>"}, {"location": "thehive/installation/upgrade-from-5.x/#important-considerations", "title": "Important Considerations", "text": "<p>Before proceeding with the upgrade, please keep the following points in mind:</p> <ol> <li> <p>Database Backup: We strongly recommend performing a full database backup before upgrading. For detailed instructions on how to perform a backup, please refer to the backup instructions.</p> </li> <li> <p>Downgrade Limitation: Once upgraded to TheHive 5.4, your instance cannot be downgraded. This means reverting to a previous version of TheHive 5 will require restoring your data from the backup.</p> </li> <li> <p>When upgrading an existing TheHive 5.x instance, the first application launch will trigger a database evolution, including schema and data updates. This operation may take some time depending on your database size.</p> </li> <li> <p>Since version 5.1, TheHive no longer supports the Lucene backend as the index engine. Lucene was an option for handling data indexing with TheHive 4.1.x. To migrate your index to Elasticsearch, please follow the provided guide.</p> </li> </ol>"}, {"location": "thehive/installation/upgrade-from-5.x/#overview", "title": "Overview", "text": "<p>This guide provides step-by-step instructions for upgrading an existing TheHive 5.x instance to TheHive 5.4.x.</p>"}, {"location": "thehive/installation/upgrade-from-5.x/#upgrade-instructions", "title": "Upgrade Instructions", "text": "<p>TheHive 5.x deliverables are hosted in distinct package repositories. Depending on your installation method, follow the instructions below:</p> DEB Package (Debian/Ubuntu)RPM Package (Red Hat/CentOS)Docker <ol> <li> <p>(Optional) Install the package repository signature key, if not already installed:</p> <pre><code>wget -O- https://raw.githubusercontent.com/StrangeBeeCorp/Security/main/PGP%20keys/packages.key | sudo gpg --dearmor -o /usr/share/keyrings/strangebee-archive-keyring.gpg\n</code></pre> </li> <li> <p>Edit the file <code>/etc/apt/sources.list.d/strangebee.list</code> and adjust the repository address as follows:</p> <pre><code>deb [arch=all signed-by=/usr/share/keyrings/strangebee-archive-keyring.gpg] https://deb.strangebee.com thehive-5.4 main\n</code></pre> </li> <li> <p>Install TheHive package:</p> <pre><code>sudo apt-get update\nsudo apt-get install -y thehive \n</code></pre> </li> </ol> <ol> <li> <p>(Optional) Install the package repository signature key, if not already installed:</p> <pre><code>sudo rpm --import https://raw.githubusercontent.com/StrangeBeeCorp/Security/main/PGP%20keys/packages.key\n</code></pre> </li> <li> <p>Edit the file <code>/etc/yum.repos.d/strangebee.repo</code> and adjust the repository address as follows:</p> <pre><code>[thehive]\nenabled=1\npriority=1\nname=StrangeBee RPM repository\nbaseurl=https://rpm.strangebee.com/thehive-5.4/noarch\ngpgkey=https://raw.githubusercontent.com/StrangeBeeCorp/Security/main/PGP%20keys/packages.key\ngpgcheck=1\n</code></pre> </li> <li> <p>Then install the package using yum:</p> <pre><code>sudo yum update\nsudo yum install thehive \n</code></pre> </li> </ol> <p>Update your existing TheHive 5.x Docker stack (docker-compose file or similar) using the image named <code>strangebee/thehive:5.4</code></p> <p>Important note</p> <p>Ensure that you update your Docker tags accordingly. The strangebee/thehive:latest tag is deprecated and remains associated with TheHive 5.0.x versions. A new strangebee/thehive:5.4 tag is now available and associated with the latest 5.4.x version.</p>"}, {"location": "thehive/installation/upgrade-from-5.x/#health-checks", "title": "Health Checks", "text": "<p>If you have health checks on the application HTTP interface, they should be disabled during the upgrade process. Otherwise, the orchestrator may kill TheHive during the update process.</p> <p> </p>"}, {"location": "thehive/operations/cassandra-cluster/", "title": "Cassandra Cluster Operations", "text": ""}, {"location": "thehive/operations/cassandra-cluster/#cassandra-cluster-operations", "title": "Cassandra Cluster Operations", "text": "<p>This guide provides comprehensive instructions for performing key operations on a Cassandra cluster, including adding nodes to an existing cluster and managing node removal.</p>"}, {"location": "thehive/operations/cassandra-cluster/#adding-a-node-to-a-cassandra-cluster", "title": "Adding a Node to a Cassandra Cluster", "text": "<p>To add a Cassandra node to an existing cluster without downtime, follow these steps:</p> <ol> <li> <p>Install the New Node:</p> <ul> <li>Install Cassandra on the new node using the same configuration file as the existing nodes, with adjustments made to the <code>listen_address</code> and <code>rpc_address</code> settings to reflect the node's IP address. Set the IP address of any existing node in the seeds section of the configuration file (cassandra.yaml). </li> </ul> </li> <li> <p>Start the Node</p> <ul> <li>Once installed and configured, start the Cassandra service on the new node.</li> </ul> </li> <li> <p>Check Cluster Status</p> <ul> <li>Use the nodetool status command to monitor the cluster status and verify that the new node is recognized and in the joining state.</li> </ul> Display Cassandra Nodes Status<pre><code># nodetool status\n\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address     Load       Tokens  Owns (effective)  Host ID                               Rack \nUN  172.24.0.2  3.68 GiB   256      100.0%            048a870f-d6d5-405e-8d0d-43dbc12be747  rack1\nUJ  172.24.0.3  89.54 MiB  256      ?                 f192ef8f-a4fd-4e24-99a7-0f92605a7cb6  rack1\n</code></pre> </li> </ol> <p>After the new node is fully operational, re-run the nodetool status command to ensure that the cluster status reflects the successful addition of the new node:</p> Display Cassandra Nodes status<pre><code># nodetool status\n\nDatacenter: datacenter1\n=======================\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address     Load      Tokens  Owns (effective)  Host ID                               Rack \nUN  172.24.0.2  3.68 GiB  256      48.8%             048a870f-d6d5-405e-8d0d-43dbc12be747  rack1\nUN  172.24.0.3  1.91 GiB  256      51.2%             f192ef8f-a4fd-4e24-99a7-0f92605a7cb6  rack1\n</code></pre> <p>The updated status will indicate the UN (Up/Normal) state for the new node, showing its load, tokens, ownership percentage, host ID, and rack assignment.</p> <p>Creating a Cluster from a Standalone Server</p> <p>If you are transitioning from a standalone server to a multi-node cluster by adding a new node, ensure that you update  the confiuration of the existing standalone server by modifying the <code>cassandra.yaml</code> file to replace the <code>localhost</code> in <code>listen_address</code> and <code>rpc_address</code> with the server's actual IP address. </p>"}, {"location": "thehive/operations/cassandra-cluster/#removing-an-alive-node-from-a-cassandra-cluster", "title": "Removing an Alive Node from a Cassandra Cluster", "text": "<p>To safely remove an alive node from your Cassandra cluster, follow these steps:</p> <ol> <li>Ensure Compatibility with Replication Factor</li> </ol> <p>Before proceeding with node removal, ensure that the replication factor is suitable for the desired number of nodes in the cluster. If necessary, update the replication factor to maintain adequate data redundancy.</p> <ol> <li>Decommission the Node</li> </ol> <p>To remove an alive node gracefully, connect to the node you intend to remove and execute the following nodetool command:</p> <pre><code>nodetool decommission\n</code></pre> <p>This command initiates the decommissioning process for the node, allowing it to transfer its data to other nodes in the cluster before removal.</p> <p>Monitor the decommissioning progress using <code>nodetool status</code> on other nodes in the cluster. Verify that the decommissioned node transitions to a <code>Leaving state</code> and completes data transfer successfully.</p>"}, {"location": "thehive/operations/cassandra-cluster/#removing-a-dead-node-from-a-cassandra-cluster", "title": "Removing a Dead Node from a Cassandra Cluster", "text": "<p>If a node has crashed and cannot be repaired, you can remove it from the cluster using the <code>nodetool removenode</code> command followed by the node <code>id</code>.</p> <p>Steps to Remove a Dead Node:</p> <ol> <li>Check Current Cluster Status:</li> <li> <p>Use <code>nodetool status</code> to view the current status of the Cassandra cluster:      </p><pre><code>nodetool status\n</code></pre> </li> <li> <p>Identify the Dead Node:</p> </li> <li> <p>Locate the node with a <code>DN</code> (Down) status in the cluster output.</p> </li> <li> <p>Execute <code>nodetool removenode</code> Command:</p> </li> <li> <p>Run the following command to remove the dead node from the cluster:      </p><pre><code>nodetool removenode &lt;node_id&gt;\n</code></pre>      Replace <code>&lt;node_id&gt;</code> with the ID of the dead node obtained from the <code>nodetool status</code> output. </li> <li> <p>Verify Cluster Status:</p> </li> <li>After executing the <code>nodetool removenode</code> command, check the cluster status again using <code>nodetool status</code> to ensure that the dead node has been successfully removed and that the remaining nodes are in a <code>Normal</code> state.</li> </ol>"}, {"location": "thehive/operations/cassandra-cluster/#increasing-replication-factor-in-cassandra", "title": "Increasing Replication Factor in Cassandra", "text": "<p>When you have multiple nodes, increasing the replication factor enhances fault tolerance by creating additional copies in the cluster. More copies mean greater resilience to hardware failures. However, this also means more disk space is used due to the increased data redundancy, potentially resulting in slower write access.</p> <p>To enhance fault tolerance in your Cassandra cluster by increasing the replication factor, follow these steps:</p> <ol> <li>Connect to cqlsh</li> </ol> <p>Use cqlsh to connect to your Cassandra cluster:</p> <ol> <li>Modify Keyspace Replication</li> </ol> <p>Execute the following ALTER KEYSPACE command to increase the replication factor for a specific keyspace (replace thehive with your keyspace name):</p> <pre><code>ALTER KEYSPACE thehive WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3 };\n</code></pre> <ol> <li>Run nodetool repair -full on Each Node</li> </ol> <p>After modifying the keyspace replication, execute <code>nodetool repair -full</code> on each node in your Cassandra cluster to ensure data is fully replicated and consistent across the cluster.</p> <p>It's recommended to increase the replication factor for system keyspaces to ensure high availability and reliability of critical Cassandra system data.</p> <p>To view the current replication settings for all keyspaces in your cluster, use the following cqlsh query:</p> Checking Current Keyspace Information<pre><code>&gt; SELECT * FROM system_schema.keyspaces;\n\n keyspace_name      | durable_writes | replication\n--------------------+----------------+-------------------------------------------------------------------------------------\n        system_auth |           True | {'class': 'org.apache.cassandra.locator.SimpleStrategy', 'replication_factor': '2'}\n      system_schema |           True |                             {'class': 'org.apache.cassandra.locator.LocalStrategy'}\n system_distributed |           True | {'class': 'org.apache.cassandra.locator.SimpleStrategy', 'replication_factor': '2'}\n             system |           True |                             {'class': 'org.apache.cassandra.locator.LocalStrategy'}\n      system_traces |           True | {'class': 'org.apache.cassandra.locator.SimpleStrategy', 'replication_factor': '2'}\n            thehive |           True | {'class': 'org.apache.cassandra.locator.SimpleStrategy', 'replication_factor': '2'}\n</code></pre> <p>This query displays detailed information about each keyspace, including its name and replication strategy with the associated replication factor.</p> <p> </p>"}, {"location": "thehive/operations/cassandra-security/", "title": "Cassandra Security Operations", "text": ""}, {"location": "thehive/operations/cassandra-security/#security-in-apache-cassandra", "title": "Security in Apache Cassandra", "text": ""}, {"location": "thehive/operations/cassandra-security/#authentication-with-cassandra", "title": "Authentication with Cassandra", "text": "<p>References</p> <p>Internal authentication</p> <ul> <li>https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/configuration/secureInternalAuthenticationTOC.html</li> </ul> <p>To authenticate with Cassandra and manage permissions, follow these steps:</p> <ol> <li>Create a Role and Grant Permissions:</li> </ol> <pre><code>CREATE ROLE thehive WITH PASSWORD = 'thehive1234' AND LOGIN = true;\nGRANT ALL PERMISSIONS ON KEYSPACE thehive TO thehive;\n</code></pre> <ol> <li> <p>Configure TheHive with the Account:</p> <p>Update <code>/etc/thehive/application.conf</code> with the Cassandra authentication details:</p> <pre><code>  db.janusgraph {\n    storage {\n      ## Cassandra configuration\n      # More information at https://docs.janusgraph.org/basics/configuration-reference/#storagecql\n      backend: cql\n      hostname: [\"xxx.xxx.xxx.xxx\"]\n      # Cassandra authentication (if configured)\n      username: \"thehive\" \n      password: \"thehive1234\" \n      cql {\n        cluster-name: thp\n        keyspace: thehive\n      }\n    }\n</code></pre> <p>Ensure to replace xxx.xxx.xxx.xxx with the appropriate Cassandra hostname or IP address.</p> </li> </ol>"}, {"location": "thehive/operations/cassandra-security/#configuring-node-to-node-encryption-for-cassandra", "title": "Configuring Node-to-Node Encryption for Cassandra", "text": "<p>References</p> <p>Node-to-Node Encryption</p> <ul> <li>https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/configuration/secureSSLNodeToNode.html</li> </ul> <p>To enable node-to-node encryption, modify the <code>cassandra.yaml</code> configuration file with the following settings:</p> <pre><code>server_encryption_options:\n    internode_encryption: all\n    keystore: /path/to/keystore.jks\n    keystore_password: keystorepassword\n    truststore: /path/to/truststore.jks\n    truststore_password: truststorepassword\n    # More advanced defaults below:\n    protocol: TLS\n    algorithm: SunX509\n    store_type: JKS\n    cipher_suites: [TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA,TLS_DHE_RSA_WITH_\nAES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_R\nSA_WITH_AES_256_CBC_SHA]\n    require_client_auth: false\n</code></pre> <p> </p>"}, {"location": "thehive/operations/cassandra-security/#setting-up-cassandra-dedicated-ssl-port-optional", "title": "Setting Up Cassandra Dedicated SSL Port (Optional)", "text": "<p>Optionally, you can configure a dedicated port for SSL communication in Cassandra. Setting up a dedicated SSL port provides enhanced security for communication with your Cassandra cluster. Follow these steps to update the <code>/etc/cassandra/cassandra.yaml</code> configuration file on each node:</p> <ol> <li> <p>Open the cassandra.yaml configuration file on each node.</p> </li> <li> <p>Locate the native_transport_port_ssl parameter within the file.</p> </li> <li> <p>Update the native_transport_port_ssl parameter to specify the desired SSL port number (e.g., 9142):</p> <pre><code>native_transport_port_ssl: 9142\n</code></pre> </li> </ol> <p>By specifying a dedicated <code>native_transport_port_ssl</code>, all SSL communications will utilize this port instead of the default port configured for non-SSL traffic (<code>native_transport_port</code>). </p>"}, {"location": "thehive/operations/cassandra-security/#client-to-node-encryption", "title": "Client to Node Encryption", "text": "<p>References</p> <p>Client to Node Encryption</p> <ul> <li>https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/configuration/secureSSLClientToNode.html</li> <li>https://docs.janusgraph.org/basics/configuration-reference/#storagecqlssl</li> </ul> <p>This guide explains how to establish a secure connection between Cassandra clients (specifically TheHive) and the Cassandra server.</p> <p> </p>"}, {"location": "thehive/operations/cassandra-security/#requirements", "title": "Requirements", "text": "<p>To set up secure encryption, you'll need the following:</p> <ol> <li>X509 Certificate for Cassandra Service</li> <li>Ensure the certificate has the following standard properties:<ul> <li>Key Usage: Digital Signature, Non-Repudiation, Key Encipherment, Key Agreement</li> <li>Extended Key Usage: TLS Web Server Authentication</li> <li>Certificate Type: SSL Server</li> </ul> </li> <li>Include a \"Subject Alternative Name\" (DNS name and/or IP address) that matches how the Cassandra server is identified by the client.</li> <li> <p>The certificate file format should be PKCS12 (with a <code>.p12</code> extension).</p> </li> <li> <p>Truststore</p> </li> <li>Create a truststore that contains the Certificate Authority (CA) used to generate the Cassandra server's certificate.</li> <li>The truststore should be in Java Keystore (JKS) format.</li> <li>If your CA file is named <code>ca.crt</code>, generate the truststore file using the following command:      <pre><code>keytool -import -file /path/to/ca.crt -alias CA -keystore ca.jks\n</code></pre>      You will be prompted to set a password for file integrity checking.</li> </ol> <p>Note: The <code>keytool</code> command is available as part of any JDK distribution.</p> <p> </p>"}, {"location": "thehive/operations/cassandra-security/#steps-to-set-up-encryption", "title": "Steps to Set Up Encryption", "text": "<p>Follow these steps to enable encryption between Cassandra clients (TheHive) and the Cassandra server:</p> <ol> <li> <p>Obtain the Server Certificate</p> <ul> <li>Acquire a valid X509 certificate for the Cassandra service with the specified properties.</li> </ul> </li> <li> <p>Configure the Server Certificate</p> <ul> <li>Ensure the certificate includes the necessary key usage and extended key usage properties.</li> </ul> </li> <li> <p>Create the Truststore</p> <ul> <li>Use the <code>keytool</code> command to import the CA certificate into a Java Keystore (JKS) file (<code>ca.jks</code>).</li> </ul> <pre><code>keytool -import -file /path/to/ca.crt -alias CA -keystore ca.jks\n</code></pre> <p>You will be prompted to set a password for the truststore.</p> </li> <li> <p>Configuring Cassandra</p> <ul> <li>Locate the section <code>client_encryption_options</code> and set the following options:</li> </ul> <pre><code>client_encryption_options:\n    enabled: true\n    # If enabled and optional is set to true encrypted and unencrypted connections are handled.\n    optional: false\n    keystore: /pat/to/keystore.jks\n    keystore_password: keystorepassword\n    require_client_auth: false\n    # Set trustore and truststore_password if require_client_auth is true\n    # truststore: conf/.truststore\n    # truststore_password: cassandra\n    # More advanced defaults below:\n    protocol: TLS\n    algorithm: SunX509\n    store_type: JKS\n    cipher_suites: [TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA,TLS_DHE_RSA_WITH_\nAES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_R\nSA_WITH_AES_256_CBC_SHA]\n</code></pre> <ul> <li>After making these changes, restart the Cassandra service.</li> </ul> </li> <li> <p>Configure TheHive to Use Encryption</p> <ul> <li>Update TheHive's Cassandra client configuration to specify the location of the truststore (<code>ca.jks</code>) and provide any additional connection properties required for SSL/TLS encryption.</li> </ul> <pre><code>db.janusgraph {\n  storage {\n    ## Cassandra configuration\n    # More information at https://docs.janusgraph.org/basics/configuration-reference/#storagecql\n    backend: cql\n    hostname: [\"ip_node_1\", \"ip_node_2\", \"ip_node_3\"]\n    # Cassandra authentication (if configured)\n    username: \"thehive\"\n    password: \"thehive1234\"\n    port: 9142 # if alternative port has been set in Cassandra configuration\n    cql {\n      cluster-name: thp\n      keyspace: thehive\n      ssl {\n        enabled: true\n        truststore {\n          location: \"/path/to/truststore.jks\"\n          password: \"truststorepassword\"\n        }\n      }\n    }\n  }\n</code></pre> <ul> <li>After making these changes, restart TheHive to apply the new configuration settings.</li> </ul> </li> </ol> <p> </p>"}, {"location": "thehive/operations/change-index/", "title": "Index Management", "text": ""}, {"location": "thehive/operations/change-index/#change-index-from-lucene-to-elasticsearch", "title": "Change Index from Lucene to Elasticsearch", "text": "<p>Lucene index support was removed starting from TheHive version 5.1. Follow this procedure to change your index to Elasticsearch. This procedure is compatible with any 5.x version.</p>"}, {"location": "thehive/operations/change-index/#setup-your-elasticsearch-server", "title": "Setup Your Elasticsearch Server", "text": "<p>Please refer to our installation manual or use your own server. Ensure that Elasticsearch is started.</p>"}, {"location": "thehive/operations/change-index/#update-thehive-configuration", "title": "Update TheHive Configuration", "text": "DEB / RPM <p>Update your <code>/etc/thehive/application.conf</code> file:</p> <pre><code># Update this configuration section\ndb.janusgraph {\n    # Retain this section for now, as TheHive will need it to migrate the index correctly\n    index.search {\n        backend: lucene\n        directory: ...\n    }\n\n    # Add this section below the Lucene configuration\n    index.search {\n        backend: elasticsearch\n        # Hostname(s) of your Elasticsearch server(s)\n        hostname: [\"localhost\"]\n        # Default is \"thehive\"\n        index-name: thehive\n    }\n}\n</code></pre> <p>Refer to the configuration reference for more options.</p> Docker <p>Update your Docker arguments:</p> <pre><code># Docker compose file\ncommand:\n    # ... other args\n    - \"--index-backend\"\n    - \"elasticsearch\"\n    - \"--es-hostnames\"\n    - \"elasticsearch\"\n</code></pre>"}, {"location": "thehive/operations/change-index/#restart-thehive-application", "title": "Restart TheHive Application", "text": "<p>TheHive will detect the index change, create the new index in Elasticsearch, and start reindexing the documents into the new index. This process may take some time depending on the size of your database.</p> <p>In your logs, you should see the following lines:</p> <pre><code>[warn] o.j.d.c.b.ReadConfigurationBuilder [] Local setting index.search.backend=elasticsearch (Type: GLOBAL_OFFLINE) is overridden by globally managed value (lucene). Use the ManagementSystem interface instead of the local configuration to control this setting.\n</code></pre> <p>During the reindexing process, you will see lines similar to these (the name <code>global1</code> may be different for you):</p> <pre><code>[info] o.j.g.o.j.IndexRepairJob [] Index global1 metrics: success-tx: 110 doc-updates: 10992 succeeded: 10992\n[info] o.j.g.o.j.IndexRepairJob [] Index global1 metrics: success-tx: 111 doc-updates: 10992 succeeded: 10992\n[info] o.j.g.d.m.ManagementSystem [] Index update job successful for [global1]\n</code></pre> <p>Finally, the application will start listening on the HTTP port, and you will be able to access the interface.</p>"}, {"location": "thehive/operations/change-index/#remove-the-lucene-configuration", "title": "Remove the Lucene Configuration", "text": "<p>Once the reindexing is complete, you can remove the Lucene configuration from your configuration file.</p> DEB / RPM <p>Update your <code>/etc/thehive/application.conf</code> file:</p> <pre><code># Update this configuration section\ndb.janusgraph {\n    # Delete this section now\n    index.search {\n        backend: lucene\n        directory: ...\n    }\n\n    # Retain this section\n    index.search {\n        backend: elasticsearch\n        # Hostname(s) of your Elasticsearch server(s)\n        hostname: [\"localhost\"]\n        # Default is \"thehive\"\n        index-name: thehive\n    }\n}\n</code></pre>"}, {"location": "thehive/operations/minio-cluster/", "title": "MinIO Cluster Operations", "text": ""}, {"location": "thehive/operations/minio-cluster/#minio-cluster-operations", "title": "MinIO Cluster Operations", "text": ""}, {"location": "thehive/operations/minio-cluster/#replace-a-disk", "title": "Replace a Disk", "text": "<p>If a disk in your MinIO cluster is faulty and needs to be replaced, you can perform this operation without downtime thanks to MinIO's support for hot-swapping disks:</p> <ol> <li> <p>Unmount the Faulty Disk</p> <ul> <li> <p>Safely unmount the faulty disk from the server where it is installed.</p> </li> <li> <p>Ensure that any data on the disk is backed up or transferred to another location if possible.</p> </li> </ul> </li> <li> <p>Install the Replacement Disk</p> <ul> <li> <p>Install the healthy replacement disk in the same location as the faulty disk.</p> </li> <li> <p>Connect the replacement disk to the server and ensure it is properly recognized by the operating system.</p> </li> </ul> </li> <li> <p>Mount the Replacement Disk</p> <ul> <li>Mount the replacement disk to the same mount point previously used by the faulty disk.</li> </ul> </li> <li> <p>Check MinIO Logs</p> <ul> <li>Check the MinIO logs to ensure that the new disk has been recognized by the system:   <pre><code>mc admin service logs &lt;myminio&gt;\n</code></pre></li> </ul> </li> <li> <p>Initiate Disk Heal</p> <ul> <li>Run a disk heal operation to synchronize data and ensure data integrity across the cluster with the new disk:   <pre><code>mc admin heal &lt;myminio&gt;\n</code></pre></li> </ul> </li> </ol>"}, {"location": "thehive/operations/minio-cluster/#replace-a-node", "title": "Replace a Node", "text": "<p>In the event that a server within your MinIO cluster has crashed and cannot be recovered, you can install a new server to replace it. Ensure that the new node is configured with the same IP address or hostname as the old node. Once the new server is operational and has joined the cluster, initiate a disk heal by running <code>mc admin heal</code>.</p> <p> </p>"}, {"location": "thehive/operations/minio-cluster/#step-by-step-guide-replace-a-node-in-minio-cluster", "title": "Step-by-Step Guide: Replace a Node in MinIO Cluster", "text": "<ol> <li> <p>Prepare the Replacement Server</p> <ul> <li> <p>Set up a new server that meets the hardware and network requirements for running MinIO.</p> </li> <li> <p>Ensure the new server has the same MinIO version as the existing cluster nodes.</p> </li> <li> <p>Assign the same IP address or hostname as the node being replaced.</p> </li> </ul> </li> <li> <p>Prepare the Existing Cluster</p> <ul> <li>Identify the node that needs to be replaced and ensure it is no longer part of the active cluster. Stop the MinIO service on this node.</li> </ul> </li> <li> <p>Transfer Data</p> <ul> <li>If possible, transfer any data stored on the node being replaced to other nodes in the cluster to avoid data loss.</li> </ul> </li> <li> <p>Distribute the Configuration</p> <ul> <li>Copy the modified <code>config.json</code> file to the new replacement node's MinIO configuration directory.</li> </ul> </li> <li> <p>Start MinIO Service on Replacement Node</p> <ul> <li>Start the MinIO service on the new replacement node and ensure it joins the cluster successfully:   <pre><code>systemctl start minio\n</code></pre></li> </ul> </li> <li> <p>Verify Node Replacement</p> <ul> <li>Check the cluster status to ensure that the new replacement node has been successfully added and is part of the cluster:   <pre><code>mc admin info myminio\n</code></pre></li> </ul> </li> <li> <p>Initiate Disk Heal</p> <ul> <li>Run a disk heal operation to synchronize data and ensure data integrity across the cluster with the new replacement node:   <pre><code>mc admin heal myminio\n</code></pre></li> </ul> </li> <li> <p>Monitor Cluster Health</p> <ul> <li>Use MinIO's monitoring tools (<code>mc admin top</code> or web-based console) to monitor the health and performance of the cluster with the new replacement node.</li> </ul> </li> </ol> <p>By following these steps, you can safely replace a node in your MinIO cluster while maintaining data integrity and cluster stability. Ensure that all operations are performed during a maintenance window to minimize impact on production services.</p>"}, {"location": "thehive/operations/minio-cluster/#add-a-node-to-the-cluster", "title": "Add a Node to the Cluster", "text": "<p>Adding a new server to an existing MinIO cluster involves restarting all MinIO nodes and updating their configuration to account for the new node. It's crucial to synchronize the configuration across all nodes. After the cluster is successfully started with the new node, perform a disk heal operation using <code>mc admin heal</code>.</p> <p>Note: MinIO strongly recommends restarting all nodes simultaneously when adding or removing nodes from a cluster. Avoid \"rolling\" restarts (i.e., restarting one node at a time).</p> <p> </p>"}, {"location": "thehive/operations/minio-cluster/#step-by-step-guide-adding-a-node-to-minio-cluster", "title": "Step-by-Step Guide: Adding a Node to MinIO Cluster", "text": "<ol> <li> <p>Prepare the New Server</p> <ul> <li> <p>Set up a new server (physical or virtual) that meets the hardware and network requirements for running MinIO.</p> </li> <li> <p>Ensure the new server has the same MinIO version as the existing cluster nodes.</p> </li> <li> <p>Assign a static IP address or configure a hostname for the new node that matches the existing cluster nodes.</p> </li> </ul> </li> <li> <p>Update MinIO Configuration</p> <ul> <li> <p>Access the configuration file (<code>config.json</code>) of each existing MinIO node in the cluster.</p> </li> <li> <p>Add the details of the new node (IP address or hostname) to the <code>config.json</code> file of each node under the <code>cluster</code> section:   </p><pre><code>{\n   \"version\": \"minio\",\n   \"cluster\": {\n      \"nodes\": [\n      {\"endpoint\": \"existing-node1:9000\"},\n      {\"endpoint\": \"existing-node2:9000\"},\n      {\"endpoint\": \"existing-node3:9000\"},\n      {\"endpoint\": \"new-node:9000\"}\n      ]\n   }\n}\n</code></pre> </li> <li> <p>Save the updated configuration file.</p> </li> </ul> </li> <li> <p>Distribute the Updated Configuration</p> <ul> <li>Copy the modified <code>config.json</code> file to the new node's MinIO configuration directory.</li> </ul> </li> <li> <p>Restart MinIO Service</p> <ul> <li>On each existing MinIO node, restart the MinIO service to apply the updated configuration:   <pre><code>systemctl restart minio\n</code></pre></li> </ul> </li> <li> <p>Verify Node Addition</p> <ul> <li>Once all nodes have been restarted, check the cluster status to ensure the new node has been successfully added:   <pre><code>mc admin info &lt;myminio&gt;\n</code></pre></li> </ul> </li> <li> <p>Initiate Disk Heal</p> <ul> <li>Run a disk heal operation to ensure data consistency across the cluster with the new node:   <pre><code>mc admin heal &lt;myminio&gt;\n</code></pre></li> </ul> </li> </ol>"}, {"location": "thehive/operations/minio-cluster/#remove-a-node-from-cluster", "title": "Remove a node from cluster", "text": "<p>When removing a node from your MinIO cluster, follow the same procedure as adding a node: update the cluster's configuration file to reflect the removal and restart all nodes in the cluster to apply the changes.</p>"}, {"location": "thehive/operations/minio-cluster/#minio-and-high-availability", "title": "MINIO and High Availability", "text": "<p>MinIO supports high availability by configuring a single S3 endpoint in applications like TheHive. To achieve high availability across MinIO nodes, it's recommended to use load balancers and virtual IP addresses to distribute connections evenly among the cluster nodes.</p> <p>Follow the guide under deploying a cluster to configure MinIO with load balancer and virtual IP.</p> <p> </p>"}, {"location": "thehive/operations/monitoring/", "title": "Monitoring Setup", "text": ""}, {"location": "thehive/operations/monitoring/#monitoring-thehive", "title": "Monitoring TheHive", "text": "<p>Monitoring your TheHive instance enables you to gather essential metrics regarding its performance, including request times, CPU usage, and memory utilization.</p> <p>TheHive leverages the Kamon library for monitoring purposes, which is disabled by default.</p> <p>TheHive includes integration with the Prometheus reporter out-of-the-box. Other reporters are not included. If you wish to have a specific reporter included by default in TheHive, please contact us.</p>"}, {"location": "thehive/operations/monitoring/#configuring-metrics-with-prometheus-and-grafana", "title": "Configuring Metrics with Prometheus and Grafana", "text": "<p>To configure TheHive for metrics reporting, add the following section to your <code>application.conf</code> file:</p> <pre><code>kamon {\n    # Activate Kamon module - disabled by default\n    enabled = true\n\n    # Enable the Prometheus reporter\n    modules {\n      prometheus-reporter.enabled = yes\n    }\n\n    environment.tags {\n        # Configure additional tags to be sent to Prometheus \n        # See https://kamon.io/docs/latest/reporters/prometheus/#sending-environment-tags-to-prometheus\n        # Example: env = prod\n    }\n\n    # Reference: https://kamon.io/docs/latest/reporters/prometheus/#configuration\n    prometheus {\n      include-environment-tags = true\n      # Start an embedded server on the specified port. \n      # If using Docker, ensure this port is accessible\n      embedded-server {\n        hostname = 0.0.0.0\n        port = 9095\n      }\n    }\n}\n</code></pre> <p>You will need to restart TheHive for the configuration changes to take effect.</p> <p>To verify that the Prometheus reporter is functioning correctly, navigate to http://THEHIVE:9095/metrics. You should see a list of metrics reported by TheHive.</p> <p> </p>"}, {"location": "thehive/operations/monitoring/#prometheus-configuration", "title": "Prometheus configuration", "text": "<p>Add the scrape configuration to prometheus configuration <code>prometheus.yml</code></p> <pre><code>scrape_configs:\n  # ...  other scrape configs \n\n  - job_name: 'thehive'\n    scrape_interval: 30s\n    static_configs:\n      - targets: ['THEHIVE:9095'] # set the ip or hostname for TheHive\n</code></pre> <p>In a dynamic environment like kubernetes, the TheHive service can be automatically discovered by prometheus. You can enable this with labels on your pod or by adding a <code>PodMonitor</code> resource. See the adaquate documentation: Prometheus configuration or Prometheus operator</p> <p> </p>"}, {"location": "thehive/operations/monitoring/#grafana-configuration", "title": "Grafana configuration", "text": "<ul> <li>Make sure that prometheus is setup as a Datasource inside Grafana</li> <li> <p>Import dashboards or create your own. We recommend the following dashboards (these dashboards were not created by Strangebee):</p> <ul> <li>Kamon 2.x - API dashboard: see API metrics like throughoutput, latency, % of error status. Note that TheHive frontend uses long polling, some requests take 60 seconds and they will appear as outliers in this dashboard</li> <li>Kamon 2.x - System metrics dashboard: see info about CPU or memory usage, JVM metrics like Heap usage or GC</li> <li>Kamon 2.x - Akka: info about Akka system, actors, processing time</li> </ul> <p>To make these dashboards work, you may need to edit the dashboard variables </p> </li> </ul>"}, {"location": "thehive/operations/troubleshooting/", "title": "Troubleshooting Guide", "text": ""}, {"location": "thehive/operations/troubleshooting/#troubleshooting", "title": "Troubleshooting", "text": "<p>For some issues, additional information in logs is needed to troubleshoot and understand the root causes. To gather and share this information, please carefully read and follow these steps.</p> <p>Warning</p> <p>ENABLING TRACE LOGS HAS A SIGNIFICANT IMPACT ON PERFORMANCE. DO NOT ENABLE IT ON PRODUCTION SERVERS.</p>"}, {"location": "thehive/operations/troubleshooting/#step-1-stop-thehive-service", "title": "Step 1: Stop TheHive Service", "text": "<p>First, stop TheHive service:</p> <pre><code>service thehive stop\n</code></pre> <p>Ensure the service is stopped with the following command:</p> <pre><code>service thehive status\n</code></pre>"}, {"location": "thehive/operations/troubleshooting/#step-2-renew-applicationlog-file", "title": "Step 2: Renew <code>application.log</code> File", "text": "<p>Move the existing <code>application.log</code> file to a backup location:</p> <pre><code>mv /var/log/thehive/application.log /var/log/thehive/application.log.bak\n</code></pre>"}, {"location": "thehive/operations/troubleshooting/#step-3-update-log-configuration", "title": "Step 3: Update Log Configuration", "text": "<p>Edit the log configuration file <code>/etc/thehive/logback.xml</code>. Locate the line containing <code>&lt;logger name=\"org.thp\" level=\"INFO\"/&gt;</code> and update it to the following:</p> <pre><code>    &lt;logger name=\"org.thp\" level=\"TRACE\"/&gt;\n</code></pre> <p>Save the file after making the changes.</p>"}, {"location": "thehive/operations/troubleshooting/#step-4-restart-thehive-service", "title": "Step 4: Restart TheHive Service", "text": "<p>Restart TheHive service:</p> <pre><code>service thehive start\n</code></pre> <p>A new log file <code>/var/log/thehive/application.log</code> will be created and will contain extensive logging information.</p>"}, {"location": "thehive/operations/troubleshooting/#step-5-monitor-and-save-logs", "title": "Step 5: Monitor and Save Logs", "text": "<p>Wait for the issue to occur or for the application to stop. Then, copy the log file to a safe location:</p> <pre><code>cp /var/log/thehive/application.log /root\n</code></pre>"}, {"location": "thehive/operations/troubleshooting/#step-6-share-the-logs", "title": "Step 6: Share the Logs", "text": "<p>Create an issue on GitHub and include the following information:</p> <ul> <li>Context:</li> <li>Instance type (single node/cluster, backend type, index engine)</li> <li> <p>System details (Operating System, amount of RAM, number of CPUs for each server/node)</p> </li> <li> <p>Symptoms:</p> </li> <li> <p>Actions taken, how the situation occurred, and what happened</p> </li> <li> <p>Log File:</p> </li> <li>Attach the log file with trace information</li> </ul>"}, {"location": "thehive/operations/troubleshooting/#step-7-revert-log-configuration", "title": "Step 7: Revert Log Configuration", "text": "<p>To revert to the normal log configuration:</p> <ol> <li>Stop TheHive service.</li> <li>Edit the <code>logback.xml</code> file to restore the previous log level configuration.</li> <li>Restart TheHive service.</li> </ol> <pre><code>service thehive stop\n# Restore the logback.xml file to previous state\nservice thehive start\n</code></pre> <p> </p>"}, {"location": "thehive/operations/backup-restore/overview/", "title": "Overview", "text": ""}, {"location": "thehive/operations/backup-restore/overview/#backup-and-restore-guides", "title": "Backup and Restore Guides", "text": "<p>Warning</p> <p>Regardless of the situation, we strongly recommend performing cold backups. TheHive utilizes Cassandra as its database and Elasticsearch as its indexing engine. Files are typically stored in a folder, although some users opt for Minio S3 object storage. For every backup, the data, index, and files must remain intact and consistent. Any inconsistency could result in data restoration failure.</p> <p>This documentation provides detailed instructions for performing cold backups. Alternatively, you may opt for a hot backup and restore strategy. To assist with this, we provide sample scripts that you can tailor to your specific requirements. However, it is important to note that the final responsibility for implementing and testing the backup and restore processes lies with you.</p> <p>We strongly recommend thoroughly validating your backup and restoration procedures in a controlled environment before relying on them in production. While we strive to provide accurate and helpful guidance, we cannot assume liability for any data loss, downtime, or system failures resulting from incorrect configurations, inconsistencies in your data, or issues during the restoration process. It is essential to ensure that your chosen approach aligns with your infrastructure and operational needs.</p>"}, {"location": "thehive/operations/backup-restore/overview/#cold-backup-restore", "title": "Cold backup &amp; restore", "text": "<p>Your backup and restore strategy heavily depends on your infrastructure and orchestration approach, whether you are using physical servers, virtual servers, Docker, Kubernetes, or cloud solutions like AWS EC2 instances.</p> <p>For example, with AWS Amazon EC2 servers where all data, indexes, and files are stored on dedicated volumes, performing a daily snapshots of the volumes may take only few minutes, including housekeeping tasks such as stopping and restarting services.</p> <p>These procedures focus exclusively on methods for creating full backups and do not cover incremental backup strategies.</p>"}, {"location": "thehive/operations/backup-restore/overview/#backup-and-restore-procedures", "title": "Backup and restore procedures", "text": "<p>Find complete backup and restore procedures for:</p> <ul> <li>Physical servers: backup and restore procedures</li> <li>Virtual servers: backup and restore procedures</li> <li>Containerized Environments (Docker Compose): backup and restore procedures</li> </ul> <p>Use the links above or navigate through the documentation to find the specific procedure suited for your environment.</p>"}, {"location": "thehive/operations/backup-restore/overview/#introduction-to-hot-backup-and-restore", "title": "Introduction to hot backup and restore", "text": "<p>While cold backups are highly recommended due to their simplicity and consistency, you may want to consider hot backups.  </p> <p>Hot backup procedures can minimize downtime, making them more suitable for production environments where service availability is critical. However, hot backups introduce additional complexity and risks, such as data inconsistencies, particularly in distributed systems like Cassandra and Elasticsearch.</p>"}, {"location": "thehive/operations/backup-restore/overview/#considerations-for-hot-backups", "title": "Considerations for hot backups", "text": "<ul> <li>Data Consistency: Ensure that the backup process handles the synchronization of data across services like Cassandra and Elasticsearch. Use tools such as <code>nodetool snapshot</code> for Cassandra and Elasticsearch APIs for snapshots.  </li> <li>Service-Specific Tools: Hot backups often require the use of specialized commands or APIs to ensure that the data state remains consistent during the process.  </li> <li>Validation: Always test your hot backup and restore process thoroughly in a non-production environment before relying on it in production.  </li> </ul> <p>Sample scripts and guidelines for hot backups are provided in this documentation. However, these are intended as a starting point and must be adapted to your infrastructure and operational requirements.</p>"}, {"location": "thehive/operations/backup-restore/backup/cloud/", "title": "Cloud backup", "text": ""}, {"location": "thehive/operations/backup-restore/backup/cloud/#cloud-backup", "title": "Cloud backup", "text": "<p>TBD</p>"}, {"location": "thehive/operations/backup-restore/backup/docker-compose/", "title": "Docker Compose", "text": ""}, {"location": "thehive/operations/backup-restore/backup/docker-compose/#backup-a-stack-run-with-docker-compose", "title": "Backup a stack run with Docker Compose", "text": "<p>Note</p> <p>This solution assumes you are following our Running with Docker guide to run your application stack.</p>"}, {"location": "thehive/operations/backup-restore/backup/docker-compose/#introduction", "title": "Introduction", "text": "<p>The backup procedure is designed to capture the state of your application stack in three simple steps:</p> <ol> <li>Stop all services to ensure data consistency and prevent any changes during the backup process.</li> <li>Copy volumes and mapped directories on the host machine, which contain your data, configurations, and logs.</li> <li>Restart the services to resume normal operations after the backup is complete.</li> </ol>"}, {"location": "thehive/operations/backup-restore/backup/docker-compose/#prerequisites", "title": "Prerequisites", "text": "<p>Before starting, ensure:</p> <ul> <li>You have sufficient storage space for the backup.</li> <li>Administrative privileges to stop and start Docker Compose services.</li> <li>Familiarity with the locations of your mapped volumes and data directories.</li> </ul> <p>This step-by-step procedure ensures a safe and consistent backup of your Docker Compose stack, enabling quick recovery in case of an issue or migration to a new environment. For more details on restoring these backups, refer to the restore procedure for Docker Compose.</p>"}, {"location": "thehive/operations/backup-restore/backup/docker-compose/#step-by-step-instructions", "title": "Step-by-step instructions", "text": ""}, {"location": "thehive/operations/backup-restore/backup/docker-compose/#stop-the-services", "title": "Stop the services", "text": "<pre><code>docker compose down \n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/docker-compose/#copy-files-in-a-backup-folder", "title": "Copy files in a backup folder", "text": "<p>For example, on the host server, create a folder on a dedicated NFS volume named <code>/opt/backups</code> and copy all files preserving their permissions</p> <pre><code>#!/bin/bash\n\n## ============================================================\n## BACKUP SCRIPT FOR THEHIVE APPLICATION STACK\n## ============================================================\n## PURPOSE:\n## This script creates a backup of TheHive application stack, \n## including its configuration, data, and logs. It is designed \n## to ensure data is preserved for restoration purposes.\n##\n## IMPORTANT:\n## - This script must be run with appropriate permissions to read all data \n##   and write to the backup folders.\n## - Ensure sufficient storage is available in the backup location to avoid \n##   partial or failed backups.\n## - Services (Elasticsearch, Cassandra, and TheHive) will be stopped during \n##   the backup process to ensure data integrity.\n##\n## DISCLAIMER:\n## - Users are strongly advised to test this script in a non-production \n##   environment to ensure it works as expected with their specific \n##   infrastructure and application stack before using it in production.\n## - The maintainers of this script are not responsible for any data loss, \n##   corruption, or issues arising from the use of this script during your \n##   backup or restore processes. Proceed at your own risk.\n##\n## USAGE:\n## 1. Update the variables at the start of the script to reflect your setup:\n##    - BACKUP_ROOT_FOLDER: Root folder where backups will be stored.\n##    - BACKUP_TO_RESTORE: Name of the backup folder to restore.\n## 2. Run the script using the following command:\n##    `bash ./scripts/backup.sh`\n##\n## ADDITIONAL RESOURCES:\n## Refer to the official documentation for detailed instructions and \n## additional information: https://docs.strangebee.com/thehive/operations/backup-restore/\n##\n## WARNING:\n## - This script stops Nginx, Elasticsearch, Cassandra, and TheHive services, \n##   performs the backup, and then restarts the services.\n## - Do not modify the rest of the script unless necessary.\n##\n## ============================================================\n## DO NOT MODIFY ANYTHING BELOW THIS LINE\n## ============================================================\n\n# Display help message\nif [[ \"$1\" == \"--help\" || \"$1\" == \"-h\" ]]\nthen\n    echo \"Usage: $0 [BACKUP_ROOT_FOLDER]\"\n    echo\n    echo \"This script performs a backup of application data, including configurations, files, and logs.\"\n    echo\n    echo \"Options:\"\n    echo \"  DOCKER_COMPOSE_PATH  Optional. Specify the path of the folder with the docker-compose.yml.\"\n    echo \"                      If not provided, you will be prompted for a folder, with a default of '.'.\"\n    echo \"  BACKUP_ROOT_FOLDER  Optional. Specify the root folder where backups will be stored.\"\n    echo \"                      If not provided, you will be prompted for a folder, with a default of './backup'.\"\n    echo\n    echo \"Examples:\"\n    echo \"  $0 /path/to/docker-compose-folder /path/to/backup  Perform backup with specified root folder.\"\n    echo \"  $0                 Prompt for docker compose folder and backup root folder.\"\n    exit 0\nfi\n\n## Checks if the first argument is provided.\n## If it is, the script uses it as the value for BACKUP_ROOT_FOLDER\n## If no argument is passed, the script prompts the user to enter a value\n## \nif [[ -z \"$1\" ]]\nthen\n    read -p \"Enter the folder path including your docker compose file [default: ./]: \" DOCKER_COMPOSE_PATH\n    DOCKER_COMPOSE_PATH=${DOCKER_COMPOSE_PATH:-\".\"}\nelse\n    DOCKER_COMPOSE_PATH=\"$1\"\nfi\n\nif [[ -e \"${DOCKER_COMPOSE_PATH}/docker-compose.yml\" ]]\nthen\n    echo \"Path to your docker compose file: ${DOCKER_COMPOSE_PATH}/docker-compose.yml\"\nelse\n    { echo \"Docker compose file not found in ${DOCKER_COMPOSE_PATH}\"; exit 1; }\nfi\n\n\nif [[ -z \"$2\" ]]\nthen\n    read -p \"Enter the backup root folder [default: ./backup]: \" BACKUP_ROOT_FOLDER\n    BACKUP_ROOT_FOLDER=${BACKUP_ROOT_FOLDER:-\"./backup\"}\nelse\n    BACKUP_ROOT_FOLDER=\"$2\"\nfi\n\n\nDATE=\"$(date +\"%Y%m%d-%H%M%z\" | sed 's/+/-/')\"\nBACKUP_FOLDER=\"${BACKUP_ROOT_FOLDER}/${DATE}\"\n\n\n## Stop services\ndocker compose -f ${DOCKER_COMPOSE_PATH}/docker-compose.yml stop\n\n## Create the backup directory\nmkdir -p \"${BACKUP_FOLDER}\"  || { echo \"Creating backup folder failed\"; exit 1; }\necho \"Created backup folder: ${BACKUP_FOLDER}\"\n\n## Define the log file and start logging\nLOG_FILE=\"${BACKUP_ROOT_FOLDER}/backup_log_${DATE}.log\"\nexec &amp;&gt; &gt;(tee -a \"$LOG_FILE\")\n\n\n\n## Prepare folders tree\nmkdir -p ${BACKUP_FOLDER}/{thehive,cassandra,elasticsearch,nginx,certificates}\necho \"Created folder structure under ${BACKUP_FOLDER}\"\n\n## Copy TheHive data\necho \"Starting TheHive backup...\"\nrsync -aW --no-compress ${DOCKER_COMPOSE_PATH}/thehive/ ${BACKUP_FOLDER}/thehive || { echo \"TheHive backup failed\"; exit 1; }\necho \"TheHive backup completed.\"\n\n## Copy Casssandra data\necho \"Starting Cassandra backup...\"\nrsync -aW --no-compress ${DOCKER_COMPOSE_PATH}/cassandra/ ${BACKUP_FOLDER}/cassandra || { echo \"Cassandra backup failed\"; exit 1; }\necho \"Cassandra backup completed.\"\n\n## Copy Elasticsearch data\necho \"Starting Elasticsearch backup...\"\nrsync -aW --no-compress ${DOCKER_COMPOSE_PATH}/elasticsearch/ ${BACKUP_FOLDER}/elasticsearch || { echo \"Elasticsearch config backup failed\"; exit 1; }\necho \"Elasticsearch backup completed.\"\n\n## Copy Nginx certificates\necho \"Starting backup of Nginx and certificates...\"\nrsync -aW --no-compress ${DOCKER_COMPOSE_PATH}/nginx/ ${BACKUP_FOLDER}/nginx || { echo \" Backup of Nginx failed\"; exit 1; }\nrsync -aW --no-compress ${DOCKER_COMPOSE_PATH}/certificates/ ${BACKUP_FOLDER}/certificates || { echo \" Backup of Nginx and certificates failed\"; exit 1; }\necho \"Backup of certificates completed.\"\n\n## Restart services\necho \"Restarting services...\"\ndocker compose up -d -f ${DOCKER_COMPOSE_PATH}/docker-compose.yml\n\n\n\necho \"Backup process completed at: $(date)\"\n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/docker-compose/#validation", "title": "Validation", "text": "<p>check the backup folder and verify the data has been well copied.</p> <p>Tip</p> <ul> <li>A comprehensive backup script, including all necessary housekeeping actions, is included with our Docker Compose profiles. Refer to the appropriate documentation for detailed instructions here.</li> <li>You can also review the backup script for <code>prod1-thehive</code> directly on our GitHub repository.</li> </ul>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/", "title": "Hot backups", "text": ""}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#hot-backups", "title": "Hot backups", "text": "<p>Warning</p> <p>As outlined in this documentation, it is crucial that the data, index, and files must remain intact and consistent during the backup process. Any inconsistency could jeopardize the restore process. While we provide guidance on creating and restoring Cassandra snapshots, it is important to note that Elasticsearch snapshots should be taken concurrently to ensure consistency and integrity across both systems. Additionally, when using clusters, snapshots should be taken simultaneously across all nodes to maintain consistency.</p> <p>The scripts provided are examples that you must customize to fit your infrastructure and application stack. For instance, folder paths may differ depending on whether you're using physical servers or Docker Compose to run the services.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#introduction", "title": "Introduction", "text": "<p>Hot backups are an essential strategy for maintaining business continuity in environments where downtime is not acceptable. Unlike cold backups, which require stopping services to ensure consistency, hot backups allow you to capture snapshots of your data while systems remain operational. This approach is particularly suited for high-availability environments where even minimal downtime could disrupt critical operations.</p> <p>However, hot backups come with unique challenges. Ensuring the consistency of data, indices, and files during the backup process is critical to avoid issues during restoration. For TheHive, this means taking simultaneous snapshots of its database (Cassandra), indexing engine (Elasticsearch), and file storage. While the process enables uninterrupted service, it requires careful planning and execution to ensure that all components remain synchronized.</p> <p>This guide provides detailed steps to perform hot backups of TheHive\u2019s components, including Cassandra, Elasticsearch, and file storage. It also discusses the risks, prerequisites, and best practices to ensure your data is securely backed up without affecting the system\u2019s availability. Whether you're operating on physical servers, virtual machines, or containerized environments, this guide will help you implement a reliable hot backup strategy tailored to your infrastructure.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#pre-requisites", "title": "Pre-requisites", "text": "<p>Before performing a hot backup, ensure the following prerequisites are met to facilitate a smooth and reliable process:</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#general-requirements", "title": "General requirements", "text": "<p>Ensure the following tools are installed on your system:</p> <ul> <li>Cassandra Nodetool: For creating database snapshots.</li> <li>tar/bzip2: For archiving and compressing backup files.</li> <li>rsync: For transferring file storage data.</li> </ul> <p>Install any missing tools using package managers such as apt or yum:</p> <ul> <li><code>apt install bzip2</code> for DEB based OS</li> <li><code>yum install bzip2</code> for RPM based OS</li> </ul> <p> </p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#configuration-knowledge", "title": "Configuration knowledge", "text": ""}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#cassandra-keyspace", "title": "Cassandra Keyspace", "text": "<p>Identify the keyspace used by TheHive. This is typically defined in the application.conf file under the <code>db.janusgraph.storage.cql.keyspace</code> attribute.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#elasticsearch-repository", "title": "Elasticsearch Repository", "text": "<p>Configure a repository for Elasticsearch snapshots. Ensure the repository is accessible and writable by Elasticsearch.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#file-storage-location", "title": "File Storage Location", "text": "<p>Locate the folder or object storage (e.g., MinIO) where TheHive stores files. This will be backed up along with the database and indices. If you're using local filesystem or NFS to store your files, the location is typically defined in the application.conf file under the <code>storage.localfs.location</code> attribute.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#consistency-considerations", "title": "Consistency Considerations", "text": ""}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#clustered-environments", "title": "Clustered Environments", "text": "<p>For Cassandra and Elasticsearch clusters, ensure snapshots are taken simultaneously across all nodes to maintain consistency.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#data-integrity-checks", "title": "Data Integrity Checks", "text": "<p>Perform a preliminary check on the system for data corruption or inconsistencies. Address any issues before proceeding with the backup.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#testing-and-validation", "title": "Testing and Validation", "text": "<p>Test the backup process in a staging or test environment to ensure scripts and configurations work as expected.</p> <p>And periodically validate your restoration procedures using test environments to confirm the integrity of the backup data.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#why-is-backing-up-the-index-optional-and-what-are-the-consequences", "title": "Why is backing up the index optional and what are the consequences ?", "text": "<p>In TheHive\u2019s architecture, the decision to back up the Elasticsearch index is a matter of balancing operational priorities such as backup speed, storage requirements, and restoration time. Here\u2019s a breakdown of why backing up the index might be considered optional and the potential consequences of doing so.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#why-backup-the-index-might-be-skipped", "title": "Why backup the index might be skipped", "text": ""}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#rebuild-capability", "title": "Rebuild capability", "text": "<p>Elasticsearch indices can be rebuilt from the data stored in Cassandra. This makes it possible to restore the system without explicitly backing up the index, provided the data is intact.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#backup-size-optimization", "title": "Backup size optimization", "text": "<p>Excluding the index from the backup process reduces the total backup size. This can be particularly beneficial when dealing with large datasets or limited storage.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#consequences-of-not-backing-up-the-index", "title": "Consequences of not backing up the index", "text": "<p>If the index is not backed up, it must be rebuilt from scratch during the restoration process. This can significantly increase the time required to fully restore the system.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#recommandation", "title": "Recommandation", "text": "<p>While skipping the index backup offers operational benefits during the backup process, it increases the restoration time and may introduce additional challenges.</p> <ul> <li>If minimal restoration time is critical, back up the index alongside the database and files.</li> <li>If backup speed and storage efficiency are prioritized, skip the index backup but prepare for a longer restoration process.</li> </ul> <p>Ultimately, the decision depends on your infrastructure, operational priorities, and acceptable downtime during recovery. Ensure you have tested and validated your backup and restore processes in a controlled environment before applying them in production.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#backup-procedures", "title": "Backup procedures", "text": ""}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#cassandra-database", "title": "Cassandra (database)", "text": "<p>Ensure that all Cassandra data is safely stored in consistent snapshots.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#prerequisites", "title": "Prerequisites", "text": "<p>To back up or export the database from Cassandra, the following information is required:</p> <ul> <li>Cassandra admin password</li> <li>Keyspace used by TheHive (default = <code>thehive</code>). This can be checked in the <code>application.conf</code> configuration file, in the database configuration under storage, cql, and <code>keyspace</code> attribute.</li> </ul> <p>Tip</p> <p>This information can be found in TheHive configuration file - application.conf - under the <code>db.janusgraph.storage</code> attribute:</p> <pre><code>db.janusgraph {\n    storage {\n        backend: cql\n        hostname: [\"127.0.0.1\"]\n        cql {\n            cluster-name: thp\n            keyspace: thehive\n        }\n    }\n}\n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#create-snapshots", "title": "Create snapshots", "text": "<p>Following actions should be performed to backup the data successfully:</p> <ol> <li>Create a snapshot</li> <li>Save the data</li> </ol> <p>The steps described below for data backup should be executed on each node. Each node's data should be backed up to ensure consistency in the backups.</p> <p>Considering that ${BACKUP} is the name of the snapshot, run the following commands:</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#1-use-the-nodetool-snapshot-command-to-create-a-snapshot-of-all-keyspaces", "title": "1 - Use the <code>nodetool snapshot</code> command to create a snapshot of all keyspaces", "text": "<pre><code>nodetool snapshot -t ${BACKUP}\n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#2-create-and-archive-with-the-snapshot-data-execute-the-following-command-for-every-cassandra-keyspace", "title": "2 - Create and archive with the snapshot data: Execute the following command For every cassandra keyspace", "text": "<pre><code>tar cjfv ${KEYSPACE_NAME}.tbz -C /var/lib/cassandra/data/${KEYSPACE_NAME}/*/snapshots/${BACKUP} .\n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#3-remove-old-snapshots-if-necessary", "title": "3 - Remove old snapshots (if necessary)", "text": "<pre><code>nodetool -h localhost -p 7199 clearsnapshot -t ${BACKUP}\n</code></pre> <p>Note</p> <p>We strongly recommend copying the snapshot archive files to a remote server or backup storage.</p> <p> </p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#example", "title": "Example", "text": "<p>Example of script to generate backups of TheHive keyspace</p> <pre><code>#!/bin/bash\n\n## Create a tbz archive containing the snapshot\n## This script should be executed on each node of the cluster\n\n## Complete variables before running:\nHOSTNAME=$(hostname)\nSNAPSHOT_DATE=\"$(date +%F)\"\n\nREMOTE_USER=&lt;remote_user_to_change&gt;\nREMOTE_HOST=&lt;remote_host_to_change&gt;\n\n## Perform a backup for all keyspaces (system included)\nnodetool snapshot -t ${SNAPSHOT_DATE}\n\n## Navigate to the snapshot directory\n\nfind /var/lib/cassandra/data -name snapshots\n\n# Archive snapshot files\nmkdir -p /var/lib/cassandra/archive_backup/$HOSTNAME/${SNAPSHOT_DATE}\ncd /var/lib/cassandra/archive_backup/$HOSTNAME/${SNAPSHOT_DATE}\n\nfor KEYSPACE in $(ls /var/lib/cassandra/data); do\nmkdir $KEYSPACE\ncd $KEYSPACE\nfor TABLE in $(ls /var/lib/cassandra/data/${KEYSPACE}); do\n    tar cjfv ${TABLE}.tbz -C /var/lib/cassandra/data/${KEYSPACE}/${TABLE}/snapshots/${SNAPSHOT_DATE} .\ndone\ncd ..\ndone\n\nnodetool -h localhost -p 7199 clearsnapshot -t ${SNAPSHOT_DATE}\n\n# Copy the snapshot archive files to a remote server\n\nscp /var/lib/cassandra/archive_backup/$HOSTNAME/${SNAPSHOT_DATE}/* ${REMOTE_USER}@${REMOTE_HOST}:/remote/node-hostname_cassandra_backup_directory\n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#elasticsearch-index-engine", "title": "Elasticsearch (index engine)", "text": ""}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#prerequisites_1", "title": "Prerequisites", "text": ""}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#snapshot-repository-configuration", "title": "Snapshot repository configuration", "text": "<p>Elasticsearch requires a snapshot repository to store backups. Common options include:</p> <ul> <li>Shared file systems</li> <li>AWS S3 buckets</li> <li>Azure Blob Storage</li> <li>Google Cloud Storage</li> </ul> <p>Set up the repository before taking snapshots.</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#permissions", "title": "Permissions", "text": "<p>Elasticsearch must have the appropriate permissions to write to the snapshot repository. For shared file systems:</p> <pre><code>chown -R elasticsearch:elasticsearch /path/to/backups\nchmod -R 770 /path/to/backups\n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#cluster-health", "title": "Cluster health", "text": "<p>Ensure the cluster health is green before initiating the backup.</p> <pre><code>curl -X GET \"localhost:9200/_cluster/health?pretty\"\n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#backup-procedure", "title": "Backup procedure", "text": ""}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#register-a-snapshot-repository", "title": "Register a Snapshot Repository", "text": "<p>Use the Elasticsearch API to register a snapshot repository. Below is an example for a file-based repository:</p> <pre><code>curl -X PUT \"http://localhost:9200/_snapshot/my_backup\" -H 'Content-Type: application/json' -d'\n{\n\"type\": \"fs\",\n\"settings\": {\n    \"location\": \"/patch/to/backups/elasticsearch\",\n    \"compress\": true\n}\n}'\n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#verify-snapshot-completion", "title": "Verify Snapshot Completion", "text": "<pre><code>curl -X GET \"http://localhost:9200/_snapshot/my_backup/snapshot_1\"\n</code></pre> <p>Note</p> <p>If using a filesystem-based repository, consider archiving the snapshot files to long-term storage (e.g., cloud storage or external disks).</p>"}, {"location": "thehive/operations/backup-restore/backup/hot-backup/#backup-files", "title": "Backup files", "text": "<p>Wether you use local or distributed files system storage, copy the content of the folder/bucket. </p>"}, {"location": "thehive/operations/backup-restore/backup/physical-server/", "title": "Physical Server", "text": ""}, {"location": "thehive/operations/backup-restore/backup/physical-server/#for-physical-servers", "title": "For Physical Servers", "text": ""}, {"location": "thehive/operations/backup-restore/backup/physical-server/#introduction", "title": "Introduction", "text": "<p>Unlike virtualized or containerized environments, physical servers require direct access to the file system and services to perform backups. This procedure focuses on cold backups, where services are stopped to ensure the integrity and consistency of the data, indices, and logs.</p> <p>When performing a backup on physical servers, it\u2019s essential to:</p> <ol> <li>Stop services (e.g., Elasticsearch, Cassandra, TheHive) to avoid data corruption.</li> <li>Ensure file permissions are adequate for the backup process.</li> <li>Use tools like rsync to copy data, configuration files, and logs to a designated backup location.</li> <li>Validate the backup to ensure it can be restored without issues.</li> </ol>"}, {"location": "thehive/operations/backup-restore/backup/physical-server/#prerequisites", "title": "Prerequisites", "text": "<p>This guide assumes you have direct access to the server via SSH or other administrative tools and sufficient disk space to store backups. By following this procedure, you can create a consistent backup that can be securely archived or transferred for disaster recovery purposes.</p> <p>This process and example below assume you have followed our step-by-step guide to install the application stack.</p> <p>Note</p> <p>Before proceeding, ensure you have read the general Backup and Restore Overview to understand the core principles of backup strategies.</p>"}, {"location": "thehive/operations/backup-restore/backup/physical-server/#step-by-step-instructions", "title": "Step-by-step instructions", "text": ""}, {"location": "thehive/operations/backup-restore/backup/physical-server/#stop-the-services-in-this-order", "title": "Stop the services in this order", "text": "<ol> <li>TheHive</li> <li>Elasticsearch</li> <li>Cassandra</li> </ol> <pre><code>systemctl stop thehive\nsystemctl stop elasticsearch\nsystemctl stop cassandra\n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/physical-server/#copy-files-in-a-backup-folder", "title": "Copy files in a backup folder", "text": "<p>For example, create a folder on a dedicated NFS volume named <code>/opt/backups</code> and copy all files preserving their permissions</p> <pre><code>#!/bin/bash\n\n## ============================================================\n## BACKUP SCRIPT FOR THEHIVE APPLICATION STACK\n## ============================================================\n## PURPOSE:\n## This script creates a backup of TheHive application stack, \n## including its configuration, data, and logs. It is designed \n## to ensure data is preserved for restoration purposes.\n##\n## IMPORTANT:\n## - This script must be run with appropriate permissions to read all data \n##   and write to the backup folders.\n## - Ensure sufficient storage is available in the backup location to avoid \n##   partial or failed backups.\n## - Services (Elasticsearch, Cassandra, and TheHive) will be stopped during \n##   the backup process to ensure data integrity.\n##\n## DISCLAIMER:\n## - Users are strongly advised to test this script in a non-production \n##   environment to ensure it works as expected with their specific \n##   infrastructure and application stack before using it in production.\n## - The maintainers of this script are not responsible for any data loss, \n##   corruption, or issues arising from the use of this script during your \n##   backup or restore processes. Proceed at your own risk.\n##\n## USAGE:\n## 1. Update the variables at the start of the script to reflect your setup:\n##    - BACKUP_ROOT_FOLDER: Root folder where backups will be stored.\n## 2. Run the script using the following command:\n##    `bash ./scripts/backup.sh`\n##\n## ADDITIONAL RESOURCES:\n## Refer to the official documentation for detailed instructions and \n## additional information: https://docs.strangebee.com/thehive/operations/backup-restore/backup/physical-server/\n##\n## WARNING:\n## - This script stops Elasticsearch, Cassandra, and TheHive services, \n##   performs the backup, and then restarts the services.\n## - Do not modify the rest of the script unless necessary.\n##\n## ============================================================\n## DO NOT MODIFY ANYTHING BELOW THIS LINE\n## ============================================================\n##\n# Display help message\nif [[ \"$1\" == \"--help\" || \"$1\" == \"-h\" ]]\nthen\n    echo \"Usage: $0 [BACKUP_ROOT_FOLDER]\"\n    echo\n    echo \"This script performs a backup of application data, including configurations, files, and logs.\"\n    echo\n    echo \"Options:\"\n    echo \"  DOCKER_COMPOSE_PATH  Optional. Specify the path of the folder with the docker-compose.yml.\"\n    echo \"                      If not provided, you will be prompted for a folder, with a default of '.'.\"\n    echo \"  BACKUP_ROOT_FOLDER  Optional. Specify the root folder where backups will be stored.\"\n    echo \"                      If not provided, you will be prompted for a folder, with a default of './backup'.\"\n    echo\n    echo \"Examples:\"\n    echo \"  $0 /path/to/docker-compose-folder /path/to/backup  Perform backup with specified root folder.\"\n    echo \"  $0                 Prompt for docker compose folder and backup root folder.\"\n    exit 0\nfi\n\n## Checks if the first argument is provided.\n## If it is, the script uses it as the value for BACKUP_ROOT_FOLDER\n## If no argument is passed, the script prompts the user to enter a value\n## \nif [[ -z \"$1\" ]]\nthen\n    read -p \"Enter the folder path including your docker compose file [default: ./]: \" DOCKER_COMPOSE_PATH\n    DOCKER_COMPOSE_PATH=${DOCKER_COMPOSE_PATH:-\".\"}\nelse\n    DOCKER_COMPOSE_PATH=\"$1\"\nfi\n\nif [[ -e \"${DOCKER_COMPOSE_PATH}/docker-compose.yml\" ]]\nthen\n    echo \"Path to your docker compose file: ${DOCKER_COMPOSE_PATH}/docker-compose.yml\"\nelse\n    { echo \"Docker compose file not found in ${DOCKER_COMPOSE_PATH}\"; exit 1; }\nfi\n\n\nif [[ -z \"$2\" ]]\nthen\nread -p \"Enter the backup root folder [default: ./backup]: \" BACKUP_ROOT_FOLDER\n    BACKUP_ROOT_FOLDER=${BACKUP_ROOT_FOLDER:-\"./backup\"}\nelse\n    BACKUP_ROOT_FOLDER=\"$2\"\nfi\n\n\nDATE=\"$(date +\"%Y%m%d-%H%M%z\" | sed 's/+/-/')\"\nBACKUP_FOLDER=\"${BACKUP_ROOT_FOLDER}/${DATE}\"\n\n# Define the log file and start logging\nLOG_FILE=\"${BACKUP_ROOT_FOLDER}/backup_log_${DATE}.log\"\nexec &amp;&gt; &gt;(tee -a \"$LOG_FILE\")\n\n## Create the backup directory\nmkdir -p \"${BACKUP_FOLDER}\"  || { echo \"Creating backup folder failed\"; exit 1; }\necho \"Created backup folder: ${BACKUP_FOLDER}\"\n\n## Prepare folders tree\nmkdir -p ${BACKUP_FOLDER}/{thehive,cassandra,elasticsearch}/{config,data,logs}\necho \"Created folder structure under ${BACKUP_FOLDER}\"\n\n# Copy TheHive data\necho \"Starting TheHive backup...\"\nrsync -aW --no-compress /etc/thehive/ ${BACKUP_FOLDER}/thehive/config || { echo \"TheHive config backup failed\"; exit 1; }\nrsync -aW --no-compress /opt/thp/thehive/files/ ${BACKUP_FOLDER}/thehive/data || { echo \"TheHive data backup failed\"; exit 1; }\nrsync -aW --no-compress /var/log/thehive/ ${BACKUP_FOLDER}/thehive/logs || { echo \"TheHive logs backup failed\"; exit 1; }\necho \"TheHive backup completed.\"\n\n# Copy Casssandra data\necho \"Starting Cassandra backup...\"\nrsync -aW --no-compress /etc/cassandra/ ${BACKUP_FOLDER}/cassandra/config || { echo \"Cassandra config backup failed\"; exit 1; }\nrsync -aW --no-compress /var/lib/cassandra/ ${BACKUP_FOLDER}/cassandra/data || { echo \"Cassandra data backup failed\"; exit 1; }\nrsync -aW --no-compress /var/log/cassandra/ ${BACKUP_FOLDER}/cassandra/logs || { echo \"Cassandra logs backup failed\"; exit 1; }\necho \"Cassandra backup completed.\"\n\n# Copy Elasticsearch data\necho \"Starting Elasticsearch backup...\"\nrsync -aW --no-compress /etc/elasticsearch/ ${BACKUP_FOLDER}/elasticsearch/config || { echo \"Elasticsearch config backup failed\"; exit 1; }\nrsync -aW --no-compress /var/lib/elasticsearch/ ${BACKUP_FOLDER}/elasticsearch/data || { echo \"Elasticsearch data backup failed\"; exit 1; }\nrsync -aW --no-compress /var/log/elasticsearch/ ${BACKUP_FOLDER}/elasticsearch/logs || { echo \"Elasticsearch logs backup failed\"; exit 1; }\necho \"Elasticsearch backup completed.\"\n\necho \"Backup process completed at: $(date)\"\n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/physical-server/#start-services-in-this-order", "title": "Start services in this order", "text": "<ol> <li>Elasticsearch</li> <li>Cassandra</li> <li>TheHive</li> </ol> <pre><code>systemctl start thehive\nsystemctl start elasticsearch\nsystemctl start cassandra\n</code></pre>"}, {"location": "thehive/operations/backup-restore/backup/physical-server/#validation", "title": "Validation", "text": "<p>check the backup folder and verify the data has been well copied.</p>"}, {"location": "thehive/operations/backup-restore/backup/virtual-server/", "title": "Virtual Server", "text": ""}, {"location": "thehive/operations/backup-restore/backup/virtual-server/#backup-virtual-server", "title": "Backup Virtual server", "text": "<p>Note</p> <p>This process and example below assume you have followed our step-by-step guide to install the application stack.</p> <p>Using virtual servers allow more solutions to perform backup and restore operations.</p>"}, {"location": "thehive/operations/backup-restore/backup/virtual-server/#first-solution-backup-data-folders", "title": "First solution: Backup data folders", "text": "<p>Similar to using a physical server, use scripts to back up the configuration, data, and logs from each application in your stack, storing them in a folder that can be archived elsewhere. Refer to the cold backup guides for detailed instructions.</p>"}, {"location": "thehive/operations/backup-restore/backup/virtual-server/#second-solution-leverage-the-capabilities-of-the-hypervisor", "title": "Second solution: Leverage the capabilities of the hypervisor", "text": "<p>Hypervisors often come with the capacity to create a snapshot volumes and entire virtual machine. We recommend creating snapshots of volumes containing data and files after stopping TheHive, Cassandra and Elasticsearch applications. </p> <p>For the restore process, begin by restoring the snapshots created with the hypervisor. This allows you to quickly revert to a previous state, ensuring that both the system configuration and application data are restored to their exact state at the time of the snapshot. Be sure to follow any additional procedures specific to your hypervisor to ensure the snapshots are properly applied and that the system operates as expected after the restore.</p>"}, {"location": "thehive/operations/backup-restore/restore/cloud/", "title": "Cloud Infrastructure", "text": ""}, {"location": "thehive/operations/backup-restore/restore/cloud/#restore-cloud", "title": "Restore Cloud", "text": "<p>TBD</p>"}, {"location": "thehive/operations/backup-restore/restore/docker-compose/", "title": "Docker Compose", "text": ""}, {"location": "thehive/operations/backup-restore/restore/docker-compose/#restore-a-stack-run-with-docker-compose", "title": "Restore a stack run with Docker Compose", "text": "<p>Note</p> <p>This process assumes you are using one of our Docker Compose profiles, and you have already created backup using the previously outlined backup procedure.</p> <p>Restore data that has been saved following the previous backup process.</p>"}, {"location": "thehive/operations/backup-restore/restore/docker-compose/#ensure-all-services-are-stopped", "title": "Ensure all services are stopped", "text": "<pre><code>docker compose down\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/docker-compose/#ensure-all-data-folder-are-empty-before-running-the-restore-process", "title": "Ensure all data folder are empty before running the restore process", "text": "<p>A backup is highly recommended before running a restore operation; this ensures you can revert to the current state if anything goes wrong.</p> <p>Ensure that the target data folders are empty before running this script. Indeed, pre-existing files can cause conflicts or data corruption during the restore process.</p>"}, {"location": "thehive/operations/backup-restore/restore/docker-compose/#choose-the-archive-to-restore-from-the-backup-folder", "title": "Choose the archive to restore from the backup folder", "text": "<pre><code>#!/bin/bash\n\n## ============================================================\n## RESTORE SCRIPT FOR THEHIVE APPLICATION STACK\n## ============================================================\n## PURPOSE:\n## This script restores a backup of TheHive application stack, \n## including its configuration, data, and logs. It is designed to \n## recover from backups created using the associated backup script.\n##\n## IMPORTANT:\n## - A backup is highly recommended before running a restore operation. \n##   This ensures you can revert to the current state if anything goes wrong.\n## - Ensure that the target data folders are empty before running this script. \n##   Pre-existing files can cause conflicts or data corruption during the restore process.\n## - This script must be run with sufficient permissions to overwrite \n##   application data and modify service configurations.\n## - Ensure the backup folder path is correct and contains all required \n##   files and data.\n##\n## DISCLAIMER:\n## - Users are strongly advised to test this script in a non-production \n##   environment to ensure it works as expected with their specific \n##   infrastructure and application stack before using it in production.\n## - The maintainers of this script are not responsible for any data loss, \n##   corruption, or issues arising from the use of this script during your \n##   backup or restore processes. Proceed at your own risk.\n##\n## USAGE:\n## 1. Update the variables at the start of the script to reflect your setup:\n##    - BACKUP_ROOT_FOLDER: Path to the root directory of your backups.\n##    - BACKUP_TO_RESTORE: Name of the backup folder to restore.\n## 2. Run the script using the following command:\n##    `bash ./scripts/restore.sh`\n##\n## ADDITIONAL RESOURCES:\n## Refer to the official documentation for detailed instructions and \n## additional information: https://docs.strangebee.com/thehive/operations/backup-restore/\n##\n## WARNING:\n## - This script ensure Nginx, Elasticsearch, Cassandra, and TheHive services are stopped before performing the restore, and then restarts the services.\n## - This script will overwrite existing data. Use it with caution.\n## - Do not modify the rest of the script unless necessary.\n##\n## ============================================================\n## DO NOT MODIFY ANYTHING BELOW THIS LINE\n## ============================================================\n# Display help message\nif [[ \"$1\" == \"--help\" || \"$1\" == \"-h\" ]]\nthen\n  echo \"Usage: $0 [DOCKER_COMPOSE_PATH] [BACKUP_FOLDER]\"\n  echo\n  echo \"This script restores a backup of application data, including configurations, files, and logs.\"\n  echo\n  echo \"Options:\"\n  echo \"  DOCKER_COMPOSE_PATH  Optional. Specify the path of the folder with the docker-compose.yml.\"\n  echo \"                      If not provided, you will be prompted for a folder, with a default of '.'.\"\n  echo \"  BACKUP_FOLDER  Optional. Specify the folder containing the data to restore.\"\n  echo \"                      If not provided, you will be prompted for a folder or exit; no default folder is used.\"\n  echo\n  echo \"Examples:\"\n  echo \"  $0 /path/to/docker-compose-folder /path/to/backup-folder  restores backup stored in the specified folder.\"\n  echo \"  $0                 Prompt for docker compose folder and backup folder to restore.\"\n  exit 0\nfi\n\n## Checks if the first argument is provided.\n## If it is, the script uses it as the value for BACKUP_ROOT_FOLDER\n## If no argument is passed, the script prompts the user to enter a value\n## \nif [[ -z \"$1\" ]]\nthen\n  read -p \"Enter the folder path including your docker compose file [default: ./]: \" DOCKER_COMPOSE_PATH\n  DOCKER_COMPOSE_PATH=${DOCKER_COMPOSE_PATH:-\".\"}\nelse\n  DOCKER_COMPOSE_PATH=\"$1\"\nfi\n\nif [[ -e \"${DOCKER_COMPOSE_PATH}/docker-compose.yml\" ]]\nthen\n  echo \"Path to your docker compose file: ${DOCKER_COMPOSE_PATH}/docker-compose.yml\"\nelse\n  { echo \"Docker compose file not found in ${DOCKER_COMPOSE_PATH}\"; exit 1; }\nfi\n\n\nif [[ -z \"$2\" ]]\nthen\n  read -p \"Enter the backup root folder [default: None]: \" BACKUP_FOLDER\n  [[ -z \"${BACKUP_FOLDER}\" ]] &amp;&amp; echo \"No backup folder specified, exiting.\" &amp;&amp; exit 1\nelse\n  BACKUP_FOLDER=\"$2\"\nfi\n\n## Check if the backup folder to restore exists, else exit\n[[ -d ${BACKUP_FOLDER} ]] || { echo \"Backup folder not found, exiting\"; exit 1; }\n\n\n# Define the log file and start logging. Log file is stored in the current folder\nDATE=\"$(date +\"%Y%m%d-%H%M%z\" | sed 's/+/-/')\"\nLOG_FILE=\"./restore_log_${DATE}.log\"\nexec &amp;&gt; &gt;(tee -a \"$LOG_FILE\")\n\n# Log the start time\necho \"Restoration process started at: $(date)\"\n\n## Exit if docker compose is running\ndocker compose ps | grep -q \"Up\" &amp;&amp; { echo \"Docker Compose services are running. Exiting. Stop services and remove data before retoring data\"; exit 1; }\n\n\n# Copy TheHive data\necho \"Restoring TheHive data and configuration...\"\nrsync -aW --no-compress ${BACKUP_FOLDER}/thehive/ ${DOCKER_COMPOSE_PATH}/thehive || { echo \"TheHive config restore failed\"; exit 1; }\n\n# Copy Casssandra data\necho \"Restoring Cassandra data ...\"\nrsync -aW --no-compress ${BACKUP_FOLDER}/cassandra/ ${DOCKER_COMPOSE_PATH}/cassandra || { echo \"Cassandra data restore failed\"; exit 1; }\n\n\n# Copy Elasticsearch data\necho \"Restoring Elasticsearch data ...\"\nrsync -aW --no-compress ${BACKUP_FOLDER}/elasticsearch/ ${DOCKER_COMPOSE_PATH}/elasticsearch || { echo \"Elasticsearch data restore failed\"; exit 1; }\n\n\n# Copy Nginx certificates\necho \"Restoring Nginx data and configuration...\"\nrsync -a ${BACKUP_FOLDER}/nginx/ ${DOCKER_COMPOSE_PATH}/nginx  ||\n { echo \" Nginx configuration and certificates restore failed\"; exit 1; } \nrsync -a ${BACKUP_FOLDER}/certificates/ ${DOCKER_COMPOSE_PATH}/certificates  ||\n { echo \" certificates restore failed\"; exit 1; } \n\n## Restart services\necho \"Restarting services...\"\ndocker compose up -d -f ${DOCKER_COMPOSE_PATH}/docker-compose.yml\n\necho \"Restoration process completed at: $(date)\"\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/docker-compose/#restart-all-services", "title": "Restart all services", "text": "<p>The script above restarts all services with the command line <code>docker compose up -d -f ${DOCKER_COMPOSE_PATH}/docker-compose.yml</code>. </p>"}, {"location": "thehive/operations/backup-restore/restore/physical-server/", "title": "Physical Server", "text": ""}, {"location": "thehive/operations/backup-restore/restore/physical-server/#restore-physical-server", "title": "Restore physical server", "text": ""}, {"location": "thehive/operations/backup-restore/restore/physical-server/#introduction", "title": "Introduction", "text": "<p>Restoring your application stack on physical servers is a process that involves recovering configuration files, data, and logs from a previously created backup. This procedure ensures the application is returned to a consistent and operational state.</p> <p>Unlike virtual or containerized environments, restoring on physical servers requires manual handling of files and services. This guide assumes that:</p> <ul> <li>You are restoring from a cold backup, where services were stopped during the backup process to maintain data consistency.</li> <li>The server environment matches the original configuration (e.g., paths, software versions, and dependencies).</li> <li>The backup was created following the Backup Procedure for Physical Servers.</li> </ul> <p>When performing a restore, you will:</p> <ol> <li>Ensure all services are stopped (Elasticsearch, Cassandra, TheHive, etc.) before running the restoration process.</li> <li>Restore the configuration, data, and log files from the backup.</li> <li>Restart services and verify that the system is functioning as expected.</li> </ol> <p>Warning</p> <ul> <li>Always test the restoration process in a non-production or test environment before applying it to a live system.</li> <li>Ensure you have a current backup before starting the restore operation, as any errors during restoration could lead to data loss.</li> <li>This guide provides general instructions; adapt them to your specific server configuration.</li> </ul>"}, {"location": "thehive/operations/backup-restore/restore/physical-server/#step-by-step-instructions", "title": "Step-by-step instructions", "text": ""}, {"location": "thehive/operations/backup-restore/restore/physical-server/#ensure-all-services-are-stopped", "title": "Ensure all services are stopped", "text": "<pre><code>systemctl stop thehive\nsystemctl stop elasticsearch\nsystemctl stop cassandra\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/physical-server/#check-all-data-folders-are-empty", "title": "Check all data folders are empty", "text": "<p>Ensure <code>/var/lib/cassandra/</code> and <code>/var/lib/elasticsearch/</code> are empty.</p>"}, {"location": "thehive/operations/backup-restore/restore/physical-server/#copy-files-from-the-backup-folder", "title": "Copy files from the backup folder", "text": "<p>For example, with a dedicated NFS volume and a folder named <code>/opt/backup</code>  copy all files preserving their permissions</p> <pre><code>#!/bin/bash\n\n## ============================================================\n## RESTORE SCRIPT FOR THEHIVE APPLICATION STACK\n## ============================================================\n## PURPOSE:\n## This script restores a backup of TheHive application stack, \n## including its configuration, data, and logs. It is designed to \n## recover from backups created using the associated backup script.\n##\n## IMPORTANT:\n## - A backup is highly recommended before running a restore operation. \n##   This ensures you can revert to the current state if anything goes wrong.\n## - Ensure that the target data folders are empty before running this script. \n##   Pre-existing files can cause conflicts or data corruption during the restore process.\n## - This script must be run with sufficient permissions to overwrite \n##   application data and modify service configurations.\n## - Ensure the backup folder path is correct and contains all required \n##   files and data.\n##\n## DISCLAIMER:\n## - Users are strongly advised to test this script in a non-production \n##   environment to ensure it works as expected with their specific \n##   infrastructure and application stack before using it in production.\n## - The maintainers of this script are not responsible for any data loss, \n##   corruption, or issues arising from the use of this script during your \n##   backup or restore processes. Proceed at your own risk.\n##\n## USAGE:\n## 1. Update the variables at the start of the script to reflect your setup:\n##    - BACKUP_ROOT_FOLDER: Path to the root directory of your backups.\n##    - BACKUP_TO_RESTORE: Name of the backup folder to restore.\n## 2. Run the script using the following command:\n##    `bash ./scripts/restore.sh`\n##\n## ADDITIONAL RESOURCES:\n## Refer to the official documentation for detailed instructions and \n## additional information: https://docs.strangebee.com/thehive/operations/backup-restore/\n##\n## WARNING:\n## - This script ensure Nginx, Elasticsearch, Cassandra, and TheHive services are stopped before performing the restore, and then restarts the services.\n## - This script will overwrite existing data. Use it with caution.\n## - Do not modify the rest of the script unless necessary.\n##\n## ============================================================\n## DO NOT MODIFY ANYTHING BELOW THIS LINE\n## ============================================================\n# Display help message\nif [[ \"$1\" == \"--help\" || \"$1\" == \"-h\" ]]\nthen\n    echo \"Usage: $0 [DOCKER_COMPOSE_PATH] [BACKUP_FOLDER]\"\n    echo\n    echo \"This script restores a backup of application data, including configurations, files, and logs.\"\n    echo\n    echo \"Options:\"\n    echo \"  DOCKER_COMPOSE_PATH  Optional. Specify the path of the folder with the docker-compose.yml.\"\n    echo \"                      If not provided, you will be prompted for a folder, with a default of '.'.\"\n    echo \"  BACKUP_FOLDER  Optional. Specify the folder containing the data to restore.\"\n    echo \"                      If not provided, you will be prompted for a folder or exit; no default folder is used.\"\n    echo\n    echo \"Examples:\"\n    echo \"  $0 /path/to/docker-compose-folder /path/to/backup-folder  restores backup stored in the specified folder.\"\n    echo \"  $0                 Prompt for docker compose folder and backup folder to restore.\"\n    exit 0\nfi\n\n## Checks if the first argument is provided.\n## If it is, the script uses it as the value for BACKUP_ROOT_FOLDER\n## If no argument is passed, the script prompts the user to enter a value\n## \nif [[ -z \"$1\" ]]\nthen\n    read -p \"Enter the folder path including your docker compose file [default: ./]: \" DOCKER_COMPOSE_PATH\n    DOCKER_COMPOSE_PATH=${DOCKER_COMPOSE_PATH:-\".\"}\nelse\n    DOCKER_COMPOSE_PATH=\"$1\"\nfi\n\nif [[ -e \"${DOCKER_COMPOSE_PATH}/docker-compose.yml\" ]]\nthen\n    echo \"Path to your docker compose file: ${DOCKER_COMPOSE_PATH}/docker-compose.yml\"\nelse\n    { echo \"Docker compose file not found in ${DOCKER_COMPOSE_PATH}\"; exit 1; }\nfi\n\n\nif [[ -z \"$2\" ]]\nthen\n    read -p \"Enter the backup root folder [default: None]: \" BACKUP_FOLDER\n    [[ -z \"${BACKUP_FOLDER}\" ]] &amp;&amp; echo \"No backup folder specified, exiting.\" &amp;&amp; exit 1\nelse\n    BACKUP_FOLDER=\"$2\"\nfi\n\n## Check if the backup folder to restore exists, else exit\n[[ -d ${BACKUP_FOLDER} ]] || { echo \"Backup folder not found, exiting\"; exit 1; }\n\n\n# Define the log file and start logging. Log file is stored in the current folder\nDATE=\"$(date +\"%Y%m%d-%H%M%z\" | sed 's/+/-/')\"\nLOG_FILE=\"${BACKUP_ROOT_FOLDER}/restore_log_${DATE}.log\"\nexec &amp;&gt; &gt;(tee -a \"$LOG_FILE\")\n\n# Log the start time\necho \"Restoration process started at: $(date)\"\n\n# Check backup backup folder exists\n[[ -d ${BACKUP_FOLDER} ]] || { echo \"Backup folder not found\"; exit 1; }\n\n\n# Copy TheHive data\nrsync -aW --no-compress ${BACKUP_FOLDER}/thehive/config/ /etc/thehive  || { echo \"TheHive config restore failed\"; exit 1; }\nrsync -aW --no-compress ${BACKUP_FOLDER}/thehive/data/ /opt/thp/thehive/files || { echo \"TheHive data restore failed\"; exit 1; }\nrsync -aW --no-compress ${BACKUP_FOLDER}/thehive/logs/ /var/log/thehive || { echo \"TheHive logs restore failed\"; exit 1; }\n\n# Copy Casssandra data\nrsync -aW --no-compress ${BACKUP_FOLDER}/cassandra/config/ /etc/cassandra || { echo \"Cassandra config restore failed\"; exit 1; }\nrsync -aW --no-compress ${BACKUP_FOLDER}/cassandra/data/ /var/lib/cassandra || { echo \"Cassandra data restore failed\"; exit 1; }\nrsync -aW --no-compress ${BACKUP_FOLDER}/cassandra/logs/ /var/log/cassandra || { echo \"Cassandra logs restore failed\"; exit 1; }\n\n# Copy Elasticsearch data\nrsync -aW --no-compress ${BACKUP_FOLDER}/elasticsearch/config/ /etc/elasticsearch || { echo \"Elasticsearch config restore failed\"; exit 1; }\nrsync -aW --no-compress ${BACKUP_FOLDER}/elasticsearch/data/ /var/lib/elasticsearch || { echo \"Elasticsearch data restore failed\"; exit 1; }\nrsync -aW --no-compress ${BACKUP_FOLDER}/elasticsearch/logs/ /var/log/elasticsearch || { echo \"Elasticsearch logs restore failed\"; exit 1; }\n\necho \"Restoration process completed at: $(date)\" \n</code></pre> <p>Ensure permissions are correctly setup before running services. </p>"}, {"location": "thehive/operations/backup-restore/restore/physical-server/#start-services-in-this-order", "title": "Start services in this order", "text": "<ol> <li>Elasticsearch</li> <li>Cassandra</li> <li>TheHive</li> </ol> <pre><code>systemctl start thehive\nsystemctl start elasticsearch\nsystemctl start cassandra\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/physical-server/#validation", "title": "Validation", "text": "<p>Open you browser, connect to TheHive, and check your data has been restored correctly. </p>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/", "title": "Restore hot backups", "text": ""}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#restore-data", "title": "Restore data", "text": ""}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#cassandra", "title": "Cassandra", "text": ""}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#pre-requisites", "title": "Pre requisites", "text": "<p>Following data is required to restore TheHive database successfully: </p> <ul> <li>A backup of the database (<code>${SNAPSHOT}_${SNAPSHOT_DATE}.tbz</code>)</li> <li>Keyspace to restore does not exist in the database (or it will be overwritten)</li> <li>All nodes in the cluster should be up before starting the restore procedure.</li> <li>TheHive application should NOT be running.</li> </ul> <p> </p>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#restore-your-data", "title": "Restore your data", "text": ""}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#start-by-drop-the-database-thehive", "title": "Start by drop the database <code>TheHive</code>", "text": "<pre><code>## SOURCE_KEYSPACE contains the name of theHive database\nCASSANDRA_PASSWORD=&lt;your_admin_password&gt;\nCASSANDRA_ADDRESS=&lt;cassandra_node_ip&gt;\nSOURCE_KEYSPACE=thehive\ncqlsh -u admin -p ${CASSANDRA_PASSWORD} ${CASSANDRA_ADDRESS} -e \"DROP KEYSPACE IF EXISTS ${SOURCE_KEYSPACE};\"\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#create-the-keyspace", "title": "Create the keyspace", "text": "<pre><code>## TARGET_KEYSPACE contains the new name of theHive database \n## NOTE that you can keep the same database name since the old one has been deleted\ncqlsh -u admin -p ${CASSANDRA_PASSWORD} ${CASSANDRA_ADDRESS} -e \"\n    CREATE KEYSPACE ${TARGET_KEYSPACE}\n    WITH replication = {'class': 'NetworkTopologyStrategy', 'replication_factor': '3'}\n    AND durable_writes = true;\"\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#unarchive-backup-files", "title": "Unarchive backup files", "text": "<p>Note</p> <p>Note that the following steps should be executed for every Cassandra cluster node.</p> <pre><code>mkdir -p /var/lib/cassandra/restore\nRESTORE_PATH=\"/var/lib/cassandra/restore\"\nSOURCE_KEYSPACE=\"thehive\"\nSNAPSHOT_DATE=&lt;date_of_backup&gt;\n## TABLES should contain the list of all tables that will be restored\n## table_name should include the uuid generated by cassandra, for example: table1-f901e0c05d8811ef87c71fc3a94044f4\n\nTABLES=\"ls -1 /var/lib/cassandra/data/${SOURCE_KEYSPACE}/\"\n## copy all of the snapshot tables that you want to restore from remote server or local cassandra node then extract it\n## repeat the following  steps on each node Cassandra for each table in the TABLES List\n\ncd /var/lib/cassandra/restore\nfor table in $TABLES; do\nscp remoteuser@remotehost:/remote/node_name_directory/${SNAPSHOT_DATE}/${SOURCE_KEYSPACE}/${table}.tbz .\nmkdir -p ${RESTORE_PATH}/${SOURCE_KEYSPACE}/${table}\necho \"Unarchive backup files for table: $table\"\ntar jxf ${table}.tbz -C ${RESTORE_PATH}/${SOURCE_KEYSPACE}/${table}\ndone\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#create-tables-from-archive", "title": "Create tables from archive", "text": "<p>The archive contains the table schemas. They must be executed in the new keyspace. The schema files are in <code>${RESTORE_PATH}/${SOURCE_KEYSPACE}/${table}</code></p> <pre><code>for CQL in $(find ${RESTORE_PATH} -name schema.cql)\ndo\ncqlsh -u admin -p ${CASSANDRA_PASSWORD} -f $CQL\ndone\n</code></pre> <p>If you want to change the name of the keyspace (<code>${SOURCE_KEYSPACE}</code> =&gt; <code>${TARGET_KEYSPACE}</code>), you need to rewrite the cql command:</p> <pre><code>for CQL in $(find ${RESTORE_PATH} -name schema.cql)\ndo\ncqlsh cassandra -e \"$(sed -e '/CREATE TABLE/s/'${SOURCE_KEYSPACE}/${TARGET_KEYSPACE}/ $CQL)\"\ndone\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#load-table-data", "title": "Load table data", "text": "<p>Note</p> <p>Note that the following command should be executed on each Cassandra node in the cluster.</p> <pre><code>for TABLE in ${RESTORE_PATH}/${TARGET_KEYSPACE}/*\ndo \nTABLE_BASENAME=$(basename ${TABLE})\nTABLE_NAME=${TABLE_BASENAME%%-*}\nnodetool import ${TARGET_KEYSPACE} ${TABLE_NAME} ${RESTORE_PATH}/${TARGET_KEYSPACE}/${TABLE_BASENAME}\ndone\n</code></pre> <p> </p> <p>If the cluster topology has changed (new nodes added ou removed from the cluster since the last data backup), please follow the run the following command to perform a restore:</p> <pre><code>for TABLE in ${RESTORE_PATH}/${TARGET_KEYSPACE}/*\ndo \nTABLE_BASENAME=$(basename ${TABLE})\nsstableloader -d ${CASSANDRA_IP} ${RESTORE_PATH}/${TARGET_KEYSPACE}/${TABLE_BASENAME}\ndone\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#cleanup", "title": "Cleanup", "text": "<pre><code>rm -rf ${RESTORE_PATH}\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#rebuid-an-existing-node", "title": "Rebuid an existing node", "text": "<p>If for a particular reason (such as corrupted system data), you need to reintegrate the node into the cluster and restore all data (including system data), here is the procedure:</p>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#make-sure-that-the-cassandra-service-is-still-down-then-delete-the-contents-of-the-data-volume", "title": "Make sure that the Cassandra service is still down then delete the contents of the data volume:", "text": "<pre><code>cd /var/lib/cassandra/data\nrm -rf *\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#copy-and-unarchive-backup-files", "title": "Copy and unarchive backup files:", "text": "<pre><code>DATA_PATH=\"/var/lib/cassandra/data\"\n\nSNAPSHOT_DATE=&lt;date_of_snaphot&gt;\n## KEYSPACES list should inlude all keyspaces\nKEYSPACES=\"system system_distributed system_traces system_virtual_schema system_auth system_schema system_views thehive\"\ncd ${DATA_PATH}\nfor ks in $KEYSPACES; do\nscp -r remoteuser@remotehost:/remote/node_name_directory/${SNAPSHOT_DATE}/${ks}/ .\nfor file in /var/lib/cassandra/data/${ks}/*; do\n    echo \"Processing $file\"\n    filename=$(basename \"$file\")\n    table_name=\"${filename%%.*}\"\n    sudo mkdir -p ${ks}/${table_name}\n    sudo tar jxf $file -C ${ks}/${table_name}\n    rm -f $file\ndone\ndone\n\nchown -R cassandra:cassandra  /var/lib/cassandra/data\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#start-cassandra-service", "title": "Start cassandra service", "text": "<pre><code>service cassandra start\n\n## heck if Cassandra has started successfully by reviewing its logs\ntail -n 100 /var/log/cassandra/system.log | grep -iE \"listening for|startup complete|error|warning\"\n\nINFO  [main] ********,773 PipelineConfigurator.java:125 - Starting listening for CQL clients on localhost/127.0.0.1:9042 (unencrypted)...\nINFO  [main] ********,790 CassandraDaemon.java:776 - Startup complete\n</code></pre> <p>Ensure no Commitlog file exist before restarting Cassandra service. (<code>/var/lib/cassandra/commitlog</code>)</p> <p>Example of script to restore TheHive keyspace in Cassandra</p> <pre><code>#!/bin/bash\n\n## Restore a KEYSPACE and its data from a CQL file with the schema of the\n## KEYSPACE and an tbz archive containing the snapshot\n\n## Complete variables before running:\n## CASSANDRA_ADDRESS: IP of cassandra server\n## RESTORE_PATH: choose a TMP folder !!! this folder will be removed if exists.\n## SOURCE_KEYSPACE: KEYSPACE used in the backup\n## TARGET_KEYSPACE: new KEYSPACE name ; use same name of SOURCE_KEYSPACE if no changes\n## TABLES: should contain the list of all tables that will be restored, table_name should include the uuid generated by cassandra, for example: table1-f901e0c05d8811ef87c71fc3a94044f4\n## SNAPSHOT: choose a name for the backup\n## SNAPSHOT_DATE: date of the snapshot to restore\n\n## IMPORTANT: Note that the following steps should be executed on each Cassandra cluster node.\n\nCASSANDRA_ADDRESS=\"10.1.1.1\"\nRESTORE_PATH=\"/var/lib/cassandra/restore\"\nSOURCE_KEYSPACE=\"thehive\"\nTARGET_KEYSPACE=\"thehive_restore\"\nTABLES=\"\ntable1-f901e0c05d8811ef87c71fc3a94044f4\ntable2-d502a0c05d8811ef87c71fc3a94044f5\ntable3-a703c0c05d8811ef87c71fc3a94044f6\n\" \nSNAPSHOT_DATE=\"2024-09-23\"\n\n## Copy from backup folder and Uncompress data in restore folder\n\ncd ${RESTORE_PATH}\nfor table in $TABLES; do\n    cp -r PATH_TO_BACKUP_DIRECTORY/${SNAPSHOT_DATE}/${SOURCE_KEYSPACE}/${table}.tbz .\n    mkdir -p ${RESTORE_PATH}/${SOURCE_KEYSPACE}/${table}\n    echo \"Unarchive backup files for table: $table\"\n    tar jxf ${table}.tbz -C ${RESTORE_PATH}/${SOURCE_KEYSPACE}/${table}\ndone\n## Read Cassandra password\necho -n \"Cassandra admin password: \" \nread -s CASSANDRA_PASSWORD\n\n# Drop the keyspace\ncqlsh -u admin -p ${CASSANDRA_PASSWORD} ${CASSANDRA_ADDRESS} -e \"DROP KEYSPACE IF EXISTS ${SOURCE_KEYSPACE};\"\n\n# Create the keyspace\n## TARGET_KEYSPACE contains the new name of theHive database \n## NOTE that you can keep the same database name since the old one has been deleted\n\ncqlsh -u admin -p ${CASSANDRA_PASSWORD} ${CASSANDRA_ADDRESS} -e \"\n    CREATE KEYSPACE ${TARGET_KEYSPACE}\n    WITH replication = {'class': 'NetworkTopologyStrategy', 'replication_factor': '3'}\n    AND durable_writes = true;\"\n\n# Create table in keyspace\nfor CQL in $(find ${RESTORE_PATH} -name schema.cql)\ndo\ncqlsh -u admin -p ${CASSANDRA_PASSWORD} ${CASSANDRA_ADDRESS} -e \"$(sed -e '/CREATE TABLE/s/'${SOURCE_KEYSPACE}/${TARGET_KEYSPACE}/ $CQL)\"\ndone\n\n\n## Load data\nfor TABLE in ${RESTORE_PATH}/${TARGET_KEYSPACE}/*\n    do \n    TABLE_BASENAME=$(basename ${TABLE})\n    TABLE_NAME=${TABLE_BASENAME%%-*}\n    nodetool import ${TARGET_KEYSPACE} ${TABLE_NAME} ${RESTORE_PATH}/${TARGET_KEYSPACE}/${TABLE_BASENAME}\ndone\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#restore-elasticsearch-index", "title": "Restore Elasticsearch index", "text": "<p>Several solutions exist regarding the index:</p> <ol> <li>Restore a saved Elasticsearch index ; follow Elasticsearch guides to perform this action</li> <li>Rebuild the index on the new server, when TheHive start for the first time.</li> </ol> <p> </p>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#restoration-steps", "title": "Restoration steps", "text": "<p>Restoring from a snapshot involves creating a new cluster or restoring the snapshot into an existing one. Here\u2019s an example to restore all indices from a snapshot. </p> <pre><code>curl -X POST \"http://localhost&gt;:9200/_snapshot/my_backup/snapshot_1/_restore\" -H 'Content-Type: application/json' -d'\n{\n\"indices\": \"*\",\n\"include_global_state\": false\n}'\n</code></pre>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#rebuild-the-index", "title": "Rebuild the index", "text": "<p>Once Cassandra database is restored, update the configuration of TheHive to rebuild the index.</p> <p>These lines should be added to the configuration file only for the first start of TheHive application, and removed later on.</p> extract from /etc/thehive/application.conf<pre><code>db.janusgraph.forceDropAndRebuildIndex = true\n</code></pre> <p>Once TheHive application is started, both lines should be removed or commented from the application.conf configuration file</p>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#restore-files", "title": "Restore Files", "text": "<p>Restore the saved files into the destination folder/bucket that will be used by TheHive. Ensure the account running TheHive application has permissions to create files and folders into the destination folder.</p>"}, {"location": "thehive/operations/backup-restore/restore/restore-hot-backup/#references", "title": "References", "text": "<ul> <li>Backing up and restoring Cassandra data: https://cassandra.apache.org/doc/stable/cassandra/operating/backups.html</li> <li>Backing up and restoring Elasticsearch data: https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshot-restore.html</li> </ul>"}, {"location": "thehive/operations/backup-restore/restore/virtual-server/", "title": "Virtual Server", "text": ""}, {"location": "thehive/operations/backup-restore/restore/virtual-server/#restore-virtual-server", "title": "Restore virtual server", "text": "<p>Note</p> <p>This process and example below assume you have followed our step-by-step guide to install the application stack.</p> <p>Using virtual servers allow more solutions to perform backup and restore operations.</p>"}, {"location": "thehive/operations/backup-restore/restore/virtual-server/#1st-solution-restore-data-folders-from-a-backup", "title": "1st solution: Restore data folders from a backup", "text": "<p>Assuming you are using our cold backup guide to backup your data, use scripts to restore the configuration, data, and logs from each application in your stack. Refer to the cold restore guide for detailed instructions.</p>"}, {"location": "thehive/operations/backup-restore/restore/virtual-server/#2nd-solution-leverage-the-capabilities-of-the-hypervisor", "title": "2nd solution: Leverage the capabilities of the hypervisor", "text": "<p>Hypervisors often come with the capacity to create a snapshot volumes and entire virtual machine. We recommend creating snapshots of volumes containing data and files after stopping TheHive, Cassandra and Elasticsearch applications. </p> <p>For the restore process, begin by restoring the snapshots created with the hypervisor. This allows you to quickly revert to a previous state, ensuring that both the system configuration and application data are restored to their exact state at the time of the snapshot. Be sure to follow any additional procedures specific to your hypervisor to ensure the snapshots are properly applied and that the system operates as expected after the restore.</p>"}, {"location": "thehive/overview/", "title": "Overview", "text": ""}, {"location": "thehive/overview/#thehive-documentation", "title": "TheHive Documentation", "text": ""}, {"location": "thehive/overview/#overview", "title": "Overview", "text": "<p>TheHive offers a comprehensive 4-in-1 Security Incident Response Platform, serving as a vital tool for Security Operations Centers (SOCs), Computer Security Incident Response Teams (CSIRTs), Computer Emergency Response Teams (CERTs), and all information security professionals involved in swift and effective handling of security incidents. It composes of a robust suite of features designed to streamline incident response workflows, enhance collaboration, and empower information security practitioners to effectively investigate and mitigate security threats. With its seamless integration with MISP and advanced capabilities for task management, evidence handling, and threat intelligence integration, TheHive is an indispensable tool for modern SOC, CSIRT, and CERT teams.</p>"}, {"location": "thehive/overview/#key-features", "title": "Key Features", "text": "<p>Integration with MISP:  Tightly integrated with MISP (Malware Information Sharing Platform) for seamless collaboration and information sharing.</p> <p>Real-Time Collaboration:  Multiple analysts can collaborate simultaneously with live stream updates on cases, tasks, observables, and Indicators of Compromise (IOCs).</p> <p>Efficient Task Management:  Special notifications enable efficient task handling and assignment, with previews and imports from various sources such as email reports, CTI providers, and SIEMs.</p> <p>Customizable Templates:  Create cases and tasks using a flexible template engine, allowing customization with metrics and custom fields to drive team activity and identify areas for automation.</p> <p>Evidence Management:  Analysts can record progress, attach evidence or files, add tags, and import password-protected ZIP archives containing suspicious data securely.</p> <p>Observables Management:  Easily add and manage observables, either individually or in bulk, with options to import directly from MISP events or alerts. Triaging and filtering capabilities streamline the process.</p> <p>Threat Intelligence Integration:  Utilize Cortex and its analyzers and responders to gain insights, accelerate investigations, and contain threats. Leverage tags, flag IOCs, and identify previously seen observables to enrich threat intelligence.</p>"}, {"location": "thehive/overview/#architecture", "title": "Architecture", "text": "<p>TheHive can be set up on either a single server or as a cluster (a group of servers) to accommodate different levels of growth requirements.  TheHive's architecture is highly modular, allowing each layer (TheHive application, database &amp; indexing engine, and file storage) to be deployed independently as standalone nodes or as part of a clustered setup. This flexibility enables complex clustered architectures with virtual IP addresses and load balancers for optimal performance and scalability. </p> <p>The essential components of TheHive's setup include:</p> <ul> <li> Apache Cassandra for robust data storage, with support for version 4.x.</li> <li> Elasticsearch, serving as a powerful indexing engine, with support for version 7.x.</li> <li> A file storage solution, which can be the local filesystem of the server hosting the application for standalone setups or, NFS or S3 MINIO for clustered environments.</li> </ul> <p></p> <p>Using Lucene</p> <p>Starting from version 5.1, TheHive no longer supports the Lucene backend for indexing. Users who were previously utilizing Lucene with TheHive 4.1.x are advised to migrate their index to Elasticsearch using this comprehensive guide.</p> Standalone ServerCluster or Hybrid Architecture <p></p> <p>A standalone server setup involves installing all necessary components on a single server:</p> <ul> <li>Cassandra</li> <li>Elasticsearch</li> <li>File storage on the local filesystem (or MinIO if desired)</li> <li>TheHive</li> <li>Optional NGINX for managing HTTPS communications</li> </ul> <p>For detailed installation instructions, refer to the step-by-step installation guide.</p> <p>TheHive and its associated applications offer flexibility in choosing the right setup based on specific requirements. This includes the ability to mix and match different nodes and applications within a cluster.</p> <p></p> <p>Each layer and node within the architecture can be installed on dedicated operating systems, allowing for tailored configurations. The installation guide for a 3-node cluster provides comprehensive instructions for setting up a more complex clustered environment.</p> <p> </p>"}, {"location": "thehive/release-notes/release-notes-5.0/", "title": "Release Notes for Version 5.0", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#release-notes-of-50-series", "title": "Release Notes of 5.0 series", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#5026-27th-february-2023", "title": "5.0.26 - 27th February 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix issue that prevented closing a case when a custom field was not set</li> <li>Fix indentation issue in TTP list</li> <li>Fix overflow in pages with long content</li> <li>Fix loading of multiple comments</li> <li>Allow importing observables from analyzers when running on an alert</li> <li>Improve error message when closing a case with mandatory custom field</li> <li>Fix style for custom field input</li> <li>Typo fixes</li> </ul> <p>Backend:</p> <ul> <li>Fix v1 api for page which used the former v0 style: new fields were added and some fields are now marked as deprecated and will be removed in the future</li> <li>Add caseId in analyer input: field <code>message</code> should now contain the observable's parent id (alert or case)</li> <li>Fix a message serialization error when running in cluster</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5025-2nd-february-2023", "title": "5.0.25 - 2nd February 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_1", "title": "Fixes", "text": "<p>Backend:</p> <ul> <li>Fix TLP and PAP of MISP events</li> <li>Fix download of attachment when content type is malformed</li> <li>TheHive 3 migration: Fix parsing of old format of Cortex jobs</li> <li>Fix serialisation of configuration that contains a pipe character</li> </ul> <p>UI:</p> <ul> <li>Remove the limit on the number of techniques when selecting a TTP tactic</li> </ul> <p>Docker:</p> <ul> <li>Add parameter for Elasticsearch authentication</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5024-9th-january-2023", "title": "5.0.24 - 9th January 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_2", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix issue in slack notifier form</li> <li>Fix colored tags in several parts of the UI: tags should now be more colorful</li> </ul> <p>Backend:</p> <ul> <li>When changing a tag name, the name is also changed in the cases and alerts</li> <li>When an alert or case changes of stage, the stage is added to the audit details</li> <li>Slack notifier now correctly sends the username</li> <li>Update analyzer reports</li> <li>Improve api docs</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5023-20th-december-2022", "title": "5.0.23 - 20th December 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_3", "title": "Fixes", "text": "<ul> <li>Downgrade logback library to version 1.3.5 which still supports Java 8</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5022-19th-december-2022", "title": "5.0.22 - 19th December 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_4", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix: \"Add share\" window is empty when no target org</li> <li>Search: Observables search result direct link not working</li> <li>Search: results for Task Logs do not show a link to the case</li> <li>Markdown table issue with vertical bar: add support for <code>&amp;vert;</code> in cell tables</li> <li>Dashboard:<ul> <li>Bar Chart with tasks by status all have same colors</li> <li>Bar chart: add an option to display or not empty values</li> </ul> </li> <li>Long alert titles cut off other UI fields</li> <li>Bad cache when listing similar alerts</li> <li>Wrong drawer title when editing a case template</li> </ul> <p>Backend:</p> <ul> <li>Update dependencies</li> <li>API Query filter _startsWith don't work on customFields</li> <li>Pages in knowledge base incorrectly display pages from cases too</li> <li>Search on absent field does not use index</li> <li>Changing auth configuration does not work for v1 routes</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements", "title": "Improvements", "text": "<ul> <li>LDAP/AD: add option to ignore the realm/domain of the login</li> <li>Cortex: Send observable attribute <code>sightedAt</code> to Cortex</li> <li>UI: in a task preview, add the possibility to edit or delete a task log</li> <li>UI: standardize disposition of TLP, PAP and SEV across forms and elements.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5021-2nd-december-2022", "title": "5.0.21 - 2nd December 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_5", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix JavaScript error</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5020-1st-december-2022", "title": "5.0.20 - 1st December 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_6", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Dashboard:<ul> <li>Fix broken export as CSV for bar chart widget</li> <li>Remove some entities (patterns) that are not useful in dashboard view</li> <li>add live feed for dashboard</li> <li>re-enable aggregation on some fields and display a warning if the query is slow</li> <li>In widgets mark mandatory fields</li> <li>Some filter queries on string field (like title) were not correctly built</li> </ul> </li> <li>Admin: be less restrictive for urls (cortex and misp)</li> <li>Case sharing:<ul> <li>Fix request timing issue when sharing a case that prevented from sharing the tasks</li> <li>Update wording when sharing a case</li> </ul> </li> <li>When a customfield has options, prevent the user from selecting an other value</li> <li>Fix issue when updating custom fields in case templates</li> <li>Fix count of similar alerts </li> <li>When creating an observable the option \"one observable per line\" is now the default</li> <li>Fix duplicated refetch when updating an entity</li> <li>Fix live feed when updating a case</li> </ul> <p>Backend:</p> <ul> <li>Oauth2 connector will read the value for its proxy from <code>application.conf</code> &gt; <code>wsConfig.proxy</code></li> <li>Create audit logs when tasks are cancelled when closing a case</li> <li>In API allow status length of 64 chars for case and alerts (was wrongly 32 chars previously)</li> <li>Fix GDPR service that did not include all the tasks, task logs and observables</li> <li>Fix permission issue where analysts could no longer generate their Api Key (regression introduced in 5.0.19)</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5019-16th-november-2022", "title": "5.0.19 - 16th November 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_7", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix urls in mardown that contain <code>&amp;</code> character</li> <li>Platform configuration: <ul> <li>Webhook version was always set to 1</li> <li>Global endpoints can now be edited</li> </ul> </li> <li>Dashboards:<ul> <li>Fix issue with dashboards using relative times (like \"last 3 months\")</li> <li>Fix crash when deleting a widget in certain conditions</li> <li>Improve conversion of TheHive 4 dashboards</li> </ul> </li> <li>Display sightedAt date when an observable is set as sighted</li> </ul> <p>Backend:</p> <ul> <li>Fix permission issue for user edition</li> <li>Fix issue when trying to repair the index with a vertex containing non indexed fields</li> <li>Refresh license quotas faster after an organization is locked</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#security-updates", "title": "Security Updates", "text": "<ul> <li>Update dependency on org.apache.commons:commons-text to 1.10.0</li> <li>Remove dependency on org.apache.ivy:ivy</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5018-27th-october-2022", "title": "5.0.18 - 27th October 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#updates", "title": "Updates", "text": "<ul> <li>Update Cortex analyzer templates</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_8", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Dashboard:<ul> <li>Fix counter widget not working with observables</li> <li>Fix entity change not updating form changes</li> <li>Fix legends in dashboard that may be truncated</li> </ul> </li> <li>Custom fields options are shown even if the field is not empty</li> <li>Fix icons in analyser reports when serving TheHive on a non root path</li> <li>Fix issue when creating a case template with an already existing name</li> <li>Fix bad autocompletion on non tag fields</li> <li>Markdown tables now respect the alignment</li> <li>Fix drawer title when editing a dashboard</li> <li>Fix rare issue where the observable counter was not refreshed when an observable was added</li> </ul> <p>API docs</p> <ul> <li>Field <code>date</code> in Alert is now corectly marked as optional</li> <li>Add api docs for observable types</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_1", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Faster load of analyzer templates when viewing an analyzer report</li> <li>Sort search results by <code>_createdAt</code> date</li> <li>Sort analyzer list</li> <li>Dashboard:<ul> <li>color can now be customized for the field status</li> </ul> </li> </ul> <p>Backend:</p> <ul> <li>Make alert merging faster</li> <li>Fix chart time interval when empty series</li> <li>Set size limit on custom field values (8191 chars)</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5017-11th-october-2022", "title": "5.0.17 - 11th October 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_9", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix the search field in alert and case merging drawer</li> <li>Add missing validation button on the UI settings when choosing a date format</li> <li> <p>Fix case export button when MISP is available</p> </li> <li> <p>Dashboard:</p> <ul> <li>Fix filters during the import of dashboards, they was ignored</li> <li>Fix text and counter widget serie filters. They was ignored in 5.0.16</li> </ul> </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_2", "title": "Improvements", "text": "<p>Backend:</p> <ul> <li>Use index to count the number of waiting tasks</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5016-7th-october-2022", "title": "5.0.16 - 7th October 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_10", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Removed clickable description</li> <li>Fixed crash on alert merge in a new case</li> <li>Fixed rule to enable/disable button for the case export (MISP and archive capability)</li> </ul> <p>API:</p> <ul> <li>startDate in task set even if we go from Waiting to Completed</li> <li>Notify user when Cortex requires admin actions to update analyzers</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_3", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Dashboard:<ul> <li>Added time selection in custom period picker</li> <li>Improved performances of Text and Counter widgets</li> </ul> </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5015-30th-septembre-2022", "title": "5.0.15 - 30th Septembre 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_11", "title": "Fixes", "text": "<p>API:</p> <ul> <li>Fix \"none of\" filter which could return wrong result when using in dashboards</li> <li>Fix result of dashboard based on custom fields</li> </ul> <p>UI:</p> <ul> <li>Case count now takes filters into account</li> <li>Array and title panel in markdown edition was disappearing</li> <li>Deleting a filter had a weird behavior before (going back to the previous applied state), it now only deletes the selected filter</li> <li>Border for cortex/misp logo fixed for Safari 14</li> <li>Task completion bar is now refreshed when a task status is updated</li> <li>Fixed empty page sometimes when login</li> <li>Webhook endpoint version is now editable</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_4", "title": "Improvements", "text": "<p>API:</p> <ul> <li>Add \"alertsCount\" extraData in case list</li> </ul> <p>UI:</p> <ul> <li>Dashboard duplication feature has been added</li> <li>Count and link for similar cases/alert has been added to alert preview</li> </ul> <p>Description:</p> <ul> <li>textarea for edition is now resizable</li> <li>linebreak in text renders with a newline in markdown</li> <li>we can now click on the description to edit it</li> <li>font size when editing is now monospace</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5014-19th-september-2022", "title": "5.0.14 - 19th September 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_12", "title": "Fixes", "text": "<p>API:</p> <ul> <li>Fix an issue where case template prefix was duplicated in case title</li> <li>Observables with files were not linked correctly to their attachments which impacted the merge of observables</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_5", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Notifications: display the name of the webhook</li> <li>Ability to filter users by profile when listing the users of an organization</li> <li>In search page, add link to observable parent (case or alert)</li> <li>In live stream, display full date instead of 'x seconds ago'</li> <li>Dashboard:<ul> <li>Display users name instead of login</li> <li>Make time intervals aware of user timezone and locale, so that months and weeks aggregation behave correctly</li> </ul> </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5013-8th-september-2022", "title": "5.0.13 - 8th September 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_13", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Dashboard:<ul> <li>Remove some entities from the entity list for which dashboards were not usefull or working (like comments or actions)</li> <li>Clicking on a counter or donut now correctly sets the filters in the search page</li> <li>conversion of v4 dashboards failed with <code>not</code> operator</li> </ul> </li> <li>Improvement around time filters (custom and periods)</li> <li>Assignees from other organizations are visible and searchable in case assignment</li> <li>Fix bad date format when using am/pm</li> <li>Case sharing displayed an empty list of organization</li> <li>Quote in the markdown editor only worked for the first line</li> <li>On small screen preview button was not visible when using Firefox</li> <li>Fix bug in list of TTP tactics</li> </ul> <p>API:</p> <ul> <li>Fix issue with integrity check of Observable</li> <li>Fix issues around Case Number Actor (responsible to give a sequential number for cases)</li> <li>Avoid locks when trying to fix inconsistencies in index</li> <li>Fix an issue that could happend during schema evolution</li> <li>Fix parsing of Cortex information (analyzers without dataType)</li> <li>Notifications: Email will now be sent in the format set by the text template (html or plain text)</li> <li>Prevent user ldap synchronisation if license is incompatible</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_6", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Notify user when an update in Cortex is available</li> <li>Dashboard:<ul> <li>Default period is now 3 months instead of \"All\"</li> <li>Remove some entities from the entity list for which dashboards were not usefull or working (like comments or actions)</li> <li>An org admin can disallow the \"All\" period in the dasboards (organization settings &gt; UI Configuration)</li> <li>Widgets legends now show fully</li> </ul> </li> <li>Add an indicator on the number of open requests made by the browser</li> <li>Admin can now configure the default user domain from the admin settings</li> <li>Admin can change the type of a user (Service or Normal users)</li> <li>Improvements around the Proxy and SSL forms (used in misp, cortex or endpoints definition)</li> </ul> <p>API:</p> <ul> <li>Add the ability to log the content of query request</li> <li>Admin can now write in the knowledge base (the permission <code>manageKnowledgeBase</code> was added to the <code>admin</code> profile)</li> <li>Improve templating capabilites in notifiers:<ul> <li>Add <code>dateFormat</code> helper (<code>{{dateFormat audit._createdAt \"EEEEE dd MMMMM yyyy\" \"fr\" }}</code> =&gt; <code>jeudi 01 septembre 2022</code>)</li> <li>Helper <code>eq</code> now supports numbers: <code>{{#if (eq object.severity 2) }}MEDIUM {{else}}Other {{/if}}</code></li> <li>Add helpers <code>tlpLabel</code>, <code>papLabel</code>, <code>severityLabel</code>: <code>{{tlpLabel object.tlp}}</code> =&gt; <code>Amber</code></li> </ul> </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5012-16th-august-2022", "title": "5.0.12 - 16th August 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_14", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix issue where case assignee was not displayed (because user was in an other organization)</li> <li>Fix org switch not working when using http context (bug introduced in 5.0.11)</li> </ul> <p>API:</p> <ul> <li>Don't fail integrityChecks if field <code>_createdAt</code> is missing</li> <li>Sync cortex jobs with status <code>Deleted</code></li> <li>Don't fail queries if a phamtom vertex is encountered</li> </ul> <p>Migration:</p> <ul> <li>Fix issue where users could be duplicated by the migration 3-&gt;5 process</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_7", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Add field to set the expiration token duration for reset password links</li> <li>In Proxy forms, add input field to set the port of the proxy</li> </ul> <p>API:</p> <ul> <li>Alert can be created even if they contain duplicated observables of type files. Before it triggered an \"AlreadyExits\" error.</li> <li>Remove orphan cortex jobs (when observable was deleted)</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5011-5th-august-2022", "title": "5.0.11 - 5th August 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_15", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix import of .thar files</li> <li>When switching of organization, the user is redirected to her homepage.</li> <li>Filters on number types showed <code>-1</code> in the preview</li> <li>In endpoints configuration, the setting \"Do not check Certificate Authority\" was not sent correctly</li> <li>Fix filters when using between dates with an hour or minute precision</li> </ul> <p>API:</p> <ul> <li>Cases created from an alert with a case template could have duplicated custom fields</li> <li>Cases created from an alert with a case template had duplicated tasks and prefix (from 5.0.10)</li> <li>Prevent failures during migration from v4 to v5: <ul> <li>TheHive will automatically reindex its data when a change in the index is detected (change from lucene to elasticsearch)</li> <li>TheHive will no longer try to run migrations when the setting <code>db.janusgraph.index.search.elasticsearch.bulk-refresh = false</code> is present</li> </ul> </li> <li>Fix issue where uploaded files like observable attachments were deleted from the server before being processed, resulting in \"File Not Found\" errors</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_8", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Improve the search experience when merging a case </li> <li>Ctrl+click on a case title in the list view will open the case in a new tab</li> </ul> <p>API:</p> <ul> <li>TheHive will try to fix ghost vertices when encountering one (a vertex that is present in the index but not in the database)</li> <li>a new field <code>extendedStatus</code> is passed to Cortex responders which represents the status of the Case which can be customized. The field <code>status</code> is still a fixed enumeration.</li> <li>Add integrity checks for <code>Share</code>s and <code>Role</code>s entities</li> <li>Some cortex jobs could be stuck in \"Waiting\" status: now when TheHive starts it will try to fix those jobs.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#5010-21st-july-2022", "title": "5.0.10 - 21st July 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_16", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Dashboard:<ul> <li>fix style issue when loading the knowledge base at the same time</li> <li>update api used by bar widget to fix issues with custom fields query</li> </ul> </li> <li>Markdown preview in full screen mode now uses the full height of the screen</li> <li>Fix a filter when using enumeration (severity, pap)</li> <li>MISP: add settings in the UI to be able to export tags on Case and Observable from TheHive to MISP</li> <li>Cortex: <ul> <li>UI is notified when an analyzer has finished adding all the observables to a report</li> <li>Fix report view for Spamhaus analyzer</li> </ul> </li> </ul> <p>API:</p> <ul> <li>Fix issue that caused the user <code>system@thehive.local</code> to be deleted by the user integrity check: this could cause issues with MISP or Cortex synchronization (Cortex jobs triggered by notifiers were left in \"Waiting\" state). If the user was missing from your instance, it will be recreated after an update of TheHive. </li> <li>Increase the timeout for count requests to 10s and add a config to increase this value (<code>db.limitedCountTimeout</code>). If a count takes longer that this duration, a truncated result is returned.</li> <li>Dashboard queries: Filter on custom fields was not applied on the name of the custom field (only on the value)</li> <li>Fix an issue that prevented TheHive from starting when misp or cortex were not configured correctly (missing <code>http</code> scheme in url for instance)</li> </ul> <p>Docker:</p> <ul> <li>Fix issue with argument <code>--no-cql-wait</code> that caused the next argument to be ignored</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_9", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Responder jobs list are now sorted by start date </li> <li>Users in Assignee field are now sorted by alphabetical order</li> <li>When showing an observable, prevent from loading all the reports details when loading the job list. Report details are now loaded only when opening the report drawer.</li> </ul> <p>API:</p> <ul> <li>Add new parameters to the endpoint \"create a case from an alert\".</li> <li>When creating a case from an alert, the events <code>CaseCreated</code> and <code>AlertImported</code> are triggered once all the alert observables are imported inside the case.</li> <li>When merging alerts inside a case, triggger the event <code>AlertImported</code> once all observables for an alert are imported inside the case.</li> <li>Emailer will now send html emails instead of text emails. This means that you use advanced formatting and styles in your emails.</li> <li>Cortex job reports are not included in the list anymore. An extra data needs to be used to retrieve them.</li> </ul> <p>Docker:</p> <ul> <li>Misp and Cortex modules are enabled by default when using the entrypoint. (They are not enabled if you use <code>--no-config</code>)</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#509-1st-july-2022", "title": "5.0.9 - 1st July 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_17", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Dashboard:<ul> <li>Fix radar when aggregating on custom fields</li> <li>Radar widget now uses a more efficient query</li> <li>Clicks on donut and counter widgets correctly sets the filters on the search page</li> </ul> </li> <li>Reset scroll when page is changed</li> <li>In alert observable list, remove the share column</li> <li>Fix french translation in quick views</li> <li>Fix links in search results for observables</li> </ul> <p>API:</p> <ul> <li>When merging an alert in a case, merge the tag reports for the observable</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_10", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>In analyzer reports, add the tags on the observables</li> <li>Sort case template by name when creating a case</li> <li>Add support for cortex entities in charts and dashboard</li> <li>Related case view: sort cases by matching percentage</li> </ul> <p>API:</p> <ul> <li>Limit the duration of count queries not using the index to 5 seconds</li> <li>Add support for cortex entities for charts api</li> <li>Add TheHive version in logs</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#508-15-june-2022", "title": "5.0.8 - 15 June 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#security", "title": "Security", "text": "<p>Fix issue related to AD/LDAP module.</p> <p>If you are using the ad/ldap authentification, you should update to TheHive 5.0.8 or later</p>"}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_18", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fixes issues around importing observables from an analyzer report</li> <li>Analyzer template list was not be exhaustive in certain cases</li> <li>Fix pagination and sorting when listing similar cases</li> <li>In related cases list, show several matching observables instead of only one</li> </ul> <p>API:</p> <ul> <li>Removed full text search on tags: that caused slow queries as the index cannot be used here</li> <li>Fixed regression from TH4: when merging alerts into a case, observables could be duplicated if they appeared in several alerts</li> <li>Add ability to filter and sort by case/alert status/stage on api v0</li> </ul> <p>Docker:</p> <ul> <li>Fix entrypoint for s3 configuration</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_11", "title": "Improvements", "text": "<p>API:</p> <ul> <li>Log login success and failures: those logs are useful for auditing purpose, to detect password guessing attacks via large unsuccessful logon attempts</li> <li>Prevent duplication of custom fields values</li> <li>Improve queries when filtering on a custom field with a high number of matches</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#507-31-may-2022", "title": "5.0.7 - 31 May 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_19", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>When creating a case from an alert, the correct case template is selected if the field was set in the alert</li> <li>Dashboard: fix an issue when converting a v4 dashboard</li> <li>Case count was not refreshed when adding a case</li> <li>Refresh comment section</li> <li>Misp configuration: Fix organization selection</li> <li>Analyzer reports:<ul> <li>in an alert, display the extractable observables</li> <li>can now import an observable of type file</li> </ul> </li> <li>Custom Fields:<ul> <li>Limit the size of custom fields in list views</li> <li>use the display name in list views</li> </ul> </li> <li>When closing a case, custom fields are no longer deleted</li> </ul> <p>API:</p> <ul> <li>Fix breaking change in api V0: don't limit the size of observable data in json. This prevented the creation of files in observables. Note: with v1 the prefered way is to use a multipart request.</li> </ul> <p>Migration 3 to 5</p> <ul> <li>Fix migration of custom fields of type number</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_12", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Add ability to manually refresh a list when auto-refresh is disabled</li> <li>Notifications: Add a json validator when creating a custom filter</li> <li>Prevent automatic scroll when an entity is updated</li> <li>Fix flickering of updated data fields when updating an entity</li> <li>Other UI improvements</li> </ul> <p>API:</p> <ul> <li>Check for duplicated files (by filename) when attaching a file to a case or to a log</li> <li>Add field <code>stage</code> to alert and case in api v0</li> <li>Users can manage their own api key without the permission <code>manageUsers</code></li> <li>Add new auth mecanism based on htpasswd file</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#506-17-may-2022", "title": "5.0.6 - 17 May 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_20", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>List of analyzers did not refresh correctly for alert observables</li> <li>Fix error when trying to download a task log attachment with the char <code>{</code> in the name</li> <li>logout popin remained open after a reconnection</li> <li>API docs did not appear when setting an http context</li> <li>Fix an issue where breadcrumps were not displayed correctly</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#improvements_13", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Faster render of big markdown section: use <code>marked-react</code> library instead of <code>react-markdown</code></li> <li>Adjust fanged message</li> <li>Improve sorting of tasks when in group mode</li> <li>Update observable count when an observable is added or removed</li> <li>Improvements for \"Required Action\" on tasks</li> </ul> <p>Migration 4 to 5:</p> <ul> <li>Improve migration for custom fields where previous script could overload the application</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#505-5-may-2022", "title": "5.0.5 - 5 May 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_21", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Analyzer templates: optimize rendering time</li> <li>Fixed SSO login when using an http context</li> </ul> <p>API:</p> <ul> <li>Dashboard: increase number of retrieved values for aggregations (eg. chart on custom field values)</li> <li>Fix for permission <code>manageConfig</code></li> <li>Improve support for AWS Keyspace: add retries on some failed queries</li> <li>Fix endpoint for deletion of catalog of ttp</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#504-3-may-2022", "title": "5.0.4 - 3 May 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_22", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Tasks are now displayed by their order</li> <li>Changed color of field for search by case id</li> <li>Fixed an issue where custom fields were deleted when editing a case template</li> <li>Fix download link of attachments when http context is set</li> <li>Update of vulnerable libraries</li> <li>When using bulk edit, \"Add tags\" and \"Remove tags\" now work</li> </ul> <p>API:</p> <ul> <li>Fixed bug introduced in 5.0.3 where TTPs were not linked to their tactics and reported <code>&lt;unknown&gt;</code></li> <li>It's now possible to delete the title prefix in a case template</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#503-15-april-2022", "title": "5.0.3 - 15 April 2022", "text": ""}, {"location": "thehive/release-notes/release-notes-5.0/#new-features", "title": "New Features", "text": "<p>API:</p> <ul> <li>Add support to procedures (TTPs) when creating alerts in TheHive</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#fixes_23", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>When importing a case from misp: additional parameters (custom fields, shares) are correctly sent</li> <li>When converting an alert to case, custom fields are no longer lost during the process</li> <li>Update moment.js library</li> </ul> <p>Migration tool:</p> <ul> <li>Fix typo in migration tool configuration</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#502-8-april-2022", "title": "5.0.2 - 8 April 2022", "text": "<p>We found a bug that prevents a user from using the reset pasword flow (present in 5.0.0). We recommend all 5.0.x users to update to this version.</p> <p>Fixes:</p> <ul> <li>Fix 404 page during the reset password flow</li> <li>Dashboard: include end date in time interval</li> <li>Fix detached live feed when using an http context</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.0/#501-7-april-2022", "title": "5.0.1 - 7 April 2022", "text": "<p>TheHive 5.0.1 is the first patch release in the 5.0 series. It contains fixes and improvements for the UI and some small changes for the API compared to 5.0.0.</p> <p>We recommend all 5.0.0 users to update to this version.</p>"}, {"location": "thehive/release-notes/release-notes-5.0/#notables-changes", "title": "Notables changes", "text": "<p>UI:</p> <ul> <li>fix description display on search page</li> <li>display org admin tabs only with required permissions</li> <li>fix permissions checks in the application</li> <li>improve case sharing user experience</li> <li>notifications - fix urls of http endpoints</li> <li>notifications - improve editor when using template variables</li> <li>be able to download a file attachment for an alert</li> <li>forms and drawers don't lose user data when the entity is refreshed by the feed</li> <li>improve live feed for cortex jobs on observables</li> </ul> <p>API:</p> <ul> <li>add ability to create alert with observables (of type string and files), see. API docs for more information</li> <li>rename field user to assignee in case creation</li> <li>rename field customFieldValues to customFields in alert creation</li> </ul> <p>Backend:</p> <ul> <li>fix tag edition</li> <li>fix permissions check for observables in case of sharing</li> <li>fix user deletion (user could be left without org)</li> <li>fix license reload on cluster nodes</li> <li>add more check to ensure uniqueness of data</li> <li>increase quotas for service users (set to unlimited) and cluster nodes (unlimited for platinum plan)</li> <li>update of dependencies</li> </ul> <p>Docs:</p> <ul> <li>fix url to website</li> <li>add documentation for MISP endpoints</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/", "title": "Release Notes for Version 5.1", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#release-notes-of-51-series", "title": "Release Notes of 5.1 series", "text": "<p>Danger</p> <p>The 5.1 release comes with some changes on the database schema that can't be reversed. Please make sure to make a backup of your database before upgrading.</p> <p>This release also comes with some breaking changes, please review them below</p> <p>Info</p> <p>An upgrade guide is available to help you migrate from TheHive 5.0</p>"}, {"location": "thehive/release-notes/release-notes-5.1/#5112-9th-april-2024", "title": "5.1.12 - 9th April 2024", "text": "<ul> <li>Fix a regression following a security fix that made the MFA authentication impossible.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#5111-4th-april-2024", "title": "5.1.11 - 4th April 2024", "text": "<ul> <li>Fix security vulnerability. An advisory will be published in the coming weeks.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#5110-21st-december-2023", "title": "5.1.10 - 21st December 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#fixes", "title": "Fixes", "text": "<p>Security:</p> <ul> <li>Fix security vulnerabilities. Please read the detailed advisories.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#519-29th-june-2023", "title": "5.1.9 - 29th June 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#fixes_1", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix display of task attachments in attachment listing</li> <li>Improve error message when merging cases</li> </ul> <p>Backend:</p> <ul> <li>Fix error \"Tag not Found\" which could occur when creating alerts and cases</li> <li>Fix link duplication when importing several times a TTP catalog</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#improvements", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Improve form for SAML authentication</li> </ul> <p>Backend:</p> <ul> <li>Add MISP event UUID to alert description in imported alerts</li> <li>Add validation for SAML configuration</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#518-20th-june-2023", "title": "5.1.8 - 20th June 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#fixes_2", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix the order of Cortex job reports in observable page</li> <li>Add events related to case templates in live feed</li> <li>Change rules of user quota</li> <li>Display the callback URL in SAML configuration</li> <li>Fix icon in timeline</li> <li>Fix format of some old generated dashboard widgets</li> </ul> <p>Backend:</p> <ul> <li>Change format of the date custom field values Ids</li> <li>Fix between filter on custom fields</li> <li>Ldap sync: add support of several mapping for the same group</li> <li>Ldap sync: fix conflict when several configurations exist with the same suffix</li> <li>Cortex job endDate is not set if the job is not finished</li> <li>Fix filter value when it contains only wilcards</li> <li>Make readonly profile not editable</li> <li>Add properties for alert KPIs</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#517-1st-june-2023", "title": "5.1.7 - 1st June 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#fixes_3", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fixes on long names</li> </ul> <p>Backend:</p> <ul> <li>Link correctly task and assignee when updating a task</li> <li>Limit the size of cortex response</li> <li>Cortex: Fix sync issue when multiple jobs are submitted at the same time</li> <li>Fix full text filter for custom fields</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#improvements_1", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Allow search for task assignee input</li> </ul> <p>Backend:</p> <ul> <li>Optimize resource usage when reading cortex jobs </li> <li>Replace default \"Job\" dashboard with a better TTP dashboard</li> <li>Cortex:<ul> <li>Add timeout for jobs (3 hours by default)</li> </ul> </li> <li>Deduplicate custom field values on case merge</li> <li>Increase observable data length in api v1 to 4096 chars</li> </ul> <p>Migration tool:</p> <ul> <li>Improve mapping of TheHive 3 Alert status </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#security", "title": "Security", "text": "<ul> <li>Update libraries</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#516-15th-may-2023", "title": "5.1.6 - 15th May 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#fixes_4", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix edition of property \"includeInTimeline\" for task activities</li> <li>Fix case template search when creating a new case</li> <li>Admin: show username and organization name as required in forms</li> <li>other small fixes</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#improvements_2", "title": "Improvements", "text": "<p>API:</p> <ul> <li>Improve performances in some areas</li> <li>Replace org default dashboard \"jobs\" with TTP</li> <li>Improve performance when running notifiers</li> <li>It's now possible to upload two attachments with the same name in a case (the second attachment will be renamed automatically)</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#security_1", "title": "Security", "text": "<ul> <li>Update libraries and remove unused dependencies</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#515-27th-april-2023", "title": "5.1.5 - 27th April 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#fixes_5", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Case template: fix issue where prefix was deleted when editing a template</li> <li>Sharing: Fix display of share options on small display</li> <li>Responder reports should now appear in the observable preview when triggered</li> </ul> <p>Backend:</p> <ul> <li>Fix Case dates when creating a case with status \"Closed\"</li> <li>Fix issue that created phamtom tags on alerts or case</li> <li>Fix issue that removed field <code>_id</code> from audits sent via notifiers (like webhook)</li> <li>Fix empty response when using the extraData <code>similarAlerts</code> on case queries</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#improvements_3", "title": "Improvements", "text": "<p>UI:</p> <ul> <li>Better user selector</li> <li>Tasks: redirect to task list after deleting a task</li> <li>Change wording in search bar</li> <li>Alert list: add capability to filter by assignee when clicking on an assignee</li> <li>Filters: assignee field will filter the dropdown list when typing</li> <li>Functions: several improvments</li> <li>Comments: use \"Enter\" to save a comment</li> <li>Responders: Sort responder reports by startDate</li> </ul> <p>API:</p> <ul> <li>Better error codes when making queries or when sending an http entity too large</li> <li>Allow attachment download using its <code>id</code> or <code>_id</code></li> <li>Fix some errors in the documentation</li> </ul> <p>Backend:</p> <ul> <li>Improve tag creation performances</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#514-13th-april-2023", "title": "5.1.4 - 13th April 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#fixes_6", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix crash when live feed is opened and a case is deleted</li> <li>Pages: several images with the same name can now be added (also fixes an issue with pasted images)</li> <li>Hide locked users in task assignee</li> <li>Custom fields of type boolean now display a set of options</li> <li>You can now press <code>Enter</code> to save a comment</li> <li>Fix report template download link</li> </ul> <p>Backend:</p> <ul> <li>Fix potential memory leak that could lead to a crash (from 5.1, issue not present in 5.0)</li> <li>Return error 413 when http input payload is too large</li> <li>Report error when email sending fails during password reset</li> <li>Fix api documentation for operator <code>_between</code> in queries</li> <li>Add field <code>_updatedBy</code> in comments</li> <li>Don't ignore cortex jobs when the report contains an unknown operation</li> <li>Deprecate page slugs (in api docs only)</li> </ul> <p>Warning</p> <p>In our next major release 5.2, the field <code>slug</code> for object <code>Page</code> will be removed. We are starting to deprecate it starting from this release</p>"}, {"location": "thehive/release-notes/release-notes-5.1/#513-29th-march-2023", "title": "5.1.3 - 29th March 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#fixes_7", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix filtering of case templates when creating a case</li> <li>When importing a case template that already exists, ask for a new name</li> <li>In dashboard list, be able to filter on group name</li> <li>Fix task list not refreshed when applying a case template on a case</li> <li>Fix url of popup livefeed when the application uses an http context</li> <li>Avoid tags deletion when editing a case template</li> </ul> <p>Backend:</p> <ul> <li>Improve error message when merging case</li> <li>Fix sharing not applied after merging cases</li> </ul> <p>Docker:</p> <ul> <li>Fixes <code>--storage-directory</code> option</li> <li>Don't show cassandra password</li> <li>Correctly escape Elasticsearch password</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#512-14th-march-2023", "title": "5.1.2 - 14th March 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#fixes_8", "title": "Fixes", "text": "<p>Backend:</p> <ul> <li>Fix SSO user autocreate</li> <li>Improve the application behavior when Janusgraph configuration gets updated while another connection exists</li> <li>Fix permission checks for case template creation</li> <li>Fix permission checks on pages</li> <li>Improve the observable type length check</li> </ul> <p>Cortex connector:</p> <ul> <li>Send the submit message to Cortex job actor when the transaction is committed</li> <li>Improve Cortex pending jobs recovery</li> <li>Fix: Recover only 100 jobs at startup. When the queue is empty, recover 100 more jobs.</li> <li>Updates of job with status \u201cDeleted\u201d are retried</li> <li>Improve logs</li> </ul> <p>MISP connector:</p> <ul> <li>MISP synchronisation misses some events in case of timeouts during synchronization</li> </ul> <p>UI:</p> <ul> <li>Refresh the task list when after bulk editing of assignee</li> <li>Fix tooltip overlap in some dashboard widgets</li> <li>Dashboard labels for cases/alerts are mixed</li> <li>Remove owner field from dashboard import drawer</li> <li>Fix the UI refresh when launching an analyzer job</li> <li>Fix incorrect search when click on donut due to persisting keyword \"domain\"</li> <li>Fix Customfield selector in case template editor</li> <li>Improve notifier name and suffix with using an existing endpoint</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#511-3rd-march-2023", "title": "5.1.1 - 3rd March 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#fixes_9", "title": "Fixes", "text": "<p>API:</p> <ul> <li>Fix a change in the observable creation API (regression from 5.0)</li> </ul> <p>UI:</p> <ul> <li>Date fields can be set using keyboard input</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#510-1st-march-2023", "title": "5.1.0 - 1st March 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.1/#breaking-changes", "title": "Breaking changes", "text": "<ul> <li> <p>Remove support for Hadoop for filestorage</p> <p>From this new release, Hadoop can no longer be used a file storage (it was removed from 5.0 documentation but could still be used)</p> </li> <li> <p>Drop support for java 8</p> <p>Java 8 version is no longer supported by TheHive. Please update to java 11 at least Our setup guide can help you on how to install a jvm</p> </li> <li> <p>Drop support for Lucene as index backend</p> <p>Former versions of TheHive supported lucene and elasticsearch as indexing engines for the data. We then encountered limitations while using the Lucene index (especially when making queries based on Custom Fields). With TheHive 5.0, we pushed users to install and migrate to Elasticsearch. Finally with TheHive 5.1, the support of Lucene index is removed: the application will start but queries involving Custom Fields will return wrong results. To migrate your index to Elasticsearch, follow this guide.</p> </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#main-features", "title": "Main features", "text": "<ul> <li> <p>Apply case template on existing case: enrich a case with tasks, custom fields, tags from other case templates</p> <p>This will allow your organization to create more reusable case templates and apply them during the lifecycle of a case</p> </li> <li> <p>KPIs</p> <p>Get more indicators about your organization response: Time to Respond, Time to Acknowledge ...</p> </li> <li> <p>Global search</p> <p>You can now search on all elements of the database instead of choosing a scope</p> </li> <li> <p>Custom Field db model update</p> <p>Database model was updated to be able to better support dashboard and queries based on custom fields. Now dashboard using filters or aggregation on custom fields should be way faster</p> </li> <li> <p>New permissions</p> <p>Split some permissions to make them more granular. For instance <code>manageAlert</code> was split into 4 permissions: <code>manageAlert/create</code>, <code>manageAlert/delete</code>, <code>manageAlert/update</code>, <code>manageAlert/import</code>. Case permissions were also split</p> </li> <li> <p>History list for object</p> <p>Added a new tab in the UI to list the changes made on an Alert or Case.</p> </li> <li> <p>Mandatory Tasks</p> <p>Some tasks can be defined as mandatory. To close a case, those tasks need to be closed and contain at least one activity.</p> </li> <li> <p>SAML Support</p> <p>You can now use SAML as an SSO source for your users (requires platinum license)</p> </li> <li> <p>Functions (Beta)</p> <p>See dedicated page for more information (requires platinum license)</p> </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#other-features", "title": "Other features", "text": "<ul> <li>New type of custom fields: url</li> <li>Change case ownership</li> <li>Similarity between observable now works with observable of kind attachment</li> <li>Improve Cortex connector resources usage</li> <li>Dashboards on org creation: default dashboards are now provided to new orgs</li> <li>Add cache for dashboard</li> <li>Auto import observables from Cortex: when an analyzer extract observables into its report, it can flag some observable to be automatically imported into the case/alert</li> <li>Experimental support for Elasticsearch 8</li> <li>Rework UX to add TTP</li> <li>Move interface date format to user settings (and localstorage) instead of org settings</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.1/#fixes_10", "title": "Fixes", "text": "<ul> <li>Notifications improvement: notifications are now triggered for each observable when creating an alert with multiple observables</li> <li>Several other fixes in the application and UI</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/", "title": "Release Notes for Version 5.2", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#release-notes-of-52-series", "title": "Release Notes of 5.2 series", "text": "<p>Danger</p> <p>The 5.2 release comes with some changes on the database schema that can't be reversed. Please make sure to make a backup of your database before upgrading.</p> <p>This release also comes with some breaking changes, please review them below</p> <p>Info</p> <p>An upgrade guide is available to help you migrate from TheHive 5.x</p>"}, {"location": "thehive/release-notes/release-notes-5.2/#5215-9th-of-january-2025", "title": "5.2.15 - 9th of January 2025", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#security-fix", "title": "Security fix", "text": "<ul> <li>This update contains a patch for a vulnerability (CVSS 6.9) non-exploited in the wild. More details will come in a further security bulletin, as per our responsible disclosure policy.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#5214-9th-april-2024", "title": "5.2.14 - 9th April 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fix", "title": "Fix", "text": "<ul> <li>Fix a regression following a security fix that made the MFA authentication impossible.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#5213-5th-april-2024", "title": "5.2.13 - 5th April 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#security", "title": "Security", "text": "<ul> <li>Fix Username Enumeration vulnerability.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#fix_1", "title": "Fix", "text": "<p>Filter/Search</p> <ul> <li>Fixed the search when using a \"not\" operator on full-text data.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#5212-12th-march-2024", "title": "5.2.12 - 12th March 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes", "title": "Fixes", "text": "<p>Cortex connector fixes:</p> <ul> <li>Enhanced Stability: Fixed an issue with the Cortex connector that had issues after updating it's configuration. Additionally, the \"Test connection\" button is no more preventing to cancel the configuration defined in the drawer.</li> </ul> <p>Notification fixes and enhancements:</p> <ul> <li>Slack notifier: Slack notifications are now sending the accurate case titles. Also, we fixed an issue with the \"Advanced settings\" that was sent to the backend, even if the box wasn't checked.</li> <li>HTTP notifications: Fixed interpretation of backslashes, ensuring correct rendering and transmission of notifications without unexpected behavior.</li> </ul> <p>Performances improvements:</p> <ul> <li>Similar Cases/Alerts pages: Optimized the Similar Cases/Alerts pages by limiting the correlation count, improving performances and preventing the application ressource exhaustion.</li> </ul> <p>MISP Connector:</p> <ul> <li>Observables export enhancement: Mapping between TheHive observables dataTypes and MISP attributes types has been reworked.</li> </ul> <p>User Experience Enhancements:</p> <ul> <li>Quick filters: Resolved issues with open case quick filter functionality.</li> <li>Shared tasks: Fixed display of User ID on task logs.</li> <li>OAuth2 authentication: We improved the drawer by renaming some fields to be more explicit. Additionally, fixing a bug that was preventing to disable the OAuth2 authentication provider.</li> <li>Dashboard donut widget: Fixed an issue with the category filter in the donut widget in dashboards.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#security-updates", "title": "Security updates", "text": "<p>The library dependencies has been updated. The following vulnerabilities has been removed: - CVE-2020-8908 - CVE-2023-2976 - CVE-2023-46749 - CVE-2023-34454 - CVE-2023-34455 - CVE-2023-43642 - CVE-2023-5072 - CVE-2022-45688 - CVE-2023-44483 - CVE-2023-34462 - CVE-2023-3635 - CVE-2023-46120</p>"}, {"location": "thehive/release-notes/release-notes-5.2/#5211-8th-february-2024", "title": "5.2.11 - 8th February 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_1", "title": "Fixes", "text": "<p>User Interface:</p> <ul> <li>Dashboard Revitalization: The Donut widget shows again the total.</li> <li>Streamlined Dashboard Filtering: We've refined dashboard filtering to utilize associated field text instead of custom label text, enhancing usability and clarity in data presentation.</li> <li>Observables Management: only protect http(s) string if it is part of a url.</li> <li>Improved Linked Alert: In the Linked Alerts tab, all types of alerts, whether with or without observables, are now seamlessly displayed for enhanced visibility and swift action.</li> <li>Efficient Alert Assignment: Fix bulk assignment issues for alerts, ensuring smooth and efficient workflow management.</li> </ul> <p>API:</p> <ul> <li>Seamless Integration with MISP: Experience effortless file upload to MISP with identical files from TheHive, streamlining your incident response workflow and ensuring data consistency across platforms.</li> <li>Custom tags: fix tags global integrity check to delete orphan custom tags</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#improvements", "title": "Improvements", "text": "<p>SAML Authentication Enhancement:</p> <ul> <li>Custom Attribute Support: Introducing a new custom attribute - the Login Name field - in SAML forms, providing greater flexibility and customization options for user authentication.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#5210-10th-january-2024", "title": "5.2.10 - 10th January 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_2", "title": "Fixes", "text": "<p>API:</p> <ul> <li>Performance Enhancement: Improved performance when loading case pages with similar/related cases or alerts. Displays \"99+\" and seamlessly loads without blocking the page.</li> <li>TheHive Alert Creation: Fixing an observable deduplication issue while creating alerts. Merged description tags unless identical.</li> <li>Similar Cases Matching: Fixed a bug where in specific scenario, a case could match itself as similar.</li> </ul> <p>MISP:</p> <ul> <li>Optimized MISP Synchronization: Resolved abnormal CPU consumption during MISP synchronization when an event contains many observables.</li> </ul> <p>UI:</p> <ul> <li>Search of Knowledge Base Fix: Resolved the issue causing a \"white screen\" when searching in the Knowledge Base.</li> <li>Log Code Formatting: Fixed the code display in logs to correctly return to the line when exceeding a specified size component.</li> <li>Dashboard Memory Leak: Addressed a memory leak in the dashboard, ensuring that memory consumption does not increase.</li> <li>Cortex Analyzer/Responder Report Fix: Rectified the error message \"id undefined\" in Cortex Analyzer/Responder reports.</li> <li>Organization Name Trimming: Trimmed organization names when creating a new organization to prevent unnecessary spaces.</li> </ul> <p>Dashboard: - Customizable Fragment Display: Take control of your visualizations by choosing the number of fragments to display on the Donut. Tailor the dashboard to your preferences for a personalized and efficient user experience.</p> <p>Docker:</p> <ul> <li>Docker User Fix: Docker containers are now using \u201cthehive\u201d user instead of root. sudo is used when necessary to address file permission issues.</li> </ul> <p>Packages:</p> <ul> <li>Dependency Updates for RPM/DEB Packages: Updated dependencies for RPM/DEB packages, ensuring compatibility with java11-runtime-headless provided by both packages.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#new-features-improvements", "title": "New Features / Improvements", "text": "<ul> <li>Case Status Modification: Users can now change the status of a case from \"Closed\" to any other status without reopening the case.</li> <li>SAML Authentication Enhancement: Improved SAML authentication by allowing minutes to be used in the Maximum Authentication Lifetime.</li> <li>Observable Management from UI: Introduced the ability to add/edit observables directly into an alert from the user interface for enhanced flexibility.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#529-21st-december-2023", "title": "5.2.9 - 21st December 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_3", "title": "Fixes", "text": "<p>Security:</p> <ul> <li>Fix security vulnerabilities. Please read the detailed advisories.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#528-23rd-november-2023", "title": "5.2.8 - 23rd November 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_4", "title": "Fixes", "text": "<p>API:</p> <ul> <li>MISP Sync: Fixed a bug introduced in the latest version which causes TheHive to crash when parsing MISP events with the fields <code>first_seen</code> or <code>last_seen</code>. This bug does not happen in earlier versions (&lt;= 5.2.6) or if those fields are not present in the MISP event</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#527-2nd-november-2023", "title": "5.2.7 - 2nd November 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_5", "title": "Fixes", "text": "<p>API:</p> <ul> <li>LDAP Sync Enhancement: We've fine-tuned our LDAP sync functionality to ensure that it doesn't overwrite critical user fields like API key and TotpSecret.</li> <li>Attachment Upload: Fixed an issue where the empty files was discarded by default. TheHive now accept empty files by default.</li> </ul> <p>User Interface:</p> <ul> <li>Case Reporting CSS Fix: We've corrected a CSS tag name for high severity cases, which fix a display issue in the reports.</li> <li>Alert Responders Tab Enhancement: Fixing issues on the responder reports list display.</li> <li>Filter Preview Improvement: Lengthy filters do not break the display in the UI anymore</li> <li>Report Template Enhancement: We've added a more intuitive format for Custom Fields variables in report templates, introducing the format case.customFieldValues.name</li> <li>SAML Information Display: Fixed a bug where the session lifetime parameter wasn't displaying the actual value.</li> </ul> <p>New Features / Improvements:</p> <ul> <li>Alert Assignee:<ul> <li>Alert auto assignment at start/closure: If the alert is yet unassigned, TheHive now automatically set the assignee to the user that is performing the action of starting/closing the alert.</li> </ul> </li> <li>MISP Integration:<ul> <li>Improved MISP Status and Sync: We've revamped MISP status and synchronization reports to provide real-time insights into ongoing synchronizations. Stay informed about the status of your data exchanges.</li> </ul> </li> <li>Task Management:<ul> <li>Extended Task Group Name: Increasing task groups with names size up to 64 characters in length (instead of 32), allowing more flexibility when organizing incident response tasks and playbooks.</li> </ul> </li> <li>Case Reporting:<ul> <li>Docx Case Report Generation: Generate case reports in the popular .docx format, making it easier to customise post generation and share your cases reports with stakeholders. NB: No report preview available for this format.</li> </ul> </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#526-19th-october-2023", "title": "5.2.6 - 19th October 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_6", "title": "Fixes", "text": "<p>User Interface:</p> <ul> <li>SAML Configuration: We've enhanced security by checking the format of the 'name' SAML configuration field before creating the 'callback' URL. Special characters and uppercase letters are now automatically replaced for improved compatibility.</li> <li>Alert Similar Cases Query: We've resolved an issue where the similar cases query was not fetching results due to the length of default filters.</li> <li>Duplicate Observables: Multiple alert imports no longer lead to duplicate observables, as we now deduplicate them automatically.</li> <li>MISP Integration:<ul> <li>MISP Attribute Handling: When exporting a case, MISP attributes of observables are now set correctly, ensuring seamless integration with MISP.</li> <li>Event Editing Strategy: We've implemented a comprehensive event edit strategy to enhance your MISP experience.</li> </ul> </li> <li>Comments: Text comments without spaces now wrap correctly within the component, ensuring a neat and organized display.</li> <li>Authentication: Fixed a bug that did not correctly remove the link between two organizations, which could lead to connection problems.</li> </ul> <p>API:</p> <ul> <li>Cortex Responders: Cortex responders now show up for Tasks and Task Logs</li> <li>Duplicate Observables: When merging multiple alerts into a case, observables are now better duplicated</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#new-features-improvements_1", "title": "New Features / Improvements", "text": "<ul> <li>Date fields: All date fields in the application can now be set to hours and minutes.</li> <li>Menu Label Updates: We've made menu label changes for clarity and consistency. \"Related Alerts\" is now \"Linked Alerts,\" and \"Related Cases\" has become \"Similar Cases.\" URL updates accompany these changes for a seamless transition.</li> <li>Alerts Attachment: You can now add attachments to alerts using a dedicated tab. Attachments can be merged and imported into cases for better incident tracking.</li> <li>Sorting and Filtering: Within the attachment tab for cases and alerts, you have the ability to sort attachments by ascending or descending order and apply filters for efficient management.</li> <li>New Permissions: We've introduced two new permissions, \"Manage Reopen Case\" and \"Manage Restart Alert.\" This feature allows specific profiles to block access to reopening cases or restarting alerts. By default, these permissions are enabled for all profiles with \"Manage Update\" enabled.</li> <li>TTPs : It is now possible to create TTPs via the API without specifying tactics. If only one tactic matches the technique, it will be automatically defined by the system. Otherwise, a message will indicate that the tactic is missing, leaving the user free to specify it via the interface. Editing is now possible on TTPs.</li> <li>Detailed Browser Tab Content: Identify page content at a glance with improved browser tab titling</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#525-5th-october-2023", "title": "5.2.5 - 5th October 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_7", "title": "Fixes", "text": "<p>API:</p> <ul> <li>Cortex Responders: Resolved an issue related to Cortex responders not triggering on TLP:RED (4) cases due to a compatibility issue with TheHive's switch to TLPv2 while Cortex was using TLPv1.</li> </ul> <p>User Interface:</p> <ul> <li> <p>Cases: </p> <ul> <li>Improved Sorting: Now you can sort the list of related cases by title, date, and observables, providing better case management flexibility.</li> <li>Multi-Case Closure Fix: Fixed a problem that previously interchanged values when closing multiple cases simultaneously, ensuring accurate data handling.</li> <li>Merged Case Closure Fix: Fixed a problem that prevented a merged folder from being closed due to a new mechanism for deduplicating similar tasks during merging.</li> </ul> </li> <li> <p>Analyzers: Resolved a problem related to the selection of analyzers to launch on an observable after a previous analyzer had finished.</p> </li> <li>Global Search: The task log search results now correctly display the link to the task within the originating case.</li> <li>Date Display Format: Fixed a problem where the date format defined in the user profile was not being taken into.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#new-features", "title": "New Features", "text": "<ul> <li>Case URL option in MISP Connector: When exporting to MISP, TheHive could includes the case URL as an internal reference, enhancing traceability and information management.</li> <li>Session Duration Management: Introduced enhanced session termination and inactivity timeout management. Now, you can define session end and inactivity timeout times effectively, and even include a user warning message before session termination.<ul> <li>Read-only profiles will not be disconnected due to inactivity if they are connected to a dashboard and only to a dashboard. They will, however, be disconnected due to the end of a classic session.</li> </ul> </li> <li>Quick Assign to Me: A new action allows for quick assignment of cases or alerts directly from their details, streamlining task management.</li> <li>Cases: <ul> <li>Display number of alerts: The number of alerts imported into a case is now displayed in the case list information, providing valuable information at a glance.</li> <li>Attachment Previews: Preview HTML and Markdown attachments directly from the attachments list. Additionally, case reports are previewable from the report tab's attachments list.</li> </ul> </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#524-19th-september-2023", "title": "5.2.4 - 19th September 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_8", "title": "Fixes", "text": "<p>API:</p> <ul> <li>Notification: The \"JobFinished\" trigger will no longer be triggered when the job is updated, but only when the responders have finished.</li> </ul> <p>User Interface:</p> <ul> <li>User Management: Administrators will now receive a warning message when attempting to create a new user with an existing login.</li> <li>Case Template: When applying a case template with tasks to an existing case with tasks, the template's tasks will be placed at the end.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#new-features_1", "title": "New Features", "text": "<ul> <li>Notification: You can now trigger a notification when an analyzer has finished using the \"ActionFinished\" trigger.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#523-5th-september-2023", "title": "5.2.3 - 5th September 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_9", "title": "Fixes", "text": "<p>API:</p> <ul> <li>Case Closure Enhancement: The case closing API has been enhanced to ensure that mandatory custom fields are filled in before a case can be closed.</li> </ul> <p>User Interface:</p> <ul> <li>Taxonomy Import: The message returned by the taxonomy import in the event of an error or duplication is clearer</li> <li>Task Creation: Newly created tasks are now added to the bottom of the task list to maintain task order consistency.</li> <li>Real-time Updates: The observables and tasks counter now updates in real-time after an item is deleted from the list.</li> <li>Sorting Fix: A sorting issue on the related alerts list has been addressed.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#new-features_2", "title": "New Features", "text": "<ul> <li>Enhanced Case Merging: When merging cases, identical unmodified tasks are now intelligently merged, streamlining case management.</li> <li>Attachment Previews: Enjoy the convenience of previewing image, text, and PDF attachments for cases and task logs.</li> <li>Task Date Handling: Task end dates now auto-populate when a task is cancelled, with added checks to ensure start-end date consistency.</li> <li>Redesigned Task Log Display: The task log display has undergone a redesign, optimizing readability for improved usability.</li> <li>Streamlined Comment Display: Comments are now displayed in a revamped layout, enhancing readability for easier comprehension.</li> <li>Self-Assignment Capability: It's now possible to assign cases and tasks to yourself</li> <li>Expanded Custom Field Usage: Custom fields can now be completed when closing an alert, offering more complete alert closure information.</li> <li>Markdown Support in Case Reports: Markdown formatting in task log displays within case reports is now correctly interpreted, maintaining rich text formatting.</li> <li>SMTP configuration testing: Easily validate your SMTP configuration directly from the platform, to ensure the smooth operation of e-mail evoies through the application.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#522-9th-august-2023", "title": "5.2.2 - 9th August 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_10", "title": "Fixes", "text": "<p>Infrastructure:</p> <ul> <li>Fix to create attachment directory if it doesn't exist when TheHive starts up</li> <li>A change in authentication configuration is now applied immediately, without the need to restart the platform.</li> <li>The http context is only present once when you configure a SAML authentication server like Okta</li> </ul> <p>API:</p> <ul> <li>Improve performances of notifications making http requests and limit the number of open processes</li> </ul> <p>User Interface:</p> <ul> <li>The name field is indicated as required in the endpoint configuration.</li> <li>Improved loading time for the list of observables</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#new-features_3", "title": "New Features", "text": "<p>Alerts, Cases and tasks:</p> <ul> <li>Cancelled tasks are now displayed in a case's task list and in the task menu. It will also be possible to see them in progress, and a quick filter on canceled tasks has been added.</li> <li>The severity component of a case and the case number have been split. A new severity component has been created and standardized in the application      </li> <li>Alert comments are visible in case they have been imported</li> <li>Added the ability to copy case number, case title and alert title to the clipboard</li> <li>Add an icon to display alerts, cases and unassigned tasks, and trigger a quick filter on lists</li> <li>Added ability to perform bulk actions on TTPs</li> <li>It is possible to obtain the URL of a case page so that it can be shared</li> </ul> <p>Administration: </p> <ul> <li>Improved case report templates<ul> <li>Added the ability to add a title to a case report widget</li> <li>It is possible to duplicate a case report template</li> <li>It is possible to duplicate a case report template widget</li> </ul> </li> <li>Notifications can now be triggered when an alert closes</li> <li>We have uniformized the labels for PAP, TLP and Severity, in making so, the template helpers severityLabel, tlpLabel and papLabel available in notifications now return the label in upper case</li> <li>The application will notify users by email when their account is modified by them or an admin in the following cases:<ul> <li>Modification of email address</li> <li>Modification of password</li> <li>Password reset</li> </ul> </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#521-11th-july-2023", "title": "5.2.1 - 11th July 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_11", "title": "Fixes", "text": "<p>UI:</p> <ul> <li>Fix slow autocomplete of custom tags</li> </ul> <p>Docker:</p> <ul> <li>Fixed a behavior where cassandra hostnames were discarded when not resolvable by the entrypoint. This caused the application to use the local file database instead of the provided cassandra hosts when no host could be resolved. This issue appeared in environments like docker swarm.</li> </ul> <p>Warning</p> <p>The docker will no longer try to connect to a cassandra host called <code>cassandra</code> by default. If you use docker-compose with a cassandra database, make sure that you use the option <code>--cql-hostnames</code></p>"}, {"location": "thehive/release-notes/release-notes-5.2/#520-6th-july-2023", "title": "5.2.0 - 6th July 2023", "text": ""}, {"location": "thehive/release-notes/release-notes-5.2/#breaking-changes", "title": "Breaking changes", "text": "<p>Warning</p> <ul> <li>The transition to TLP 2.0 involves changing the ID of the TLP:RED value and adding TLP:AMBER+STRICT. The updated assignments are: <ul> <li>TLP:CLEAR = 0</li> <li>TLP:GREEN = 1</li> <li>TLP:AMBER = 2</li> <li>New: TLP:AMBER+STRICT = 3</li> <li>Change: TLP:RED = 4 (previously = 3)</li> </ul> </li> <li>Please make sure to update your dashboard and any integrations that rely on these values.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#main-features", "title": "Main features", "text": "<ul> <li> <p>What's new in templates</p> <ul> <li> <p>Report template: Boost your reporting with Case Reporting</p> <p>Create customized, high-impact reports with Case Reporting. Use a variety of dynamic widgets such as text, images, tables and lists. Relevant case data (tasks, observables, etc.) are automatically integrated. Export your reports in HTML and Markdown.</p> <p>See dedicated page for more information (requires platinum license)</p> </li> <li> <p>Page template: Customize and organize your cases pages</p> <p>Guide your collaborators in writing the documentation for a case by importing pages directly from the template to provide all the necessary elements and improve processes.</p> <p>See dedicated page for more information (requires platinum license)</p> </li> </ul> <p> </p> </li> <li> <p>What's new in alerts: </p> <ul> <li> <p>Alert assignment</p> <p>Assign alerts to members of the organization. Filter to find alerts assigned to a user.</p> </li> <li> <p>Triggers for alerts in notifications</p> <p>Benefit from new alert triggers to trigger your notifications.</p> </li> </ul> <p> </p> </li> <li> <p>Transition to TLP 2.0</p> <p>Our compatibility with the new TLP 2.0 standard is a key advantage for your business. Use the new TLP 2.0 terminologies to strengthen your cases, dashboards and reports.</p> <p> </p> </li> <li> <p>Notifiers Redis and Microsoft Teams</p> <p>With the new Redis Notifiers and Microsoft Teams, strengthen your communication. Keep your teams informed in real time about the progress of your processes.</p> <p> </p> </li> <li> <p>List Export</p> <p>Export your list information as you wish in JSON or CSV format. Apply filters and/or select items for export to keep only what you need. Exploit exported data according to your specific needs.</p> <p> </p> </li> <li> <p>Two-factor authentication activation indicator</p> <p>Identify users with two-factor authentication enabled. Enhance access security and promote two-factor authentication adoption.</p> </li> <li> <p>Add your own certificate authority on your servers</p> <p>Use your own CA for enhanced server security. Manage your own CA for complete control over certificate issuance, revocation, and management.</p> </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#other-features", "title": "Other features", "text": "<ul> <li>PAP:WHITE changes to PAP:CLEAR</li> <li>Add new observable to alert</li> <li>Custom field mandotory indicator added</li> <li>Improve markdown editor and library change</li> <li>Improve validation errors in api</li> <li>Improve performance of NotificationActor</li> <li>Add button to test MISP/Cortex configuration</li> <li>API could understand \"last x days\" filters</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.2/#fixes_12", "title": "Fixes", "text": "<ul> <li>Fixed some display problems on custom fields</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/", "title": "Release Notes for Version 5.3", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#release-notes-of-53-series", "title": "Release Notes of 5.3 series", "text": "<p>Danger</p> <p>The 5.3 release comes with some changes on the database schema that can't be reversed. Please make sure to make a backup of your database before upgrading.</p> <p>This release also comes with some breaking changes, please review them below</p> <p>Warning</p> <p>Note: public API v0 is now considered as deprecated.</p> <p>The public API v0 is obsolete, and you should not be using it anymore. All the endpoints are available in the public API v1. That being said, it will be deactivated in a future version.</p> <p>The API v0 was initially developed for TheHive 3 and maintained for backward compatibility reasons only. </p> <p>API v0 endpoints refer to APIs beginning with <code>/api/</code> or <code>/api/v0/</code> (but not with <code>/api/v1/</code>).</p> <p>Info</p> <p>An upgrade guide is available to help you migrate from TheHive 5.x</p>"}, {"location": "thehive/release-notes/release-notes-5.3/#5310-9th-of-january-2025", "title": "5.3.10 - 9th of January 2025", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#security-fix", "title": "Security fix", "text": "<ul> <li>This update contains a patch for a vulnerability (CVSS 6.9) non-exploited in the wild. More details will come in a further security bulletin, as per our responsible disclosure policy.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#539-21st-of-november-2024", "title": "5.3.9 - 21st of November 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#fix", "title": "Fix", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#cortex", "title": "Cortex", "text": "<ul> <li>Resolved an issue causing incorrect differentiation between \"In Progress\" Cortex analyzers and responders during TheHive startup process, that was causing some Responder jobs to never cleaned up.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#538-7th-of-november-2024", "title": "5.3.8 - 7th of November 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#fixes-improvements", "title": "Fixes &amp; improvements", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#cortex-job-queue", "title": "Cortex Job Queue", "text": "<ul> <li>Enhanced the handling of concurrent job submissions to the Cortex server for better efficiency and stability.</li> <li>Fixed an issue related to job status recovery in TheHive when the Cortex server crashes.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#537-11th-of-october-2024", "title": "5.3.7 - 11th of October 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#fix_1", "title": "Fix", "text": "<ul> <li>We fixed an issue with the method used to filter entity Ids. In certain very specific situations, the filter could return incorrect results.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#improvements", "title": "Improvements", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#cortex-job-queue_1", "title": "Cortex Job Queue", "text": "<p>We have made two improvements to the management of Cortex job queues from TheHive to:</p> <ul> <li>Prevent spamming the Cortex server when a large number of jobs are submitted.</li> <li>Reduce the latency in retrieving completed job reports, even when the job queue is highly loaded.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#536-12th-of-september-2024", "title": "5.3.6 - 12th of September 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#fixes", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#case-closure-with-mandatory-tasks", "title": "Case Closure with Mandatory Tasks", "text": "<ul> <li>It is no longer possible to close a case if there are mandatory tasks that remain incomplete. This prevents backend errors by ensuring that all required tasks are finished before allowing case closure.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#alert-status-display", "title": "Alert Status Display", "text": "<ul> <li>Fixed a display issue that incorrectly allowed closed alerts to be re-closed and already-started alerts to be started again.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#case-closure-custom-fields", "title": "Case Closure Custom Fields", "text": "<ul> <li>Fixed a problem where required custom fields with blank values were not properly flagged as required during case closure.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#case-closure-tab-refresh", "title": "Case Closure Tab Refresh", "text": "<ul> <li>Fixed an issue where the case closure tab would refresh unexpectedly while a user was filling out the form, due to actions taken by other users on the platform. This issue caused users to lose the values they had entered. The tab now remains stable during form completion, preventing data loss.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#markdown-formatting-in-case-reports", "title": "Markdown Formatting in Case Reports", "text": "<ul> <li>Fixed an issue with markdown formatting in case reports, specifically addressing problems with underlining and striking text.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#session-timeout-configuration", "title": "Session Timeout Configuration", "text": "<ul> <li>Fixed an issue that prevented users from editing fields related to session timeout due to inactivity.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#improvements_1", "title": "Improvements", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#login-page", "title": "Login Page", "text": "<ul> <li>Users can now tab through the fields to focus on the MFA code input when multi-factor authentication is enabled, making the login process smoother.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#security-fixes", "title": "Security Fixes", "text": "<ul> <li>CVE-2024-20952</li> <li>CVE-2024-20932</li> <li>CVE-2024-20918</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#535-28th-of-august-2024-hotfix", "title": "5.3.5 - 28th of August 2024 - hotfix", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#fixes_1", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#analyzer-reports", "title": "Analyzer reports", "text": "<ul> <li>we fixed a regression that prevented the analyzer reports to be displayed when the observable is attached to an alert.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#534-26th-of-august-2024", "title": "5.3.4 - 26th of August 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#improvements_2", "title": "Improvements", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#login-page_1", "title": "Login Page", "text": "<ul> <li>The text box now automatically gains focus when the page loads, allowing users to immediately begin typing their information.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#fixes_2", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#analyzer-jobs-report-display", "title": "Analyzer Jobs Report Display", "text": "<ul> <li>We improved the loading speed of analyzer reports in TheHive, reducing the time it takes for them to display (This change required a fix in 5.3.5 version).</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#activity-timestamp-in-timeline", "title": "Activity Timestamp in Timeline", "text": "<ul> <li>Fixed an issue that occurred when editing activity dates in the timeline.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#index-engine-configuration", "title": "Index Engine Configuration", "text": "<ul> <li>TheHive now prevents starting with an index engine that differs from the one specified in the configuration file.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#similar-alerts-display-safari-only", "title": "Similar Alerts Display (Safari Only)", "text": "<ul> <li>Resolved a display issue in the search input field within the drawer on Safari.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#navigation-menu", "title": "Navigation Menu", "text": "<ul> <li>Fixed a regression that prevented navigation menu links from opening in a new browser tab when using the mouse scroll button.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#list-component-fixes", "title": "List Component Fixes", "text": "<ul> <li>Corrected duration display in alert lists.</li> <li>Fixed status display in task lists.</li> <li>Resolved an issue where the \"hide custom field\" option was not functioning in case lists.</li> <li>Fixed the cropping of long custom field values to prevent display errors.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#case-reports", "title": "Case Reports", "text": "<ul> <li>Users from locked organizations are no longer visible in the user list.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#security-fix_1", "title": "Security fix", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#cve-vulnerability", "title": "CVE vulnerability", "text": "<ul> <li>CVE-2023-52428 : This vulnerability has been resolved.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#533-9th-of-july-2024", "title": "5.3.3 - 9th of July 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#improvements_3", "title": "Improvements", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#ui-enhancements", "title": "UI Enhancements", "text": "<ul> <li>List Display Improvements: Various components within list displays have been updated to enhance the overall aesthetic and functional experience. These improvements include modifications to the design of status and other minor visual adjustments aimed at enhancing usability.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#fixes_3", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#sorting-on-similar-casesalerts", "title": "Sorting on Similar Cases/Alerts", "text": "<ul> <li>Sorting Logic Correction: Fixed an issue in the sorting logic of the similarities column to ensure that cases or alerts are first prioritized by the highest number of similar observables, and in cases where two or more entries have the same number, they are then ordered by the highest ratio of common to total observables.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#datatype-filtering-in-similar-casesalerts", "title": "DataType Filtering in Similar Cases/Alerts", "text": "<ul> <li>Filtering Functionality Restoration: Restored the ability to define and apply specific data types in the matches column that filter similar alerts and cases. This update ensures that only observables of the selected types are considered when displaying similar cases and alerts, thereby improving the relevance and accuracy of similarity matches.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#user-count-in-administration-section", "title": "User Count in Administration Section", "text": "<ul> <li>The user count is now immediately updated when an account is removed or locked.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#api-case-list", "title": "API Case List", "text": "<ul> <li>Fixed a bug in the <code>query</code> API route that caused cases to be unobtainable when using the <code>caseid</code> filter.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#custom-tags", "title": "Custom Tags", "text": "<ul> <li>Corrected an issue that generated an error when removing and re-adding a custom tag.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#dropdown-selectors", "title": "Dropdown Selectors", "text": "<ul> <li>Fixed a bug in dropdown menus that prevented the menu action from launching if the click was not on the text item.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#532-14th-of-june-2024", "title": "5.3.2 - 14th of June 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#improvements_4", "title": "Improvements", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#similar-casesalerts", "title": "Similar Cases/Alerts", "text": "<ul> <li>Improved the queries to get and display the similar Cases &amp; similar Alerts lists. Only useful information is now loaded, significantly speeding up the list display. A new query is performed when accessing the observable list drawer of a similar Case/Alert.</li> </ul> <p><code>To ensure performance, the observable list preview drawer can display up to 100 observables only.</code></p>"}, {"location": "thehive/release-notes/release-notes-5.3/#fixes_4", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#directquery", "title": "DirectQuery", "text": "<ul> <li>Fixed an issue that could cause platform instability due to the handling of empty array requests when DirectQuery is activated.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#arrow-end-home-keys", "title": "Arrow / end / home keys", "text": "<ul> <li>Resolved a regression that prevented the use of arrow, end, and home keys in the edit mode of various components: Tasklog, Dashboard, Endpoints, Custom fields, Report template, and Case template.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#notifications", "title": "Notifications", "text": "<ul> <li>Corrected an issue in the httpRequest Notifier where the JSON mode was not properly applied when activated.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#misp-connector", "title": "MISP Connector", "text": "<ul> <li>Fixed an issue that prevented the MISP connector from capturing all events during synchronization.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#case-creation", "title": "Case Creation", "text": "<ul> <li> <p>Corrected a problem that prevented the selection of a custom Start Date when creating a case from an alert. Users can now select a custom Start Date for their cases.</p> </li> <li> <p>When multiple alerts are selected, the action button associated with a given alert now provides clearer information about the possible actions, like the creation of a case.</p> </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#tasks", "title": "Tasks", "text": "<ul> <li>Locked users no longer appear in the assignable user list.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#531-16th-of-may-2024", "title": "5.3.1 - 16th of May 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#improvements_5", "title": "Improvements", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#email-intake", "title": "Email Intake", "text": "<ul> <li>Added the possibility to specify the Microsoft Office365/Google Workspace host instead of the one provided by default.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#fixes_5", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#custom-fields", "title": "Custom Fields", "text": "<ul> <li>Fixed a bug where merging of alerts and cases could generate duplicated customfields values in the index (invisible in the UI).</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#misp-connector_1", "title": "MISP Connector", "text": "<ul> <li>Resolved a problem that prevented alert deletion.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#alerts-cases", "title": "Alerts &amp; Cases", "text": "<ul> <li>Fixed a bug related to assignable users.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#similar-alerts", "title": "Similar Alerts", "text": "<ul> <li>Fixed the counter in the pagination.</li> <li>Fixed the display of the pending status.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#dashboard", "title": "Dashboard", "text": "<ul> <li>Fixed an issue with the properties of the donut widget.</li> <li>Changed the list to display more than 30 dashboards.</li> <li>Improved the behavior of the diagram widget.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#notifications_1", "title": "Notifications", "text": "<ul> <li>Fixed a problem with the recipent field of the email notifier.</li> <li>Solved an issue with the <code>{{ url }}</code> variable when it concerns a task.</li> <li>Fixed an issue that made it impossible to delete a webhook endpoint.</li> <li>An Event is now triggered when a Case is created from an Alert.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#responders", "title": "Responders", "text": "<ul> <li>Resolved a problem with the display of a responder report in the task preview. </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#api", "title": "API", "text": "<ul> <li>Fixed an API error return code in the post <code>/case</code> route when the <code>status</code> value is <code>unknown</code>.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#ui", "title": "UI", "text": "<ul> <li>Renamed a field name in the SAML authentication configuration page for better understanding.</li> <li>Reviewed the breadcrumb to better manage long alert names.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#security-fixes_1", "title": "Security Fixes", "text": "<ul> <li>Embedded patches for the following vulnerability: CVE-2024-25710</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#530-24th-of-april-2024", "title": "5.3.0 - 24th of April 2024", "text": "<p>Info</p> <p>The licensing model for the community version has been updated. Users are now required to register on our licensing portal and request a community license to use TheHive in the community version. Additionally, TheHive will now include a default 14-day free Platinum trial license, allowing users to explore the full range of features offered by the platform.</p>"}, {"location": "thehive/release-notes/release-notes-5.3/#new-features", "title": "New features", "text": ""}, {"location": "thehive/release-notes/release-notes-5.3/#email-intake_1", "title": "Email intake", "text": "<p>The Email Intake connector now fully automates the transformation of incoming emails into actionable alerts on TheHive platform. It supports Microsoft 365, Google Workspace, and IMAP-based email services. </p> <p>It automates the detection and processing of suspicious elements such as links, attachments and sender details, which it all adds to the list of observables.</p>"}, {"location": "thehive/release-notes/release-notes-5.3/#new-timeline-widget", "title": "New timeline widget", "text": "<p>We've added a timeline widget to TheHive's Platinum case reports, allowing users to visually track attack and defense actions. This widget displays key events and indicators like IOCs and TTPs.</p> <p>Only admins can customize these reports, choosing elements like alerts and tasks to include. This customization ensures the timeline meets the specific needs of each report, making it easier for everyone, including non-technical staff, to understand the sequence of security events.</p>"}, {"location": "thehive/release-notes/release-notes-5.3/#data-list-export", "title": "Data List Export", "text": "<p>We've improved the data export options across TheHive. Users can now select specific fields from application lists to export, making the data more relevant and manageable for analysis.</p>"}, {"location": "thehive/release-notes/release-notes-5.3/#opensearch-support", "title": "OpenSearch Support", "text": "<p>OpenSearch is now available as an indexing option alongside Elasticsearch. This addition offers more choices for your indexing needs.</p>"}, {"location": "thehive/release-notes/release-notes-5.3/#dynamic-date-filtering", "title": "Dynamic Date Filtering", "text": "<p>A new relative date filter on dashboards and search pages allows users to filter data based on specific time frames like the last few days or months.</p>"}, {"location": "thehive/release-notes/release-notes-5.3/#similar-case-and-alert-enhancements", "title": "Similar Case and Alert Enhancements", "text": "<p>We've updated the similar cases and alerts pages to display more accurate data, adding a drawer for observables common to related cases and alerts and including additional details like case status for clearer insights.</p>"}, {"location": "thehive/release-notes/release-notes-5.3/#observable-export-improvements", "title": "Observable Export Improvements", "text": "<p>The observable export feature now supports more formats, including JSON and customizable CSV, allowing users to select specific fields for export.</p>"}, {"location": "thehive/release-notes/release-notes-5.3/#elasticsearch-performance-and-interface-improvements", "title": "Elasticsearch performance and interface improvements", "text": "<ul> <li>Queries have been optimized for better dashboard and search performance.</li> <li>Full support for Elasticsearch 8.</li> <li>Improved handling of custom fields with new operators (isEmpty, nonEmpty, between).</li> <li>Users can now customize the number of segments in dashboard donuts.</li> <li>All data points are now included in category aggregations for donuts and charts, providing a complete view\u2014in the past, it was capped at 100 displayed values.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.3/#bug-fixes", "title": "Bug Fixes", "text": "<ul> <li>Fixed the display issue with the number of open cases in quick filters.</li> <li>Corrected a merging bug for custom tags to prevent duplicates.</li> <li>Fixed a bug in markdown editor related to the <code>&lt;</code> &amp; <code>&gt;</code> characters.</li> </ul> <p>Info</p> <p>As we have updated some front-end components, please remember to refresh your browser page after upgrading to version 5.3 to prevent any UI issues.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/", "title": "Release Notes for Version 5.4", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#release-notes-of-54-series", "title": "Release Notes of 5.4 series", "text": "<p>Warning</p> <p>Backend framework upgraded to Pekko/Play3</p> <p>We upgraded our backend framework from Play 2 (also known as Akka) to Play 3 (also known as Pekko). While there are no functional changes, if you use TheHive in cluster mode, your configuration file will need to be modified when upgrading to TheHive 5.4. Please refer to this guide for the necessary changes.</p> <p>Please also note that the <code>play.http.secret.key</code> parameter requires now at least a 32 character value. See more details about secret configuration.</p> <p>Info</p> <p>The following API endpoints will no longer be accessible via GET requests. You will now need to use POST requests to access them:</p> <ul> <li>api/v1/admin/log/set/</li> <li>api/v1/admin/check/_all/trigger</li> <li>api/v1/admin/check/{name}/trigger</li> </ul> <p>For more details, please refer to the public API documentation.</p> <p>Info</p> <p>An upgrade guide is available to help you migrate from TheHive 5.x</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#548-february-24-2025", "title": "5.4.8 - February 24, 2025", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#fixes", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#dark-mode", "title": "Dark mode", "text": "<ul> <li>Improved the visibility of the  button in notification messages for better readability.</li> <li>Enhanced hover state contrast in analyzer reports for better accessibility.</li> <li>Increased the visibility of error messages when a dashboard widget fails.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#other-fixes", "title": "Other fixes", "text": "<ul> <li>Fixed an issue in notifications where endpoints with names ending in a space character were not handled correctly.</li> <li>Fixed incorrect counter widget behavior when used with the <code>closeDate</code> field.</li> <li>Fixed an issue preventing scrolling in the case template selection menu when creating a case from templates.</li> <li>Added more detailed error messages for issues related to attached file storage.</li> <li>Fixed an issue with Email Intake synchronization when TheHive is configured in a cluster environment.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#547-16th-of-january-2025", "title": "5.4.7 - 16th of January 2025", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#fixes_1", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#global-search", "title": "Global Search", "text": "<ul> <li>Added support for wildcard searches using the * operator.   Example for a case named Phishing incident on BU-FR45, will be returned by searching BU-F or BU..</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#ui", "title": "UI", "text": "<ul> <li>Impact field is now more readable in dark theme after case closure.</li> <li>Fixed an issue on avatar change in the user profile page.</li> <li>Removed an incorrect message displayed when launching a responder on an observable.</li> <li>Fixed a display issue occurring when the function/responder list is excessively long.</li> <li>Enhanced handling for overly long function names during input.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#dashboard", "title": "Dashboard", "text": "<ul> <li>Corrected the display of text color in the donut and bar charts for the dark theme.</li> <li>Removed the \u201c_total\u201d value from the radar widget display.</li> <li>Removed cache option in UI configuration when DirectQuery is activate.</li> <li>Ensured that customized date formats are now consistently applied in dashboards.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#docker-configuration-file", "title": "Docker configuration file", "text": "<ul> <li>The entry point docker parameter --cql-cluster is replaced by --cql-datacenter. This parameter, used in cluster configuration, allows to define the name of the Cassandra datacenter used by the TheHive node.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#546-12th-of-december-2024", "title": "5.4.6 - 12th of December 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#security-fix", "title": "Security fix", "text": "<ul> <li>This update contains a patch for a vulnerability (CVSS 6.9) non-exploited in the wild. More details will come in a further security bulletin, as per our responsible disclosure policy.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#fixes_2", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#unlicensed-users", "title": "Unlicensed users", "text": "<ul> <li>Unlicensed profiles can now be assigned even when the quota is full.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#ui_1", "title": "UI", "text": "<ul> <li>Fixed readability issues with Analyzer reports and list export previews in dark mode.</li> <li>Solved an issue in the similar observable detailed view: similar observables spotted in other cases can now be opened in a blank tab.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#dashboards", "title": "Dashboards", "text": "<ul> <li>Removed a useless parameter when DirectQuery / ESChart options are enabled.</li> <li>Fixed a problem that could generate an error during the agregation query. </li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#other-fixes_1", "title": "Other fixes", "text": "<ul> <li>Fixed a regression introduced in 5.4.5 version; a route was missing in the OpenAPI documentation.</li> <li>Fixed an issue related to uppercase characters in logins and LDAP synchronization module. </li> <li>Corrected a log formatting issue from notifiers.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#545-21st-of-november-2024", "title": "5.4.5 - 21st of November 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#fixes_3", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#cortex", "title": "Cortex", "text": "<ul> <li>Resolved an issue causing incorrect differentiation between \"In Progress\" Cortex analyzers and responders during TheHive startup process, that was causing some Responder jobs to never cleaned up.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#dashboard_1", "title": "Dashboard", "text": "<ul> <li>Fixed an issue related to Custom Field and negative filter on some dashboard widgets: gauge, text, and counter.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#index-es", "title": "Index ES", "text": "<ul> <li>Fixed index deactivation during a global reindex request. Double reindexation is not required anymore.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#544-8th-of-november-2024", "title": "5.4.4 - 8th of November 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#fixes_4", "title": "Fixes", "text": "<ul> <li>Resolved a display issue with the status component in cases and alerts, which was not rendering correctly on Safari and Firefox.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#543-7th-of-november-2024", "title": "5.4.3 - 7th of November 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#improvements", "title": "Improvements", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#microsoft-teams-notifier-update", "title": "Microsoft teams Notifier Update", "text": "<p>Updated the Microsoft Teams notifier to use Power Automate as Microsoft has deprecated the webhook used previously. A guide to updating your notifier is available here.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#casesalerts-status-visibility", "title": "Cases/Alerts status visibility", "text": "<p>Added a colored background to the stage icon in status components for better visibility in case and alert lists.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#license-check-improvements", "title": "License Check Improvements", "text": "<p>Improved display of permissions and profiles that consume licenses for clearer management by administrators. The \u201cManage Dashboard\u201d permission no longer consumes a license.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#task-title-limit", "title": "Task title Limit", "text": "<p>Added a character limit check for task titles to notify users when their input exceeds the allowed length.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#edit-alert-title", "title": "Edit Alert title", "text": "<p>Adding the ability to edit alert title directly from the general tab.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#fixes_5", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#cortex-job-queue", "title": "Cortex job queue", "text": "<ul> <li>Enhanced the handling of concurrent job submissions to the Cortex server for better efficiency and stability.</li> <li>Fixed an issue related to job status recovery in TheHive when the Cortex server crashes.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#live-feed-display", "title": "Live feed display", "text": "<p>Fixed issues with overly long text and tags in the live feed display.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#observables-list-loading", "title": "Observables list loading", "text": "<p>Optimized the rendering speed for the observables tab to improve performance.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#app-default-language", "title": "App default language", "text": "<p>Fixed default language selection to use the browser\u2019s language on first connection.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#improved-case-closure-error-handling", "title": "Improved Case Closure Error Handling", "text": "<p>Modified case closure behavior: if a backend error occurs, the case closure window now remains open to prevent data loss.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#tasklog-display-in-timeline", "title": "Tasklog Display in Timeline", "text": "<p>When adding a tasklog with the option \"display in the timeline\", the tasklog now appears in the timeline view from the task preview after the preview drawer is closed.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#542-21st-of-october-2024", "title": "5.4.2 - 21st of October 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#fix", "title": "Fix", "text": "<ul> <li>This version fixes a regression related to the query boolean parameters in the public API. These parameter values are case insensitive again.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#541-11th-of-october-2024", "title": "5.4.1 - 11th of October 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#fix_1", "title": "Fix", "text": "<ul> <li>We fixed an issue related to our backend framework configuration (pekko). This problem impacted the generated configuration file for a new installation of TheHive on Kubernetes.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#improvements_1", "title": "Improvements", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#cortex-job-queue_1", "title": "Cortex Job Queue", "text": "<p>We have made two improvements to the management of Cortex job queues from TheHive to:</p> <ul> <li>Prevent spamming the Cortex server when a large number of jobs are submitted.</li> <li>Reduce the latency in retrieving completed job reports, even when the job queue is highly loaded.</li> </ul>"}, {"location": "thehive/release-notes/release-notes-5.4/#540-26th-of-september-2024", "title": "5.4.0 - 26th of September 2024", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#new-features", "title": "New Features", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#dark-mode_1", "title": "Dark Mode", "text": "<p>We have introduced a Dark Mode option to enhance user comfort during low-light or night-time usage. This feature is accessible via the theme settings and provides a dark-themed interface for reduced eye strain and improved visibility.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#report-tab-in-case-details", "title": "Report Tab in case details", "text": "<p>A new \"Report\" tab has been added to the case detail screen, allowing users to access and generate case reports directly from a case. This feature utilizes the existing Case Report Templates, enabling customization and configuration of reports based on the templates set by organization administrators. The Report Tab supports multiple formats (HTML, Markdown, Word) and offers dynamic previews for quick and informed decision-making.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#comment-and-page-widgets-in-case-report-templates", "title": "Comment and Page Widgets in Case Report Templates", "text": "<p>Two new widgets\u2014Comments and Pages\u2014have been added to case report templates. These widgets allow users to include comments and documentation directly in case reports. Administrators can configure these widgets in the template section under org admin settings, ensuring richer reports with relevant context.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#functions-as-notifiers-can-be-automatically-triggered", "title": "Functions as notifiers, can be automatically triggered", "text": "<p>A new notifier is available: function notifier. You can now write TheHive functions that can be triggered by an internal event, and then perform automated actions in TheHive. This new feature opens up a wide range of new automation possibilities within TheHive.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#functions-can-be-performed-manually-like-responders", "title": "Functions can be performed manually, like responders", "text": "<p>TheHive functions can now be manually triggered directly from a Case or an Alert, just like responders. It allows you to save time by  automating some repetitive tasks. The functions must be written and assigned with the corresponding type in order to be visible in a Case or Alert.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#duplicate-a-case-template", "title": "Duplicate a case template", "text": "<p>Creating a case template can be very time effective, we now offer  the ability to duplicate a case template, instead of creating each one from scratch or from an import.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#hide-some-time-metrics", "title": "Hide some time metrics", "text": "<p>We have introduced the option for the OrgAdmin to hide some of (or all) time metrics. It makes the user interface lighter if these metrics are not used.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#improvements_2", "title": "Improvements", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#restrict-dashboard-editing-for-read-only-users", "title": "Restrict Dashboard Editing for Read-Only Users", "text": "<p>A new permission system has been introduced to restrict read-only users from editing dashboards. However, read-only users retain the ability to adjust settings like the refresh rate and cache values. This helps maintain dashboard integrity by limiting editing capabilities to authorized users only.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#enhanced-display-of-time-metrics-ttx", "title": "Enhanced display of time metrics (TTx)", "text": "<p>We changed the display format of time metrics in Alert &amp; Case pages, and made it more accurate for the users.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#backend-framework-upgraded-to-pekkoplay3", "title": "Backend framework upgraded to Pekko/Play3", "text": "<p>We upgraded our backend framework to Play 2 (also named Akka) to Play 3 (also named Pekko). While there is no functional changes,  if you use TheHive in a cluster mode, your configuration will need to be changed when upgrading to TheHive 5.4. Please refer to this guide for further details.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#elasticsearch-query-optimisations-directquery-eschart", "title": "Elasticsearch query optimisations: DirectQuery &amp; ESChart", "text": "<p>A new query optimisation system enables the union of the best aspects of both graph and search engine data models. Dashboards will fully delegate data processing to Elasticsearch, resulting in an effective and precise output. Search filters will also benefit from the performance and precision of Elasticsearch.</p> <p>Those two options DirectQuery &amp; ESChart are enabled by default, but can be deactivated through API configuration.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#new-logo-and-favicon", "title": "New logo and favicon", "text": "<p>As part of our recent brand visual identity update, TheHive logo has been updated throughout the entire application. This includes changes on the login page, favicon, and navigation bar.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#fixes_6", "title": "Fixes", "text": ""}, {"location": "thehive/release-notes/release-notes-5.4/#time-metrics", "title": "Time metrics", "text": "<p>We resolved an issue with the \"Time to Detect\" metric during alert creation.</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#known-issues", "title": "Known issues", "text": "<p>Last update: 21st of October 2024</p>"}, {"location": "thehive/release-notes/release-notes-5.4/#public-api-query-boolean-parameters-case-sensitive", "title": "Public API - Query boolean parameters case sensitive", "text": "<p>TheHive 5.4.0 introduced a non expected breaking change related to the query boolean parameters. The values passed in the query URL, with upper case (ex: <code>True</code> or <code>False</code>) are not accepted anymore. It does not concern the parameters passed in the body/payload. It impacts the endpoints listed below, and the tools that use those endpoints (like TH4Py 2.0). The 5.4.2 version fixes this issue.</p> <p>The following endpoints are impacted:</p> <ul> <li>Download Attachment from observable: GET /api/v1/observable/$id/attachment/id/download with the asZip param</li> <li>Delete CustomField: <code>DELETE /api/v1/customField/$id</code> with <code>force</code> flag</li> <li>Invoke Function: <code>POST /api/v1/function/$id</code> with <code>dryRun</code> flag</li> <li>Invoke Function on an object: <code>POST /api/v1/function/$id/$objectType/$objectId</code> with <code>dryRun</code> and <code>sync</code> params</li> <li>Test Function: <code>POST /api/v1/function/_test</code> with <code>dryRun</code> param</li> <li>Get platform status: <code>GET /api/v1/status</code> with <code>verbose</code> param</li> </ul>"}, {"location": "thehive/user-guides/forgot-password/", "title": "Forgot Password Guide", "text": ""}, {"location": "thehive/user-guides/forgot-password/#i-forgot-my-password", "title": "I forgot my password", "text": "<p>If TheHive is connected to a SMTP server, as a user, you can change your password.</p> <ol> <li> <p>On the login page of TheHive, click the I forgot my password button</p> <p> </p> </li> <li> <p>Enter your email address and click send</p> <p> </p> </li> <li> <p>You should received an email including a magic link to change your password</p> <p> </p> </li> <li> <p>Click on the link and change your password. You should be able to login again once updated.</p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/Filter-and-sort/", "title": "Filters", "text": ""}, {"location": "thehive/user-guides/analyst-corner/Filter-and-sort/#filters", "title": "Filters", "text": "<p>In this section, you can find information about applying filters.</p> <p>To apply filter:</p> <ol> <li>On the list of incidents page, switch on the Filters toggle button.</li> <li>Click Add filters.</li> </ol> <p>Apply Filter to the required field.</p> <p></p> <ol> <li>Select the filters from the list.</li> <li>Click Apply filters.</li> <li>(Optional) Click Clear filters to clear all applied filters.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/Filter-and-sort/#sorting", "title": "Sorting", "text": "<p>Sorting can be performed on any field values.  </p> <p>To Sort:</p> <ol> <li>On the list of incidents page, Click the small arrow that points upwards/downwards to sort on a particular filed name. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/authentication/", "title": "Authentication", "text": ""}, {"location": "thehive/user-guides/analyst-corner/contacting-support/", "title": "Contact Support", "text": ""}, {"location": "thehive/user-guides/analyst-corner/getting-started/", "title": "Getting Started", "text": ""}, {"location": "thehive/user-guides/analyst-corner/getting-started/#getting-started", "title": "Getting Started", "text": "<p>TheHive supports different roles for users. Whether you are an administrator of the platform, an organization, or an analyst, you can have access and run different actions on the platform.</p> <p>This user guide aims at describing all major howtos when you sign in as a Org-Admin.</p>"}, {"location": "thehive/user-guides/analyst-corner/introduction/", "title": "Introduction", "text": ""}, {"location": "thehive/user-guides/analyst-corner/list-of-incidents/", "title": "List of Incidents", "text": ""}, {"location": "thehive/user-guides/analyst-corner/list-of-incidents/#list-of-incidents", "title": "List of Incidents", "text": "<p>After you login to TheHive application, you can see a list of incidents displayed on the screen by default. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/list-of-incidents/#main-menu", "title": "Main Menu", "text": "<p>In the left pane, you can see the main Menu. </p> <ul> <li>Case List</li> <li>Alerts</li> <li>Tasks</li> <li>Dashboards</li> <li>Search </li> <li>Organization</li> </ul> <p>Clicking on the arrow will switch you back to the image view. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/list-of-incidents/#top-menu", "title": "Top Menu", "text": "<p>On the top of the page are the following options: </p> <ul> <li>Defaults</li> <li>Quick Filters</li> <li>Auto Refresh</li> <li>Stats</li> <li>Filter</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/list-of-incidents/#defaults", "title": "Defaults", "text": "<p>It displays the default view. </p> <ol> <li> <p>Click on Default. A list is displayed. </p> <p></p> <p>To Save a view: </p> </li> <li> <p>Click Save view As.</p> <p>A new window opens. </p> </li> <li> <p>Click Confirm. </p> <p></p> </li> </ol> <p>To Manage views: </p> <ol> <li>Click the default button. </li> <li> <p>Click Manage Views from the list. </p> <p></p> </li> </ol> <p>A new page opens. It has the Name of the view and the corresponding Actions. </p> <ol> <li>Click the ellipsis (...) corresponding to the name of the view.</li> <li>Select the action. e.g. Delete</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/list-of-incidents/#quick-filters", "title": "Quick Filters", "text": "<p>To apply Quick filter:</p> <ol> <li>Click the quick filter option. </li> </ol> <p>The list displays options to select. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/list-of-incidents/#auto-refresh", "title": "Auto refresh", "text": "<p>The auto-refresh option allows you to automatically refresh a page. </p> <p>To perform Auto refresh:</p> <ol> <li>On the list of incidents page, switch on the Auto refresh toggle button. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/list-of-incidents/#stats", "title": "Stats", "text": "<p>To view Stats: </p> <ol> <li>On the cases list page, switch on the Stats toggle button.</li> </ol> <p>The stats are displayed. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/list-of-incidents/#filters", "title": "Filters", "text": "<p>To apply filter:</p> <ol> <li> <p>On the cases list page, switch on the Filters button.</p> </li> <li> <p>Click Add filters.</p> <p>Apply Filter to the required field.</p> <p></p> </li> <li> <p>Select the filters from the list.</p> </li> <li>Click Apply filters.</li> <li>(Optional) Click Clear filters to clear all applied filters.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/sign-in-as-an-admin/", "title": "Sign In as Org-Admin", "text": ""}, {"location": "thehive/user-guides/analyst-corner/sign-in-as-an-admin/#sign-in-as-org-admin", "title": "Sign In as Org-Admin", "text": "<ol> <li>Open the TheHive application in your browser. </li> <li>Enter user credentials, Login name and password.</li> <li>Click the Let me In button. </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/theme/", "title": "Choose Your Theme", "text": ""}, {"location": "thehive/user-guides/analyst-corner/theme/#choosing-your-theme-in-thehive", "title": "Choosing Your Theme in TheHive", "text": "<p>Starting from version 5.4.0, TheHive allows you to customize the application's appearance by selecting between Light, Dark, or System themes. This feature enhances user experience by accommodating personal preferences and varying lighting conditions.</p>"}, {"location": "thehive/user-guides/analyst-corner/theme/#theme-options", "title": "Theme Options", "text": "<ul> <li>Light Theme: Ideal for well-lit environments, the Light theme uses brighter colors and lighter backgrounds to enhance readability and reduce glare.</li> <li>Dark Theme: Suitable for low-light conditions, the Dark theme employs darker colors and backgrounds to reduce eye strain during nighttime or in dimly lit rooms.</li> <li>System Theme: This option allows TheHive to follow your operating system's theme settings. If your system automatically switches between light and dark modes based on the time of day or other factors, TheHive will adapt accordingly.</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/theme/#how-to-change-your-theme", "title": "How to Change Your Theme", "text": "<p>Follow these steps to customize your theme in TheHive:</p> <ol> <li> <p>Log In to TheHive : Access your TheHive instance using your credentials.</p> </li> <li> <p>Access the User Menu: Locate your avatar or username at the top-right corner of the interface and click on it to open the dropdown menu.</p> </li> <li> <p>Open Theme Settings: In the dropdown menu, click on \"Themes\". A popup window will appear displaying the theme options.</p> <p></p> </li> <li> <p>Select Your Preferred Theme: The popup will present three options with radio buttons:</p> <ul> <li>Light</li> <li>Dark</li> <li>System</li> </ul> <p></p> </li> <li> <p>Apply Changes: Click on the radio button next to your desired theme. The interface will update immediately to reflect your selection.</p> Light ThemeDark Theme <p></p> <p></p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/theme/#additional-information", "title": "Additional Information", "text": "<ul> <li>Default Setting: The Light theme is activated by default for all users.</li> <li>Persistent Preferences: If you access TheHive from a different device or browser, you will need to set your theme preference again.</li> <li>System Theme Adaptation: Selecting the System theme allows TheHive to automatically switch themes in sync with your operating system settings, providing optimal visibility without manual adjustments.</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/alerts/about-alerts/", "title": "About Alerts", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/about-alerts/#about-alerts", "title": "About Alerts", "text": "<p>This topic explains alerts, their components, and how they're created in TheHive.</p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/about-alerts/#definition", "title": "Definition", "text": "<p>An alert is a security event generated by detection tools such as SIEM, IDS, EDR, firewalls, or threat intelligence platforms like MISP. It serves as an early warning that helps analysts identify, investigate, and respond to potential threats.</p> <p>Alerts are reviewed, triaged, and transformed into cases for deeper investigation.</p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/about-alerts/#sources", "title": "Sources", "text": "<p>Manual alert creation not possible</p> <p>You can't manually create an alert in TheHive. Alerts must be generated by external tools connected to TheHive.</p> <p>An alert can be created from the following sources:</p> <ul> <li> <p>Detection tools such as SIEM, IDS, EDR, or firewalls connected to TheHive</p> </li> <li> <p>Threat intelligence platforms like MISP connected to TheHive</p> </li> <li> <p>Email servers connected to TheHive</p> </li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/alerts/about-alerts/#key-components", "title": "Key components", "text": "<p>In TheHive, an alert includes the following elements:</p> <ul> <li> <p>Observables: Data points such as IP addresses, file hashes, domains, and email addresses that are relevant to an investigation.</p> </li> <li> <p>TTPs: The methods and strategies used by attackers, based on the MITRE ATT&amp;CK knowledge base.</p> </li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/alerts/about-alerts/#next-steps", "title": "Next steps", "text": "<ul> <li>Find an Alert</li> <li>New Case from Selection</li> <li>Merge Alerts</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/actions/", "title": "Actions on Alerts", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/actions/#actions", "title": "Actions", "text": "<p>You can make use of any of the available actions.</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/actions/#start", "title": "Start", "text": "<ol> <li>Click the Start option to begin an alert.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/actions/#close", "title": "Close", "text": "<ol> <li>Click the Close option to remove a task.</li> </ol> <p>A new window opens.</p> <ol> <li>Select Status from the list. </li> <li>Change the Summary</li> <li>Click the Close tasks and case button.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/actions/#trackignore-new-updates", "title": "Track/Ignore New Updates", "text": "<ol> <li>Click the Track New Updates option to track an alert.</li> <li>A success message is displayed. </li> </ol> <ol> <li>Click the Ignore New Updates option to ignore an alert.</li> <li>A success message is displayed. </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/actions/#unlink", "title": "Unlink", "text": "<ol> <li>Click the Unlink option to unlink an alert.</li> <li>Click the OK button. </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/general/", "title": "View Alert Details", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/general/#general", "title": "General", "text": "<p>The information on the general page comes from templates and is auto-populated.  In the left pane of the window, you can see details such as created by, created date, TLP, PAP, severity details, status of the alert, start date, and task completion details. </p> <p>In the left pane of the window you can configure the PAP,TLP and Severity.  Refer to <code>Configure Alert Details</code> for more details. </p> <ol> <li>In the right pane of the window, enter Comments if any. </li> <li>Click the Comment button. </li> <li>Add Tags. (Refer to <code>Add tags</code>).</li> <li>Enter the Description. </li> <li>Add Custom fields. (Refer to <code>Add custom fields</code>)</li> <li> <p>Click Add to enter the respective business unit and location details. </p> <p></p> </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/manage-views/", "title": "Manage Views", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/manage-views/#manage-views", "title": "Manage views", "text": "<p>In this section, you can find information about managing views.  </p> <p>To manage views: </p> <ol> <li>Click the default button. </li> <li>Click on Manage Views from the list. </li> </ol> <p></p> <p>A new page opens. It has the Name of the view and the corresponding Actions. </p> <ol> <li>Click the ellipsis (...) corresponding to the name of the view that you want to delete. </li> <li>Click Delete.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/manage-views/#manage-alerts", "title": "Manage Alerts", "text": "<p>There are various option available for to apply on the alerts. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/manage-views/#quick-filters", "title": "Quick Filters", "text": "<p>To apply Quick filter:</p> <ol> <li>Click the Quick Filter option. </li> <li>The list displays options to select from. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/manage-views/#auto-refresh", "title": "Auto refresh", "text": "<p>The auto-refresh option allows you to automatically refresh a page. </p> <p>To perform Auto refresh:</p> <ol> <li>On the alerts page, switch on the Auto refresh button. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/manage-views/#stats", "title": "Stats", "text": "<p>To view stats: </p> <ol> <li>On the alerts page, switch on the Stats toggle button, the stats will be displayed. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/manage-views/#filters", "title": "Filters", "text": "<p>To apply filter:</p> <ol> <li>On the alerts page, switch on the Filters toggle button.</li> <li>Click Add filters.</li> </ol> <p>Apply Filter to the required field.</p> <p></p> <ol> <li>Select the filters from the list.</li> <li>Click Apply filters.</li> <li>(Optional) Click Clear filters to clear all applied filters.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/manage-views/#sorting", "title": "Sorting", "text": "<p>Sorting can be performed on any field values.  </p> <p>To Sort:</p> <ol> <li>On the alerts page, Click the small arrow that points upwards/downwards to sort on a particular filed name. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/merge-alerts/", "title": "Merge Alerts", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/merge-alerts/#merge-alerts", "title": "Merge alerts", "text": "<p>In this section you can find information about merging alerts. </p> <p>On the main page where all the alerts are listed, there are various alerts. Some are new, some are imported. Merge alerts / merge selection into case option is available only for New alerts from the list. </p> <p>To merge alerts:</p> <ol> <li>Go to alert details page.</li> <li>Select the alert to merge data into</li> <li>Click merge alerts.</li> </ol> <p></p> <p>NOTE: Merging two cases, removes the originating cases, and creates a new one with all the merged data.</p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/new-case-from-selection/", "title": "Create a Case from Alerts", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/new-case-from-selection/#creating-a-new-case-from-selection", "title": "Creating a New Case from Selection", "text": "<p>This section provides guidance on creating a new case from a selected alert.</p> <p>On the main alerts page, where all alerts are displayed, there are various types of alerts, including new and imported ones. The New Case from Selection option is only available for new alerts listed.</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/new-case-from-selection/#steps-to-add-a-new-case-from-a-selected-alert", "title": "Steps to Add a New Case from a Selected Alert", "text": "<ol> <li>Navigate to the alert details page.</li> <li>Select the alert for which you want to create a new case.</li> <li>Click on the New Case from Selection option.</li> </ol> <p>A new window will open to facilitate the creation of the new case.</p> <p></p> <p>Important Notes</p> <ul> <li>Single Case Creation: The New Case from Selection option allows the creation of only one case, regardless of how many alerts are selected.</li> <li>Merge Action: Similarly, the merge button also merges only one case at a time, regardless of the number of selected alerts.</li> </ul> <p>For bulk actions, such as creating multiple cases or merging multiple alerts, use the bulk action buttons available at the top of the alerts list.</p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/preview-alerts/", "title": "Preview Alerts", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/preview-alerts/#preview-alerts", "title": "Preview alerts", "text": "<p>In this section you can find information about  previewing alerts and associated details. </p> <p>To preview the alert details:</p> <p>On the list of alerts page, there is a Preview button corresponding to the specific alert name.</p> <ol> <li>Click the Preview option. </li> </ol> <p></p> <p>The alert details preview window opens.</p> <p></p> <p>You can see details like the id, created by, created at date, last reviewed by, last reviewed date, import date, TLP, PAP and severity details, title, tags, description, status and summary of the alert. </p> <p>Add Custom fields (Refer to <code>Add custom fields</code>), business unit, and location  details.</p> <ol> <li> <p>Click Add to enter business unit and location details. </p> <p></p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/preview-alerts/#actions", "title": "Actions", "text": "<p>You can click the <code>Actions Button</code>  to start, close, track/ignore new updates, unlink the alerts or to <code>Run Responders</code>. </p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/preview-alerts/#alert-details", "title": "Alert Details", "text": "<ol> <li>Click the Go to details button to view more details of the alert. </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/preview-alerts/#alert-details-menu", "title": "Alert details menu", "text": "<ol> <li>Click the Go to details button to view more details of the alert. </li> </ol> <p>On the top of the page, there are many task options available such as start, close, track/ignore new updates, unlink the alerts and run responders. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/run-responders/", "title": "Run Responders on Alert", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/run-responders/#run-responders", "title": "Run responders", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/run-responders/#responders", "title": "Responders", "text": "<ol> <li>Click on responders option.</li> </ol> <p>A new window appears. </p> <ol> <li>Search for a specific responder in the search box.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-observables/", "title": "View Observables", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-observables/#view-observables", "title": "View observables", "text": "<p>In this section you can find information about viewing observables. </p> <p>When you install the TheHive application, it comes with a set of pre-defined observables such as IP and email addresses, URLs, domain names, files or hashes.</p> <p>You can define your own observable type. You can see the list of all Observable Types.</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-responders/", "title": "View Responders", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-responders/#view-responders", "title": "View responders", "text": "<p>Responder is a tool that can be used in security penetration tests on the infrastructure of the networks. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-similar-alerts/", "title": "View Similar Alerts", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-similar-alerts/#view-similar-alerts", "title": "View similar alerts", "text": "<p>In this section, you can find information about all the similar alerts listed down.</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-similar-alerts/#observable-preview-drawer", "title": "Observable Preview Drawer", "text": "<p>The Observable Preview Drawer allows you to view observables that are common between two events, such as alerts or cases. This feature is resource-intensive, and to optimize performance, there is a limit of 100 observables displayed in this drawer.</p> <p></p> <p>Note: This limit can be adjusted by the platform administrator in the <code>application.conf</code> file. However, modifying this limitation may affect the performance of the application. We cannot guarantee optimal performance if the limit is increased beyond 100 observables.</p> <p> </p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-similar-cases/", "title": "View Similar Cases", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-similar-cases/#view-similar-cases", "title": "View similar cases", "text": "<p>In this section, you can find information about all the similar cases listed down.</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-similar-cases/#observable-preview-drawer", "title": "Observable Preview Drawer", "text": "<p>The Observable Preview Drawer allows you to view observables that are common between two events, such as alerts or cases. This feature is resource-intensive, and to optimize performance, there is a limit of 100 observables displayed in this drawer.</p> <p></p> <p>Note: This limit can be adjusted by the platform administrator in the <code>application.conf</code> file. However, modifying this limitation may affect the performance of the application. We cannot guarantee optimal performance if the limit is increased beyond 100 observables.</p> <p> </p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-ttps/", "title": "View TTPs", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/alerts-description/view-ttps/#view-ttps", "title": "View TTPS", "text": "<p>In this section, you can find information about all the TTPS listed down.</p> <p>Tactics, techniques, and procedures (TTPs) are the patterns of activities or methods associated with a specific threat actor or group of threat actors.</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/search-for-alerts/find-an-alert/", "title": "Find an Alert", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/search-for-alerts/find-an-alert/#how-to-find-an-alert", "title": "How to Find an Alert", "text": "<p>This topic provides step-by-step instructions for using various methods to search for an alert in TheHive.</p> <p>If you\u2019re unsure which method to use, refer to the Overview of Search Methods for Alerts topic.</p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/search-for-alerts/find-an-alert/#method-1-similar-alerts", "title": "Method 1: Similar alerts", "text": "<p>Use this method if you want to find one or more alerts similar to a known alert and need to perform actions on them simultaneously.</p> <ol> <li> <p>Open a case, an alert, or a task, and select the Similar alerts tab.</p> <p></p> </li> <li> <p>Apply filters using any of these options individually or in combination:</p> <ul> <li> <p>Select Quick filters to access predefined filters.</p> <p></p> </li> <li> <p>Turn on the Filters toggle and enter one or more filters.</p> <p></p> </li> <li> <p>Select a value from a field to use it as a filter criterion.</p> <p></p> </li> </ul> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/search-for-alerts/find-an-alert/#method-2-filters-in-the-alerts-view", "title": "Method 2: Filters in the Alerts view", "text": "<p>Use this method if you need to search for one or more alerts to perform actions on them simultaneously.</p> <ol> <li> <p>Go to the Alerts view from the sidebar menu.</p> <p></p> </li> <li> <p>Apply filters using any of these options individually or in combination:</p> <ul> <li> <p>Select Quick filters to access predefined filters.</p> <p></p> </li> <li> <p>Turn on the Filters toggle and enter one or more filters.</p> <p></p> </li> <li> <p>Select a value from a field to use it as a filter criterion.</p> <p></p> </li> </ul> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/search-for-alerts/find-an-alert/#method-3-global-search-feature", "title": "Method 3: Global Search feature", "text": "<p>Use this method if you need to conduct advanced searches for one or more alerts without requiring simultaneous actions.</p> <ol> <li> <p>Go to the Global Search view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Alerts item on the Search scope pane.</p> <p></p> <p>All elements</p> <p>Select the All elements item for a comprehensive tool-wide overview that includes all entity types, such as cases, alerts, observables, jobs, tasks, and task logs. Use this option to analyze cross-linked information or to conduct a detailed investigation.</p> </li> <li> <p>Enter the keywords you want to search for in the search box displayed by default.</p> <p>Wildcard character</p> <p>You can use the wildcard character * to broaden your searches since version 5.4.7.</p> <p>The wildcard character acts as a placeholder that matches zero or more characters, helping you find variations of a term or incomplete information.</p> <p>Examples of use cases: - Email domains: Entering *@gmail.com will return entities containing the gmail.com domain. - IP subnets: Entering 192.168.*.* will return entities with IP addresses in the 192.168.x.x subnet. - URLs: Entering https://malwaredomain.com/* will return entities hosted under the malwaredomain.com directory.</p> <p>Other advanced search options, such as Boolean and phrase searches, are not currently supported.</p> </li> <li> <p>If you need additional filters, apply one or more filters by selecting Add new filter. </p> <p>These filters refine your search results and act as an equivalent to the AND operator in Boolean search.</p> <p>Warning</p> <p>Filters are required for the following fields to ensure the search engine accurately interprets values: - Fields with specific date formats - Custom fields</p> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/search-for-alerts/find-an-alert/#next-steps", "title": "Next steps", "text": "<ul> <li>Actions</li> <li>Merge Alerts</li> <li>New Case From Selection</li> <li>Preview Alerts</li> <li>Run Responders</li> <li>View Responders</li> <li>View Observables</li> <li>View Similar Alerts</li> <li>View Similar Cases</li> <li>View TTPs</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/alerts/search-for-alerts/overview-search-methods-alert/", "title": "Overview of Search Methods for Alerts", "text": ""}, {"location": "thehive/user-guides/analyst-corner/alerts/search-for-alerts/overview-search-methods-alert/#overview-of-search-methods-for-alerts", "title": "Overview of Search Methods for Alerts", "text": "<p>TheHive offers multiple methods for searching alerts, each tailored to specific scenarios.</p> <p>This topic provides an overview of the available search methods, compares their features, and explains when to use each one.</p> <p>Use this guide to choose the most effective method for your needs.</p>"}, {"location": "thehive/user-guides/analyst-corner/alerts/search-for-alerts/overview-search-methods-alert/#search-method-comparison", "title": "Search method comparison", "text": "Method Filter options Result scope Allows bulk actions Use case Similar alerts Multiple Multiple Yes If you want to find one or more alerts similar to a known alert and need to perform actions on them simultaneously. Filters in the Alerts view Multiple Multiple Yes If you need to search for one or more alerts to perform actions on them simultaneously. Global Search feature Advanced Multiple No If you need to conduct advanced searches for one or more alerts without requiring simultaneous actions."}, {"location": "thehive/user-guides/analyst-corner/alerts/search-for-alerts/overview-search-methods-alert/#next-steps", "title": "Next steps", "text": "<ul> <li>How to Find an Alert</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/about-cases/", "title": "About Cases", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/about-cases/#about-cases", "title": "About Cases", "text": "<p>This topic explains cases, their components, and how to create them in TheHive.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/about-cases/#definition", "title": "Definition", "text": "<p>A case is a structured entity used to track, investigate, and respond to security incidents, threats, or suspicious activities. It serves as a central repository where security teams organize information, collaborate on investigations, and document their findings.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/about-cases/#sources", "title": "Sources", "text": "<p>In TheHive, you can create a case from the following sources:</p> <ul> <li> <p>Manual entry: Create a case manually by entering details.</p> </li> <li> <p>Case templates: Use predefined templates to standardize and simplify case creation.</p> </li> <li> <p>Archived cases: Restore cases from previous investigations stored in TheHive.</p> </li> <li> <p>MISP event files: Create cases by manually importing MISP events for further investigation.</p> </li> <li> <p>Alerts: Convert alerts from connected detection tools (SIEM, EDR, IDS, or firewalls), threat intelligence platforms (like MISP), or email servers into cases for further investigation.</p> </li> <li> <p>Detection tools (SIEM, EDR, IDS, or firewalls): Create cases directly from your detection tools if you prefer to manage alert triage there or if you trust the tool to generate mostly true positives.</p> </li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/about-cases/#key-components", "title": "Key components", "text": "<p>In TheHive, a case includes the following elements:</p> <ul> <li> <p>Observables: Data points such as IP addresses, file hashes, domains, and email addresses that are relevant to an investigation.</p> </li> <li> <p>Tasks: Actions assigned to analysts to analyze, assess, and mitigate threats.</p> </li> <li> <p>TTPs: The methods and strategies used by attackers, based on the MITRE ATT&amp;CK knowledge base.</p> </li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/about-cases/#next-steps", "title": "Next steps", "text": "<ul> <li>Find a Case</li> <li>Create a Case</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/adding_to_a_case/", "title": "Adding to a Case (Tags/Tasks/Custom Field Values)", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/adding_to_a_case/#adding-to-a-case-tagstaskscustom-field-values", "title": "Adding to a case (Tags/Tasks/Custom field values)", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/adding_to_a_case/#add-tags", "title": "Add tags", "text": "<ol> <li>Choose tags from the Taxonomy. The selected tag will appear in the Selected Tags box.</li> <li>Click the Add selected tags button.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/adding_to_a_case/#add-tasks", "title": "Add tasks", "text": "<p>The task Group is default. </p> <ol> <li>Enter the task Title.</li> <li>Enter the task description in the Description. </li> <li>Switch the toggle button to Flag this task?. </li> <li>Select the Due date. </li> <li>Click Save and add another, to add another task. </li> <li>Click Confirm.</li> </ol> <p></p> <p>Note</p> <p>Task Group names are limited to a maximum of 64 characters. Exceeding this limit will result in a generic \u201cInvalid JSON\u201d error message. Please ensure your Task Group names do not exceed 64 characters to avoid this issue.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/adding_to_a_case/#add-custom-field-values", "title": "Add custom field values", "text": "<ol> <li>Select custom field value from the given list. (location/business-unit/detection-source/test).</li> <li>Click Confirm custom field value creation.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/apply-a-case-template/", "title": "Apply a Case Template", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/apply-a-case-template/#how-to-apply-a-case-template", "title": "How to Apply a Case Template", "text": "<p>This topic provides step-by-step instructions for applying a case template to an existing case in TheHive.</p> <p>If you want to apply a template to a new case, refer to the Create a Case topic.</p> <p>Required permissions for updating a case</p> <p>Only users with the <code>manageCase/update</code> permission can update a case in TheHive.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/apply-a-case-template/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Locate the case to apply the template.</p> </li> <li> <p>In the case description, select the Apply a case template button.</p> <p></p> </li> <li> <p>In the Apply case template drawer, select a template from the dropdown list.</p> </li> <li> <p>Review the predefined values from the case template that you want to apply by selecting or clearing the checkboxes.</p> </li> <li> <p>Select Confirm.</p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/apply-a-case-template/#next-steps", "title": "Next steps", "text": "<ul> <li>Adding to a Case</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/create-a-new-case/", "title": "Create a Case", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/create-a-new-case/#how-to-create-a-case", "title": "How to Create a Case", "text": "<p>This topic provides step-by-step instructions for creating a case in TheHive.</p> <p>Several options are offered to create a case in TheHive:</p> <ul> <li> <p>Create an empty case</p> </li> <li> <p>Create a case from a template</p> </li> <li> <p>Create a case from an archived case</p> </li> <li> <p>Create a case from a MISP event</p> </li> <li> <p>Create a case from an alert</p> </li> <li> <p>Create a case from a detection tool</p> </li> </ul> <p>Required permissions for creating a case</p> <p>Only users with the <code>manageCase/create</code> permission can create a case in TheHive.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/create-a-new-case/#create-an-empty-case", "title": "Create an empty case", "text": "<ol> <li> <p>From any view, select + Create case.</p> <p></p> </li> <li> <p>In the Create case drawer, select Empty case.</p> </li> <li> <p>Enter the following fields:</p> <p>Title * The title of the case.</p> <p>Date * The start date and time of the case. It indicates when the incident occured. By default, this field is pre-filled with the current date and time. This information is used to calculate KPIs.</p> <p>Severity * The severity level for the case.</p> <p>TLP * The TLP level for the case. It guides analysts on how they can share case information.</p> <p>PAP * The PAP level for the case. It guides analysts on how they can use case data.</p> <p>Tags Relevant tags to categorize the case.</p> <p>Description * A description of the case.</p> <p>Tasks Tasks for the case.</p> <p>Custom fields Custom fields for the case, with or without predefined values.</p> <p>Pages Pages to document the case.</p> <p>Sharing By default, global sharing rules set at the organization level are applied when you create a new case. Here, you can modify these rules to apply local sharing settings to the case. You can modify local sharing rules for tasks and observables linked to the case after it is created. For more details, see the Share a Case topic.</p> </li> <li> <p>Select Confirm.</p> </li> </ol> <p>Case template</p> <p>You can apply a case template after creating the case. For more details, see the Apply a Case Template topic.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/create-a-new-case/#create-a-case-from-a-template", "title": "Create a case from a template", "text": "<ol> <li> <p>From any view, select + Create case.</p> <p></p> </li> <li> <p>In the Create case drawer, select a template from the dropdown list in the From template section.</p> </li> <li> <p>In the Create case from template drawer, review the values inherited from the template and complete any missing ones. For more information about the fields, see the Create an empty case section.</p> </li> <li> <p>Select Confirm.</p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/create-a-new-case/#create-a-case-from-an-archived-case", "title": "Create a case from an archived case", "text": "<ol> <li> <p>From any view, select + Create case.</p> <p></p> </li> <li> <p>In the Create case drawer, select From archive (.thar).</p> </li> <li> <p>In the Import case drawer:</p> <p>Attachment * Drop a THAR file direclty into the Attachment section or select it from your computer. THAR files are TheHive archive files. Use the file you obtained from exporting an archived case.</p> <p>Password * Enter the archive password that was set during the case export.</p> <p>Sharing By default, global sharing rules set at the organization level are applied when you create a new case. Here, you can modify these rules to apply local sharing settings to the case. You can modify local sharing rules for tasks and observables linked to the case after it is created. For more details, see the Share a Case topic.</p> </li> <li> <p>Select Confirm.</p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/create-a-new-case/#create-a-case-from-a-misp-event", "title": "Create a case from a MISP event", "text": "<p>Data transfer</p> <p>When creating a case from a MISP event, data from the event, such as observables, is automatically transferred to the case.</p> <ol> <li> <p>From any view, select + Create case.</p> <p></p> </li> <li> <p>In the Create case drawer, select From MISP (.json).</p> </li> <li> <p>In the Import from MISP drawer:</p> <p>Attachment *</p> <p>Drop a JSON file direclty into the Attachment section or select the JSON file from your computer. Refer to the MISP documentation to see how to export an event.</p> <p>Tasks Tasks for the case.</p> <p>Custom fields Custom fields for the case, with or without predefined values.</p> <p>Sharing By default, global sharing rules set at the organization level are applied when you create a new case. Here, you can modify these rules to apply local sharing settings to the case. You can modify local sharing rules for tasks and observables linked to the case after it is created. For more details, see the Share a Case topic.</p> </li> <li> <p>Select Confirm.</p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/create-a-new-case/#create-a-case-from-an-alert", "title": "Create a case from an alert", "text": "<p>Required permissions for creating a case from an alert</p> <p>Only users with the <code>manageAlert/update</code> permission can create a case from an alert in TheHive.</p> <p>Data transfer</p> <p>When creating a case from an alert, data from the alert, including observables, TTPs, attachments, comments, and custom fields, is automatically transferred to the case. The alert is also linked to the case.</p> <ol> <li> <p>Locate the alert you want to convert into a case.</p> </li> <li> <p>In the alert description, select the Create case from alert button.</p> <p></p> </li> <li> <p>In the Create case drawer, select either Empty case or From template.</p> </li> <li> <p>Follow the instructions provided in the related sections:</p> <ul> <li>Create an empty case</li> <li>Create a case from a template</li> </ul> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/create-a-new-case/#create-a-case-from-a-detection-tool", "title": "Create a case from a detection tool", "text": "<p>The creation of cases through detection tools is managed directly via the API.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/create-a-new-case/#next-steps", "title": "Next steps", "text": "<ul> <li>Apply a Case Template</li> <li>Adding to a Case</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/export-a-case-to-misp/", "title": "Export a Case to MISP", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/export-a-case-to-misp/#how-to-export-a-case-to-misp", "title": "How to Export a Case to MISP", "text": "<p>This topic provides step-by-step instructions for exporting a case to MISP in TheHive.</p> <p>Only observables marked as IOCs will be exported in the case. Once exported to MISP, any updates to the case IOCs will be automatically synchronized with MISP, requiring no manual intervention.</p> <p>Manual export to MISP only</p> <p>You must manually export cases to MISP, as each case requires individual review.</p> <p>MISP actions required</p> <p>The event created in MISP is not published by default. You must review it and update its status in MISP to publish it.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/export-a-case-to-misp/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Locate the case you want to export.</p> </li> <li> <p>In the case description, select the Export button.</p> <p></p> </li> <li> <p>Select the relevant servers in the Export to MISP section.</p> </li> <li> <p>Select Export.</p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/export-a-case-to-misp/#next-steps", "title": "Next steps", "text": "<ul> <li>Create a Case</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/export-an-archived-case/", "title": "Export an Archived Case", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/export-an-archived-case/#how-to-export-an-archived-case", "title": "How to Export an Archived Case", "text": "<p>This topic provides step-by-step instructions for exporting an archived case in TheHive.</p> <p>You might need to export an archived case to create a case based on a past investigation.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/export-an-archived-case/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Locate the case you want to export.</p> </li> <li> <p>In the case description, select the Export button.</p> <p></p> </li> <li> <p>Enter an archive password in the Export as an archive section. </p> <p>This password will be required when importing the archived case.</p> </li> <li> <p>Select Export archive to export the case in THAR format.</p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/export-an-archived-case/#next-steps", "title": "Next steps", "text": "<ul> <li>Create a Case</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/share-a-case/", "title": "Share a Case with Other Organizations", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/share-a-case/#how-to-share-a-case-with-other-organizations", "title": "How to Share a Case with Other Organizations", "text": "<p>This topic provides step-by-step instructions for configuring local sharing rules with linked organizations for an existing case in TheHive.</p> <p>Global sharing rules</p> <p>This guide focuses on local sharing rules for individual existing cases. To configure global sharing rules for all cases in your organization, refer to How to Link an Organization.</p> <p>To learn more about how sharing rules function and interact, refer to the About Organizations Sharing Rules topic.</p> <p>Required permissions for setting local sharing rules</p> <p>Only users with the <code>manageCase/update</code> and <code>manageShare</code> permissions can modify sharing rules of an existing case in TheHive.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/share-a-case/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Locate the case you want to share.</p> </li> <li> <p>On the case description, select the Sharing button.</p> <p></p> </li> <li> <p>Select the tasks sharing rules to apply.</p> <p>Pick an option from the dropdown list:         - manual (default): Tasks aren't shared automatically. Users must share them manually.         - autoShare: Tasks are shared automatically.</p> </li> <li> <p>Select the observables sharing rules to apply.</p> <p>Pick an option from the dropdown list:         - manual (default): Observables aren't shared automatically. Users must share them manually.         - autoShare: Observables are shared automatically.</p> <p>Task and observable sharing scope</p> <p>Task and observable sharing rules apply to all linked organizations the case is shared with.</p> </li> <li> <p>Select Confirm.</p> </li> <li> <p>Select Manage case sharings.</p> </li> <li> <p>Turn on the Share this case toggle for each relevant organization and select the appropriate permission profile.</p> </li> <li> <p>Select Confirm.</p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/share-a-case/#next-steps", "title": "Next steps", "text": "<ul> <li>Share a Task with Other Organizations</li> <li>Share an Observable with Other Organizations</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/share-an-observable/", "title": "Share an Observable with Other Organizations", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/share-an-observable/#how-to-share-an-observable-with-other-organizations", "title": "How to Share an Observable with Other Organizations", "text": "<p>This topic provides step-by-step instructions for manually sharing an observable in a shared case with linked organizations in TheHive.</p> <p>Shared cases only</p> <p>To share an observable manually, the case must already be shared with the relevant linked organizations. If not, refer to How to Share a Case.</p> <p>This is useful when observable sharing rules are set to manual, ensuring that users share only the relevant observables.</p> <p>To learn more about how sharing rules function and interact, see the About Organizations Sharing Rules topic.</p> <p>Required permissions for setting local sharing rules</p> <p>Only users with the <code>manageCase/update</code> and <code>manageShare</code> permissions can modify sharing rules of an existing case in TheHive.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/share-an-observable/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Locate the shared case where you want to share the observable.</p> </li> <li> <p>Go to the Observables tab.</p> </li> <li> <p>Move through the Shares section.</p> </li> <li> <p>Select .</p> </li> <li> <p>Select the linked organization to share the observable with.</p> </li> <li> <p>Select Add share.</p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/share-an-observable/#next-steps", "title": "Next steps", "text": "<ul> <li>Share a Task with Other Organizations</li> <li>Share a Case with Other Organizations</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/actions/", "title": "Actions on Cases", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/actions/#actions", "title": "Actions", "text": "<p>You can make use of any of the available actions.</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/actions/#flagunflag", "title": "Flag/Unflag", "text": "<ol> <li>Click the Flag/Unflag option to either flag or unflag a case. </li> </ol> <p>A pop-up message appears</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/actions/#close", "title": "Close", "text": "<ol> <li>Click the Close option to remove a case</li> </ol> <p>A new window opens.</p> <ol> <li>Select Status from the list. </li> <li>Change the Summary</li> <li>Click the Close tasks and case button.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/add-custom-event/", "title": "Add custom event", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/add-custom-event/#add-custom-event", "title": "Add custom event", "text": "<p>In this section you can find information about adding cutom events.</p> <p>To add custom event: </p> <p>After clicking the + option. </p> <p>A new window opens. </p> <ol> <li>Add the Title.</li> <li>Enter the Description.</li> <li>Select Date.</li> <li>Select End date.</li> <li>Click the Add button.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/add-custom-fields/", "title": "Add Custom Fields", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/add-custom-fields/#add-custom-fields", "title": "Add Custom Fields", "text": "<p>In this section you can find information about adding custom fields.</p> <p>To add custom fields: </p> <p>After clicking the Add option beside the custom fields. </p> <p>A new window opens. </p> <ol> <li>Add the custom fields from the list.</li> <li>Click the Confirm button.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/attachments/", "title": "View Attachments", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/attachments/#view-attachments", "title": "View attachments", "text": "<p>In this section you can find information about Attachments . </p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/attachments/#add-attachment", "title": "Add Attachment", "text": "<p>To add a new attachment:</p> <ol> <li>On the cases list page, on the attachments tab, on the cases sub-tab, Click the + to add a new attachment.</li> </ol> <p></p> <p>A new window opens. </p> <ol> <li>Click the Drop file or Click option in attachment. </li> <li>Click the Confirm button. </li> </ol> <p></p> <p>NOTE: A user can add one or more files simultaneously. </p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/attachments/#copy-url", "title": "Copy URL", "text": "<ol> <li>On the cases list page, on the attachments tab, on the Tasks sub-tab, click the ellipsis (...) corresponding to the url to be copied.</li> <li>Click copy URL. </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/attachments/#download", "title": "Download", "text": "<ol> <li>On the cases list page, on the attachments tab, on the Tasks sub-tab, Click the ellipsis (...) corresponding to the download option.</li> <li>Click Download. </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/configure-pap-tlp-severity/", "title": "Configure Case details", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/configure-pap-tlp-severity/#configure-case-details", "title": "Configure Case details", "text": "<p>In this section you can find information about configuring case details. </p> <p>Every case has three important elements the TLP, PAP and Severity.  TLP defines the confidentiality of information. PAP is the level of exposure of information to the outsde world and Severity implies the severity of information. </p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/configure-pap-tlp-severity/#configure-tlp-confidentiality-of-information", "title": "Configure TLP (Confidentiality of information)", "text": "<ol> <li>Select TLP, (White/Green/Amber/Red) from the list.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/configure-pap-tlp-severity/#configure-pap-level-of-exposure-of-information", "title": "Configure PAP (Level of exposure of information)", "text": "<ol> <li>Select PAP, (White/Green/Amber/Red) from the list.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/configure-pap-tlp-severity/#configure-severity-severity-of-information", "title": "Configure Severity (Severity of information)", "text": "<ol> <li>Select Severity, (Low/Medium/High/Critical) from the list.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/general/", "title": "View a Case", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/general/#general", "title": "General", "text": "<p>The information on this page comes from templates and is populated. In the left pane of the window, details are displayed, such as created by, created date, TLP, PAP, and severity details. The status of the alert, start date and task completion details can be seen. </p> <p>In the left pane of the window you can configure the PAP,TLP and Severity of the case.  Refer to <code>Configure Case Details</code> for more details. </p> <ol> <li>In the right pane, at bottom of the window, type Comments if any for the team. </li> <li>Enter the Title.</li> <li>Add Tags. (Refer to <code>Add tags</code>).</li> <li>Enter the Description. </li> <li>Add Custom fields. (Refer to <code>Add custom fields</code>).</li> <li>Enter the Company name. </li> <li> <p>Add business unit, detection source and location details. </p> <p></p> </li> <li> <p>Click the Confirm button. </p> </li> <li>Click the Comment button. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/manage-views/", "title": "Manage Views", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/manage-views/#manage-views", "title": "Manage views", "text": "<p>In this section, you can find information about managing views.  </p> <p>To manage views: </p> <ol> <li>Click the default button. </li> <li>Click on Manage Views from the list. </li> </ol> <p></p> <p>A new page opens. It has the Name of the view and the corresponding Actions. </p> <ol> <li>Click the ellipsis (...) corresponding to the name of the view that you want to delete. </li> <li>Click Delete.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/manage-views/#manage-cases", "title": "Manage Cases", "text": "<p>There are various option available to apply on the cases.</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/manage-views/#quick-filters", "title": "Quick Filters", "text": "<p>To apply Quick filter:</p> <ol> <li>Click the Quick Filter option. </li> <li>The list displays options to select from. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/manage-views/#auto-refresh", "title": "Auto refresh", "text": "<p>The auto-refresh option allows you to automatically refresh a page. </p> <p>To perform Auto refresh:</p> <ol> <li>On the cases list page, switch on the Auto refresh button. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/manage-views/#stats", "title": "Stats", "text": "<p>To view Stats: </p> <ol> <li>On the cases list page, switch on the Stats toggle button, the stats will be displayed. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/manage-views/#filters", "title": "Filters", "text": "<p>To apply filter:</p> <ol> <li> <p>On the page, in the tab, switch on the Filters toggle button.</p> </li> <li> <p>Click Add filters.</p> </li> </ol> <p>Apply Filter to the required field.</p> <p></p> <ol> <li>Select the filters from the list.</li> <li>Click Apply filters.</li> <li>(Optional) Click Clear filters to clear all applied filters.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/manage-views/#sorting", "title": "Sorting", "text": "<p>Sorting can be performed on any field values.  </p> <p>To Sort:</p> <ol> <li>On the cases list page, click the small arrow that points upwards/downwards to sort on a particular filed name. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/observables/", "title": "View Observables", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/observables/#view-observables", "title": "View observables", "text": "<p>In this section you can find information about observables.</p> <p>Observables represent stateful properties (such as the MD5 hash of a file or the value of a registry key) or measurable events (such as the creation of a registry key or the deletion of a file) that are pertinent to the operation of computers and networks. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/observables/#add-observables", "title": "Add observables", "text": "<ol> <li>Click the + to add an observable.</li> <li>Type the Type.</li> <li>Type the Value.</li> <li>Select TLP, (White/Green/Amber/Red) from the options.</li> <li>Select PAP, (White/Green/Amber/Red) from the options.</li> <li>Switch the on button for Is IOC. (IoC repository contains objects, and each of the objects contain a specific piece of information.)</li> <li>Switch on the button for Has Been Sighted. </li> <li>Switch on the button for Ignore Similarity. </li> <li>Add Tags. (Refer to <code>Add tags</code>).</li> <li>Type the Description. </li> <li>Click the Save and add another button. </li> <li>Click the Confirm button. </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/observables/#observables-actions", "title": "Observables Actions", "text": "<p>You can make use of any of the available actions.</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/observables/#delete", "title": "Delete", "text": "<ol> <li>Click the Delete option to remove an observable.</li> </ol> <p>A message pops-up</p> <ol> <li>Click the OK button. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/observables/#run-analyzers", "title": "Run Analyzers", "text": "<ol> <li>Click the Run Analyzers option.</li> </ol> <p>A new window opens.</p> <ol> <li>Select one or more Analyzers from the list.</li> <li>Click the Run Analyzers button.  </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/observables/#responders", "title": "Responders", "text": "<ol> <li>Click the Responders option.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/observables/#pinunpin", "title": "Pin/Unpin", "text": "<ol> <li>Click the Pin/Unpin option to pin or unpin observables.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/observables/#export", "title": "Export", "text": "<p>To Export an observable details file: </p> <ol> <li>Click the Export option.</li> <li>A file is downloaded, that can be exported/sent.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/observables/#copy-data", "title": "Copy Data", "text": "<ol> <li>Click the Copy data option.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/pages/", "title": "View Pages", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/pages/#view-pages", "title": "View pages", "text": "<p>In this section you will find information regarding the lessons learnt. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/pages/#addedit-pages", "title": "Add/Edit Pages", "text": "<p>A user can add a new page.</p> <ol> <li>In the right pane of the window, Click + </li> </ol> <p>A new window opens. </p> <ol> <li>Add a Title. </li> <li>Add a Category.</li> <li>Click the Confirm button. </li> </ol> <p></p> <p>A user can edit pages by clicking on the pencil icon. Make changes and click the save icon. </p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/pages/#search-a-page-by-title", "title": "Search a Page by Title", "text": "<p>A user can search a page by typing the title in the search box.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/preview-cases/", "title": "Preview Cases", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/preview-cases/#preview-cases", "title": "Preview Cases", "text": "<p>In this section you can find information about previewing cases and associated details. </p> <p>To preview the cases details:</p> <p>On the list of case details page, there is a Preview button corresponding to the specific case name.</p> <ol> <li>Click the Preview option. </li> </ol> <p></p> <p>The case details preview window opens.</p> <p></p> <p>You can see details like the id, created by, created at date, updated date, TLP, PAP and severity details, title, status, tags, and description details. </p> <p>In the right pane of the window, there is an option to Add the following: </p> <ol> <li>Add Task.</li> <li>Add Observable.</li> <li>Add TTP.</li> </ol> <p>At the bottom of the window, there is an option to Add the following: </p> <ol> <li>Add custom fields.</li> <li> <p>Add business unit, and location  details.</p> </li> <li> <p>Click Add to type business unit, detection-source and location details. </p> <p></p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/preview-cases/#actions", "title": "Actions", "text": "<p>You can click the <code>Actions Button</code>  to Flag/unflag, close, or to <code>Run Responders</code>. </p> <p>and to `Run Analyzer. </p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/preview-cases/#case-details", "title": "Case Details", "text": "<ol> <li> <p>Click on the Go to details button. </p> <p>You can view more details of the case. </p> </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/preview-cases/#case-details-menu", "title": "Case details menu", "text": "<p>You can view more details of the case by going to the menu. </p> <p>On the top of the page, there are many case options available such as flag/unflag, merge, export, close delete and run responders. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/run-analyzer/", "title": "Run Analyzers", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/run-responders/", "title": "Run Responders on Case", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/run-responders/#run-responders", "title": "Run responders", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/run-responders/#responders", "title": "Responders", "text": "<ol> <li>Click on responders option.</li> </ol> <p>A new window appears. </p> <ol> <li>Search for a specific responder in the search box.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/tasks/", "title": "View Tasks", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/tasks/#view-tasks", "title": "View tasks", "text": "<p>Refer to the full section on Tasks for more details.</p> <ul> <li>'About tasks'</li> <li>'Preview task details'</li> <li>'Manage Views'</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/timeline/", "title": "View Timeline", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/timeline/#view-timeline", "title": "View timeline", "text": "<p>In this section you can find information about timelines.</p> <p>A time line is a where a user can view the case details at a glance. The timeline has details about custom events, TTPs, logs, tasks, alerts, case events shown on a timeline. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/timeline/#configure-timeline", "title": "Configure timeline", "text": "<p>Add a custom event (refer to - <code>Add a Custom Event</code>), Export to JSON, Zoom out, zoom in, centre timeline, graph view, list view. There is an option to view the list of custom events. (under the custom events i.e. the last icon, - you can select the custom event to include in the timeline or not).</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/ttps/", "title": "View TTPs", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/ttps/#ttps", "title": "TTPs", "text": "<p>In this section you will find information about TTPs. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/ttps/#add-ttp", "title": "Add TTP", "text": "<p>To add TTP: </p> <p>After clicking the + option. </p> <p>A new window opens. </p> <ol> <li>Select the Catalogue from the list.</li> <li>Select the Occur date.</li> <li>Click the Add toggle button on to add Procedure.</li> <li>Click the Save and add another or the Confirm button.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/cases/cases-description/ttps/#delete-ttp", "title": "Delete TTP", "text": "<ol> <li>Click the ellipsis (...) corresponding to the TTP to be deleted.</li> <li>Click the delete option.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-a-case/", "title": "Find a Case", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-a-case/#how-to-find-a-case", "title": "How to Find a Case", "text": "<p>This topic provides step-by-step instructions for using various methods to search for a case in TheHive.</p> <p>If you\u2019re unsure which method to use, refer to the Overview of Search Methods for Cases topic.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-a-case/#method-1-enter-a-case-number-search-box", "title": "Method 1: Enter a case number search box", "text": "<p>Use this method if you already know the case number you're looking for.</p> <ol> <li> <p>Enter the case number in the search box located at the top of the page, visible across all views.</p> <p></p> </li> <li> <p>Press Enter or select .</p> </li> <li> <p>The case description appears.</p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-a-case/#method-2-similar-cases", "title": "Method 2: Similar cases", "text": "<p>Use this method if you want to find one or more cases similar to a known case without needing to perform actions on them simultaneously.</p> <ol> <li> <p>Open a case, an alert, or a task, and select the Similar cases tab.</p> <p></p> </li> <li> <p>Apply filters using any of these options individually or in combination:</p> <ul> <li> <p>Select Quick filters to access predefined filters.</p> <p></p> </li> <li> <p>Turn on the Filters toggle and enter one or more filters.</p> <p></p> </li> <li> <p>Select a value from a field to use it as a filter criterion.</p> <p></p> </li> </ul> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-a-case/#method-3-filters-in-the-cases-view", "title": "Method 3: Filters in the Cases view", "text": "<p>Use this method if you want to find one or more cases to perform actions on them simultaneously.</p> <ol> <li> <p>Go to the Cases view from the sidebar menu.</p> <p></p> </li> <li> <p>Apply filters using any of these options individually or in combination:</p> <ul> <li> <p>Select Quick filters to access predefined filters.</p> <p></p> </li> <li> <p>Turn on the Filters toggle and enter one or more filters.</p> <p></p> </li> <li> <p>Select a value from a field to use it as a filter criterion.</p> <p></p> </li> </ul> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-a-case/#method-4-global-search-feature", "title": "Method 4: Global Search feature", "text": "<p>Use this method if you need to conduct advanced searches for one or more cases without requiring simultaneous actions.</p> <ol> <li> <p>Go to the Global Search view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Cases item on the Search scope pane.</p> <p></p> <p>All elements</p> <p>Select the All elements item for a comprehensive tool-wide overview that includes all entity types, such as cases, alerts, observables, jobs, tasks, and task logs. Use this option to analyze cross-linked information or to conduct a detailed investigation.</p> </li> <li> <p>Enter the keywords you want to search for in the search box displayed by default.</p> <p>Wildcard character</p> <p>You can use the wildcard character * to broaden your searches since version 5.4.7.</p> <p>The wildcard character acts as a placeholder that matches zero or more characters, helping you find variations of a term or incomplete information.</p> <p>Examples of use cases: - Email domains: Entering *@gmail.com will return entities containing the gmail.com domain. - IP subnets: Entering 192.168.*.* will return entities with IP addresses in the 192.168.x.x subnet. - URLs: Entering https://malwaredomain.com/* will return entities hosted under the malwaredomain.com directory.</p> <p>Other advanced search options, such as Boolean and phrase searches, are not currently supported.</p> </li> <li> <p>If you need additional filters, apply one or more filters by selecting Add new filter. </p> <p>These filters refine your search results and act as an equivalent to the AND operator in Boolean search.</p> <p>Warning</p> <p>Filters are required for the following fields to ensure the search engine accurately interprets values: - Fields with specific date formats - Custom fields</p> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-a-case/#next-steps", "title": "Next steps", "text": "<ul> <li>Actions on Cases</li> <li>View a Case</li> <li>Adding to a Case (Tags/Tasks/Custom Field Values)</li> <li>View Tasks</li> <li>View Observables</li> <li>View TTPs</li> <li>View Attachments</li> <li>View Timeline</li> <li>View Pages</li> <li>Run Responders on Case</li> <li>Run Analyzers on Case</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-a-job/", "title": "Find a Job", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-a-job/#how-to-find-a-job", "title": "How to Find a Job", "text": "<p>This topic provides step-by-step instructions for searching a job in TheHive.</p> <p>A job is a task initiated by Cortex to run an analyzer on an observable.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-a-job/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Global Search view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Jobs item on the Search scope pane.</p> <p></p> <p>All elements</p> <p>Select the All elements item for a comprehensive tool-wide overview that includes all entity types, such as cases, alerts, observables, jobs, tasks, and task logs. Use this option to analyze cross-linked information or to conduct a detailed investigation.</p> </li> <li> <p>Enter the keywords you want to search for in the search box displayed by default.</p> <p>Wildcard character</p> <p>You can use the wildcard character * to broaden your searches since version 5.4.7.</p> <p>The wildcard character acts as a placeholder that matches zero or more characters, helping you find variations of a term or incomplete information.</p> <p>Examples of use cases: - Email domains: Entering *@gmail.com will return entities containing the gmail.com domain. - IP subnets: Entering 192.168.*.* will return entities with IP addresses in the 192.168.x.x subnet. - URLs: Entering https://malwaredomain.com/* will return entities hosted under the malwaredomain.com directory.</p> <p>Other advanced search options, such as Boolean and phrase searches, are not currently supported.</p> <p>Warning</p> <p>The <code>workerDefinition</code> field and the <code>operations[]</code> array aren't indexed for search.</p> </li> <li> <p>If you need additional filters, apply one or more filters by selecting Add new filter. </p> <p>These filters refine your search results and act as an equivalent to the AND operator in Boolean search.</p> <p>Warning</p> <p>Filters are required for the following fields to ensure the search engine accurately interprets values: - Fields with specific date formats - Custom fields</p> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-a-job/#next-steps", "title": "Next steps", "text": "<ul> <li>Run Analyzers on Case</li> <li>Run Responders on Case</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-an-observable/", "title": "Find an Observable", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-an-observable/#how-to-find-an-observable", "title": "How to Find an Observable", "text": "<p>This topic provides step-by-step instructions for searching an observable in TheHive.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-an-observable/#method-1-observables-tab-in-cases-and-alerts-descriptions", "title": "Method 1: Observables tab in cases and alerts descriptions", "text": "<p>Use this method if you know the case or alert containing the observable you're looking for and if you need to perform actions on one or more observables simultaneously.</p> <ol> <li> <p>Open a case or an alert, and select the Observables tab.</p> <p></p> </li> <li> <p>Apply filters using any of these options individually or in combination:</p> <ul> <li> <p>Turn on the Filters toggle and enter one or more filters.</p> <p></p> </li> <li> <p>Select a value from a field to use it as a filter criterion.</p> <p></p> </li> </ul> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-an-observable/#method-2-global-search-feature", "title": "Method 2: Global Search feature", "text": "<p>Use this method if you\u2019re unsure where to find the observable you\u2019re looking for or if you need to conduct advanced searches for one or more observables without requiring simultaneous actions.</p> <ol> <li> <p>Go to the Global Search view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Observables item on the Search scope pane.</p> <p></p> <p>All elements</p> <p>Select the All elements item for a comprehensive tool-wide overview that includes all entity types, such as cases, alerts, observables, jobs, tasks, and task logs. Use this option to analyze cross-linked information or to conduct a detailed investigation.</p> </li> <li> <p>Enter the keywords you want to search for in the search box displayed by default.</p> <p>Wildcard character</p> <p>You can use the wildcard character * to broaden your searches since version 5.4.7.</p> <p>The wildcard character acts as a placeholder that matches zero or more characters, helping you find variations of a term or incomplete information.</p> <p>Examples of use cases: - Email domains: Entering *@gmail.com will return entities containing the gmail.com domain. - IP subnets: Entering 192.168.*.* will return entities with IP addresses in the 192.168.x.x subnet. - URLs: Entering https://malwaredomain.com/* will return entities hosted under the malwaredomain.com directory.</p> <p>Other advanced search options, such as Boolean and phrase searches, are not currently supported.</p> </li> <li> <p>If you need additional filters, apply one or more filters by selecting Add new filter. </p> <p>These filters refine your search results and act as an equivalent to the AND operator in Boolean search.</p> <p>Warning</p> <p>Filters are required for the following fields to ensure the search engine accurately interprets values: - Fields with specific date formats - Custom fields</p> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/find-an-observable/#next-steps", "title": "Next steps", "text": "<ul> <li>View Observables</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/overview-search-methods-case/", "title": "Overview of Search Methods for Cases", "text": ""}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/overview-search-methods-case/#overview-of-search-methods-for-cases", "title": "Overview of Search Methods for Cases", "text": "<p>TheHive offers multiple methods for searching cases, each tailored to specific scenarios.</p> <p>This topic provides an overview of the available search methods, compares their features, and explains when to use each one.</p> <p>Use this guide to choose the most effective method for your needs.</p>"}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/overview-search-methods-case/#search-method-comparison", "title": "Search method comparison", "text": "Method Filter options Result scope Allows bulk actions Use case Enter a case number search box Single Simple No If you already know the case number you're looking for. Similar cases Multiple Multiple No If you want to find one or more cases similar to a known case without needing to perform actions on them simultaneously. Filters in the Cases view Multiple Multiple Yes If you want to find one or more cases to perform actions on them simultaneously. Global Search feature Advanced Multiple No If you need to conduct advanced searches for one or more cases without requiring simultaneous actions."}, {"location": "thehive/user-guides/analyst-corner/cases/search-for-cases/overview-search-methods-case/#next-steps", "title": "Next steps", "text": "<ul> <li>How to Find a Case</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/dashboard/about-dashboard/", "title": "About Dashboard", "text": ""}, {"location": "thehive/user-guides/analyst-corner/dashboard/about-dashboard/#dashboards", "title": "Dashboards", "text": "<p>In this section you can find information about dashboards.</p> <p>A dashboard is a visual display of data to provide information at-a-glance. The dashboard is configurable, allowing you to choose which data you want to see and whether you want to include charts or graphs to visualize the numbers.</p> <p>The dashboard lists all details of cases such as, status, name, version number, widget, created by, dates of creation and date on which data was updated. A user can apply filters on the dashboard, sort based on fields, and manage views. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/dashboard/filter-sort/", "title": "Filter and Sort", "text": ""}, {"location": "thehive/user-guides/analyst-corner/dashboard/filter-sort/#filters-and-sort", "title": "Filters and Sort", "text": "<p>In this section, you can find information about applying filters.</p>"}, {"location": "thehive/user-guides/analyst-corner/dashboard/filter-sort/#filters", "title": "Filters", "text": "<p>To apply filter:</p> <ol> <li> <p>On the dashboard page, switch on the Filters toggle button.</p> </li> <li> <p>Click Add filters.</p> </li> </ol> <p>Apply Filter to the required field.</p> <p></p> <ol> <li>Select the filters from the list.</li> <li>Click Apply filters.</li> <li>(Optional) Click Clear filters to clear all applied filters.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/dashboard/filter-sort/#sorting", "title": "Sorting", "text": "<p>Sorting can be performed on any field values.  </p> <p>To Sort:</p> <ol> <li>On the dashboard page, Click the small arrow that points upwards/downwards to sort on a particular filed name. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/dashboard/manage-dashboard/", "title": "Manage Dashboard", "text": ""}, {"location": "thehive/user-guides/analyst-corner/dashboard/manage-dashboard/#manage-dashboard", "title": "Manage Dashboard", "text": "<p>In this section you can find information about managing dashboards.</p>"}, {"location": "thehive/user-guides/analyst-corner/dashboard/manage-dashboard/#add-a-dashboard", "title": "Add a dashboard", "text": "<p>To Add a dashboard: </p> <ol> <li> <p>Click the + , to Add a dashboard. </p> <p></p> <p>A new window opens. </p> </li> <li> <p>Enter the  Title.</p> </li> <li>Enter the  Description.</li> <li>Select the Visibility option. (Private or Shared) </li> <li>Click the confirm button. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/dashboard/manage-dashboard/#edit-a-dashboard", "title": "Edit a dashboard", "text": "<p>To Edit a dashboard: </p> <ol> <li> <p>Click the Edit option from the list. </p> <p></p> <p>A new window opens. </p> </li> <li> <p>Edit the required fields.    </p> </li> <li>Click the Confirm button. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/dashboard/manage-dashboard/#delete-a-dashboard", "title": "Delete a dashboard", "text": "<p>To Delete a dashboard: </p> <ol> <li> <p>Click the Delete option from the list.</p> <p></p> <p>A new message pops-up.</p> </li> <li> <p>Click OK to delete the dashboard from the list.</p> </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/dashboard/manage-dashboard/#import-a-dashboard", "title": "Import a dashboard", "text": "<p>To Import a dashboard: </p> <ol> <li> <p>Click the Import dashboard option. </p> <p></p> <p>A new window opens. </p> </li> <li> <p>Click the Drop file or Click option in attachment. </p> </li> </ol> <p>NOTE: The file must be a valid JSON file. You can use the exported dashboard directly from theHive platform. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/dashboard/manage-dashboard/#export-a-dashboard", "title": "Export a dashboard", "text": "<p>To Export a dashboard: </p> <ol> <li>Click the Export option.</li> <li>A file is downloaded, that can be exported/sent.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/dashboard/manage-views/", "title": "Manage View", "text": ""}, {"location": "thehive/user-guides/analyst-corner/dashboard/manage-views/#manage-views", "title": "Manage Views", "text": "<p>In this section, you can find information about managing dashboard views.  </p> <p>To manage views: </p> <ol> <li>Click the default button. </li> <li>Click the Manage Views from the list. </li> </ol> <p></p> <p>A new page opens. </p> <p>It has the Name of the view and the corresponding Actions. </p> <ol> <li>Click the ellipsis (...) corresponding to the name of the view that you want to delete. </li> <li>Click Delete.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/", "title": "Index", "text": "<p>Preview task details</p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/about-tasks/", "title": "About Tasks", "text": ""}, {"location": "thehive/user-guides/analyst-corner/tasks/about-tasks/#tasks", "title": "Tasks", "text": "<p>Task details, require action from its users. Task details page displays a list of tasks.  When navigating through the Task list, you can easily see and determine which Task needs an action. </p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/about-tasks/#to-view-task-details", "title": "To view task details", "text": "<p>You can click on any of the tasks in the list to view more details. </p> <p></p> <p>The details are displayed</p> <p></p> <p>In the left pane of the window you can configure the PAP, TLP and Severity.  Refer to 'Configure Alert Details' for more details. </p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/manage-views/", "title": "Manage Views", "text": ""}, {"location": "thehive/user-guides/analyst-corner/tasks/manage-views/#manage-views", "title": "Manage Views", "text": "<p>In this section, you can find information about managing views.  </p> <p>To manage views: </p> <ol> <li>Click the default button. </li> <li>Click the Manage Views from the list. </li> </ol> <p></p> <p>A new page opens. It has the Name of the view and the corresponding Actions. </p> <ol> <li>Click the ellipsis (...) corresponding to the name of the view that you want to delete. </li> <li>Click Delete.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/manage-views/#manage-tasks", "title": "Manage Tasks", "text": "<p>There are various option available to apply on the tasks. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/manage-views/#quick-filters", "title": "Quick Filters", "text": "<p>To apply Quick filter:</p> <ol> <li>Click the Quick Filter option. </li> <li>The list displays options to select from. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/manage-views/#auto-refresh", "title": "Auto refresh", "text": "<p>The auto-refresh option allows you to automatically refresh a page. </p> <p>To perform Auto refresh:</p> <ol> <li>On the tasks list page, switch on the Auto refresh button. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/manage-views/#show-tasks-as-groups", "title": "Show tasks as groups", "text": "<p>To view tasks as groups: </p> <ol> <li>On the tasks list page, switch on the tasks as groups button, the task groups will be displayed. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/manage-views/#filters", "title": "Filters", "text": "<p>To apply filter:</p> <ol> <li>On the tasks list page, switch on the Filters toggle button.</li> <li>Click Add filters.</li> </ol> <p>Apply Filter to the required field.</p> <p></p> <ol> <li>Select the filters from the list.</li> <li>Click Apply filters.</li> <li>(Optional) Click Clear filters to clear all applied filters.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/tasks/manage-views/#sorting", "title": "Sorting", "text": "<p>Sorting can be performed on any field values.  </p> <p>To Sort:</p> <ol> <li>On the tasks list page, Click the small arrow that points upwards/downwards to sort on a particular filed name. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/share-a-task/", "title": "Share a Task with Other Organizations", "text": ""}, {"location": "thehive/user-guides/analyst-corner/tasks/share-a-task/#how-to-share-a-task-with-other-organizations", "title": "How to Share a Task with Other Organizations", "text": "<p>This topic provides step-by-step instructions for manually sharing a task in a shared case with linked organizations in TheHive.</p> <p>Shared cases only</p> <p>To share a task manually, the case must already be shared with the relevant linked organizations. If not, refer to How to Share a Case.</p> <p>This is useful when task sharing rules are set to manual, ensuring that users share only the relevant tasks.</p> <p>To learn more about how sharing rules function and interact, see the About Organizations Sharing Rules topic.</p> <p>Required permissions for setting local sharing rules</p> <p>Only users with the <code>manageCase/update</code> and <code>manageShare</code> permissions can modify sharing rules of an existing case in TheHive.</p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/share-a-task/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Locate the shared case where you want to share the task.</p> </li> <li> <p>Go to the Tasks tab.</p> </li> <li> <p>Move through the Shares section.</p> </li> <li> <p>Select .</p> </li> <li> <p>Select the linked organization to share the task with.</p> </li> <li> <p>Select Add share.</p> </li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/tasks/share-a-task/#next-steps", "title": "Next steps", "text": "<ul> <li>Share an Observable</li> <li>Share a Case</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/Preview-tasks/", "title": "Preview Tasks", "text": ""}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/Preview-tasks/#preview-tasks", "title": "Preview Tasks", "text": "<p>In this section you can find information about previewing tasks. </p> <p>To preview the task details:</p> <p>On the list of tasks page, there is a Preview button corresponding to the specific task name.</p> <ol> <li>Click the Preview option. </li> </ol> <p></p> <p>The task details preview window opens.</p> <p></p> <p>You can see details like the id, created by, created at date, updated date, title, flag, status, group, assignee, start date, due date, description, activity, responder reports of the task. </p> <p>You can click the <code>Actions Button</code>  to start, delete, pin/unpin, flag/unflag the tasks or to <code>Run Responders</code>. </p> <p></p> <p>You can add activities/task logs by clicking on the +. Refer to <code>Create a task log</code>.</p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/Preview-tasks/#task-details", "title": "Task Details", "text": "<ol> <li>Click the Go to details button to view more details of the task.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/Preview-tasks/#task-details-menu", "title": "Task details menu", "text": "<ol> <li>Click the Go to details button to view more details of the task. </li> </ol> <p>On the top of the page, there are many task options available such as flag, merge, export, close, delete, responders. </p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/actions/", "title": "Actions on Tasks", "text": ""}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/actions/#actions", "title": "Actions", "text": "<p>You can make use of any of the available actions.</p> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/actions/#start", "title": "Start", "text": "<ol> <li>Click the Start option to begin a task.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/actions/#delete", "title": "Delete", "text": "<ol> <li>Click the Delete option to remove a task.</li> </ol> <p>A message pops-up</p> <ol> <li>Click the OK button. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/actions/#unflag", "title": "Unflag", "text": "<ol> <li>Click the Flag/Unflag option to flag or unflag a task.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/actions/#unpin", "title": "Unpin", "text": "<ol> <li>Click the Pin/Unpin option to pin or unpin a task.</li> </ol>"}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/create-a-task-log/", "title": "Create a task log", "text": ""}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/create-a-task-log/#create-a-task-log", "title": "Create a task log", "text": "<p>In this section you can find information about creating a task log.</p> <p>To  create a task log: </p> <ol> <li>Enter the log message in Description area of the given box. </li> <li>Switch on the Toggle the button to include in timeline. (If you opt for a timeline, you have to provide the date for the timeline).</li> <li>In Attachment Drop file or click. You can upload an attachment. </li> <li>Click the Create a Task Log button. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/run-responders/", "title": "Run Responders from Task", "text": ""}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/run-responders/#run-responders", "title": "Run Responders", "text": ""}, {"location": "thehive/user-guides/analyst-corner/tasks/preview-task-details/run-responders/#responders", "title": "Responders", "text": "<ol> <li>Click on responders option.</li> </ol> <p>A new window appears. </p> <ol> <li>Search for a specific responder in the search box.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/find-a-task-log/", "title": "Find a Task Log", "text": ""}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/find-a-task-log/#how-to-find-a-task-log", "title": "How to Find a Task Log", "text": "<p>This topic provides step-by-step instructions for searching a task log in TheHive.</p> <p>A task log is a recorded history of actions, updates, or decisions taken on a specific task. It provides a detailed audit trail that helps track investigation progress, accountability, and compliance.</p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/find-a-task-log/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Global Search view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Task logs item on the Search scope pane.</p> <p></p> <p>All elements</p> <p>Select the All elements item for a comprehensive tool-wide overview that includes all entity types, such as cases, alerts, observables, jobs, tasks, and task logs. Use this option to analyze cross-linked information or to conduct a detailed investigation.</p> </li> <li> <p>Enter the keywords you want to search for in the search box displayed by default.</p> <p>Wildcard character</p> <p>You can use the wildcard character * to broaden your searches since version 5.4.7.</p> <p>The wildcard character acts as a placeholder that matches zero or more characters, helping you find variations of a term or incomplete information.</p> <p>Examples of use cases: - Email domains: Entering *@gmail.com will return entities containing the gmail.com domain. - IP subnets: Entering 192.168.*.* will return entities with IP addresses in the 192.168.x.x subnet. - URLs: Entering https://malwaredomain.com/* will return entities hosted under the malwaredomain.com directory.</p> <p>Other advanced search options, such as Boolean and phrase searches, are not currently supported.</p> </li> <li> <p>If you need additional filters, apply one or more filters by selecting Add new filter. </p> <p>These filters refine your search results and act as an equivalent to the AND operator in Boolean search.</p> <p>Warning</p> <p>Filters are required for the following fields to ensure the search engine accurately interprets values: - Fields with specific date formats - Custom fields</p> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/find-a-task-log/#next-steps", "title": "Next steps", "text": "<ul> <li>View tasks</li> <li>Preview Tasks</li> <li>Actions on Tasks</li> <li>Run Responders</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/find-a-task/", "title": "Find a Task", "text": ""}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/find-a-task/#how-to-find-a-task", "title": "How to Find a Task", "text": "<p>This topic provides step-by-step instructions for using various methods to search for a task in TheHive.</p> <p>If you\u2019re unsure which method to use, refer to the Overview of Search Methods for Tasks topic.</p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/find-a-task/#method-1-tasks-tab-in-cases-descriptions", "title": "Method 1: Tasks tab in cases descriptions", "text": "<p>Use this method if you want to find one or more tasks related to a case and want to perform actions on them simultaneously.</p> <ol> <li> <p>Open a case and select the Tasks tab.</p> <p></p> </li> <li> <p>Apply filters using any of these options individually or in combination:</p> <ul> <li> <p>Select Quick filters to access predefined filters.</p> <p></p> </li> <li> <p>Turn on the Filters toggle and enter one or more filters.</p> <p></p> </li> <li> <p>Select a value from a field to use it as a filter criterion.</p> <p></p> </li> </ul> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/find-a-task/#method-2-filters-in-the-tasks-view", "title": "Method 2: Filters in the Tasks view", "text": "<p>Use this method if you need to search for one or more tasks without requiring simultaneous actions.</p> <ol> <li> <p>Go to the Tasks view from the sidebar menu.</p> <p></p> </li> <li> <p>Apply filters using any of these options individually or in combination:</p> <ul> <li> <p>Select Quick filters to access predefined filters.</p> <p></p> </li> <li> <p>Turn on the Filters toggle and enter one or more filters.</p> <p></p> </li> <li> <p>Select a value from a field to use it as a filter criterion.</p> <p></p> </li> </ul> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/find-a-task/#method-3-global-search-feature", "title": "Method 3: Global Search feature", "text": "<p>Use this method if you need to conduct advanced searches for one or more tasks without requiring simultaneous actions.</p> <ol> <li> <p>Go to the Global Search view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Tasks item on the Search scope pane.</p> <p></p> <p>All elements</p> <p>Select the All elements item for a comprehensive tool-wide overview that includes all entity types, such as cases, alerts, observables, jobs, tasks, and task logs. Use this option to analyze cross-linked information or to conduct a detailed investigation.</p> </li> <li> <p>Enter the keywords you want to search for in the search box displayed by default.</p> <p>Wildcard character</p> <p>You can use the wildcard character * to broaden your searches since version 5.4.7.</p> <p>The wildcard character acts as a placeholder that matches zero or more characters, helping you find variations of a term or incomplete information.</p> <p>Examples of use cases: - Email domains: Entering *@gmail.com will return entities containing the gmail.com domain. - IP subnets: Entering 192.168.*.* will return entities with IP addresses in the 192.168.x.x subnet. - URLs: Entering https://malwaredomain.com/* will return entities hosted under the malwaredomain.com directory.</p> <p>Other advanced search options, such as Boolean and phrase searches, are not currently supported.</p> </li> <li> <p>If you need additional filters, apply one or more filters by selecting Add new filter. </p> <p>These filters refine your search results and act as an equivalent to the AND operator in Boolean search.</p> <p>Warning</p> <p>Filters are required for the following fields to ensure the search engine accurately interprets values: - Fields with specific date formats - Custom fields</p> </li> <li> <p>Based on your inputs, a list of results appears.</p> </li> </ol> <p>You can view up to 300 results per page and navigate through them using Previous and Next.</p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/find-a-task/#next-steps", "title": "Next steps", "text": "<ul> <li>Actions on Tasks</li> <li>Run Responders From Task</li> </ul>"}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/overview-search-methods-task/", "title": "Overview of Search Methods for Tasks", "text": ""}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/overview-search-methods-task/#overview-of-search-methods-for-tasks", "title": "Overview of Search Methods for Tasks", "text": "<p>TheHive offers multiple methods for searching tasks, each tailored to specific scenarios.</p> <p>This topic provides an overview of the available search methods, compares their features, and explains when to use each one.</p> <p>Use this guide to choose the most effective method for your needs.</p>"}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/overview-search-methods-task/#search-method-comparison", "title": "Search method comparison", "text": "Method Filter options Result scope Allows bulk actions Use case Tasks tab in cases descriptions Multiple Multiple Yes If you want to find one or more tasks related to a case and want to perform actions on them simultaneously. Filters in the Tasks view Multiple Multiple No If you need to search for one or more tasks without requiring simultaneous actions. Global Search feature Advanced Multiple No If you need to conduct advanced searches for one or more tasks without requiring simultaneous actions."}, {"location": "thehive/user-guides/analyst-corner/tasks/search-for-tasks/overview-search-methods-task/#next-steps", "title": "Next steps", "text": "<ul> <li>How to Find an Task</li> </ul>"}, {"location": "thehive/user-guides/key-performance-indicators/about-key-performance-indicators/", "title": "About KPIs", "text": ""}, {"location": "thehive/user-guides/key-performance-indicators/about-key-performance-indicators/#about-key-performance-indicators", "title": "About Key Performance Indicators", "text": "<p>Starting from version 5.1, TheHive provides valuable insights into event and incident time metrics, enabling you to track key performance indicators (KPIs) for cases and alerts.</p> <p>These KPIs are displayed by default on all cases and alerts in TheHive. You can also integrate them into dashboards and case reports.</p> <p>This topic defines each of these indicators.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/about-key-performance-indicators/#time-to-detect-ttd", "title": "Time to detect (TTD)", "text": "<p>The time it takes for your security team to detect abnormal activity that may indicate malicious, suspicious, or risky behavior in your environment. This metric helps assess the effectiveness of your monitoring tools and detection capabilities.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/about-key-performance-indicators/#time-to-triage-ttt", "title": "Time to triage (TTT)", "text": "<p>The time it takes for your security team to assess and prioritize a detected alert, determining its relevance, severity, and required response. It reflects how efficiently alerts are reviewed and escalated for investigation.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/about-key-performance-indicators/#time-to-acknowledge-tta", "title": "Time to acknowledge (TTA)", "text": "<p>The time it takes for your security team to acknowledge an event by transitioning its status to In Progress. This measures the responsiveness of your team after detecting a potential security incident.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/about-key-performance-indicators/#time-to-qualify-ttq", "title": "Time to qualify (TTQ)", "text": "<p>The time it takes for your security team to analyze an alert and determine its validity\u2014whether it's a true positive, a false positive, or requires further investigation. This metric helps measure the accuracy and speed of the qualification process.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/about-key-performance-indicators/#time-to-resolve-ttr", "title": "Time to resolve (TTR)", "text": "<p>The time it takes to fully resolve an incident after it has been marked In Progress. This includes investigation, remediation, and closure, indicating the efficiency of your incident response process.</p> <p>To view the formulas for each indicator, refer to the Key Performance Indicator Formulas topic.</p> <p>For more information on these KPIs, we recommend you consult this SecurityScorecard blog post.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/about-key-performance-indicators/#next-steps", "title": "Next steps", "text": "<ul> <li>Hide Key Performance Indicators</li> <li>Measure Case Performance</li> <li>Measure Alert Performance</li> </ul>"}, {"location": "thehive/user-guides/key-performance-indicators/hide-key-performance-indicators/", "title": "Hide KPIs", "text": ""}, {"location": "thehive/user-guides/key-performance-indicators/hide-key-performance-indicators/#how-to-hide-key-performance-indicators", "title": "How to Hide Key Performance Indicators", "text": "<p>This topic provides step-by-step instructions for hiding one or several key performance indicators (KPIs) for cases and alerts in TheHive.</p> <p>By default, all indicators are displayed in case and alert descriptions. </p> <p>Since version 5.4, you can hide some or all indicators if they're not useful or could be misleading for your organization.</p> <p>If you want to know more about the KPIs available in TheHive, refer to the About Key Performance Indicators topic.</p> <p>Required permissions for hiding KPIs</p> <p>Only users with an admin-type profile that has the <code>manageConfig</code> permission can hide KPIs in case and alert descriptions in TheHive.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/hide-key-performance-indicators/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organization view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the UI Configuration tab.</p> <p></p> </li> <li> <p>Move through the Time metrics section.</p> </li> <li> <p>Turn on the toggles for the indicators you want to hide in case and alert descriptions.</p> </li> <li> <p>Select Confirm.</p> </li> </ol>"}, {"location": "thehive/user-guides/key-performance-indicators/hide-key-performance-indicators/#next-steps", "title": "Next steps", "text": "<ul> <li>Measure Case Management Performance</li> <li>Measure Alert Management Performance</li> </ul>"}, {"location": "thehive/user-guides/key-performance-indicators/key-performance-indicators-formulas/", "title": "KPIs Formulas", "text": ""}, {"location": "thehive/user-guides/key-performance-indicators/key-performance-indicators-formulas/#key-performance-indicator-formulas", "title": "Key Performance Indicator Formulas", "text": "<p>This topic outlines the formulas used to calculate key performance indicators (KPIs) for cases and alerts in TheHive.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/key-performance-indicators-formulas/#key-performance-indicator-formulas-table", "title": "Key performance indicator formulas table", "text": "KPI Formula In case description In alert description Time to detect (TTD) = creation date in TheHive - event date = <code>case.newDate</code> - <code>case.startDate</code> = <code>alert.newDate</code> - <code>alert.date</code> Time to triage (TTT) = date of status In Progress - creation date in TheHive = <code>case.inProgressDate</code> - <code>case.newDate</code> = <code>alert.inProgressDate</code> - <code>alert.newDate</code> Time to acknowledge (TTA) = date of status In Progress - event date = <code>case.inProgressDate</code> - <code>case.startDate</code> = <code>alert.inProgressDate</code> - <code>alert.date</code> Time to qualify (TTQ) = date of alert closure or merge into case - alert creation date in TheHive = <code>max(alert.importedDate, alert.closedDate)</code> - <code>alert.newDate</code> not applicable Time to resolve (TTR) = end of the incident date - date of status In Progress = <code>case.endDate</code> - <code>min(alert.inProgress, case.inProgress)</code> not applicable <p>Units</p> <p>If the unit of an indicator is not explicitly mentioned, values are in milliseconds.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/key-performance-indicators-formulas/#next-steps", "title": "Next steps", "text": "<ul> <li>About Key Performance Indicators</li> <li>Hide Key Performance Indicators</li> <li>Measure Case Performance</li> <li>Measure Alert Performance</li> </ul>"}, {"location": "thehive/user-guides/key-performance-indicators/measure-alert-management-performance/", "title": "Measure Alert Management Performance", "text": ""}, {"location": "thehive/user-guides/key-performance-indicators/measure-alert-management-performance/#how-to-measure-alert-management-performance", "title": "How to Measure Alert Management Performance", "text": "<p>This topic provides step-by-step instructions for measuring alert management performance in TheHive.</p> <p>You can measure alert management performance for all alerts in your organization or a specific case.</p> <p>If you want to know more about the key performance indicators (KPIs) available in TheHive, refer to the About Key Performance Indicators topic.</p> <p>Automated actions</p> <p>If alerts are created or updated through automated actions (API, functions, or external services), some indicators may be identical or very close in value, especially if multiple operations occur within the same second.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/measure-alert-management-performance/#measure-the-performance-of-all-alerts-in-your-organization", "title": "Measure the performance of all alerts in your organization", "text": "<p>Required permissions for editing dashboards</p> <p>Only users with the <code>manageDashboard</code> permission can edit dashboards in TheHive.</p> <ol> <li> <p>Go to the Dashboards view from the sidebar menu.</p> <p></p> </li> <li> <p>Select a dashboard related to alerts.</p> </li> <li> <p>Select .</p> </li> <li> <p>Select Edit on the section where you want to add your alert management KPIs.</p> </li> <li> <p>Select any value that begins with timeTo to any Filters box.</p> </li> </ol> <p>Units</p> <p>If the unit of an indicator is not explicitly mentioned, values are in milliseconds.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/measure-alert-management-performance/#measure-the-performance-of-a-specific-alert", "title": "Measure the performance of a specific alert", "text": "<ol> <li> <p>Locate the case you want to check.</p> </li> <li> <p>In the alert description, move through the Time metrics section in the left pane.</p> <p></p> </li> <li> <p>Review the available indicators for your alert.</p> </li> </ol>"}, {"location": "thehive/user-guides/key-performance-indicators/measure-alert-management-performance/#next-steps", "title": "Next steps", "text": "<ul> <li>Measure Case Performance</li> </ul>"}, {"location": "thehive/user-guides/key-performance-indicators/measure-case-management-performance/", "title": "Measure Case Management Performance", "text": ""}, {"location": "thehive/user-guides/key-performance-indicators/measure-case-management-performance/#how-to-measure-case-management-performance", "title": "How to Measure Case Management Performance", "text": "<p>This topic provides step-by-step instructions for measuring case management performance in TheHive.</p> <p>You can measure case management performance for all cases in your organization or a specific case.</p> <p>If you want to know more about the key performance indicators (KPIs) available in TheHive, refer to the About Key Performance Indicators topic.</p> <p>Automated actions</p> <p>If cases are created or updated through automated actions (API, functions, or external services), some indicators may be identical or very close in value, especially if multiple operations occur within the same second.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/measure-case-management-performance/#measure-the-performance-of-all-cases-in-your-organization", "title": "Measure the performance of all cases in your organization", "text": "<p>Required permissions for editing dashboards</p> <p>Only users with the <code>manageDashboard</code> permission can edit dashboards in TheHive.</p> <ol> <li> <p>Go to the Dashboards view from the sidebar menu.</p> <p></p> </li> <li> <p>Select a dashboard related to cases.</p> </li> <li> <p>Select .</p> </li> <li> <p>Select Edit on the section where you want to add your case management KPIs.</p> </li> <li> <p>Select any value that begins with timeTo to any Filters box.</p> </li> </ol> <p>Units</p> <p>If the unit of an indicator is not explicitly mentioned, values are in milliseconds.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/measure-case-management-performance/#measure-the-performance-of-a-specific-case", "title": "Measure the performance of a specific case", "text": "<p>Two options are available to measure a case's performance:</p> <p>In a case description:</p> <ol> <li> <p>Locate the case you want to check.</p> </li> <li> <p>In the case description, move through the Time metrics section in the left pane.</p> <p></p> </li> <li> <p>Review the available indicators for your case.</p> </li> </ol> <p>In a case report template:</p> <p>Required permissions for managing case reports</p> <pre><code>Only users with the `manageCaseReport` permission can manage case templates in TheHive.\n</code></pre> <ol> <li> <p>Go to the Organization view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Templates tab.</p> <p></p> </li> <li> <p>Select the Reports tab.</p> <p></p> </li> <li> <p>Select a case report template.</p> </li> <li> <p>Select  on the section where you want to add your case management KPIs.</p> </li> <li> <p>Select Add variable.</p> </li> <li> <p>Select any value that begins with timeTo.</p> </li> </ol> <p>Units</p> <p>If the unit of an indicator is not explicitly mentioned, values are in milliseconds.</p>"}, {"location": "thehive/user-guides/key-performance-indicators/measure-case-management-performance/#next-steps", "title": "Next steps", "text": "<ul> <li>Measure Alert Performance</li> </ul>"}, {"location": "thehive/user-guides/organization/accounts/", "title": "User", "text": ""}, {"location": "thehive/user-guides/organization/accounts/#manage-users-in-your-organization", "title": "Manage users in your Organization", "text": "<p>Info</p> <p>org-admin profile or at least the permission <code>manageUser</code> is required to manage users in your organization.</p>"}, {"location": "thehive/user-guides/organization/accounts/#list-of-users", "title": "List of users", "text": "<p>In your organization, click on Organization in the menu on the left to access the list of users. The first tab is Users.</p> <p> </p> List of user accounts"}, {"location": "thehive/user-guides/organization/accounts/#user-information", "title": "User information", "text": "<p>To access detailed information about a user, click the Preview button</p> <p> </p> User information"}, {"location": "thehive/user-guides/organization/accounts/#configuration-parameters", "title": "Configuration parameters", "text": "Avatar Update the avatar associated with the user by drag&amp;drop a new file (PNG or JPG files). Login User login Email email address for the account. This is used to send notifications or reset password links to users. Login is used if no email is filled there Type Type of the account. Normal or Service. A Service account cannot open interactive session Locked Block a user from logging in the application MFA Tells if a user has configured MFA or not (Multi Factor Authentication). If yes, Yes is displayed API Key Define, Renew, Reveal or Revoke API key of the account Profile Information about the profile given to the user Permissions List of permissions included in the profile Password Create or update the password of the user Reset Password If the application is configured with a SMTP server, send an email with a magic link to the user. link is active for a short time period. Sessions List of opened interactive sessions. Click delete to close a session"}, {"location": "thehive/user-guides/organization/accounts/#add-users", "title": "Add Users", "text": "<p>org-admin users or users with the role <code>manageUser</code> in their profile can add users in the current organization. </p> <p>Click the  button to add an account in the current organization, and follow create an account and update an account guides.</p>"}, {"location": "thehive/user-guides/organization/accounts/#user-management", "title": "User management", "text": "<p>Accounts can be deleted or locked, only in the current organization.</p>"}, {"location": "thehive/user-guides/organization/attachments/", "title": "Attachments", "text": ""}, {"location": "thehive/user-guides/organization/attachments/#attachments", "title": "Attachments", "text": "<p>This sections gather all the files and images added at the organization level, like the knowledge base.</p>"}, {"location": "thehive/user-guides/organization/custom-tags/", "title": "Custom Tags", "text": ""}, {"location": "thehive/user-guides/organization/custom-tags/#custom-tags", "title": "Custom tags", "text": "<p>Custom tags gathers all tags coming from Alerts or added to Cases or Observables that are not included in Taxonomies added to TheHive, even if they are not activated.</p> <p> </p> Custom tags <p>The list shows statistics about the number of them found in Cases,Alerts or Observables.</p>"}, {"location": "thehive/user-guides/organization/custom-tags/#configuration", "title": "Configuration", "text": "<ul> <li>Names and colors can be adjusted for all Custom tags</li> <li>Each tag can also be deleted</li> </ul> <p>Warning</p> <ul> <li>Deleting a tag from this menu will remove the tag on every Alert, Case &amp; Observables in the organization.</li> </ul>"}, {"location": "thehive/user-guides/organization/functions/", "title": "Functions", "text": ""}, {"location": "thehive/user-guides/organization/functions/#functions", "title": "Functions", "text": ""}, {"location": "thehive/user-guides/organization/functions/#overview", "title": "Overview", "text": "<p>A Function in TheHive is a custom JavaScript code block that runs within the platform, accepting inputs from external sources, processing data, and interacting directly with TheHive's APIs to seamlessly integrate external applications into its workflow.</p> <p>For example, you can use a Function to create alerts within TheHive without the need for an additional Python service to convert the data.</p> <p>This feature is supported in TheHive starting from version 5.1 and later.</p>"}, {"location": "thehive/user-guides/organization/functions/#function-usages", "title": "Function Usages", "text": "<p>In real-life use, a Function in TheHive automates tasks like processing data from external systems, triggering alerts, or updating cases. It streamlines workflows by connecting TheHive to other tools, reducing manual work and improving incident management efficiency.</p>"}, {"location": "thehive/user-guides/organization/functions/#function-types", "title": "Function Types", "text": "<p>Below are the different types of functions supported in TheHive. The function type you select determines the scope where the function can be executed:</p> <ol> <li> <p>API: These functions are triggered by an external service through TheHive's public API, allowing automated workflows initiated from outside the platform.</p> </li> <li> <p>Notification: Notification functions act as notifiers and are triggered when certain events occur, such as alerts or case updates, automating the notification process based on predefined conditions.</p> </li> <li> <p>Action: Case: Functions of the <code>action:case</code> type are manually triggered within the context of a specific case, allowing users to perform actions related to case management.</p> </li> <li> <p>Action: Alert: The <code>action:alert</code> type refers to functions manually executed in the context of an alert, enabling users to process and act on alerts within TheHive.</p> </li> </ol>"}, {"location": "thehive/user-guides/organization/functions/#function-modes", "title": "Function Modes", "text": "<p>A function in TheHive can operate in one of three modes:</p> <ul> <li>Enabled: The function will run as expected when triggered.</li> <li>Disabled: The function will not run when triggered.</li> <li>Dry-Run: The function will execute, but no entities will be created or modified in TheHive. Entity creation attempts will return <code>null</code>, making this mode ideal for testing integrations before going live.</li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#create-a-function", "title": "Create a Function", "text": "<p>Follow the steps below to create a function in TheHive:</p> <ol> <li>Navigate to the Organization Tab: On the left side of the interface, go to the \"Organization\" tab.</li> <li>Access Functions: In the navigation options, locate \"Functions\" and click on it.</li> <li>Create a New Function: Click on the + Create a function button.</li> <li>Fill Out the Create Function Form: You will be presented with the \"Create Function\" form. Fill out the following details:<ul> <li>Name: Enter a name for the function.</li> <li>Mode: Select the mode (Enabled, Disabled, or Dry-Run).</li> <li>Type: Choose the function type (API, Notification, Action: Case, Action: Alert).</li> <li>Description: Provide a brief description of the function\u2019s purpose.</li> <li>Definition: Write or paste the function's JavaScript code.</li> <li>Test Function: You can test the function using input data.</li> <li>How to Call the Function: Provides an example command for calling the function.</li> </ul> </li> <li>Save the Function: After completing the form, click Save to create the function.</li> </ol> <p> </p> <p></p>"}, {"location": "thehive/user-guides/organization/functions/#call-a-function", "title": "Call a Function", "text": "<p>Once saved, the function can then be called with an http call from your system:</p> <pre><code>curl -X POST -H 'Authorization: Bearer $API_KEY' https://&lt;thehive_url&gt;/api/v1/function/&lt;function_name&gt; -H 'Content-Type: application/json' --data '\n{\n    \"eventId\": \"d9ec98b1-410f-40eb-8634-cfe189749da6\",\n    \"date\": \"2021-06-05T12:45:36.698Z\",\n    \"title\": \"An intrusion was detected\",\n    \"details\": \"An intrusion was detected on the server 10.10.43.2\",\n    \"data\": [\n        {\"kind\": \"ip\", \"value\": \"10.10.43.2\", \"name\": \"server-ip\" },\n        {\"kind\": \"name\", \"value\": \"root\", \"name\": \"login\" },\n        {\"kind\": \"ip\", \"value\": \"92.43.123.1\", \"name\": \"origin\" }\n    ]\n}\n'\n</code></pre> <p>TheHive will take your input (the body of the http call), the definition of your function and execute the function with the input. It will respond to the HTTP call with the data returned by the function.</p>"}, {"location": "thehive/user-guides/organization/functions/#example-1-function-use-case", "title": "Example 1: Function Use Case", "text": "<p>Suppose you want to create an alert in TheHive when an event occurs in your system. Your external system may have its own event schema, similar to the example below:</p> <pre><code>{\n    \"eventId\": \"d9ec98b1-410f-40eb-8634-cfe189749da6\",\n    \"date\": \"2021-06-05T12:45:36.698Z\",\n    \"title\": \"An intrusion was detected\",\n    \"details\": \"An intrusion was detected on the server 10.10.43.2\",\n    \"data\": [\n        {\"kind\": \"ip\", \"value\": \"10.10.43.2\", \"name\": \"server-ip\" },\n        {\"kind\": \"name\", \"value\": \"root\", \"name\": \"login\" },\n        {\"kind\": \"ip\", \"value\": \"92.43.123.1\", \"name\": \"origin\" }\n    ]\n}\n</code></pre> <p>Because this format differs from TheHive's alert schema, the data needs to be transformed into the correct format.</p> <p>As an org-admin, you can create a new function for your organization to convert this input into TheHive's alert format and generate an alert. The function might look like this:</p> <pre><code>function handle(input, context) {\n    const theHiveAlert = {\n        \"type\": \"event\",\n        \"source\": \"my-system\",\n        \"sourceRef\": input.eventId,\n        \"title\": input.title,\n        \"description\": input.details,\n        \"date\": (new Date(input.date)).getTime(),\n        \"observables\": input.data.map(data =&gt; {\n            // map event data kind to TheHive Observable type\n            const dataType = data.kind === \"ip\" ? \"ip\" : \"other\";\n            return {\n                \"dataType\": dataType,\n                \"data\": data.value,\n                \"tags\": [`name:${data.name}`] // use a tag for the data name\n            };\n        })\n    };\n    // call TheHive APIs, here alert creation\n    return context.alert.create(theHiveAlert);\n}\n</code></pre> <p>Creating and testing this function allows you to effortlessly convert your external event data into a format that TheHive can process as an alert.</p>"}, {"location": "thehive/user-guides/organization/functions/#example-2-creating-an-alert-based-on-a-splunk-alert", "title": "Example 2: Creating an Alert Based on a Splunk Alert", "text": "<p>When setting up a Splunk alert, you can configure a webhook as an action. When the alert is triggered, the webhook will be invoked with a predefined payload, which cannot be modified. The payload will resemble something like this:</p> <pre><code>{\n\"sid\": \"rt_scheduler__admin__search__RMD582e21fd1bdd5c96f_at_1659705853_1.1\",\n\"search_name\": \"My Alert\",\n\"app\": \"search\",\n\"owner\": \"admin\",\n\"results_link\": \"http://8afeb4633464:8000/app/search/search?q=%7Cloadjob%20rt_scheduler__admin__search__RMD582e21fd1bdd5c96f_at_1659705853_1.1%20%7C%20head%201%20%7C%20tail%201&amp;earliest=0&amp;latest=now\",\n\"result\": {\n    \"_time\": \"1659705859.827088\",\n    \"host\": \"8afeb4633464\",\n    \"source\": \"audittrail\",\n    \"sourcetype\": \"audittrail\",\n    \"action\": \"edit_search_schedule_priority\",\n    \"info\": \"granted\",\n    \"user\": \"admin\",\n    \"is_searches\": \"0\",\n    \"is_not_searches\": \"1\",\n    \"is_modify\": \"0\",\n    \"is_not_modify\": \"1\",\n    \"_confstr\": \"source::audittrail|host::8afeb4633464|audittrail\",\n    \"_indextime\": \"1659705859\",\n    \"_kv\": \"1\",\n    \"_raw\": \"Audit:[timestamp=08-05-2022 13:24:19.827, user=admin, action=edit_search_schedule_priority, info=granted ]\",\n    \"_serial\": \"1\",\n    \"_si\": [\n    \"8afeb4633464\",\n    \"_audit\"\n    ],\n    \"_sourcetype\": \"audittrail\",\n    \"_subsecond\": \".827088\"\n}\n}\n</code></pre> <p>To convert this Splunk alert into a TheHive alert, you can use a function like the following:</p> <pre><code>function handle(input, context) {\n    const theHiveAlert = {\n        \"type\": \"splunk\",\n        \"source\": input.search_name,\n        \"sourceRef\": input.result._serial,\n        \"title\": `Splunk Alert triggered: ${input.search_name} by ${input.result.sourcetype}`,\n        \"description\": `Alert created by splunk search '${input.search_name}:\\n${input.result._raw}'`,\n        \"date\": (new Date(parseFloat(input.result._time)*1000)).getTime(),\n        \"observables\": [\n            {\"dataType\": \"hostname\", \"data\": input.result.host},\n            {\"dataType\": \"other\", \"data\": input.result.action, \"message\": \"action\"},\n            {\"dataType\": \"other\", \"data\": input.result._raw, \"message\": \"raw\"}\n        ]\n    };\n    return context.alert.create(theHiveAlert);\n}\n</code></pre> <p>In Splunk, you'll need to configure the webhook URL to point to the TheHive function URL.</p>"}, {"location": "thehive/user-guides/organization/functions/#example-3-cold-case-automation-process", "title": "Example 3: Cold Case Automation Process", "text": "<p>When invoked, this function will:</p> <ul> <li>Identify all cases marked as <code>New</code> or <code>InProgress</code> that haven't been updated in the past month.</li> <li>Add a <code>cold-case</code> tag to each of these cases.</li> </ul> <pre><code>// Will find the \"New\" or \"InProgress\" cases that were not updated since one month\n// For each case, add a tag \"cold-case\"\nfunction handle(input, context) {\n    const now = new Date();\n    const lastMonth = new Date();\n    lastMonth.setMonth(now.getMonth() - 1);\n    const filters = [\n        {\n            _name: \"filter\",\n            _and: [\n                {\n                    _or: [{ _field: \"stage\", _value: \"New\" }, { _field: \"stage\", _value: \"InProgress\" },]\n                },\n                {\n                    _lt: { _field: \"_updatedAt\", _value: lastMonth.getTime() }\n                }\n            ]\n        }\n    ];\n    const list = context.caze.find(filters);\n    const authorizedCases = list\n        .filter(caze =&gt; caze.userPermissions.indexOf(\"manageCase/update\") &gt; 0);\n    console.log(authorizedCases.map(c =&gt; c.number));\n    console.log(`Will update ${authorizedCases.length} cases`);\n\n    authorizedCases.forEach(caze =&gt; {\n        context.caze.update(caze._id, { addTags: [\"cold-case\"] })\n    });\n}\n</code></pre>"}, {"location": "thehive/user-guides/organization/functions/#context-api", "title": "Context API", "text": "<p>Info</p> <p>The objects in the context API are the same as the ones used in the v1 Http Api.</p> <p>For more details on the expected fields of each object, please refer to the Http Api Documentation</p>"}, {"location": "thehive/user-guides/organization/functions/#user", "title": "User", "text": "<ul> <li><code>userId: string</code> : login of the user executing the function</li> <li><code>userName: string</code>: name of the user executing the function</li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#http-request", "title": "Http request", "text": "<ul> <li><code>request.queryString() : Record&lt;string, string[]&gt;</code>: Dictionary with the request query string formatted as a map</li> <li><code>request.getQueryString(key: string): string | null</code>: Get a value from the query string</li> <li><code>request.getHeader(name: string): string | null</code>: Get the value of a header from the request</li> <li><code>request.headers(): Record&lt;string, string&gt;</code>: Get the request headers</li> <li><code>request.contentType: string</code>: Value of the request header Content-Type</li> <li><code>request.remoteAddress()</code>: Get the ip adress of the caller</li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#query", "title": "Query", "text": "<ul> <li><code>query.execute(query: any[])</code>: execute a query on the database (cf. Api docs =&gt; query)</li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#alert", "title": "Alert", "text": "<ul> <li><code>alert.create(input: InputCreateAlert): OutputAlert</code></li> <li><code>alert.get(id: string): OutputAlert</code></li> <li><code>alert.update(alertId: string, input: InputUpdateAlert): OutputAlert</code></li> <li><code>alert.delete(alertId: string): void</code></li> <li><code>alert.createCase(alertId: string, input: InputCreateAlert): OutputCase</code></li> <li><code>alert.bulkDelete(input: {ids: string[]}): void</code></li> <li><code>alert.mergeWithCase(alertId: string, caseId: string): OutputCase</code></li> <li><code>alert.bulkMergeWithCase( {caseId: string, alertIds: string[]} ): OutputCase</code></li> <li><code>alert.followAlert(alertId: string): OutputAlert</code></li> <li><code>alert.unfollowAlert(alertId: string): OutputAlert</code></li> <li><code>alert.importInCase(alertId: string, caseId: string): OutputAlert</code></li> <li><code>alert.bulkUpdate(input: {ids: string[]} &amp; InputUpdateAlert): void</code></li> <li><code>alert.find(query: any[]): OutputAlert[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#case", "title": "Case", "text": "<p><code>case</code> is a reserved keywork is java, so <code>caze</code> is used instead.</p> <ul> <li><code>caze.create(input: InputCreateCase): OutputCase</code></li> <li><code>caze.get(idOrNumber: string): OutputCase</code></li> <li><code>caze.update(idOrNumber: string, update: InputUpdateCase): void</code></li> <li><code>caze.merge(ids: string[]): OutputCase</code></li> <li><code>caze.delete(idOrNumber: string): void</code></li> <li><code>caze.changeCaseOwnership(idOrNumber: string, update: InputChangeCaseOwnership): void</code></li> <li><code>caze.unlinkAlert(caseId: string, alertId: string): void</code></li> <li><code>caze.mergeSimilarObservables(caseId: string): void</code></li> <li><code>caze.bulkUpdate(update: {ids: string[]} &amp; InputUpdateCase): void</code></li> <li><code>caze.bulkApplyCaseTemplate(update: {ids: string[]} &amp; InputApplyCaseTemplate): void</code></li> <li><code>caze.find(query: any[]): OutputCase[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#tasks", "title": "Tasks", "text": "<ul> <li><code>task.get(id: string): OutputTask</code></li> <li><code>task.update(idOrName: string, update: Partial&lt;OutputTask&gt;): void</code></li> <li><code>task.delete(id: string): void</code></li> <li><code>task.find(query: any[]): OutputTask[]</code></li> <li><code>task.setActionRequired(taskId: string, orgId: string): void</code></li> <li><code>task.setActionDone(taskId: string, orgId: string): void</code></li> <li><code>task.isActionRequired(taskId: string): Record&lt;string, bool&gt;</code></li> <li><code>task.createInCase(caseId: string, task: InputTask): OutputTask</code></li> <li><code>task.bulkUpdate(update: {ids: string[]} &amp; Partial&lt;OutputTask&gt;): void</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#log", "title": "Log", "text": "<ul> <li><code>log.create(taskId: string, log: InputCreateLog): OutputLog</code></li> <li><code>log.update(logId: string, update: InputUpdateLog): void</code></li> <li><code>log.delete(logId: string): void</code></li> <li><code>log.deleteAttachment(logId: string, attachmentId: string): void</code></li> <li><code>log.find(query: any[]): OutputLog[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#observable", "title": "Observable", "text": "<ul> <li><code>observable.createInCase(caseId: string, observable: InputObservable): OutputObservable</code></li> <li><code>observable.createInAlert(alertId: string, observable: InputObservable): OutputObservable)</code> </li> <li><code>observable.bulkUpdate(update: {ids: string[]} &amp; Partial&lt;OutputObservable&gt;)</code></li> <li><code>observable.get(idOrName: string): OutputObservable</code></li> <li><code>observable.update(id: string, update: Partial&lt;OutputObservable&gt;): void</code></li> <li><code>observable.delete(id: string): void</code></li> <li><code>observable.find(query: any[]): OutputObservable[]</code></li> <li><code>observable.updateAllTypes(fromType: string, toType: String): void</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#observable-type", "title": "Observable Type", "text": "<ul> <li><code>observableType.get(id: string): OutputObservableType</code></li> <li><code>observableType.delete(id: string): void</code></li> <li><code>observableType.create(ot: InputObservableType)</code></li> <li><code>observableType.find(query: any[]): OutputObservableType[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#customfield", "title": "CustomField", "text": "<ul> <li><code>customField.list(): OutputCustomField[]</code></li> <li><code>customField.update(idOrName: string, update: Partial&lt;OutputCustomField&gt;): void</code></li> <li><code>customField.delete(idOrName: string): void</code></li> <li><code>customField.create(cf: InputCustomField): OutputCustomField</code></li> <li><code>customField.find(query: any[]): OutputCustomField[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#case-template", "title": "Case Template", "text": "<ul> <li><code>caseTemplate.get(idOrName: string): OutputCaseTemplate</code> </li> <li><code>caseTemplate.update(idOrName: string, update: Partial&lt;InputCaseTemplate&gt;): void</code></li> <li><code>caseTemplate.delete(idOrName: string): void</code></li> <li><code>caseTemplate.create(template: InputCaseTemplate): OutputCaseTemplate</code></li> <li><code>caseTemplate.find(query: any[]): OutputCaseTemplate[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#procedure", "title": "Procedure", "text": "<ul> <li><code>procedure.bulkCreateInCase(caseId: string, input: {procedures: InputProcedure[]}): OutputProcedure[]</code></li> <li><code>procedure.bulkCreateInAlert(alertId: string, input: {procedures: InputProcedure[]}): OutputProcedure[]</code></li> <li><code>procedure.createInCase(caseId: string, procedure: InputProcedure): OutputProcedure</code></li> <li><code>procedure.createInAlert(alertId: string, procedure: InputProcedure): OutputProcedure</code></li> <li><code>procedure.update(id: string, procedure: Partial&lt;OutputProcedure&gt;): void</code></li> <li><code>procedure.delete(id: string): void</code></li> <li><code>procedure.find(query: any[])</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#case-status", "title": "Case Status", "text": "<ul> <li><code>caseStatus.create(input: InputCreateCaseStatus): OutputCaseStatus</code></li> <li><code>caseStatus.update(idOrName: string, update: InputUpdateCaseStatus): void</code></li> <li><code>caseStatus.delete(idOrName: string): void</code></li> <li><code>caseStatus.find(query: any[]): OutputCaseStatus[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#alert-status", "title": "Alert Status", "text": "<ul> <li><code>alertStatus.create(input: InputCreateAlertStatus): OutputAlerttatus</code></li> <li><code>alertStatus.update(idOrName: string, update: InputUpdateAlertStatus): void</code></li> <li><code>alertStatus.delete(idOrName: string): void</code></li> <li><code>alertStatus.find(query: any[]): OutputAlerttatus[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#comment", "title": "Comment", "text": "<ul> <li><code>comment.createInCase(caseId: string, comment: InputCreateComment): OutputComment</code></li> <li><code>comment.createInAlert(alertId:: string, comment: InputCreateComment): OutputComment</code></li> <li><code>comment.update(id: string, update: InputUpdateComment): void</code></li> <li><code>comment.delete(id: string): void</code></li> <li><code>comment.find(query: any[]): OutputComment[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#share", "title": "Share", "text": "<ul> <li><code>share.setCaseShares(caseId: string, input: InputCreateShares): OutputShare[]</code></li> <li><code>share.removeSharesFromCase(caseId: string, input: InputRemoveShares): void</code></li> <li><code>share.removeShare(shareId: string): void</code></li> <li><code>share.removeShares(input: {ids: string[]} ): void</code></li> <li><code>share.removeTaskShares(taskId: string, input: InputRemoveShares): void</code></li> <li><code>share.removeObservableShares(observableId: string, input: InputRemoveShares): void</code></li> <li><code>share.listShareCases(caseId: string): OutputShare[]</code></li> <li><code>share.listShareTasks(taskId: string): OutputShare[]</code></li> <li><code>share.listShareObservables(observableId: string): OutputShare[]</code></li> <li><code>share.shareCase(caseId: string, input: InputCreateShare): OutputShare</code></li> <li><code>share.shareTask(taskId: string, input: InputCreateShare): OutputShare</code></li> <li><code>share.shareObservable(observableId: string, input: InputCreateShare): OutputShare</code></li> <li><code>share.updateShare(shareId: string, update: InputUpdateShare): void</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#organization", "title": "Organization", "text": "<ul> <li><code>organisation.get(orgIdOrName: string): OutputOrganisation</code></li> <li><code>organisation.create(org: InputCreateOrganisation): OutputOrganisation</code></li> <li><code>organisation.update(orgIdOrName: string, update: InputUpdateOrganisation): void</code></li> <li><code>organisation.bulkLink(orgIdOrName: string, links: InputOrganisationBulkLink): void</code></li> <li><code>organisation.listLinks(orgIdOrName: string): OutputOrganisationLink[]</code></li> <li><code>organisation.listSharingProfiles(): OutputSharingProfile[]</code></li> <li><code>organisation.link(orgA: string, orgB: string, link: InputOrganisationLink | null): void</code></li> <li><code>organisation.unlink(orgA: string, orgB: string): void</code></li> <li><code>organisation.find(query: any[]): OutputOrganisation[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#profile", "title": "Profile", "text": "<ul> <li><code>profile.get(idOrName: string): OutputProfile</code></li> <li><code>profile.update(profileIdOrName: string, update: InputUpdateProfile): void</code></li> <li><code>profile.delete(profileIdOrName: string): void</code></li> <li><code>profile.create(profile: InputCreateProfile): OutputProfile</code></li> <li><code>profile.find(query: any[]): OutputProfile[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#custom-event", "title": "Custom Event", "text": "<ul> <li><code>customEvent.createInCase(caseId: string, input: InputCreateCustomEvent): OutputCustomEvent</code></li> <li><code>customEvent.update(id: string, update: InputUpdateCustomEvent): void</code></li> <li><code>customEvent.delete(id: string): void</code></li> <li><code>customEvent.find(query: any[]): OutputCustomEvent[]</code></li> </ul>"}, {"location": "thehive/user-guides/organization/functions/#function", "title": "Function", "text": "<ul> <li><code>function.create(function: InputCreateFunction): OutputFunction</code></li> <li><code>function.update(functionIdOrName: string, update: InputUpdateFunction): void</code></li> <li><code>function.delete(functionIdOrName: string): void</code></li> <li><code>function.find(query: any[]): OutputFunction</code></li> </ul>"}, {"location": "thehive/user-guides/organization/ui-configuration/", "title": "UI Configuration", "text": ""}, {"location": "thehive/user-guides/organization/ui-configuration/#ui-configuration", "title": "UI configuration", "text": "<p>At the organization level, few UI behaviours can be configured.</p> <p>Access to the list by opening the Organization menu, and the UI Configuration tab.</p> <p> </p> UI configuration panel"}, {"location": "thehive/user-guides/organization/ui-configuration/#configuration-parameters", "title": "Configuration parameters", "text": "Hide Empty Case button disabled by default. When enabled, users from the current organization cannot create empty Cases and will have to chose between create a Case using a template or from an archive Disable Empty Case Merge Alerts into closed cases disabled by default. When enabled, users from the current organization are allowed to choose a closed Case to merge Alerts in Disallow refresh option in dashboards disabled by default. When enabled, users from the current organization cannot refresh dashboards. This could be useful if performance issues are encountered with the UI with a certain number of users Don't refresh dashboards Disallow \"All\" period option in dashboards disabled by default. When enabled, users from the current organization cannot use the All period in dashboards. This could be useful if performance issues are encountered with the UI Don't select period on dashboards Select the default filter of alert case similarity panel Default filter for Similar Case tab, in the view of an Alert Select default filters for Case similarity Result in Similar Cases tab in Alerts Define the default date format used to display dates Select which format you want the dates to be displayed within the current organization"}, {"location": "thehive/user-guides/organization/configure-organization/manage-attachments/about-attachments/", "title": "About Attachments", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-attachments/about-attachments/#about-attachments", "title": "About Attachments", "text": "<p>In this section you can find information about Attachments . </p> <p>To add a new attachment:</p> <ol> <li>On the attachments tab, Click the + to add a new attachment.</li> </ol> <p></p> <p>A new window opens. </p> <p></p> <ol> <li>Click the Drop file or Click option in attachment. </li> <li>Click the Confirm button. </li> </ol> <p>NOTE: A user can add one or more files simultaneously. </p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-attachments/update-attachments/", "title": "Update Attachments", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-attachments/update-attachments/#update-attachments", "title": "Update Attachments", "text": "<p>In this section you can find more information about updating Attachments . </p> <p>To copy an attachment:</p> <ol> <li>On the attachments tab, Click the ellipsis (...) corresponding to the attachment to view more options.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-attachments/update-attachments/#copy", "title": "Copy", "text": "<p>The copy URL option lets you copy the url of the attachment. </p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-attachments/update-attachments/#download", "title": "Download", "text": "<p>The download option lets you download the attachment. </p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-attachments/update-attachments/#remove", "title": "Remove", "text": "<p>The Remove option lets you remove/delete the attachment. </p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-custom-tags/about_custom_tags/", "title": "Custom Tags", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-custom-tags/about_custom_tags/#custom-tags", "title": "Custom Tags", "text": "<p>In this section you can find information about custom tags. </p> <p>Custom tags or free tags are free text tags associated with TheHive objects. Custom tags are not shared across organizations. Users can define sensitive data in tags without worrying about any data leakage issue.</p> <p>A user can add, edit, delete, and change the colour of a custom tags. A user can use the toggle filter button to apply filters, add filters and clear the filters. By default, the custom tags page displays a list of 30 items that can be navigated using the previous and next buttons. A user can manage views.  </p> <p>A user can view all the details about the number of cases, alerts, observables, templates, and details of created By, dates of creation and dates of update. </p> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-custom-tags/manage_views/", "title": "Manage Views", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-custom-tags/manage_views/#manage-views", "title": "Manage Views", "text": "<p>A user can manage views. </p> <p>To manage views:</p> <ol> <li>Click the default button. </li> <li>Click the Manage Views from the list. </li> </ol> <p></p> <p>A new page opens. It has the Name of the view and the corresponding Actions. </p> <ol> <li>Click the ellipsis (...) corresponding to the name of the view that you want to delete. </li> <li>Click Delete.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-custom-tags/update/", "title": "Update Custom Tags", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-custom-tags/update/#update-custom-tags", "title": "Update Custom Tags", "text": "<p>To update custom tags:</p> <ol> <li>Edit the Name of the tag. </li> <li>Click the tick mark to save changes.</li> <li>Click the cross mark to discard changes. </li> </ol> <p></p> <p>To update colour of the tag:</p> <ol> <li>Edit the Colour of the tag.</li> <li>Select the colour from the pallette.</li> <li>Click the tick mark to save changes.</li> <li>Click the cross mark to discard changes. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-endpoints/about-endpoints/", "title": "About Endpoints", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-endpoints/about-endpoints/#about-endpoints", "title": "About endpoints", "text": "<p>In this section you can find information regarding endpoints. An endpoint is the point of entry in a communication channel when two systems interact with each other. </p> <p>A user can create an endpoint. </p> <p></p> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-endpoints/about-endpoints/#supported-connectors", "title": "Supported connectors", "text": "<ol> <li>Webhook.</li> <li>Mattermost.</li> <li>Slack.</li> <li>Http.</li> </ol>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-endpoints/add_endpoints/", "title": "Add Endpoints", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-endpoints/add_endpoints/#add-endpoints", "title": "Add endpoints", "text": "<p>A user can create an endpoint. </p> <p>To Add an Endpoint:</p> <ol> <li>Click the + button or Click the Add a new endpoint link.</li> </ol> <p></p> <p>A new page opens.</p> <ol> <li>Select the connector.</li> <li>Click the Save button.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-notifications/manage_notification/", "title": "Manage Notification", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-notifications/manage_notification/#manage-notification", "title": "Manage Notification", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-notifications/manage_notification/#add-notification", "title": "Add notification", "text": "<p>A user can create a notification. </p> <p>To Add a notification:</p> <ol> <li>Enter notfification Name.</li> <li>Send notification to every user in the organization. </li> <li>Select Trigger from the list. (Refer to <code>Trigger events</code>)</li> <li>Enable notification.</li> <li>Select Notifiers. (Refer to <code>Selecting supported notifiers</code>)</li> <li>Click the Save button.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-notifications/supported-notifiers/", "title": "Supported notifiers", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-notifications/supported-notifiers/#supported-notifiers", "title": "Supported notifiers", "text": "<ol> <li> <p>Click EmailerToAddr.</p> <ol> <li>Enter Subject.</li> <li>Enter the email address of the sender in From.</li> <li>Enter the email address of the receiver in To.</li> <li>Click Add variable to add in the Template field.</li> <li>Click the Save button.</li> </ol> <p></p> </li> <li> <p>Click HttpRequest.</p> <ol> <li>Select Endpoint. (Refer to <code>Add endpoints</code>)</li> <li>Select the HTTP Method.</li> <li>Either enter the URL. </li> <li>Or select the option Use endpoint url as prefix. </li> <li>Click Add variable to add in the Template field.</li> <li>Select option to Log errors. </li> <li>Click the + to add headers.         <ul> <li>enter a valid header key.</li> <li>enter a valid header value.</li> </ul> </li> <li>Under Authentication select the Type. </li> <li>Select the option Proxy. </li> <li>Select the option Do not check certificate Authority. (Not recommended)</li> <li>Select the option Disable hostname verification.</li> <li>Click the Save button.</li> </ol> <p></p> </li> <li> <p>Click MatterMost.</p> <ol> <li>Select Endpoint.(Refer to <code>Add endpoints</code>)</li> <li>Enter the Username.</li> <li>Enter the Channel.</li> <li>Click Add variable to add in the Template field.</li> <li>Click the Save button.</li> </ol> <p></p> </li> <li> <p>Click Slack.</p> <ol> <li>Select Endpoint. (Refer to <code>Add endpoints</code>)</li> <li>Click Add variable to add in the Text Template field.</li> <li>Enter the Username.</li> <li>Enter the Channel.</li> <li>Check the box for Advanced Settings <p>If you need help filling the Advance Settings fields, check the Slack documentation link </p> </li> <li>Enter a Blocks template.</li> <li>Enter an Attachment template.</li> <li>Select As User.</li> <li>Enter an icon emoji.</li> <li>Enter icon URL.</li> <li>Select Link names.</li> <li>Select Markdown.</li> <li>Enter a valid Parse string.</li> <li>Select Unfirl Links.</li> <li>Select Unfirl Media. </li> <li>Click the Save button.</li> </ol> <p></p> </li> <li> <p>Click Kafka.</p> <ol> <li>Enter a Topic.</li> <li>Enter type the list of servers in Bootstrap servers. </li> </ol> <p></p> </li> </ol>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-notifications/triggering-events/", "title": "Trigger events", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-notifications/triggering-events/#trigger-events", "title": "Trigger events", "text": "<ol> <li> <p>Default (AnyCase).</p> </li> <li> <p>Case.</p> <ul> <li>CaseClosed</li> <li>CaseShared</li> <li>CaseCreated</li> </ul> </li> <li> <p>Alert.</p> <ul> <li>AlertCreated</li> <li>AlertImported</li> </ul> </li> <li> <p>Observable.</p> <ul> <li>ObservableCreated</li> </ul> </li> <li> <p>Job.</p> <ul> <li>JobFinished</li> </ul> </li> <li> <p>Task.</p> <ul> <li>TaskAssigned</li> <li>TaskClosed</li> </ul> </li> </ol>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-case-report-templates/", "title": "About Case Report Templates", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-case-report-templates/#about-case-report-templates", "title": "About Case Report Templates", "text": "<p>Case report templates generate reports in a predefined format, available from case descriptions.</p> <p>This topic provides an overview of case report templates and their usage in TheHive.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-case-report-templates/#benefits", "title": "Benefits", "text": "<p>Use case reports to:</p> <ul> <li>Highlight key details for faster security actions</li> <li>Enhance better collaboration and decision-making</li> <li>Standardize reports for accurate analysis and comparisons</li> <li>Keep structured records for audits and regulations</li> <li>Build an archive for historical analysis and threat prevention</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-case-report-templates/#usage", "title": "Usage", "text": "<p>Create a case report template to automatically generate reports in case descriptions.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-case-report-templates/#structure", "title": "Structure", "text": "<p>Every case report template includes a default header and footer section, which you can customize with content and case variables. You can't move or delete these sections, but they won't appear in the case report if left empty.</p> <p>You can add widgets between these sections to display case data. You can rearrange the order of widgets at any time.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-case-report-templates/#permissions", "title": "Permissions", "text": "<p>Required permissions for managing case report templates</p> <p>Only users with the <code>manageCaseReportTemplate</code> permission can manage case report templates in TheHive.</p> <p>Once created, case report templates are automatically available to all users in your organization within case descriptions.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-case-report-templates/#next-steps", "title": "Next steps", "text": "<ul> <li>About Widgets</li> <li>Create a Case Report Template</li> <li>Edit a Case Report Template</li> <li>Delete a Case Report Template</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-widgets/", "title": "About Widgets", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-widgets/#about-widgets", "title": "About Widgets", "text": "<p>Several widget types are available for case report templates in TheHive.</p> <p>This topic describes each widget type and its attributes.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-widgets/#text-widget", "title": "Text widget", "text": "<p>Add a text block to your case report template.</p> <p>Text widget configuration includes:</p> <ul> <li>A title for the text block</li> <li>The content of the text block, with the option to include case variables</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-widgets/#image-widget", "title": "Image widget", "text": "<p>Add an image to your case report template.</p> <p>Supported image formats</p> <p>Image widgets only support JPG, JPEG, and PNG formats.</p> <p>Image widget configuration includes:</p> <ul> <li>A title for the image</li> <li>An image that you can upload by dragging and dropping or selecting from your computer</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-widgets/#table-widget", "title": "Table widget", "text": "<p>Add a table to your case report template.</p> <p>Table widget configuration includes:</p> <ul> <li>A title for the table</li> <li>A parameter selection to choose from observables, tasks, TTPs, alerts, or custom fields, along with the data to display</li> </ul> <p>Protect observable URLs</p> <p>Turn on the Protect data? toggle to defang URLs and prevent accidental clicks.</p> <ul> <li>Sorting rules and filters to refine the displayed data</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-widgets/#list-widget", "title": "List widget", "text": "<p>Add a list to your case report template.</p> <p>List widget configuration includes:</p> <ul> <li>A title for the list</li> <li>A parameter selection to choose from observables, tasks, TTPs, or alerts, along with the data to display</li> </ul> <p>Protect observable URLs</p> <p>Turn on the Protect data? toggle to defang URLs and prevent accidental clicks.</p> <ul> <li>Sorting rules and filters to refine the displayed data</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-widgets/#timeline-widget", "title": "Timeline widget", "text": "<p>Add a case timeline in a list format to your case report template.</p> <p>Timeline widget configuration includes:</p> <ul> <li>A title for the timeline</li> <li>A selection of multiple parameters, allowing you to choose from alerts, case events, tasks, task logs, sighted IOCs, TTPs, and custom events</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-widgets/#comments-widget", "title": "Comments widget", "text": "<p>Available since version 5.4</p> <p>Comments widgets are available only for users running TheHive version 5.4 or later.</p> <p>Add case comments to your case report template.</p> <p>Comments widget configuration includes:</p> <ul> <li>A title for the comments widget</li> <li>The maximum number of comments to display</li> <li>Filters to refine the displayed comments</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-widgets/#pages-widget", "title": "Pages widget", "text": "<p>Available since version 5.4</p> <p>Pages widgets are available only for users running TheHive version 5.4 or later.</p> <p>Add case pages to your case report template.</p> <p>Pages widget configuration includes:</p> <ul> <li>A title for the pages widget</li> <li>Filters to refine the displayed pages</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/about-widgets/#next-steps", "title": "Next steps", "text": "<ul> <li>About Case Report Templates</li> <li>Create a Case Report Template</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/create-a-case-report-template/", "title": "Create a Case Report Template", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/create-a-case-report-template/#how-to-create-a-case-report-template", "title": "How to Create a Case Report Template", "text": "<p>This topic provides step-by-step instructions for creating a case report template in TheHive.</p> <p>Required permissions for managing case report templates</p> <p>Only users with the <code>manageCaseReportTemplate</code> permission can manage case report templates in TheHive.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/create-a-case-report-template/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organization view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Templates tab.</p> <p></p> </li> <li> <p>Select the Reports tab.</p> <p></p> </li> <li> <p>Two options are available:</p> <ul> <li> <p>Create a case report template from scratch by selecting .</p> </li> <li> <p>Duplicate an existing case report template by selecting  next to the case report template you want to duplicate, then select Duplicate.</p> </li> </ul> </li> <li> <p>In the drawer, enter the following fields:</p> <p>Title * The title users will see when selecting reports in case descriptions.</p> <p>Description A brief summary of your case report template, outlining its purpose and contents.</p> </li> <li> <p>Select Add report template or Edit report template. </p> </li> <li> <p>Drag available widgets to position them as needed.</p> <p></p> </li> <li> <p>Enter the required information for the widget.</p> </li> <li> <p>Select Confirm.</p> </li> <li> <p>Select  to edit sections,  to duplicate them, and  to delete them.</p> </li> <li> <p>Select  to preview the case report display.</p> </li> <li> <p>Select  to save your case report template.</p> </li> </ol>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/create-a-case-report-template/#next-steps", "title": "Next steps", "text": "<ul> <li>Edit a Case Report Template</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/delete-a-case-report-template/", "title": "Delete a Case Report Template", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/delete-a-case-report-template/#how-to-delete-a-case-report-template", "title": "How to Delete a Case Report Template", "text": "<p>This topic provides step-by-step instructions for deleting a case report template in TheHive.</p> <p>Required permissions for managing case report templates</p> <p>Only users with the <code>manageCaseReportTemplate</code> permission can manage case report templates in TheHive.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/delete-a-case-report-template/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organization view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Templates tab.</p> <p></p> </li> <li> <p>Select the Reports tab.</p> <p></p> </li> <li> <p>Select  next to the case report template you want to delete.</p> </li> <li> <p>Select Delete.</p> </li> </ol>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/delete-a-case-report-template/#next-steps", "title": "Next steps", "text": "<ul> <li>Create a Case Report Template</li> <li>Edit a Case Report Template</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/edit-a-case-report-template/", "title": "Edit a Case Report Template", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/edit-a-case-report-template/#how-to-edit-a-case-report-template", "title": "How to Edit a Case Report Template", "text": "<p>This topic provides step-by-step instructions for editing a case report template in TheHive.</p> <p>Required permissions for managing case report templates</p> <p>Only users with the <code>manageCaseReportTemplate</code> permission can manage case report templates in TheHive.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/edit-a-case-report-template/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organization view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Templates tab.</p> <p></p> </li> <li> <p>Select the Reports tab.</p> <p></p> </li> <li> <p>Select the case report template you want to edit, or select  next to the case report template you want to edit and then Edit.</p> </li> <li> <p>Drag available widgets to position them as needed.</p> <p></p> </li> <li> <p>Enter the required information for the widget.</p> </li> <li> <p>Select Confirm.</p> </li> <li> <p>Select  to edit sections,  to duplicate them, and  to delete them.</p> </li> <li> <p>Select  to preview the case report display.</p> </li> <li> <p>Select  to save your case report template.</p> </li> </ol>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-report-templates/edit-a-case-report-template/#next-steps", "title": "Next steps", "text": "<ul> <li>Delete a Case Report Template</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/about-case-templates/", "title": "About Case Templates", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/about-case-templates/#about-case-templates", "title": "About Case Templates", "text": "<p>Case templates streamline case creation in TheHive by automatically filling predefined fields.</p> <p>This topic provides an overview of case template usage in TheHive.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/about-case-templates/#benefits", "title": "Benefits", "text": "<p>Use case templates to:</p> <ul> <li>Simplify case creation workflows</li> <li>Save time when creating new cases</li> <li>Maintain consistency in case descriptions</li> <li>Enrich ongoing cases by adding additional information</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/about-case-templates/#usage", "title": "Usage", "text": "<p>You can create a case from a case template when initiating a new case.</p> <p>You can also apply a case template to an existing case.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/about-case-templates/#permissions", "title": "Permissions", "text": "<p>Required permissions for managing case templates</p> <p>Only users with the <code>manageCaseTemplate</code> permission can manage case templates in TheHive.</p> <p>Once created, case templates are automatically available to all users in your organization.</p> <p>If you need to share a case template with another organization or TheHive instance, you can export it and import it.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/about-case-templates/#next-steps", "title": "Next steps", "text": "<ul> <li>Create a Case Template</li> <li>Create a Case</li> <li>Apply a Case Template</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/create-a-case-template/", "title": "Create a Case Template", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/create-a-case-template/#how-to-create-a-case-template", "title": "How to Create a Case Template", "text": "<p>This topic provides step-by-step instructions for creating a case template in TheHive.</p> <p>Duplicate an existing case template</p> <p>Since version 5.4, you can duplicate an existing case template within your organization to quickly pre-fill fields and streamline the process.</p> <p>To import an existing case template from another organization or TheHive instance, refer to the Import a Case Template topic.</p> <p>Required permissions for managing case templates</p> <p>Only users with the <code>manageCaseTemplate</code> permission can manage case templates in TheHive.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/create-a-case-template/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organization view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Templates tab.</p> <p></p> </li> <li> <p>Select the Cases tab.</p> <p></p> </li> <li> <p>Two options are available:</p> <ul> <li> <p>Create a case template from scratch by selecting .</p> </li> <li> <p>Duplicate an existing template by selecting  next to the case template you want to duplicate, then select Duplicate (available since version 5.4).</p> </li> </ul> </li> <li> <p>In the Adding a case template drawer, enter values in some or all the following fields to pre-fill:</p> <p>Prefix A prefix that's automatically added to case titles. The prefix value isn't visible when creating a case from the template but applies after creation. Use it to categorize cases for reporting.</p> <p>Name * The name of the case template. This name identifies the case template in the API.</p> <p>Display name The name that appears when users select this template to create a new case or to apply it to an existing case. If you don't specify a display name, the case template name is used.</p> <p>TLP * The TLP level for the case. It guides analysts on how they can share case information.</p> <p>PAP * The PAP level for the case. It guides analysts on how they can use case data.</p> <p>Severity The default severity level for cases.</p> <p>Tags One or more tags to categorize cases. Only tags defined in the taxonomies are available for selection.</p> <p>Description * A description for cases.</p> <p>Tasks One or more tasks for cases.</p> <p>Custom fields One or more custom fields for cases, with or without predefined values.</p> <p>Pages A page template to document cases.</p> </li> <li> <p>Select Confirm case template creation.</p> </li> </ol>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/create-a-case-template/#next-steps", "title": "Next steps", "text": "<ul> <li>Edit a Case Template</li> <li>Export a Case Template</li> <li>Create a Case</li> <li>Apply a Case Template</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/delete-a-case-template/", "title": "Delete a Case Template", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/delete-a-case-template/#how-to-delete-a-case-template", "title": "How to Delete a Case Template", "text": "<p>This topic provides step-by-step instructions for deleting a case template in TheHive.</p> <p>Required permissions for managing case templates</p> <p>Only users with the <code>manageCaseTemplate</code> permission can manage case templates in TheHive.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/delete-a-case-template/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organization view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Templates tab.</p> <p></p> </li> <li> <p>Select the Cases tab.</p> <p></p> </li> <li> <p>Select  next to the case template you want to delete.</p> </li> <li> <p>Select Delete.</p> </li> <li> <p>Select OK.</p> </li> </ol>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/delete-a-case-template/#next-steps", "title": "Next steps", "text": "<ul> <li>Export a Case Template</li> <li>Create a Case</li> <li>Apply a Case Template</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/edit-a-case-template/", "title": "Edit a Case Template", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/edit-a-case-template/#how-to-edit-a-case-template", "title": "How to Edit a Case Template", "text": "<p>This topic provides step-by-step instructions for editing a case template in TheHive.</p> <p>Required permissions for managing case templates</p> <p>Only users with the <code>manageCaseTemplate</code> permission can manage case templates in TheHive.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/edit-a-case-template/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organization view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Templates tab.</p> <p></p> </li> <li> <p>Select the Cases tab.</p> <p></p> </li> <li> <p>Select  next to the case template you want to edit.</p> </li> <li> <p>Select Edit.</p> </li> <li> <p>In the Editing a case template drawer, enter your new values in the following fields:</p> <p>Prefix A prefix that's automatically added to case titles. The prefix value isn't visible when creating a case from the template but applies after creation. Use it to categorize cases for reporting.</p> <p>Name * The name of the case template. This name identifies the case template in the API.</p> <p>Display name The name that appears when users select this template to create a new case or to apply it to an existing case. If you don't specify a display name, the case template name is used.</p> <p>TLP * The TLP level for the case. It guides analysts on how they can share case information.</p> <p>PAP * The PAP level for the case. It guides analysts on how they can use case data.</p> <p>Severity The default severity level for cases.</p> <p>Tags One or more tags to categorize cases. Only tags defined in the taxonomies are available for selection.</p> <p>Description * A description for cases.</p> <p>Tasks One or more tasks for cases.</p> <p>Custom fields One or more custom fields for cases, with or without predefined values.</p> <p>Pages A page template to document cases.</p> </li> <li> <p>Select Confirm case template creation.</p> </li> </ol>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/edit-a-case-template/#next-steps", "title": "Next steps", "text": "<ul> <li>Export a Case Template</li> <li>Create a Case</li> <li>Apply a Case Template</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/export-a-case-template/", "title": "Export a Case Template", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/export-a-case-template/#how-to-export-a-case-template", "title": "How to Export a Case Template", "text": "<p>This topic provides step-by-step instructions for exporting a case template in TheHive.</p> <p>This is useful if you want to share a case template with another organization or TheHive instance.</p> <p>Share your case templates</p> <p>Contribute your case templates to our public GitHub repository.  </p> <p>Before submitting your pull request: - Remove any sensitive information. - Exclude custom fields.  </p> <p>Each contribution is reviewed by StrangeBee before being published.</p> <p>Required permissions for managing case templates</p> <p>Only users with the <code>manageCaseTemplate</code> permission can manage case templates in TheHive.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/export-a-case-template/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organization view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Templates tab.</p> <p></p> </li> <li> <p>Select the Cases tab.</p> <p></p> </li> <li> <p>Select  next to the case template you want to export.</p> </li> <li> <p>Select Export case template to export the case template in JSON format.</p> </li> </ol>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/export-a-case-template/#next-steps", "title": "Next steps", "text": "<ul> <li>Import a Case Template</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/import-a-case-template/", "title": "Import a Case Template", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/import-a-case-template/#how-to-import-a-case-template", "title": "How to Import a Case Template", "text": "<p>This topic provides step-by-step instructions for importing a case template in TheHive.</p> <p>This is useful if you want to use a case template from another organization or TheHive instance.</p> <p>Find case templates</p> <p>Check out our public GitHub repository for case templates shared by other users.</p> <p>Required permissions for managing case templates</p> <p>Only users with the <code>manageCaseTemplate</code> permission can manage case templates in TheHive.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/import-a-case-template/#procedure", "title": "Procedure", "text": "<ol> <li> <p>Go to the Organization view from the sidebar menu.</p> <p></p> </li> <li> <p>Select the Templates tab.</p> <p></p> </li> <li> <p>Select the Cases tab.</p> <p></p> </li> <li> <p>Select Import case template.</p> </li> <li> <p>In the Importing a case template drawer, drop a JSON file directly into the Attachment section or select it from your computer. Use the file you obtained from exporting the case template.</p> </li> <li> <p>Select Confirm case template import.</p> </li> </ol>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/case-templates/import-a-case-template/#next-steps", "title": "Next steps", "text": "<ul> <li>Create a Case</li> <li>Apply a Case Template</li> </ul>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/page-templates/page-templates/", "title": "Page Templates Management", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/page-templates/page-templates/#define-page-templates", "title": "Define Page templates", "text": "<p>This section contains the Page templates you prepare for your organization.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/page-templates/page-templates/#list-of-page-templates", "title": "List of Page Templates", "text": "<p>Access to the list by opening the Organization menu, then the Templates tab, and the Pages tab.</p> <p> </p> List of Pages templates <p>Click the  button to create a new Page template.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/page-templates/page-templates/#new-page-template", "title": "New Page template", "text": "Create a page template"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/page-templates/page-templates/#configuration-parameters", "title": "Configuration parameters", "text": "Title Page template title. Used to identify the Page template with the API. Also used as a page title when the template is used in a case. Category Category for grouping pages on a common theme. Is used as a page tree in the case of. Content Default page content when the page template is used in a case."}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/page-templates/page-templates/#importexport", "title": "Import/Export", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/page-templates/page-templates/#export-a-page-template", "title": "Export a Page template", "text": "<p>Page templates can be exported and stored as JSON files by clicking on the option icon  and selecting  Export page template</p> <p></p> Export a page template"}, {"location": "thehive/user-guides/organization/configure-organization/manage-templates/page-templates/page-templates/#import-a-page-template", "title": "Import a Page template", "text": "<p>Click on the button Import Page Template and select the JSON formatted file to import.</p> <p></p> Import a page template"}, {"location": "thehive/user-guides/organization/configure-organization/manage-ui-configuration/about-ui-configuration/", "title": "About UI Configuration", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-ui-configuration/about-ui-configuration/#about-ui-configuration", "title": "About UI Configuration", "text": "<p>In this section you can find information about UI Configuration . </p> <p>To configure the UI:</p> <ol> <li>Select the option Hide Empty Case Button to disallow creating empty cases.</li> <li>Select the option Merge alerts into closed cases to disallow merging alerts into closed cases.</li> <li>Select the option Disallow refresh option in dashboards to disallow the refresh option in dashboards</li> <li>Select the default filter of alert case similarity panel from the list.</li> <li>Define the default date format used to display dates.<ul> <li>e.g. YYYY-MM-DD HH:mm</li> </ul> </li> <li>Click the Save button. </li> </ol> <p></p> <p>NOTE:  Default date format can be configured at the organization level, by defining the preferred format in the UI Configuration view. This requires a user with org-admin profile or any profile with manageConfig permission.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/add-delete-user/", "title": "Users (Add/Delete)", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/add-delete-user/#users-adddelete", "title": "Users (Add/Delete)", "text": "<p>After you login to TheHive application, you can see the organization icon on the page. </p> <ol> <li>Click the Organization icon. </li> </ol> <p></p> <p>On the first tab, you can find information about Users. You can add and delete user details.</p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/add-delete-user/#add-user", "title": "Add User", "text": "<p>To Add the user details:</p> <ol> <li>Click the + to Add user. </li> </ol> <p></p> <p>A new window opens.</p> <ol> <li>Enter Login credentials.</li> <li>Enter the Name.</li> <li>Select a Profile from the list. </li> <li>Click the Save and add another button to add more users. </li> <li>Click the Save button to add a user. </li> </ol> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/add-delete-user/#delete-user", "title": "Delete User", "text": "<p>If a user has left the organization in such cases a user profile may be deleted. </p> <p>To Delete the user details:</p> <ol> <li>Click the ellipsis (...) corresponding to the required user.</li> <li>Click the Delete option.</li> </ol> <p></p> <p>The following message pops up:</p> <ol> <li>Click the OK button.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/lock/", "title": "Lock User", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/lock/#lock-user", "title": "Lock User", "text": "<p>If a user is on contract in the organization and the contract ends, in such cases a user profile may be locked. </p> <p>To lock the user details:</p> <ol> <li>Click the ellipsis (...) corresponding to the user details that you want to lock.</li> <li>Click the Lock option.</li> </ol> <p></p> <p>A new pop up message opens.</p> <ol> <li>Click the OK button.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/manage-views/", "title": "Manage Views", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/manage-views/#manage-views", "title": "Manage Views", "text": "<p>In this section, you can find information about managing views.  </p> <p>To manage views: </p> <ol> <li>Click the default button. </li> <li>Click Manage Views from the list. </li> </ol> <p></p> <p>A new page opens. It has the Name of the view and the corresponding Actions. </p> <ol> <li>Click the ellipsis (...) corresponding to the name of the view.</li> <li>Select the action. e.g. Delete</li> </ol> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/preview/", "title": "Preview", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/preview/#preview", "title": "Preview", "text": "<p>You can manage previews to see the details of a specific user.</p> <p>To preview the user details:</p> <p>On the list of users page, there is a Preview button corresponding to the specific user name.</p> <ol> <li>Click the Preview option. </li> </ol> <p></p> <p>The user details preview window opens.</p> <p>You can see details like the id, created by, created at date, updated date, name, login id, email, logo, MFA, API Key, and locked status of the user. </p> <p></p>"}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/sort/", "title": "Sort", "text": ""}, {"location": "thehive/user-guides/organization/configure-organization/manage-users/sort/#sort", "title": "Sort", "text": "<p>If a user wants to re-arranged any field, it can be done using the sort option.</p> <p>To sort on a field:</p> <ol> <li>Click the small arrows beside the field to be sorted.</li> </ol> <p></p>"}, {"location": "thehive/user-guides/organization/notifications/analyzers/", "title": "Analyzers", "text": ""}, {"location": "thehive/user-guides/organization/notifications/email-to-addr/", "title": "Email to addr", "text": ""}, {"location": "thehive/user-guides/organization/notifications/email-to-users/", "title": "Email to users", "text": ""}, {"location": "thehive/user-guides/organization/notifications/endpoints/", "title": "Endpoints", "text": ""}, {"location": "thehive/user-guides/organization/notifications/filteredevents/", "title": "Filtered Events Setup", "text": ""}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#how-to-write-filtered-events-for-notifications", "title": "How to write filtered events for notifications ?", "text": "Filtered event example: \"Case severity has been updated to High or Critical\" <p>Selecting \u201cFilteredEvent\u201d opens an empty field where we set our custom filter. The filters will apply to the audit of every actions that are happening in your organization. When there is a match, a notification is sent. </p> <p>Info</p> <p>We recommend reading this blog post that introduces the capabilities of filtered events.</p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#anatomy-of-an-audit", "title": "Anatomy of an audit", "text": "<p>An audit is presented as a json like this:</p> <pre><code>{\n  \"_id\": \"~327684328\",\n  \"_type\": \"Audit\",\n  \"_createdBy\": \"director@movies.io\",\n  \"_createdAt\": 1694441999960,\n  \"action\": \"update\",\n  \"requestId\": \"74dc37479904ebe7:3957d351:18a847d4266:-8000:109\",\n  \"rootId\": \"~327925760\",\n  \"details\": {\n    \"status\": \"InProgress\",\n    \"stage\": \"InProgress\"\n  },\n  \"objectId\": \"~327925760\",\n  \"objectType\": \"Case\",\n  \"object\": {\n    \"_id\": \"~327925760\",\n    \"_type\": \"Case\",\n    \"_createdBy\": \"mia@movies.io\",\n    \"_updatedBy\": \"director@movies.io\",\n    \"_createdAt\": 1693412835689,\n    \"_updatedAt\": 1694441999230,\n    \"number\": 34,\n    \"title\": \"Behind themselves watch price take. I probably single service. Develop fear hotel real.\",\n    \"description\": \"***Description***\",\n    \"severity\": 3,\n    \"severityLabel\": \"HIGH\",\n    \"startDate\": 1693151602000,\n    \"tags\": [\n      \"tagA\"\n    ],\n    \"flag\": false,\n    \"tlp\": 2,\n    \"tlpLabel\": \"AMBER\",\n    \"pap\": 1,\n    \"papLabel\": \"GREEN\",\n    \"status\": \"InProgress\",\n    \"stage\": \"InProgress\",\n    \"assignee\": \"mia@movies.io\",\n    \"customFields\": [],\n    \"userPermissions\": [],\n    \"extraData\": {},\n    \"newDate\": 1693412835673,\n    \"inProgressDate\": 1694441998841,\n    \"timeToDetect\": 261233673,\n    \"timeToTriage\": 1029163168,\n    \"timeToAcknowledge\": 1290396841,\n    \"customFieldValues\": {}\n  },\n  \"context\": {\n    \"_id\": \"~327925760\",\n    \"_type\": \"Case\",\n    \"_createdBy\": \"mia@movies.io\",\n    \"_updatedBy\": \"director@movies.io\",\n    \"_createdAt\": 1693412835689,\n    \"_updatedAt\": 1694441999230,\n    \"number\": 34,\n    \"title\": \"Behind themselves watch price take. I probably single service. Develop fear hotel real.\",\n    \"description\": \"***Description***\",\n    \"severity\": 3,\n    \"severityLabel\": \"HIGH\",\n    \"startDate\": 1693151602000,\n    \"tags\": [\n      \"tagA\"\n    ],\n    \"flag\": false,\n    \"tlp\": 2,\n    \"tlpLabel\": \"AMBER\",\n    \"pap\": 1,\n    \"papLabel\": \"GREEN\",\n    \"status\": \"InProgress\",\n    \"stage\": \"InProgress\",\n    \"assignee\": \"mia@movies.io\",\n    \"customFields\": [],\n    \"userPermissions\": [],\n    \"extraData\": {},\n    \"newDate\": 1693412835673,\n    \"inProgressDate\": 1694441998841,\n    \"timeToDetect\": 261233673,\n    \"timeToTriage\": 1029163168,\n    \"timeToAcknowledge\": 1290396841,\n    \"customFieldValues\": {}\n  },\n  \"organisation\": {\n    \"organisationId\": \"~4169864\",\n    \"organisation\": \"Pulp Fiction\"\n  }\n}\n</code></pre> <p>Audit fields:</p> <ul> <li><code>_id</code>: id of the audit</li> <li><code>_type</code>: always <code>Audit</code></li> <li><code>_createdBy</code>: Author of the action</li> <li><code>action</code>: nature of the action. Can be <code>create</code>, <code>update</code>, <code>delete</code>, <code>merge</code> or <code>invoke</code> (for functions)</li> <li><code>requestId</code>: Id of the http request</li> <li><code>details</code>: a json object that contains the changes made on the object </li> <li><code>objectId</code>: <code>_id</code> of the object that was impacted by the action</li> <li><code>objectType</code>: <code>_type</code> of the object</li> <li><code>object</code>: full description of the object (after the modification)</li> <li><code>rootId</code>: <code>_id</code> of the top most object. For instance if a task is updated, this will be the <code>_id</code> of the case</li> <li><code>context</code>: context of the audit. This depends on what object is updated / created.</li> <li><code>organisation</code>: details about the organization where this action happened</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#writing-a-filter", "title": "Writing a filter", "text": "<p>Filters must be JSON formatted and can use following operators:</p> <ul> <li><code>_and</code></li> <li><code>_or</code></li> <li><code>_not</code></li> <li><code>_any</code></li> <li><code>_lt</code></li> <li><code>_gt</code></li> <li><code>_lte</code></li> <li><code>_gte</code></li> <li><code>_eq</code></li> <li><code>_is</code></li> <li><code>_startsWith</code></li> <li><code>_endsWith</code></li> <li><code>_between</code></li> <li><code>_in</code></li> <li><code>_contains</code></li> <li><code>_like</code></li> <li><code>_has</code></li> <li><code>_empty</code></li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#field-selection", "title": "Field selection", "text": "<p>When targeting a field, you can use a <code>.</code> notation to walk inside the json object.</p> <p>For instance <code>object.severity</code> will get the field severity in the json: </p> <pre><code>{\n  \"object\": {\n    \"severity\": 3\n  }\n}\n</code></pre>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_and", "title": "<code>_and</code>", "text": "<pre><code>{\"_and\": [\n  { ... filterA },\n  { ... filterB }\n]}\n</code></pre> <p>Returns true when all filters (filterA and filterB) return true</p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_or", "title": "<code>_or</code>", "text": "<pre><code>{\"_or\": [\n  { ... filterA },\n  { ... filterB }\n]}\n</code></pre> <p>Returns true when one filters (filterA or filterB) return true</p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_not", "title": "<code>_not</code>", "text": "<pre><code>{\"_not\": {... filterA} }\n</code></pre> <p>Inverse the result of filterA</p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_any", "title": "<code>_any</code>", "text": "<pre><code>{  \"_any\": \"\" }\n</code></pre> <p>Returns always true, useful for testing</p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_lt-_gt-_lte-_gte", "title": "<code>_lt</code>, <code>_gt</code>, <code>_lte</code>, <code>_gte</code>", "text": "<pre><code>{ \"_lt\": { \"foo\" : 42 } }\n</code></pre> <p>Returns true when field <code>foo</code> is strictly lower than <code>42</code></p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_eq-_is", "title": "<code>_eq</code>, <code>_is</code>", "text": "<p><code>_eq</code> is an alias for <code>_is</code></p> <pre><code>{ \"_eq\": { \"foo\": 42 } }\n</code></pre> <p>Returns true when field <code>foo</code> is equal to <code>42</code>.</p> <pre><code>{ \"_eq\": { \"foo\": \"LOW\" } }\n</code></pre> <p>Returns true when field <code>foo</code> is equal to <code>\"LOW\"</code>.</p> <p>Also works with arrays:</p> <pre><code>{ \"_eq\": { \"tags\": [\"foo\", \"bar\"] } }\n</code></pre> <p>Returns true when field <code>tags</code> will be equal to <code>[\"foo\", \"bar\"]</code></p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_startswith-_endswith", "title": "<code>_startsWith</code>, <code>_endsWith</code>", "text": "<pre><code>{ \"_startsWith\": { \"foo\": \"LOW\" } }\n</code></pre> <p>Check that field <code>foo</code> starts with string <code>\"LOW\"</code></p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_like", "title": "<code>_like</code>", "text": "<pre><code>{ \"_like\": { \"foo\": \"*ice\" } }\n</code></pre> <p>Returns true when field <code>foo</code> ends with <code>\"lce\"</code></p> <pre><code>{ \"_like\": { \"foo\": \"ali*\" } }\n</code></pre> <p>Returns true when field <code>foo</code> starts with <code>\"ali\"</code></p> <pre><code>{ \"_like\": { \"foo\": \"*lce*\" } }\n</code></pre> <p>Returns true when field <code>foo</code> contains with <code>\"lce\"</code></p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_between", "title": "<code>_between</code>", "text": "<pre><code>{ \"_between\": { \"_field\": \"foo\", \"_from\": 0, \"_to\": 2 } }\n</code></pre> <p>Check that field <code>foo</code> is between <code>0</code> and <code>2</code> (<code>_from &lt;= value &lt; _to</code>). Only works when <code>foo</code> is a number</p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_in", "title": "<code>_in</code>", "text": "<pre><code>{ \"_in\": { \"_field\": \"foo\", \"_values\": [\"foo\", \"bar\"] } }\n</code></pre> <p>Checks that field <code>foo</code> is either <code>foo</code> or <code>bar</code>.</p> <p>This also works with numbers:</p> <pre><code>{ \"_in\": { \"_field\": \"foo\", \"_values\": [1, 42] } }\n</code></pre> <p><code>_in</code> can also be used when the field is an array:</p> <pre><code>{ \"_in\": { \"_field\": \"tags\", \"_values\": [\"foo\", \"bar\"] } }\n</code></pre> <pre><code>{\"tags\": [\"foo\"] } ==&gt; true\n{\"tags\": [\"bar\", \"baz\"] } ==&gt; true\n{\"tags\": [\"alice\", \"bob\"] } ==&gt; false\n</code></pre>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_contains", "title": "<code>_contains</code>", "text": "<pre><code>{ \"_contains\": { \"foo\": \"LOW\" } }\n</code></pre> <p>Check that field <code>foo</code> contains the value <code>\"LOW\"</code>. This works with string and arrays of string.</p> <pre><code>{\"foo\": \"LOWER\" } ==&gt; true\n{\"foo\": [\"bar\", \"LOW\"] } ==&gt; true\n{\"foo\": [\"bar\", \"LOWER\"] } ==&gt; false\n</code></pre>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_has", "title": "<code>_has</code>", "text": "<pre><code>{ \"_has\": \"foo\" }\n</code></pre> <p>Returns true when json object has a field named <code>foo</code></p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#_empty", "title": "<code>_empty</code>", "text": "<pre><code>{ \"_empty\": \"foo\" }\n</code></pre> <p>Returns true when field <code>foo</code> is either <code>[]</code> or <code>\"\"</code> or <code>null</code>.</p> <p>It will return false if the field is not defined. For this use case, use <code>{\"_not\": {\"_has\": \"foo\" } }</code></p>"}, {"location": "thehive/user-guides/organization/notifications/filteredevents/#examples", "title": "Examples", "text": "<ul> <li>An alert is closed but no assignee was defined</li> </ul> <pre><code>{\n    \"_and\": [\n        {\n            \"_is\": {\n                \"objectType\": \"Alert\"\n            }\n        },\n        {\n            \"_is\": {\n                \"details.stage\": \"Closed\"\n            }\n        },\n        {\n            \"_not\": {\n                \"_has\": \"object.assignee\"\n            }\n        },\n        {\n            \"_not\": {\n                \"_has\": \"details.assignee\"\n            }\n        }\n    ]\n}\n</code></pre> <ul> <li>An observable was updated with a report from the analyzer <code>Crt_sh_Transparency_Logs_1_0</code></li> </ul> <pre><code>{\n    \"_and\": [\n        {\n            \"_is\": {\n                \"action\": \"update\"\n            }\n        },\n        {\n            \"_is\": {\n                \"objectType\": \"Observable\"\n            }\n        },\n        {\n            \"_has\": \"details.reports.Crt_sh_Transparency_Logs_1_0\"\n        }\n    ]\n}\n</code></pre> <ul> <li>Responder has finished</li> </ul> <pre><code>{\n    \"_and\": [\n        {\n            \"_is\": {\n                \"action\": \"update\"\n            }\n        },\n        {\n            \"_is\": {\n                \"objectType\": \"Action\"\n            }\n        },\n        {\n            \"_or\": [\n                {\n                    \"_is\": {\n                        \"details.status\": \"Success\"\n                    }\n                },\n                {\n                    \"_is\": {\n                        \"details.status\": \"Failure\"\n                    }\n                }\n            ]\n        }\n    ]\n}\n</code></pre> <ul> <li>Case is updated with a status <code>TruePositive</code> or <code>FalsePositive</code> and the custom field <code>business-unit</code> is either <code>Sales</code> or <code>Marketing</code></li> </ul> <pre><code>{\n    \"_and\": [\n        {\n            \"_is\": {\n                \"action\": \"update\"\n            }\n        },\n        {\n            \"_is\": {\n                \"objectType\": \"Case\"\n            }\n        },\n        {\n            \"_or\": [\n                {\n                    \"_is\": {\n                        \"details.status\": \"TruePositive\"\n                    }\n                },\n                {\n                    \"_is\": {\n                        \"details.status\": \"FalsePositive\"\n                    }\n                }\n            ]\n        },\n        {\n            \"_or\": [\n                {\n                    \"_is\": {\n                        \"object.customFieldValues.business-unit\": \"Sales\"\n                    }\n                },\n                {\n                    \"_is\": {\n                        \"object.customFieldValues.business-unit\": \"Marketing\"\n                    }\n                }\n            ]\n        }\n    ]\n}\n</code></pre> <ul> <li>The analyzer <code>EmlParser_2_1</code> finishes with a Success <pre><code>{\n    \"_and\": [\n        {\n            \"_is\": {\n                \"objectType\": \"Job\"\n            }\n        },\n        {\n            \"_is\": {\n                \"object.analyzerName\": \"EmlParser_2_1\"\n            }\n        },\n        {\n            \"_is\": {\n                \"object.status\": \"Success\"\n            }\n        }\n    ]\n}\n</code></pre></li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/http-request/", "title": "Send notifications to a HTTP Request endpoint", "text": ""}, {"location": "thehive/user-guides/organization/notifications/introduction/", "title": "Introduction to Notifications & Endpoints", "text": ""}, {"location": "thehive/user-guides/organization/notifications/introduction/#notifications", "title": "Notifications", "text": ""}, {"location": "thehive/user-guides/organization/notifications/introduction/#definition", "title": "Definition", "text": "<p>A notification is a described by:</p> <ol> <li>A Trigger</li> <li>One or more Notifiers</li> </ol> <p></p>"}, {"location": "thehive/user-guides/organization/notifications/introduction/#triggers", "title": "Triggers", "text": "<p>Each notification is associated to only one trigger. TheHive comes with several predefined triggers on Cases, Alerts, Tasks, Observables and Jobs. Custom triggers can also be defined with FilteredEvent.</p> <p>Another trigger let you run notifications on any event when selecting AnyEvents.</p>"}, {"location": "thehive/user-guides/organization/notifications/introduction/#triggers-on-cases", "title": "Triggers on Cases", "text": "<ul> <li>CaseClosed: Run an action when closing a Case</li> <li>CaseCreated: Run an action when a Case is created</li> <li>CaseShared: Run an action when a Case is shared</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/introduction/#triggers-on-alerts", "title": "Triggers on Alerts", "text": "<ul> <li>AlertCreated: Run an action when an Alert is created</li> <li>AlertImported: Run an action when an Alert in imported (a Case is created from an Alert or an Alert is attached to an existing Case)</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/introduction/#triggers-on-jobs", "title": "Triggers on Jobs", "text": "<ul> <li>JobFinished: Run an action when a Job is terminated, with success or failure</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/introduction/#triggers-on-observables", "title": "Triggers on Observables", "text": "<ul> <li>ObservableCreated: Run an action when an Observable is created</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/introduction/#triggers-on-tasks", "title": "Triggers on Tasks", "text": "<ul> <li>LoginMyTask: Run an action when a Task gain a new Log</li> <li>TaskAssigned: Run an action when a Task is assigned, or the assignee is updated</li> <li>TaskClosed: Run an action when a Task is closed</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/introduction/#filtered-event", "title": "Filtered Event", "text": "<p>When selecting FilteredEvent, TheHive lets you write a structured JSON filter. This filter aims to match particular events in the application that will trigger one or more actions described by notifiers.</p> <p> </p> Filtered event example: \"Case severity has been updated to Hight or Critical <p>Learn how to write filtered events and find more example in the dedicated page.</p>"}, {"location": "thehive/user-guides/organization/notifications/introduction/#notifiers", "title": "Notifiers", "text": "<p>Several types of Notifiers are available in TheHive:</p> <ul> <li>EmailToUser: send an email to all users in the current organization</li> <li>EmailToAddr: send an email to a specific email address</li> <li>HTTP Request: send data to a chosen HTTP endpoint</li> <li>Mattermost: send data to a chosen Mattermost endoint</li> <li>Slack: send data to a chosen Slack endpoint</li> <li>MS Teams: send data to a chosen Microsoft Teams endpoint</li> <li>Webhook: send data to a chosen webhook endpoint</li> <li>Kafka: send data to a chosen Kafka queue</li> <li>Redis: send data to a chosen Redis endpoint</li> </ul> <p>Two of them are dedicated to run Cortex Analyzers and Responders:</p> <ul> <li>RunAnalyzer: run selected Analyzers</li> <li>RunResponder: run selected Responders</li> </ul> <p>Some Notifiers require configuring Endpoints</p> <p>Some Notifiers require at least one endpoint to be defined. Refer to the page dedicated to each Notifier to learn how to create related endpoints.</p>"}, {"location": "thehive/user-guides/organization/notifications/introduction/#create-a-notification", "title": "Create a Notification", "text": "<p>Access to the Notifications list by opening the Organization menu, and the Notifications tab.</p> <p></p> <p>Click the  button to add a notification.</p> <p></p> <ol> <li>Give a unique name to the notification</li> <li>Select a trigger</li> <li>Select a notifier and configure it</li> </ol> <p>Then click confirm to register the notification.</p>"}, {"location": "thehive/user-guides/organization/notifications/introduction/#operations-on-notifications", "title": "Operations on Notifications", "text": ""}, {"location": "thehive/user-guides/organization/notifications/introduction/#delete-a-notification", "title": "Delete a Notification", "text": "<p>In the list of notification, click on the delete option:</p> <p></p>"}, {"location": "thehive/user-guides/organization/notifications/introduction/#disable-a-notificaiton", "title": "Disable a Notificaiton", "text": "<ul> <li>In the list of Notifications, edit the one to disable: </li> </ul> <ul> <li>Verify the result in the list of Notifications</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/kafka/", "title": "Kafka Configuration", "text": ""}, {"location": "thehive/user-guides/organization/notifications/kafka/#send-notifications-to-kafka", "title": "Send notifications to Kafka", "text": "<p>Info</p> <ul> <li>No endpoint definition is required to send data to a topic in Kafka</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/kafka/#configuration", "title": "Configuration", "text": "<ul> <li>When creating a Notification select Kafka as Notifier and complete the form with: </li> <li>The Topic used in Kafka</li> <li>The IP address/homstname and port to connect</li> </ul> <ul> <li>Then, add other notifiers by clicking on the  button, or click confirm to create the Notification</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/mattermost/", "title": "Mattermost Configuration", "text": ""}, {"location": "thehive/user-guides/organization/notifications/mattermost/#send-notifications-to-a-mattermost-channel", "title": "Send notifications to a Mattermost channel", "text": "<p>Using Mattermost as Notifier requires to create at least one endpoint. This endpoint defines how TheHive will connect to Mattermost.</p>"}, {"location": "thehive/user-guides/organization/notifications/mattermost/#create-an-enpoint", "title": "Create an enpoint", "text": "<p>In the Organization configuration view, open the Endpoints tab. Then, click on the  button to create a new Notifier. </p> <p></p>"}, {"location": "thehive/user-guides/organization/notifications/mattermost/#enpoint-configuration", "title": "Enpoint configuration", "text": "<p>Choose Mattermost and complete required information.</p> <p></p> <ul> <li>Name: give a unique name to the endpoint</li> <li>URL: specify the URL to connect to your Mattermost instance</li> <li>Username: default username used to send data</li> <li>Channel: default channel used to send data</li> <li>Auth Type: Use Basic authentication to connect to this endpoint, or use Key or Bearer method</li> <li>Proxy settings: choose to use a web proxy to connect to this endpoint</li> <li>Certificate authorities: add custom Certificate Authorities if required (PEM format)</li> <li>SSL settings: disable Certificate Authority checking and/or checks on hostnames</li> </ul> <p>Then, click confirm to create the endpoint.</p>"}, {"location": "thehive/user-guides/organization/notifications/mattermost/#notification-configuration", "title": "Notification configuration", "text": "<p>When creating a Notification select Mattermost as Notifier and complete the form.</p> <p></p> <p>TheHive uses Handlebars to let you build templates with input data, and this can be used in most of all fields of the form:</p> <ul> <li>Endpoint: choose the endpoint to use</li> <li>Username: choose a username. Click on add variable if you want to use an information from the input data. This will override the default username configured in the endpoint</li> <li>Channel: choose the target channel on Mattermost to send data to. Click on add variable if you want to use an information from the input data. This will override the default channel configured in the endpoint</li> <li>Template:<ul> <li>Available format are: JSON, Markdown and Plain text </li> <li>Click Add variable to select a variable to insert in the template</li> </ul> </li> </ul> <p>Then click confirm to register this Notifier.</p>"}, {"location": "thehive/user-guides/organization/notifications/redis/", "title": "Redis Configuration", "text": ""}, {"location": "thehive/user-guides/organization/notifications/redis/#send-notifications-to-kafka", "title": "Send notifications to Kafka", "text": "<p>Info</p> <ul> <li>No endpoint definition is required to send data to a database in Redis</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/redis/#configuration", "title": "Configuration", "text": "<p>Start by clicking on the  button to create an new notification.</p> <p></p> <p>Then select Redis as Notifier and complete the form with: </p> <p></p> <ul> <li>The Channel name used in Redis</li> <li>The IP address/homstname and port to connect</li> <li>A Username</li> <li>A password</li> <li>A database name</li> <li>SSL settings and custom Certificate Authorities can also be configured</li> </ul> <p>Then click confirm to create the Notification.</p>"}, {"location": "thehive/user-guides/organization/notifications/responders/", "title": "Run Responders on events", "text": ""}, {"location": "thehive/user-guides/organization/notifications/slack/", "title": "Slack Configuration", "text": ""}, {"location": "thehive/user-guides/organization/notifications/slack/#send-notifications-to-slack-channels", "title": "Send notifications to Slack channels", "text": "<p>Using Slack as Notifier requires to create at least one endpoint. This endpoint defines how TheHive will connect to Slack.</p>"}, {"location": "thehive/user-guides/organization/notifications/slack/#create-an-enpoint", "title": "Create an enpoint", "text": "<p>In the Organsation configuration view, open the Endpoints tab. Then, click on the  button to create a new Notifier. </p> <p></p>"}, {"location": "thehive/user-guides/organization/notifications/slack/#enpoint-configuration", "title": "Enpoint configuration", "text": "<p>Choose Slack and complete required information.</p> <p></p> <ul> <li>Name: give a unique name to the endpoint</li> <li>Token: specify the token to use to connect to the service</li> <li>Auth Type: Use Basic authentication to connect to this endpoint, or use Key or Bearer method</li> <li>Proxy settings: choose to use a web proxy to connect to this endpoint</li> <li>Certificate authorities: add custom Certificate Authorities if required (PEM format)</li> <li>SSL settings: disable Certificate Authority checking and/or checks on hostnames</li> </ul> <p>Then, click confirm to create the endpoint.</p>"}, {"location": "thehive/user-guides/organization/notifications/slack/#notification-configuration", "title": "Notification configuration", "text": "<p>When creating a Notification select Slack as Notifier and complete the form.</p> <p></p> <p>TheHive uses Handlebars to let you build templates with input data, and this can be used in most form fields:</p> <ul> <li>Endpoint: choose the endpoint to use</li> <li>Username: choose a username. Click on add variable if you want to use an information from the input data. This will override the default username configured in the endpoint</li> <li>Channel: choose the target channel on Slack to send data to. Click on add variable if you want to use an information from the input data. This will override the default channel configured in the endpoint</li> <li>Template: * Available format are: JSON, Markdown and Plain text <ul> <li>Click Add variable to select a variable to insert in the template</li> </ul> </li> </ul> <p>Then click confirm to register this Notifier.</p>"}, {"location": "thehive/user-guides/organization/notifications/slack/#advanced-settings", "title": "Advanced settings", "text": "<p>Several configuration options come with the integration with Slack. </p> <p>Slack documentation to the rescue</p> <ul> <li>Test your integration here</li> <li>Build your blocks with the Slack Block kit builder</li> </ul> <p></p>"}, {"location": "thehive/user-guides/organization/notifications/slack/#examples", "title": "Examples", "text": "<p>Example of a blocks template: send notification about case creation</p> <ul> <li>Trigger: CaseCreated</li> <li>Notifier: Slack</li> </ul> <pre><code>[\n  {\n    \"type\": \"section\",\n    \"text\": {\n      \"type\": \"mrkdwn\",\n      \"text\": \"*New Case created: Case #{{object.number}}*\"\n    }\n  },\n  {\n    \"type\": \"divider\"\n  },\n  {\n    \"type\": \"section\",\n    \"text\": {\n      \"type\": \"mrkdwn\",\n      \"text\": \"&lt;{{url}}|{{object.title}}&gt; \\n :bee: \\n {{object.description}}\"\n    }\n  },\n  {\n    \"type\": \"section\",\n    \"fields\": [\n      {\n        \"type\": \"mrkdwn\",\n        \"text\": \"*Created by*\\n{{object._createdBy}}\\n*Assigned to*\\n{{object.assignee}}\"\n      }\n    ]\n  }\n]\n</code></pre>"}, {"location": "thehive/user-guides/organization/notifications/teams/", "title": "MS Teams Configuration", "text": ""}, {"location": "thehive/user-guides/organization/notifications/teams/#send-notifications-to-a-ms-teams-channel", "title": "Send notifications to a MS Teams channel", "text": ""}, {"location": "thehive/user-guides/organization/notifications/teams/#overview", "title": "Overview", "text": "<p>With the 5.4.3 release, TheHive has updated the Microsoft Teams notifier due to Microsoft's deprecation of the incoming webhook workflow in Teams. This change requires users to migrate from the legacy Teams webhook setup to a new configuration using Power Automate workflows.</p>"}, {"location": "thehive/user-guides/organization/notifications/teams/#teams-notifier-setup-using-power-automate", "title": "Teams Notifier Setup Using Power Automate", "text": "<p>To accommodate Microsoft's changes and ensure continued functionality of Teams notifications, follow these steps to set up the new Teams notifier using Power Automate.</p> <p> </p>"}, {"location": "thehive/user-guides/organization/notifications/teams/#step-1-create-a-new-power-automate-flow", "title": "Step 1: Create a New Power Automate Flow", "text": "<ol> <li> <p>Navigate to Power Automate:</p> <ul> <li>Go to Power Automate and sign in with your Microsoft account.</li> </ul> <p></p> </li> <li> <p>Create a Flow:</p> <ul> <li>Click on Create and select Instant cloud flow.</li> </ul> </li> <li> <p>Select Template:</p> <ul> <li>Choose the template \"Post to a channel when a HTTP request is received\".</li> </ul> <p></p> </li> <li> <p>Configure Flow Details:</p> <ul> <li>Name your flow and select the Microsoft Teams channel where notifications should be sent.</li> <li>Confirm the necessary permissions for Power Automate to post messages on your behalf.</li> </ul> <p></p> </li> <li> <p>Save the Flow:</p> <ul> <li>Click Save to complete the flow setup.</li> <li>After saving, the flow will generate a unique HTTP POST URL. Copy this URL for use in TheHive configuration.</li> </ul> </li> </ol> <p> </p>"}, {"location": "thehive/user-guides/organization/notifications/teams/#step-2-create-a-new-endpoint", "title": "Step 2: Create a New Endpoint", "text": "<p>In the Organization configuration view, go to the Endpoints tab. Click the  button to add a new Connector.</p> <p></p> <p> </p>"}, {"location": "thehive/user-guides/organization/notifications/teams/#step-3-enter-the-required-information", "title": "Step 3: Enter the Required Information", "text": "<p>Select Teams as the connector type and complete the necessary details.</p> <p></p> <ul> <li>Name: Provide a unique name for the endpoint.</li> <li>URL: Enter the URL for connecting to Microsoft Teams. This URL should be the one copied from Power Automate when setting up the new workflow.</li> <li>Auth Type: Select an authentication method \u2014 Basic Authentication, Key, or Bearer.</li> <li>Proxy settings: Optionally, enable a web proxy to connect to this endpoint.</li> <li>Certificate Authorities: If required, add custom Certificate Authorities in PEM format.</li> <li>SSL settings: Optionally, disable Certificate Authority validation or hostname checks.</li> </ul> <p>Once all fields are completed, click Confirm to create the endpoint.</p>"}, {"location": "thehive/user-guides/organization/notifications/teams/#migration-instructions-for-current-users", "title": "Migration Instructions for Current Users", "text": "<p>If you are currently using the legacy Teams webhook, follow these steps to migrate:</p> <ol> <li>Complete the Create a New Power Automate Flow steps above to obtain the new HTTP POST URL.</li> <li>Go to TheHive &gt; Organization Admin &gt; Endpoint &gt; Connector Teams.</li> <li>In the Teams webhook URL field, replace the existing webhook URL with the new HTTP POST URL from your Power Automate flow.</li> <li>Click Save to apply the update.</li> </ol>"}, {"location": "thehive/user-guides/organization/notifications/teams/#notification-configuration", "title": "Notification Configuration", "text": "<p>When creating a Notification select Teams/ENDPOINT (with ENDPOINT the name of the endpoint created) as Connector and complete the form.</p> <p></p> <p>TheHive uses Handlebars to let you build templates with input data, and this can be used in most of all fields of the form:</p> <ul> <li>Endpoint: choose the endpoint to use</li> <li>Text template: If an adaptive card template is not provided, a plain text template is required. In version 5.4.3, plain text will automatically convert into an adaptive card format.</li> <li>Adaptive card template:<ul> <li>Available format are: JSON, Markdown and Plain text </li> <li>Click Add variable to select a variable to insert in the template</li> </ul> </li> </ul> <p>Example: template used to display notification when a new Case is created</p> <pre><code>{\n\"type\": \"AdaptiveCard\",\n\"body\": [\n    {\n    \"type\": \"TextBlock\",\n    \"size\": \"Medium\",\n    \"weight\": \"Bolder\",\n    \"text\": \"#{{object.number}}: {{object.title}}\",\n    \"horizontalAlignment\": \"Left\",\n    \"spacing\": \"None\",\n    \"wrap\": true\n    },\n    {\n    \"type\": \"ColumnSet\",\n    \"columns\": [\n        {\n        \"type\": \"Column\",\n        \"items\": [\n            {\n            \"type\": \"TextBlock\",\n            \"weight\": \"Bolder\",\n            \"text\": \"{{object._createdBy}}\",\n            \"fontType\": \"Default\",\n            \"color\": \"Accent\",\n            \"spacing\": \"None\"\n            },\n            {\n            \"type\": \"TextBlock\",\n            \"spacing\": \"None\",\n            \"text\": \"Created {{dateFormat object._createdAt 'EEEE d MMMM, k:m Z' locale='en' tz='Europe/Paris'}}\",\n            \"isSubtle\": true,\n            \"wrap\": true,\n            \"fontType\": \"Default\",\n            \"weight\": \"Default\",\n            \"size\": \"Default\"\n            }\n        ]\n        }\n    ]\n    },\n    {\n    \"type\": \"FactSet\",\n    \"facts\": [\n        {\n        \"title\": \"severity\",\n        \"weight\": \"Bolder\",\n        \"value\": \"{{ severityLabel object.severity}}\"\n        },\n        {\n        \"title\": \"TLP\",\n        \"weight\": \"Bolder\",\n        \"value\": \"{{ tlpLabel object.tlp}}\"\n        }\n    ]\n    },\n    {\n    \"type\": \"TextBlock\",\n    \"weight\": \"Bolder\",\n    \"text\": \"Description\",\n    \"spacing\": \"Large\",\n    \"wrap\": true,\n    \"horizontalAlignment\": \"Left\"\n    },\n    {\n    \"type\": \"TextBlock\",\n    \"text\": \"{{object.description}}\",\n    \"spacing\": \"None\",\n    \"wrap\": true,\n    \"horizontalAlignment\": \"Left\",\n    \"maxLines\": 3\n    }\n],\n\"actions\": [\n    {\n    \"type\": \"Action.OpenUrl\",\n    \"title\": \"Open Case in TheHive\",\n    \"iconUrl\": \"https://docs.strangebee.com/images/thehive.png\",\n    \"url\": \"{{url}}\",\n    \"style\": \"positive\"\n    }\n],\n\"$schema\": \"http://adaptivecards.io/schemas/adaptive-card.json\",\n\"version\": \"1.5\"\n}\n</code></pre> <p>Used with the trigger Case created, this template will create a card like this in Microsoft Teams:</p> <p></p> <p>Tips</p>"}, {"location": "thehive/user-guides/organization/notifications/teams/#write-ms-teams-active-cards", "title": "Write MS Teams active Cards", "text": "<p>Use https://adaptivecards.io/designer/ as a starting point to design your adaptive card</p>"}, {"location": "thehive/user-guides/organization/notifications/teams/#format-dates", "title": "Format dates", "text": "<ul> <li>TheHive uses handlerbars string helpers to read dates</li> <li>Formatting date and time in notifications requires using dedicated Java patterns</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/teams/#format-other-custom-data-from-thehive", "title": "Format other custom data from TheHive", "text": "<p>Few data custom to TheHive can be properly displayed using custom string handlers together with <code>object</code> data in notifications: </p> <ul> <li><code>tlpLabel</code> to display the TLP value (example: <code>{{tlpLabel object.tlp}}</code>)</li> <li><code>papLabel</code> to display the PAP value (example: <code>{{papLabel object.pap}}</code>)</li> <li><code>severityLabel</code> to display the severity value (example: <code>{{severityLabel object.severity}}</code>)</li> </ul>"}, {"location": "thehive/user-guides/organization/notifications/teams/#older-thehive-versions", "title": "Older TheHive Versions", "text": "<p>For TheHive versions prior to 5.4.3, users can still send notifications to Microsoft Teams through incoming webhooks. This simpler method involves creating a Teams webhook and using its URL within TheHive's settings.</p> <p>Although straightforward, this legacy method lacks the customization and enhanced security features available with the newer Power Automate setup. Additionally, with Microsoft\u2019s deprecation of incoming webhooks, continued use may lead to limited functionality in the future.</p>"}, {"location": "thehive/user-guides/organization/notifications/teams/#legacy-setup-steps", "title": "Legacy Setup Steps:", "text": "<ol> <li> <p>Set Up Microsoft Teams:</p> <ul> <li>Follow the video tutorial to create an incoming webhook and copy the provided URL</li> </ul> <p> </p> </li> <li> <p>Configure TheHive:</p> <ul> <li> <p>Navigate to TheHive &gt; Organization Admin &gt; Endpoint &gt; Connector Teams.</p> </li> <li> <p>Paste the webhook URL and complete the configuration as needed.</p> </li> </ul> </li> </ol> <p> </p> <p>Note: As communicated by Microsoft on their official blog, connector owners must update their webhook URLs by January 31, 2025 to comply with the new structure. This update is essential to ensure seamless integration and continued functionality of connectors within Microsoft Teams.</p> <p> </p>"}, {"location": "thehive/user-guides/organization/notifications/webhook/", "title": "Use a Webhook notifier", "text": ""}]}